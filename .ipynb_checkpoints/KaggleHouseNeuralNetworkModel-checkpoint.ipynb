{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('~/Datas/KaggleHouse/X_train.csv').to_numpy()\n",
    "y = pd.read_csv('~/Datas/KaggleHouse/Y_train.csv').to_numpy()\n",
    "X_final = pd.read_csv('~/Datas/KaggleHouse/X_test.csv').to_numpy()\n",
    "Id = pd.read_csv('~/Datas/KaggleHouse/Id.csv',header=None,names=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 405)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 695,297\n",
      "Trainable params: 695,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam = Sequential()\n",
    "NN_5000E_Adam.add(Dense(512,input_dim = 405,activation = 'relu'))\n",
    "NN_5000E_Adam.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam.add(Dense(1))\n",
    "NN_5000E_Adam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_5000E_Adam.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_5_input to have shape (330,) but got array with shape (405,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1f72b03acde0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_5000E_Adam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_5_input to have shape (330,) but got array with shape (405,)"
     ]
    }
   ],
   "source": [
    "history = NN_5000E_Adam.fit(x=X,y=y,batch_size=2100,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_5000E_Adam.save('NN_5000E_Adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 695,297\n",
      "Trainable params: 695,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_SGD = Sequential()\n",
    "NN_5000E_SGD.add(Dense(512,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_SGD.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_SGD.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_SGD.add(Dense(1))\n",
    "NN_5000E_SGD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/5000\n",
      "1167/1167 [==============================] - 0s 355us/step - loss: 805095049.3779 - val_loss: 2339640503.4521\n",
      "Epoch 2/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 724585595.3385 - val_loss: 2272729555.7260\n",
      "Epoch 3/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 740486269.4225 - val_loss: 2612074837.9178\n",
      "Epoch 4/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 758621413.5664 - val_loss: 2388494852.1644\n",
      "Epoch 5/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 831229603.5921 - val_loss: 2397848736.8767\n",
      "Epoch 6/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 884570571.1602 - val_loss: 2363444789.9178\n",
      "Epoch 7/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 727425355.8458 - val_loss: 2276199469.9178\n",
      "Epoch 8/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 702267601.4944 - val_loss: 2610940195.0685\n",
      "Epoch 9/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 737825843.0026 - val_loss: 2525609672.7671\n",
      "Epoch 10/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 740689167.7121 - val_loss: 2286440889.5342\n",
      "Epoch 11/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 756570699.5716 - val_loss: 2791012310.3562\n",
      "Epoch 12/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 741880790.1285 - val_loss: 2289956880.7671\n",
      "Epoch 13/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 714556646.4439 - val_loss: 2262307488.2192\n",
      "Epoch 14/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 738643169.2888 - val_loss: 2589223659.8356\n",
      "Epoch 15/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 775154594.8655 - val_loss: 2231786225.9726\n",
      "Epoch 16/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 733976765.2031 - val_loss: 2285787038.2466\n",
      "Epoch 17/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 715174803.4687 - val_loss: 2376747083.8356\n",
      "Epoch 18/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 686208784.6170 - val_loss: 2219500423.4521\n",
      "Epoch 19/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 678705332.4833 - val_loss: 2753699498.0822\n",
      "Epoch 20/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 795676846.6153 - val_loss: 2404134976.8767\n",
      "Epoch 21/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 919873180.0788 - val_loss: 2263406343.4521\n",
      "Epoch 22/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 775437445.4567 - val_loss: 2219513242.9589\n",
      "Epoch 23/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 767142857.5424 - val_loss: 2739020240.6575\n",
      "Epoch 24/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 697446193.7412 - val_loss: 2445173776.8767\n",
      "Epoch 25/5000\n",
      "1167/1167 [==============================] - 0s 290us/step - loss: 767389434.4610 - val_loss: 2214958153.3151\n",
      "Epoch 26/5000\n",
      "1167/1167 [==============================] - 0s 292us/step - loss: 797283557.9503 - val_loss: 2397050279.8904\n",
      "Epoch 27/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 750187248.8089 - val_loss: 2502000239.6712\n",
      "Epoch 28/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 710247325.6692 - val_loss: 2305332944.3288\n",
      "Epoch 29/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 665003717.5938 - val_loss: 2260380555.3973\n",
      "Epoch 30/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 785269653.2511 - val_loss: 2489831857.5342\n",
      "Epoch 31/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 672085183.1500 - val_loss: 2206332922.5205\n",
      "Epoch 32/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 674689243.0094 - val_loss: 2156482662.7945\n",
      "Epoch 33/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 671071823.9314 - val_loss: 2221301513.9726\n",
      "Epoch 34/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 670392440.1028 - val_loss: 2272772480.8767\n",
      "Epoch 35/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 699314543.3830 - val_loss: 2372719788.7123\n",
      "Epoch 36/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 747163936.7952 - val_loss: 2135169175.6712\n",
      "Epoch 37/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 702035673.9126 - val_loss: 2282437782.7945\n",
      "Epoch 38/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 633136849.4944 - val_loss: 2140490217.6438\n",
      "Epoch 39/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 702352788.9494 - val_loss: 2138820368.0000\n",
      "Epoch 40/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 700033451.5716 - val_loss: 2220515242.5205\n",
      "Epoch 41/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 770426300.7506 - val_loss: 2322042906.3014\n",
      "Epoch 42/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 631752476.3530 - val_loss: 2138167047.4521\n",
      "Epoch 43/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 655710311.9246 - val_loss: 2303109738.9589\n",
      "Epoch 44/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 655503391.8629 - val_loss: 2393987913.2055\n",
      "Epoch 45/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 632637463.1431 - val_loss: 2317796452.3836\n",
      "Epoch 46/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 750495769.6110 - val_loss: 2142195883.6164\n",
      "Epoch 47/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 695977655.7189 - val_loss: 2425519854.4658\n",
      "Epoch 48/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 641064504.8158 - val_loss: 2235643356.0548\n",
      "Epoch 49/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 688832105.5150 - val_loss: 2364635536.4384\n",
      "Epoch 50/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 686799820.3393 - val_loss: 2202507913.4247\n",
      "Epoch 51/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 629603712.2468 - val_loss: 2377697859.9452\n",
      "Epoch 52/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 691427067.6127 - val_loss: 2202392234.5205\n",
      "Epoch 53/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 723127053.0797 - val_loss: 2165827782.1370\n",
      "Epoch 54/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 648336363.9280 - val_loss: 2148615212.2740\n",
      "Epoch 55/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 616405744.9734 - val_loss: 2356897528.9863\n",
      "Epoch 56/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 630539436.8466 - val_loss: 2189158305.7534\n",
      "Epoch 57/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 591556581.0728 - val_loss: 2152415086.6849\n",
      "Epoch 58/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 585439289.0351 - val_loss: 2111540255.5616\n",
      "Epoch 59/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 590068949.4979 - val_loss: 2103804851.2877\n",
      "Epoch 60/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 611496850.1525 - val_loss: 2101170104.1096\n",
      "Epoch 61/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 626178255.1637 - val_loss: 2181002567.4521\n",
      "Epoch 62/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 609659219.0574 - val_loss: 2186885910.7945\n",
      "Epoch 63/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 597823114.0360 - val_loss: 2126591656.7671\n",
      "Epoch 64/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 601055067.9966 - val_loss: 2190292050.6301\n",
      "Epoch 65/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 588904549.3196 - val_loss: 2092438998.1370\n",
      "Epoch 66/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 653977841.5219 - val_loss: 2335233333.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 685151644.9563 - val_loss: 3010042652.0548\n",
      "Epoch 68/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 810988096.7952 - val_loss: 2059094104.6575\n",
      "Epoch 69/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 684682271.6984 - val_loss: 2406194359.2329\n",
      "Epoch 70/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 560700672.6444 - val_loss: 2090803389.4795\n",
      "Epoch 71/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 565359619.1260 - val_loss: 2307618550.7945\n",
      "Epoch 72/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 546144967.3488 - val_loss: 2208144491.3973\n",
      "Epoch 73/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 610526111.2322 - val_loss: 2128362329.6438\n",
      "Epoch 74/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 554150995.5784 - val_loss: 2167923961.2055\n",
      "Epoch 75/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 542763274.0360 - val_loss: 2185611700.1644\n",
      "Epoch 76/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 565873501.2031 - val_loss: 2086080967.4521\n",
      "Epoch 77/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 545168622.8346 - val_loss: 2356164327.4521\n",
      "Epoch 78/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 712503253.2099 - val_loss: 2068876632.9863\n",
      "Epoch 79/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 664086011.9692 - val_loss: 2043532253.3699\n",
      "Epoch 80/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 611516216.6307 - val_loss: 2437011995.3973\n",
      "Epoch 81/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 645236681.8440 - val_loss: 2062099037.4795\n",
      "Epoch 82/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 547991617.5081 - val_loss: 2101830890.5205\n",
      "Epoch 83/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 536315257.4464 - val_loss: 2122871940.6027\n",
      "Epoch 84/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 545601831.1568 - val_loss: 2105691538.8493\n",
      "Epoch 85/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 514790639.1637 - val_loss: 2099714576.2192\n",
      "Epoch 86/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 635495821.6007 - val_loss: 2122597583.5616\n",
      "Epoch 87/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 617078381.4087 - val_loss: 2181125618.4110\n",
      "Epoch 88/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 510323637.4156 - val_loss: 2129924662.7945\n",
      "Epoch 89/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 524124709.9914 - val_loss: 2081356353.3151\n",
      "Epoch 90/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 522959957.5527 - val_loss: 2044878782.2466\n",
      "Epoch 91/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 754634012.9563 - val_loss: 2666761650.8493\n",
      "Epoch 92/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 560557915.7772 - val_loss: 2073539240.5479\n",
      "Epoch 93/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 623396406.5124 - val_loss: 2018900353.0959\n",
      "Epoch 94/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 599272986.1457 - val_loss: 2064128337.9726\n",
      "Epoch 95/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 563292986.9820 - val_loss: 2028231555.5068\n",
      "Epoch 96/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 578109050.9272 - val_loss: 2119535377.9726\n",
      "Epoch 97/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 535862920.2262 - val_loss: 2158447642.3014\n",
      "Epoch 98/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 591104835.0163 - val_loss: 2044137888.8767\n",
      "Epoch 99/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 494552706.4679 - val_loss: 2058329532.9315\n",
      "Epoch 100/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 523550584.8295 - val_loss: 2027871703.2329\n",
      "Epoch 101/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 549080121.6932 - val_loss: 1988603280.1096\n",
      "Epoch 102/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 573350910.8483 - val_loss: 2015205958.7945\n",
      "Epoch 103/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 563482370.2485 - val_loss: 2156475790.0274\n",
      "Epoch 104/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 530131840.1234 - val_loss: 1934197551.3425\n",
      "Epoch 105/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 516915551.1500 - val_loss: 1957638723.7260\n",
      "Epoch 106/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 545922156.2022 - val_loss: 2092834119.8904\n",
      "Epoch 107/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 515683070.7935 - val_loss: 1959753305.9726\n",
      "Epoch 108/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 558732854.9100 - val_loss: 1941773130.5205\n",
      "Epoch 109/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 588375562.9683 - val_loss: 2054970194.4110\n",
      "Epoch 110/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 509985634.9066 - val_loss: 1917190606.9041\n",
      "Epoch 111/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 516752137.2408 - val_loss: 2190682236.2740\n",
      "Epoch 112/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 511323574.4576 - val_loss: 2061035347.7260\n",
      "Epoch 113/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 472208821.5801 - val_loss: 2031230902.7945\n",
      "Epoch 114/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 504357018.3787 - val_loss: 2090607231.1233\n",
      "Epoch 115/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 488065054.5193 - val_loss: 2012236893.5890\n",
      "Epoch 116/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 505517998.7798 - val_loss: 2063709948.7123\n",
      "Epoch 117/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 712787142.8552 - val_loss: 1970355126.7945\n",
      "Epoch 118/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 574296904.8843 - val_loss: 1917522568.4384\n",
      "Epoch 119/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 485141589.9366 - val_loss: 1975253460.6027\n",
      "Epoch 120/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 442985761.6727 - val_loss: 2057987267.9452\n",
      "Epoch 121/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 559109097.7344 - val_loss: 2135163440.8767\n",
      "Epoch 122/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 474500795.9829 - val_loss: 2022917973.2603\n",
      "Epoch 123/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 490584331.1602 - val_loss: 2136833773.1507\n",
      "Epoch 124/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 498083012.7164 - val_loss: 1918077803.3973\n",
      "Epoch 125/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 530340420.7164 - val_loss: 1962752136.3288\n",
      "Epoch 126/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 473901603.5099 - val_loss: 1958370680.1096\n",
      "Epoch 127/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 458893720.8706 - val_loss: 1875193720.9863\n",
      "Epoch 128/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 444444863.0814 - val_loss: 1995178497.9726\n",
      "Epoch 129/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 464138237.9709 - val_loss: 1898952584.1096\n",
      "Epoch 130/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 496883457.0694 - val_loss: 1902391988.6027\n",
      "Epoch 131/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 526438768.7678 - val_loss: 2003081346.6301\n",
      "Epoch 132/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 493795611.6127 - val_loss: 1993738433.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 457494940.5450 - val_loss: 1895378910.6849\n",
      "Epoch 134/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 444115552.0000 - val_loss: 1939233121.0959\n",
      "Epoch 135/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 427279373.0523 - val_loss: 1909373308.2740\n",
      "Epoch 136/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 480645408.9597 - val_loss: 1820870713.8630\n",
      "Epoch 137/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 564971854.1491 - val_loss: 2016165119.1233\n",
      "Epoch 138/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 437953525.5390 - val_loss: 1926402052.8219\n",
      "Epoch 139/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 433437443.8663 - val_loss: 1835087422.4658\n",
      "Epoch 140/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 422649260.8329 - val_loss: 1898081959.8904\n",
      "Epoch 141/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 459106214.0051 - val_loss: 1871182505.2055\n",
      "Epoch 142/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 428020010.0223 - val_loss: 1820152450.8493\n",
      "Epoch 143/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 442389306.1868 - val_loss: 1946276066.1918\n",
      "Epoch 144/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 514476121.5835 - val_loss: 1831339175.8904\n",
      "Epoch 145/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 566176570.2691 - val_loss: 2099817053.3699\n",
      "Epoch 146/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 428443763.3590 - val_loss: 1898991065.4247\n",
      "Epoch 147/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 394278713.6932 - val_loss: 2133160696.5479\n",
      "Epoch 148/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 466937565.7721 - val_loss: 2360240249.8630\n",
      "Epoch 149/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 454811029.0591 - val_loss: 1795613617.3151\n",
      "Epoch 150/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 437066144.2194 - val_loss: 1832556208.6575\n",
      "Epoch 151/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 421039358.0943 - val_loss: 1881988172.9315\n",
      "Epoch 152/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 395153546.5296 - val_loss: 1821320530.6301\n",
      "Epoch 153/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 400938762.9135 - val_loss: 1878441752.5479\n",
      "Epoch 154/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 410192868.2365 - val_loss: 1828274883.5068\n",
      "Epoch 155/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 405704094.7935 - val_loss: 1847873434.3014\n",
      "Epoch 156/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 416050755.6195 - val_loss: 1807203207.0137\n",
      "Epoch 157/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 383867194.5981 - val_loss: 1810879677.8082\n",
      "Epoch 158/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 387677189.5664 - val_loss: 2031874962.4110\n",
      "Epoch 159/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 417736566.7592 - val_loss: 1887165655.6712\n",
      "Epoch 160/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 381790714.5707 - val_loss: 1774082719.1233\n",
      "Epoch 161/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 390055400.1302 - val_loss: 2104009208.9863\n",
      "Epoch 162/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 482502577.0831 - val_loss: 2066324165.6986\n",
      "Epoch 163/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 417411813.5664 - val_loss: 1810784995.7260\n",
      "Epoch 164/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 444475949.5733 - val_loss: 1779689036.9315\n",
      "Epoch 165/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 450483432.8569 - val_loss: 1980218314.5205\n",
      "Epoch 166/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 418246298.3376 - val_loss: 1812056008.3288\n",
      "Epoch 167/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 377795414.8415 - val_loss: 1734669610.7397\n",
      "Epoch 168/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 441750304.1919 - val_loss: 1900157477.9178\n",
      "Epoch 169/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 430133790.2177 - val_loss: 1947848429.5890\n",
      "Epoch 170/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 401872971.9006 - val_loss: 1780455397.6986\n",
      "Epoch 171/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 376483257.1997 - val_loss: 2058854349.1507\n",
      "Epoch 172/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 455126612.7301 - val_loss: 2167161110.7945\n",
      "Epoch 173/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 498040431.8218 - val_loss: 2016741261.1507\n",
      "Epoch 174/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 418840484.4147 - val_loss: 1726456205.1507\n",
      "Epoch 175/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 371266945.3985 - val_loss: 1687660586.7397\n",
      "Epoch 176/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 373809795.3179 - val_loss: 1705962606.0274\n",
      "Epoch 177/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 387899544.2125 - val_loss: 1688167725.1507\n",
      "Epoch 178/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 355327889.6864 - val_loss: 1747333097.2055\n",
      "Epoch 179/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 365696403.0163 - val_loss: 1713187329.3151\n",
      "Epoch 180/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 339046730.3102 - val_loss: 1704059581.3699\n",
      "Epoch 181/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 340388004.5107 - val_loss: 1765950334.2466\n",
      "Epoch 182/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 351417843.0574 - val_loss: 1844332816.6575\n",
      "Epoch 183/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 470915787.5990 - val_loss: 1742278864.8767\n",
      "Epoch 184/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 417926678.2039 - val_loss: 1683770583.2329\n",
      "Epoch 185/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 362365116.3256 - val_loss: 1771260426.9589\n",
      "Epoch 186/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 353809125.9777 - val_loss: 1707841216.0000\n",
      "Epoch 187/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 385868550.3342 - val_loss: 1775183512.1096\n",
      "Epoch 188/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 365572663.2939 - val_loss: 1726456956.9315\n",
      "Epoch 189/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 378761031.7189 - val_loss: 1714234049.7534\n",
      "Epoch 190/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 374632971.9554 - val_loss: 1740048017.5342\n",
      "Epoch 191/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 340941669.0180 - val_loss: 1694435245.1507\n",
      "Epoch 192/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 342488048.1782 - val_loss: 1649097898.9589\n",
      "Epoch 193/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 320510024.2262 - val_loss: 1647031464.7671\n",
      "Epoch 194/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 317444277.6761 - val_loss: 1729816219.6164\n",
      "Epoch 195/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 367349555.3865 - val_loss: 1832022461.3699\n",
      "Epoch 196/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 366764376.4456 - val_loss: 1670430884.3836\n",
      "Epoch 197/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 446420857.6932 - val_loss: 1917589545.2055\n",
      "Epoch 198/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 424171061.1414 - val_loss: 1608548858.0822\n",
      "Epoch 199/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 412485262.9306 - val_loss: 2218010045.3699\n",
      "Epoch 200/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 370607132.1748 - val_loss: 1634893216.8767\n",
      "Epoch 201/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 347381788.1611 - val_loss: 1678050477.1507\n",
      "Epoch 202/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 313723978.1183 - val_loss: 1726204101.2603\n",
      "Epoch 203/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 328026724.4147 - val_loss: 1717605129.6438\n",
      "Epoch 204/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 325798730.6941 - val_loss: 1870083801.4247\n",
      "Epoch 205/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 364723475.9897 - val_loss: 1776314453.9178\n",
      "Epoch 206/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 314382834.8929 - val_loss: 1755548008.7671\n",
      "Epoch 207/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 300232357.5116 - val_loss: 1582424963.9452\n",
      "Epoch 208/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 289071572.7301 - val_loss: 1567653010.4110\n",
      "Epoch 209/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 293319607.2528 - val_loss: 1560515681.7534\n",
      "Epoch 210/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 275627665.1105 - val_loss: 1676620567.2329\n",
      "Epoch 211/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 355461927.8698 - val_loss: 1610396915.7260\n",
      "Epoch 212/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 337370692.5518 - val_loss: 1555484203.8356\n",
      "Epoch 213/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 337162698.4199 - val_loss: 1544449455.3425\n",
      "Epoch 214/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 348067287.8012 - val_loss: 1630381124.3836\n",
      "Epoch 215/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 307402363.8046 - val_loss: 1665431161.4247\n",
      "Epoch 216/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 308826940.7644 - val_loss: 1612875576.9863\n",
      "Epoch 217/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 288626141.2305 - val_loss: 1506686802.8493\n",
      "Epoch 218/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 295428180.4490 - val_loss: 1633565624.9863\n",
      "Epoch 219/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 321793901.3265 - val_loss: 1639657540.3836\n",
      "Epoch 220/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 293887047.5544 - val_loss: 1535258364.0548\n",
      "Epoch 221/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 329793669.7309 - val_loss: 1542776242.8493\n",
      "Epoch 222/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 334691624.5553 - val_loss: 1537890902.7945\n",
      "Epoch 223/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 348090405.4567 - val_loss: 1642767971.9452\n",
      "Epoch 224/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 346294406.0600 - val_loss: 1574499000.9863\n",
      "Epoch 225/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 301550947.4276 - val_loss: 1611975455.1233\n",
      "Epoch 226/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 292773552.0411 - val_loss: 1523298835.2877\n",
      "Epoch 227/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 301708305.3093 - val_loss: 1564931136.8767\n",
      "Epoch 228/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 313375222.2108 - val_loss: 1515745297.9726\n",
      "Epoch 229/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 280224925.2579 - val_loss: 1490597456.2192\n",
      "Epoch 230/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 257115535.3282 - val_loss: 1481138748.4932\n",
      "Epoch 231/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 268896744.6101 - val_loss: 1583007683.9452\n",
      "Epoch 232/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 277664741.1825 - val_loss: 1769502304.4384\n",
      "Epoch 233/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 426800631.4996 - val_loss: 1509222488.9863\n",
      "Epoch 234/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 308857577.3231 - val_loss: 1480443530.9589\n",
      "Epoch 235/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 379736822.1834 - val_loss: 1535243744.4384\n",
      "Epoch 236/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 282963001.7481 - val_loss: 1452130140.0548\n",
      "Epoch 237/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 250585079.7738 - val_loss: 1491404509.8082\n",
      "Epoch 238/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 266133208.8432 - val_loss: 1480112260.8219\n",
      "Epoch 239/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 260608716.8740 - val_loss: 1431753786.7397\n",
      "Epoch 240/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 264935954.8929 - val_loss: 1459800548.8219\n",
      "Epoch 241/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 293037670.1148 - val_loss: 1513886083.0685\n",
      "Epoch 242/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 322219924.4901 - val_loss: 1567357923.9452\n",
      "Epoch 243/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 237879328.8089 - val_loss: 1466208284.9315\n",
      "Epoch 244/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 287733289.6110 - val_loss: 1460878521.8630\n",
      "Epoch 245/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 243030414.2039 - val_loss: 1578262813.8082\n",
      "Epoch 246/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 265939931.8595 - val_loss: 1621752863.5616\n",
      "Epoch 247/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 243286982.6015 - val_loss: 1509071028.1644\n",
      "Epoch 248/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 251725983.7155 - val_loss: 1465513752.5479\n",
      "Epoch 249/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 267806538.3787 - val_loss: 1743076513.3151\n",
      "Epoch 250/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 308424017.3710 - val_loss: 1425414690.6301\n",
      "Epoch 251/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 245454514.7695 - val_loss: 1480339171.0685\n",
      "Epoch 252/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 297158666.6118 - val_loss: 1405804729.8630\n",
      "Epoch 253/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 262043216.3428 - val_loss: 1458622871.6712\n",
      "Epoch 254/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 222336237.9160 - val_loss: 1458223011.9452\n",
      "Epoch 255/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 237181311.9177 - val_loss: 1430183366.1370\n",
      "Epoch 256/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 307356754.6187 - val_loss: 1841780055.6712\n",
      "Epoch 257/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 292395508.8123 - val_loss: 1478475518.2466\n",
      "Epoch 258/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 239617777.4122 - val_loss: 1392652853.4795\n",
      "Epoch 259/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 254287049.4602 - val_loss: 1437415820.2740\n",
      "Epoch 260/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 242885856.4250 - val_loss: 1415693190.1370\n",
      "Epoch 261/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 262279349.6624 - val_loss: 1415177164.7123\n",
      "Epoch 262/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 232151961.2545 - val_loss: 1358678272.8767\n",
      "Epoch 263/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 243us/step - loss: 210237496.9529 - val_loss: 1375682395.1781\n",
      "Epoch 264/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 268021667.9760 - val_loss: 1468746039.2329\n",
      "Epoch 265/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 262632612.5244 - val_loss: 1395673627.1781\n",
      "Epoch 266/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 222857894.9306 - val_loss: 1365218552.1096\n",
      "Epoch 267/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 210435337.1037 - val_loss: 1425222940.4932\n",
      "Epoch 268/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 224666161.8098 - val_loss: 1405636051.2877\n",
      "Epoch 269/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 213499513.2408 - val_loss: 1352211776.0000\n",
      "Epoch 270/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 220351722.1731 - val_loss: 1384517206.7945\n",
      "Epoch 271/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 298104428.7506 - val_loss: 1363825609.6438\n",
      "Epoch 272/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 203932562.7695 - val_loss: 1448810283.8356\n",
      "Epoch 273/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 223698122.4199 - val_loss: 1364712825.8630\n",
      "Epoch 274/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 275710814.5467 - val_loss: 1426409653.4795\n",
      "Epoch 275/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 232888588.9426 - val_loss: 1331825942.3562\n",
      "Epoch 276/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 221137327.3659 - val_loss: 1404017244.0548\n",
      "Epoch 277/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 239904864.2879 - val_loss: 1397730137.4247\n",
      "Epoch 278/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 238393623.4173 - val_loss: 1348143445.0411\n",
      "Epoch 279/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 209696773.9297 - val_loss: 1388223808.8767\n",
      "Epoch 280/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 202034513.4259 - val_loss: 1350546550.3562\n",
      "Epoch 281/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 198524210.8449 - val_loss: 1336070893.1507\n",
      "Epoch 282/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 223209733.3882 - val_loss: 1388535268.8219\n",
      "Epoch 283/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 220454049.0146 - val_loss: 1360424853.0411\n",
      "Epoch 284/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 202972054.0189 - val_loss: 1382555094.7945\n",
      "Epoch 285/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 195234589.0386 - val_loss: 1364988374.3562\n",
      "Epoch 286/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 190732844.1611 - val_loss: 1362664771.5068\n",
      "Epoch 287/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 221340702.5604 - val_loss: 1399061206.7945\n",
      "Epoch 288/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 212295195.9966 - val_loss: 1381379121.9726\n",
      "Epoch 289/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 213493648.0823 - val_loss: 1322039994.7397\n",
      "Epoch 290/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 195072746.2348 - val_loss: 1428035036.9315\n",
      "Epoch 291/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 231291084.8603 - val_loss: 1315911938.6301\n",
      "Epoch 292/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 217462307.5784 - val_loss: 1409451731.2877\n",
      "Epoch 293/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 211428534.8415 - val_loss: 1430014665.6438\n",
      "Epoch 294/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 317465772.0103 - val_loss: 1388056729.4247\n",
      "Epoch 295/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 266689923.0848 - val_loss: 1387507462.1370\n",
      "Epoch 296/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 243690541.1620 - val_loss: 1314106480.2192\n",
      "Epoch 297/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 190265768.4593 - val_loss: 1378311323.1781\n",
      "Epoch 298/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 175890960.6170 - val_loss: 1309763284.1644\n",
      "Epoch 299/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 218062040.5690 - val_loss: 1364355438.4658\n",
      "Epoch 300/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 207796450.1662 - val_loss: 1300260243.7260\n",
      "Epoch 301/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 241453394.5227 - val_loss: 1357906290.8493\n",
      "Epoch 302/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 237677356.8603 - val_loss: 1366197085.8082\n",
      "Epoch 303/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 216353531.6264 - val_loss: 1332075959.2329\n",
      "Epoch 304/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 203973620.5176 - val_loss: 1327563716.3836\n",
      "Epoch 305/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 198575698.9614 - val_loss: 1372705138.8493\n",
      "Epoch 306/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 191498254.9717 - val_loss: 1358496475.1781\n",
      "Epoch 307/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 205583007.3145 - val_loss: 1288183385.8630\n",
      "Epoch 308/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 183808169.1037 - val_loss: 1321898833.9726\n",
      "Epoch 309/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 175804082.0017 - val_loss: 1284507209.2055\n",
      "Epoch 310/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 189194067.0643 - val_loss: 1307792665.4247\n",
      "Epoch 311/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 181942123.7909 - val_loss: 1478676437.9178\n",
      "Epoch 312/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 227617477.1825 - val_loss: 1466182250.0822\n",
      "Epoch 313/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 191560866.4130 - val_loss: 1314321500.9315\n",
      "Epoch 314/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 186316766.3273 - val_loss: 1309872789.0411\n",
      "Epoch 315/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 192269238.7455 - val_loss: 1369444730.7397\n",
      "Epoch 316/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 225275441.1654 - val_loss: 1433281937.5342\n",
      "Epoch 317/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 222216908.9769 - val_loss: 1313723424.4384\n",
      "Epoch 318/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 167213896.7198 - val_loss: 1314794140.0548\n",
      "Epoch 319/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 178296092.0994 - val_loss: 1308823188.1644\n",
      "Epoch 320/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 192275847.1500 - val_loss: 1275445852.0548\n",
      "Epoch 321/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 177649375.8629 - val_loss: 1358448640.4384\n",
      "Epoch 322/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 205952100.4696 - val_loss: 1326500375.2329\n",
      "Epoch 323/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 180359917.4910 - val_loss: 1410756980.6027\n",
      "Epoch 324/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 241663720.9666 - val_loss: 1277411584.8767\n",
      "Epoch 325/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 174036395.5167 - val_loss: 1329859098.3014\n",
      "Epoch 326/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 164153900.5518 - val_loss: 1284338316.2740\n",
      "Epoch 327/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 168507281.7275 - val_loss: 1302969041.0959\n",
      "Epoch 328/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 170744129.7001 - val_loss: 1328390524.4932\n",
      "Epoch 329/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 211350778.5844 - val_loss: 1247447289.8630\n",
      "Epoch 330/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 179236236.3873 - val_loss: 1269025400.1096\n",
      "Epoch 331/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 170020886.4439 - val_loss: 1341953494.3562\n",
      "Epoch 332/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 157043698.1251 - val_loss: 1293908929.7534\n",
      "Epoch 333/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 190949200.8638 - val_loss: 1291217838.0274\n",
      "Epoch 334/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 211630265.3093 - val_loss: 1301934919.8904\n",
      "Epoch 335/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 303260451.1534 - val_loss: 1510395893.4795\n",
      "Epoch 336/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 197726111.9383 - val_loss: 1347892378.3014\n",
      "Epoch 337/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 167254996.3736 - val_loss: 1300449078.3562\n",
      "Epoch 338/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 183412495.7395 - val_loss: 1322297946.3014\n",
      "Epoch 339/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 145256903.1842 - val_loss: 1324656413.8082\n",
      "Epoch 340/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 218787787.6058 - val_loss: 1282327501.1507\n",
      "Epoch 341/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 191013908.8055 - val_loss: 1334140641.3151\n",
      "Epoch 342/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 188271281.4670 - val_loss: 1304607096.1096\n",
      "Epoch 343/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 171314647.5681 - val_loss: 1298594908.0548\n",
      "Epoch 344/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 152502009.9537 - val_loss: 1290627864.5479\n",
      "Epoch 345/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 143667072.8500 - val_loss: 1295035361.3151\n",
      "Epoch 346/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 153773937.7549 - val_loss: 1341261393.5342\n",
      "Epoch 347/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 177834803.3590 - val_loss: 1281377706.9589\n",
      "Epoch 348/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 176094438.7318 - val_loss: 1373802242.6301\n",
      "Epoch 349/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 169394989.3813 - val_loss: 1232448455.8904\n",
      "Epoch 350/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 200451064.2057 - val_loss: 1268390090.9589\n",
      "Epoch 351/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 167510307.1945 - val_loss: 1254737507.9452\n",
      "Epoch 352/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 162769698.2759 - val_loss: 1260073359.7808\n",
      "Epoch 353/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 148858745.8817 - val_loss: 1263887050.5205\n",
      "Epoch 354/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 153641775.6298 - val_loss: 1308685260.2740\n",
      "Epoch 355/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 172961104.9186 - val_loss: 1357114270.2466\n",
      "Epoch 356/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 242075912.9803 - val_loss: 1452041375.5616\n",
      "Epoch 357/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 241960336.7849 - val_loss: 1346004593.9726\n",
      "Epoch 358/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 185901451.3865 - val_loss: 1258007972.8219\n",
      "Epoch 359/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 152169662.0120 - val_loss: 1254991617.7534\n",
      "Epoch 360/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 160828701.9983 - val_loss: 1249860163.5068\n",
      "Epoch 361/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 177699371.5167 - val_loss: 1346318661.2603\n",
      "Epoch 362/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 201987714.2348 - val_loss: 1361435588.8219\n",
      "Epoch 363/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 247916401.2065 - val_loss: 1298038740.1644\n",
      "Epoch 364/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 189795338.2965 - val_loss: 1340475593.6438\n",
      "Epoch 365/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 166866279.2665 - val_loss: 1264061952.0000\n",
      "Epoch 366/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 152805239.7875 - val_loss: 1206278323.7260\n",
      "Epoch 367/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 166101688.9803 - val_loss: 1316363377.0959\n",
      "Epoch 368/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 280566492.5450 - val_loss: 1376867333.6986\n",
      "Epoch 369/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 227955832.1851 - val_loss: 1218075151.7808\n",
      "Epoch 370/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 153066612.1131 - val_loss: 1293556759.6712\n",
      "Epoch 371/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 163008900.5244 - val_loss: 1281697622.7945\n",
      "Epoch 372/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 172012351.4653 - val_loss: 1265321578.0822\n",
      "Epoch 373/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 167948037.2511 - val_loss: 1237409447.4521\n",
      "Epoch 374/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 137109495.3488 - val_loss: 1226239088.2192\n",
      "Epoch 375/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 151635671.2939 - val_loss: 1193634292.6027\n",
      "Epoch 376/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 148166644.2296 - val_loss: 1277070428.0548\n",
      "Epoch 377/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 140213859.0300 - val_loss: 1239582195.2877\n",
      "Epoch 378/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 133737004.9700 - val_loss: 1210550819.0685\n",
      "Epoch 379/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 160656704.8432 - val_loss: 1201523363.5068\n",
      "Epoch 380/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 238805391.5201 - val_loss: 1412274581.9178\n",
      "Epoch 381/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 202557064.6101 - val_loss: 1264414789.2603\n",
      "Epoch 382/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 165013774.3959 - val_loss: 1233930837.9178\n",
      "Epoch 383/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 142365409.0694 - val_loss: 1294364030.6849\n",
      "Epoch 384/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 142687586.2279 - val_loss: 1235111731.7260\n",
      "Epoch 385/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 137111963.5441 - val_loss: 1210944947.2877\n",
      "Epoch 386/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 127766507.5921 - val_loss: 1218819076.3836\n",
      "Epoch 387/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 132419032.7404 - val_loss: 1209707742.6849\n",
      "Epoch 388/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 128625697.4533 - val_loss: 1208199751.0137\n",
      "Epoch 389/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 133914636.2571 - val_loss: 1232195221.0411\n",
      "Epoch 390/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 153004994.4953 - val_loss: 1272111793.9726\n",
      "Epoch 391/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 168326030.6564 - val_loss: 1268923502.4658\n",
      "Epoch 392/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 260443884.6272 - val_loss: 1349484189.8082\n",
      "Epoch 393/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 245us/step - loss: 159746156.2022 - val_loss: 1199368726.7945\n",
      "Epoch 394/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 160514785.1517 - val_loss: 1310309994.0822\n",
      "Epoch 395/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 151398239.7326 - val_loss: 1208324684.2740\n",
      "Epoch 396/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 127189903.9177 - val_loss: 1250697915.6164\n",
      "Epoch 397/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 131887596.3256 - val_loss: 1220699522.6301\n",
      "Epoch 398/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 141370146.7489 - val_loss: 1226063496.7671\n",
      "Epoch 399/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 132347402.8175 - val_loss: 1218535616.8767\n",
      "Epoch 400/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 120672368.1440 - val_loss: 1199075959.2329\n",
      "Epoch 401/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 124741914.7147 - val_loss: 1191930499.5068\n",
      "Epoch 402/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 147710791.5921 - val_loss: 1240173195.3973\n",
      "Epoch 403/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 180229785.4053 - val_loss: 1243289753.4247\n",
      "Epoch 404/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 161408661.0591 - val_loss: 1214289233.5342\n",
      "Epoch 405/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 126857110.9580 - val_loss: 1289684313.4247\n",
      "Epoch 406/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 175154015.2459 - val_loss: 1274935601.5342\n",
      "Epoch 407/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 148238164.1200 - val_loss: 1218746567.8904\n",
      "Epoch 408/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 176265671.3076 - val_loss: 1298146821.2603\n",
      "Epoch 409/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 182326944.1508 - val_loss: 1324296640.0000\n",
      "Epoch 410/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 141619117.7652 - val_loss: 1208659975.0137\n",
      "Epoch 411/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 153937374.6221 - val_loss: 1223142734.0274\n",
      "Epoch 412/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 140810581.9983 - val_loss: 1173771125.4795\n",
      "Epoch 413/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 126733606.7763 - val_loss: 1246063032.1096\n",
      "Epoch 414/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 123061386.6941 - val_loss: 1218018321.5342\n",
      "Epoch 415/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 125991322.4542 - val_loss: 1216938558.2466\n",
      "Epoch 416/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 125208920.2262 - val_loss: 1207521776.2192\n",
      "Epoch 417/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 139545246.7661 - val_loss: 1237576277.0411\n",
      "Epoch 418/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 124153341.8406 - val_loss: 1223341320.7671\n",
      "Epoch 419/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 112885659.1671 - val_loss: 1223753718.3562\n",
      "Epoch 420/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 155260534.2382 - val_loss: 1192281538.6301\n",
      "Epoch 421/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 171529959.3350 - val_loss: 1328682983.4521\n",
      "Epoch 422/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 126839011.0026 - val_loss: 1157024381.3699\n",
      "Epoch 423/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 121620383.6572 - val_loss: 1208973704.7671\n",
      "Epoch 424/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 122927706.5981 - val_loss: 1202410744.9863\n",
      "Epoch 425/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 110447296.8638 - val_loss: 1194178412.7123\n",
      "Epoch 426/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 122324326.7318 - val_loss: 1213162797.5890\n",
      "Epoch 427/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 163995808.0548 - val_loss: 1215094264.9863\n",
      "Epoch 428/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 133436630.8552 - val_loss: 1254926396.9315\n",
      "Epoch 429/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 136670008.2468 - val_loss: 1243178133.0411\n",
      "Epoch 430/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 153878197.3608 - val_loss: 1475219013.2603\n",
      "Epoch 431/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 223678981.9983 - val_loss: 1246869942.7945\n",
      "Epoch 432/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 135144827.3453 - val_loss: 1218181567.1233\n",
      "Epoch 433/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 118964227.3179 - val_loss: 1277130381.1507\n",
      "Epoch 434/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 138501262.8792 - val_loss: 1238053895.0137\n",
      "Epoch 435/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 136862568.9152 - val_loss: 1233034860.7123\n",
      "Epoch 436/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 114211206.5741 - val_loss: 1221815280.2192\n",
      "Epoch 437/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 117076534.1114 - val_loss: 1214605197.1507\n",
      "Epoch 438/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 141715619.7635 - val_loss: 1223602733.5890\n",
      "Epoch 439/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 119421760.0960 - val_loss: 1189487175.8904\n",
      "Epoch 440/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 134765798.6221 - val_loss: 1190819541.0411\n",
      "Epoch 441/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 121325848.8775 - val_loss: 1208382648.1096\n",
      "Epoch 442/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 110508214.9032 - val_loss: 1219026395.1781\n",
      "Epoch 443/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 155097189.0934 - val_loss: 1260354052.3836\n",
      "Epoch 444/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 138926577.9023 - val_loss: 1272378736.2192\n",
      "Epoch 445/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 110273661.3128 - val_loss: 1186328137.6438\n",
      "Epoch 446/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 122801413.1825 - val_loss: 1267016346.3014\n",
      "Epoch 447/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 129346629.6504 - val_loss: 1177576377.8630\n",
      "Epoch 448/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 111648258.4199 - val_loss: 1272537294.9041\n",
      "Epoch 449/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 103874684.7918 - val_loss: 1224813629.3699\n",
      "Epoch 450/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 122646663.1911 - val_loss: 1251253239.2329\n",
      "Epoch 451/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 128225189.2237 - val_loss: 1245537894.5753\n",
      "Epoch 452/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 122370242.8860 - val_loss: 1167856708.3836\n",
      "Epoch 453/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 124966701.4362 - val_loss: 1219357376.8767\n",
      "Epoch 454/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 142731296.3873 - val_loss: 1259730936.9863\n",
      "Epoch 455/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 116129906.2005 - val_loss: 1301354385.5342\n",
      "Epoch 456/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 158552618.6427 - val_loss: 1228472277.9178\n",
      "Epoch 457/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 121863738.5124 - val_loss: 1246577223.0137\n",
      "Epoch 458/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 112497114.3513 - val_loss: 1221199305.6438\n",
      "Epoch 459/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 113185918.7044 - val_loss: 1220335891.2877\n",
      "Epoch 460/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 107699747.8903 - val_loss: 1193684840.3288\n",
      "Epoch 461/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 101900704.0103 - val_loss: 1204133665.3151\n",
      "Epoch 462/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 121014846.5810 - val_loss: 1256273109.9178\n",
      "Epoch 463/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 126442174.0600 - val_loss: 1287537727.1233\n",
      "Epoch 464/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 125926144.4045 - val_loss: 1264066709.9178\n",
      "Epoch 465/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 133120532.4147 - val_loss: 1162625728.0000\n",
      "Epoch 466/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 113224729.8303 - val_loss: 1200322881.7534\n",
      "Epoch 467/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 150456636.9563 - val_loss: 1225871575.6712\n",
      "Epoch 468/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 183088773.5253 - val_loss: 1319293893.6986\n",
      "Epoch 469/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 242547290.5364 - val_loss: 1274655655.4521\n",
      "Epoch 470/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 188793000.4336 - val_loss: 1286868291.5068\n",
      "Epoch 471/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 179488724.1680 - val_loss: 1259324334.4658\n",
      "Epoch 472/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 127466159.1054 - val_loss: 1206031954.4110\n",
      "Epoch 473/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 119278293.2442 - val_loss: 1203444760.5479\n",
      "Epoch 474/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 164891453.8715 - val_loss: 1230735850.9589\n",
      "Epoch 475/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 175068952.3565 - val_loss: 1286870003.7260\n",
      "Epoch 476/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 162121276.2913 - val_loss: 1277321550.9041\n",
      "Epoch 477/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 122972666.0086 - val_loss: 1220312083.2877\n",
      "Epoch 478/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 115280465.3573 - val_loss: 1224772919.2329\n",
      "Epoch 479/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 115249656.2948 - val_loss: 1240736840.7671\n",
      "Epoch 480/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 114149494.0874 - val_loss: 1268101084.9315\n",
      "Epoch 481/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 112075138.0497 - val_loss: 1264936572.4932\n",
      "Epoch 482/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 116671321.6452 - val_loss: 1268563533.1507\n",
      "Epoch 483/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 126194126.8209 - val_loss: 1220403818.9589\n",
      "Epoch 484/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 114284857.2134 - val_loss: 1222981974.7945\n",
      "Epoch 485/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 111915335.5818 - val_loss: 1152371226.3014\n",
      "Epoch 486/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 119874716.3051 - val_loss: 1245689228.2740\n",
      "Epoch 487/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 104840770.8380 - val_loss: 1193221952.0000\n",
      "Epoch 488/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 98191930.4884 - val_loss: 1187520295.4521\n",
      "Epoch 489/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 94198816.6033 - val_loss: 1185449989.2603\n",
      "Epoch 490/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 100929100.0994 - val_loss: 1237420906.0822\n",
      "Epoch 491/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 97749628.5895 - val_loss: 1242733032.3288\n",
      "Epoch 492/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 96473084.8055 - val_loss: 1212722319.7808\n",
      "Epoch 493/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 113288266.9546 - val_loss: 1264452862.2466\n",
      "Epoch 494/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 147337453.6350 - val_loss: 1278899345.5342\n",
      "Epoch 495/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 147552984.7472 - val_loss: 1260173347.0685\n",
      "Epoch 496/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 114290625.1859 - val_loss: 1222718932.1644\n",
      "Epoch 497/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 113919923.5578 - val_loss: 1249631143.4521\n",
      "Epoch 498/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 101582206.8483 - val_loss: 1208028207.3425\n",
      "Epoch 499/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 105280672.0908 - val_loss: 1242259102.6849\n",
      "Epoch 500/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 108097393.0694 - val_loss: 1188469223.4521\n",
      "Epoch 501/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 137922526.9580 - val_loss: 1262260799.1233\n",
      "Epoch 502/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 214691425.9469 - val_loss: 1317718265.8630\n",
      "Epoch 503/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 176478417.0488 - val_loss: 1276434004.1644\n",
      "Epoch 504/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 149883028.5518 - val_loss: 1304523354.3014\n",
      "Epoch 505/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 140910717.1020 - val_loss: 1197152787.2877\n",
      "Epoch 506/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 94989595.5647 - val_loss: 1185014496.4384\n",
      "Epoch 507/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 107252566.9512 - val_loss: 1276618711.6712\n",
      "Epoch 508/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 121223103.8286 - val_loss: 1180612180.1644\n",
      "Epoch 509/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 89447089.1174 - val_loss: 1185864915.2877\n",
      "Epoch 510/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 92173268.5381 - val_loss: 1174928855.6712\n",
      "Epoch 511/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 101291628.5107 - val_loss: 1205074690.6301\n",
      "Epoch 512/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 96818877.3333 - val_loss: 1168909141.0411\n",
      "Epoch 513/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 88016798.1080 - val_loss: 1169869802.0822\n",
      "Epoch 514/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 93764056.2159 - val_loss: 1198716025.8630\n",
      "Epoch 515/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 95777069.1140 - val_loss: 1164437234.8493\n",
      "Epoch 516/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 89154336.6581 - val_loss: 1206829184.8767\n",
      "Epoch 517/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 83348621.4567 - val_loss: 1229223149.5890\n",
      "Epoch 518/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 121302364.6547 - val_loss: 1188286488.5479\n",
      "Epoch 519/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 121164557.0317 - val_loss: 1275845030.5753\n",
      "Epoch 520/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 103998355.2836 - val_loss: 1151062154.5205\n",
      "Epoch 521/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 84262876.4833 - val_loss: 1225962852.8219\n",
      "Epoch 522/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 92619093.6692 - val_loss: 1189199896.5479\n",
      "Epoch 523/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 88500683.5784 - val_loss: 1152800506.7397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 146753425.3299 - val_loss: 1257623923.7260\n",
      "Epoch 525/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 113641098.3685 - val_loss: 1243806972.4932\n",
      "Epoch 526/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 94995908.6478 - val_loss: 1206001304.5479\n",
      "Epoch 527/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 95084274.8278 - val_loss: 1185740330.0822\n",
      "Epoch 528/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 88224840.0000 - val_loss: 1257275926.7945\n",
      "Epoch 529/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 86578150.9854 - val_loss: 1190008225.3151\n",
      "Epoch 530/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 82278418.5707 - val_loss: 1290071320.5479\n",
      "Epoch 531/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 153608539.0334 - val_loss: 1362841097.6438\n",
      "Epoch 532/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 274798634.4473 - val_loss: 1303905274.7397\n",
      "Epoch 533/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 187533243.5716 - val_loss: 1356310583.2329\n",
      "Epoch 534/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 115454298.7558 - val_loss: 1245660838.5753\n",
      "Epoch 535/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 103345115.8595 - val_loss: 1196642626.6301\n",
      "Epoch 536/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 109567327.5407 - val_loss: 1202950096.6575\n",
      "Epoch 537/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 108858793.1894 - val_loss: 1262978147.0685\n",
      "Epoch 538/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 116925601.7961 - val_loss: 1192891742.6849\n",
      "Epoch 539/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 95384305.3916 - val_loss: 1214741180.4932\n",
      "Epoch 540/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 106253879.6435 - val_loss: 1223087960.5479\n",
      "Epoch 541/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 88420318.7592 - val_loss: 1239647893.0411\n",
      "Epoch 542/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 86953628.8295 - val_loss: 1223778274.1918\n",
      "Epoch 543/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 99044631.9623 - val_loss: 1211366971.6164\n",
      "Epoch 544/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 110601911.2528 - val_loss: 1192391963.1781\n",
      "Epoch 545/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 96367895.6915 - val_loss: 1260176817.9726\n",
      "Epoch 546/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 92893723.4482 - val_loss: 1245499275.3973\n",
      "Epoch 547/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 160211747.8458 - val_loss: 1262367302.1370\n",
      "Epoch 548/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 112774608.2194 - val_loss: 1181827615.5616\n",
      "Epoch 549/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 99383309.9914 - val_loss: 1189666756.3836\n",
      "Epoch 550/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 75005830.9786 - val_loss: 1252287905.3151\n",
      "Epoch 551/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 94834855.9931 - val_loss: 1170473771.8356\n",
      "Epoch 552/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 98352918.1697 - val_loss: 1213663104.0000\n",
      "Epoch 553/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 78860603.1808 - val_loss: 1180986652.0548\n",
      "Epoch 554/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 80274300.9837 - val_loss: 1203033922.6301\n",
      "Epoch 555/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 113229793.8029 - val_loss: 1198270574.4658\n",
      "Epoch 556/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 92491135.4413 - val_loss: 1156687138.1918\n",
      "Epoch 557/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 80499048.3530 - val_loss: 1155463226.7397\n",
      "Epoch 558/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 96931874.2108 - val_loss: 1181232505.8630\n",
      "Epoch 559/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 115926476.3393 - val_loss: 1214333195.3973\n",
      "Epoch 560/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 80283960.0891 - val_loss: 1165147062.3562\n",
      "Epoch 561/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 92209200.4662 - val_loss: 1207116168.7671\n",
      "Epoch 562/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 131522956.7027 - val_loss: 1187057381.6986\n",
      "Epoch 563/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 103152982.5330 - val_loss: 1215843399.8904\n",
      "Epoch 564/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 109222448.3462 - val_loss: 1197776626.8493\n",
      "Epoch 565/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 134515676.4113 - val_loss: 1221763817.2055\n",
      "Epoch 566/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 82152686.2245 - val_loss: 1261025092.3836\n",
      "Epoch 567/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 95733824.6444 - val_loss: 1239224050.8493\n",
      "Epoch 568/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 108281697.8509 - val_loss: 1248496924.9315\n",
      "Epoch 569/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 100286340.4559 - val_loss: 1335334757.6986\n",
      "Epoch 570/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 109726224.4764 - val_loss: 1323708405.4795\n",
      "Epoch 571/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 108571996.8603 - val_loss: 1260694821.6986\n",
      "Epoch 572/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 111213115.4036 - val_loss: 1175137408.8767\n",
      "Epoch 573/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 116763539.7566 - val_loss: 1191360976.6575\n",
      "Epoch 574/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 85349821.5081 - val_loss: 1173287786.0822\n",
      "Epoch 575/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 71571377.9400 - val_loss: 1197555233.3151\n",
      "Epoch 576/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 94057972.3839 - val_loss: 1216860203.8356\n",
      "Epoch 577/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 82060805.5955 - val_loss: 1140371669.9178\n",
      "Epoch 578/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 75744212.2922 - val_loss: 1184454761.2055\n",
      "Epoch 579/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 75777505.9195 - val_loss: 1170462134.3562\n",
      "Epoch 580/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 75931573.9057 - val_loss: 1193631959.6712\n",
      "Epoch 581/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 134006238.9306 - val_loss: 1143563241.2055\n",
      "Epoch 582/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 148777761.6041 - val_loss: 1186780560.6575\n",
      "Epoch 583/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 121876832.5484 - val_loss: 1387443611.1781\n",
      "Epoch 584/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 115290705.9606 - val_loss: 1171247484.4932\n",
      "Epoch 585/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 88818106.3993 - val_loss: 1177951955.2877\n",
      "Epoch 586/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 106944772.9254 - val_loss: 1183036202.0822\n",
      "Epoch 587/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 92031876.7575 - val_loss: 1238228562.4110\n",
      "Epoch 588/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 135905867.3693 - val_loss: 1334386481.9726\n",
      "Epoch 589/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 105357414.4370 - val_loss: 1215248638.2466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 96097408.1782 - val_loss: 1176760419.0685\n",
      "Epoch 591/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 155238955.1602 - val_loss: 1201425782.3562\n",
      "Epoch 592/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 122515196.6153 - val_loss: 1168460003.0685\n",
      "Epoch 593/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 99218259.9349 - val_loss: 1164268409.8630\n",
      "Epoch 594/5000\n",
      "1167/1167 [==============================] - 0s 229us/step - loss: 89817352.2536 - val_loss: 1216907947.8356\n",
      "Epoch 595/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 78126588.9700 - val_loss: 1187827777.7534\n",
      "Epoch 596/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 80916036.9906 - val_loss: 1222152909.1507\n",
      "Epoch 597/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 67480832.7575 - val_loss: 1165319795.7260\n",
      "Epoch 598/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 70513350.8483 - val_loss: 1177284441.4247\n",
      "Epoch 599/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 94659375.3145 - val_loss: 1171758472.7671\n",
      "Epoch 600/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 83646762.7524 - val_loss: 1228316230.1370\n",
      "Epoch 601/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 108251290.6530 - val_loss: 1199077781.0411\n",
      "Epoch 602/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 100191255.5407 - val_loss: 1204219000.1096\n",
      "Epoch 603/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 99664656.8980 - val_loss: 1183105606.1370\n",
      "Epoch 604/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 103362072.6444 - val_loss: 1246636490.5205\n",
      "Epoch 605/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 79437665.3059 - val_loss: 1165726630.5753\n",
      "Epoch 606/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 73046828.1200 - val_loss: 1194199952.6575\n",
      "Epoch 607/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 82195222.2485 - val_loss: 1217646153.6438\n",
      "Epoch 608/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 93711304.1782 - val_loss: 1170619747.9452\n",
      "Epoch 609/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 83007110.4576 - val_loss: 1239896208.6575\n",
      "Epoch 610/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 82401214.5261 - val_loss: 1280266606.4658\n",
      "Epoch 611/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 75301746.8518 - val_loss: 1177719537.0959\n",
      "Epoch 612/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 66731208.4730 - val_loss: 1164968168.3288\n",
      "Epoch 613/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 86517564.8912 - val_loss: 1221750529.7534\n",
      "Epoch 614/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 85580845.9434 - val_loss: 1201089479.0137\n",
      "Epoch 615/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 75993023.0403 - val_loss: 1173066709.9178\n",
      "Epoch 616/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 74583249.5870 - val_loss: 1145951496.7671\n",
      "Epoch 617/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 73489187.3933 - val_loss: 1141247404.7123\n",
      "Epoch 618/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 100376690.2005 - val_loss: 1380910407.8904\n",
      "Epoch 619/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 142823184.1508 - val_loss: 1199198321.0959\n",
      "Epoch 620/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 139478543.5750 - val_loss: 1246321343.1233\n",
      "Epoch 621/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 245764715.5441 - val_loss: 1196287922.8493\n",
      "Epoch 622/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 101356609.0403 - val_loss: 1277050948.3836\n",
      "Epoch 623/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 81144658.3616 - val_loss: 1228874204.9315\n",
      "Epoch 624/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 86862520.1919 - val_loss: 1234884129.3151\n",
      "Epoch 625/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 87336437.0009 - val_loss: 1233301283.9452\n",
      "Epoch 626/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 67005139.1191 - val_loss: 1193279444.1644\n",
      "Epoch 627/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 77329358.8620 - val_loss: 1208587783.8904\n",
      "Epoch 628/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 99597470.4370 - val_loss: 1220250131.2877\n",
      "Epoch 629/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 71199872.0377 - val_loss: 1192986223.3425\n",
      "Epoch 630/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 95627035.2168 - val_loss: 1197869823.1233\n",
      "Epoch 631/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 74636423.5578 - val_loss: 1198752249.8630\n",
      "Epoch 632/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 100866602.5021 - val_loss: 1235245026.1918\n",
      "Epoch 633/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 193787958.1834 - val_loss: 1358738498.6301\n",
      "Epoch 634/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 228958698.9957 - val_loss: 1762313145.4247\n",
      "Epoch 635/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 269078848.2468 - val_loss: 1361014034.4110\n",
      "Epoch 636/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 115590992.4764 - val_loss: 1211425371.1781\n",
      "Epoch 637/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 69325608.6495 - val_loss: 1199477589.0411\n",
      "Epoch 638/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 63670777.7549 - val_loss: 1220749327.7808\n",
      "Epoch 639/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 63437445.7069 - val_loss: 1176006243.0685\n",
      "Epoch 640/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 62313070.6015 - val_loss: 1191196088.9863\n",
      "Epoch 641/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 86258568.3873 - val_loss: 1147404879.7808\n",
      "Epoch 642/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 70761909.7858 - val_loss: 1191979930.3014\n",
      "Epoch 643/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 64996785.0351 - val_loss: 1150715086.9041\n",
      "Epoch 644/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 60284419.0848 - val_loss: 1160351848.3288\n",
      "Epoch 645/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 58937808.5398 - val_loss: 1142816518.1370\n",
      "Epoch 646/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 61982665.4396 - val_loss: 1287388292.3836\n",
      "Epoch 647/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 94524803.9692 - val_loss: 1168409217.7534\n",
      "Epoch 648/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 78591478.1997 - val_loss: 1154910511.3425\n",
      "Epoch 649/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 81325041.0934 - val_loss: 1168953497.4247\n",
      "Epoch 650/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 130850790.4987 - val_loss: 1111878449.0959\n",
      "Epoch 651/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 101200805.9503 - val_loss: 1237145771.8356\n",
      "Epoch 652/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 101530382.5673 - val_loss: 1208933171.7260\n",
      "Epoch 653/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 87600758.9786 - val_loss: 1178363948.7123\n",
      "Epoch 654/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 81184447.7738 - val_loss: 1183314914.1918\n",
      "Epoch 655/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 78486302.1217 - val_loss: 1198951739.6164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 82807160.7883 - val_loss: 1172106393.4247\n",
      "Epoch 657/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 59098284.8363 - val_loss: 1261832536.5479\n",
      "Epoch 658/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 103346034.8003 - val_loss: 1208344879.3425\n",
      "Epoch 659/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 78430876.3325 - val_loss: 1213600341.9178\n",
      "Epoch 660/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 68222969.6315 - val_loss: 1157387736.5479\n",
      "Epoch 661/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 61407334.3890 - val_loss: 1189530917.6986\n",
      "Epoch 662/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 66965842.0257 - val_loss: 1218938099.7260\n",
      "Epoch 663/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 70674691.5064 - val_loss: 1144518552.5479\n",
      "Epoch 664/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 61090185.9949 - val_loss: 1162590488.5479\n",
      "Epoch 665/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 62350035.3676 - val_loss: 1203923961.8630\n",
      "Epoch 666/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 54525753.8372 - val_loss: 1154400837.2603\n",
      "Epoch 667/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 62032270.9923 - val_loss: 1168550592.8767\n",
      "Epoch 668/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 69512253.2442 - val_loss: 1172009678.9041\n",
      "Epoch 669/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 67296855.8663 - val_loss: 1198615813.2603\n",
      "Epoch 670/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 78479384.9049 - val_loss: 1193680954.7397\n",
      "Epoch 671/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 67121129.1105 - val_loss: 1170007972.8219\n",
      "Epoch 672/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 72313454.2862 - val_loss: 1437625884.0548\n",
      "Epoch 673/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 178545786.4816 - val_loss: 1264587051.8356\n",
      "Epoch 674/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 81614175.5476 - val_loss: 1128090398.6849\n",
      "Epoch 675/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 75052746.0291 - val_loss: 1186283400.7671\n",
      "Epoch 676/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 62592420.5141 - val_loss: 1166522455.6712\n",
      "Epoch 677/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 53908739.7532 - val_loss: 1258790252.7123\n",
      "Epoch 678/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 74521735.7738 - val_loss: 1218825520.2192\n",
      "Epoch 679/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 62461438.5021 - val_loss: 1149840718.0274\n",
      "Epoch 680/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 59412532.8260 - val_loss: 1173868129.3151\n",
      "Epoch 681/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 54070410.0600 - val_loss: 1153163359.5616\n",
      "Epoch 682/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 59596548.1097 - val_loss: 1203465422.0274\n",
      "Epoch 683/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 85239445.2648 - val_loss: 1089504903.0137\n",
      "Epoch 684/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 64821731.3556 - val_loss: 1178320728.5479\n",
      "Epoch 685/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 104899365.5801 - val_loss: 1237054215.0137\n",
      "Epoch 686/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 96804544.1302 - val_loss: 1225914464.4384\n",
      "Epoch 687/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 79747722.2108 - val_loss: 1212998789.2603\n",
      "Epoch 688/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 77081795.4996 - val_loss: 1176922851.0685\n",
      "Epoch 689/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 62023758.9854 - val_loss: 1180340417.7534\n",
      "Epoch 690/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 63661891.9657 - val_loss: 1180644428.2740\n",
      "Epoch 691/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 61372669.8338 - val_loss: 1192100963.9452\n",
      "Epoch 692/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 79199475.1705 - val_loss: 1175060348.4932\n",
      "Epoch 693/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 55325231.9777 - val_loss: 1159921174.7945\n",
      "Epoch 694/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 55431158.3342 - val_loss: 1207240428.7123\n",
      "Epoch 695/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 59047143.9829 - val_loss: 1180115892.6027\n",
      "Epoch 696/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 71597777.9057 - val_loss: 1219050403.0685\n",
      "Epoch 697/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 82899814.1148 - val_loss: 1180390306.1918\n",
      "Epoch 698/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 84021114.7009 - val_loss: 1114309610.0822\n",
      "Epoch 699/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 69199253.6213 - val_loss: 1153292940.2740\n",
      "Epoch 700/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 59918652.1508 - val_loss: 1126035318.3562\n",
      "Epoch 701/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 62978334.0668 - val_loss: 1165202540.7123\n",
      "Epoch 702/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 75582604.2948 - val_loss: 1146402424.1096\n",
      "Epoch 703/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 75924568.4833 - val_loss: 1134869636.3836\n",
      "Epoch 704/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 59959506.0394 - val_loss: 1180949884.4932\n",
      "Epoch 705/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 75758926.6530 - val_loss: 1272976861.8082\n",
      "Epoch 706/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 77568693.4704 - val_loss: 1177903125.0411\n",
      "Epoch 707/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 128007063.4859 - val_loss: 1225846778.7397\n",
      "Epoch 708/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 108265113.0351 - val_loss: 1182348057.4247\n",
      "Epoch 709/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 132032260.4079 - val_loss: 1190404011.8356\n",
      "Epoch 710/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 88623749.6692 - val_loss: 1163305873.5342\n",
      "Epoch 711/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 176185781.2853 - val_loss: 1139889337.8630\n",
      "Epoch 712/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 120042017.8338 - val_loss: 1186015300.3836\n",
      "Epoch 713/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 69926435.6093 - val_loss: 1134862088.7671\n",
      "Epoch 714/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 55042935.5613 - val_loss: 1136562375.8904\n",
      "Epoch 715/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 55781094.2039 - val_loss: 1192209358.0274\n",
      "Epoch 716/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 56207301.2716 - val_loss: 1127411292.9315\n",
      "Epoch 717/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 51995741.8269 - val_loss: 1138349944.9863\n",
      "Epoch 718/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 53206397.3710 - val_loss: 1188083059.7260\n",
      "Epoch 719/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 49781580.7301 - val_loss: 1157688211.2877\n",
      "Epoch 720/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 61891559.5201 - val_loss: 1106880586.5205\n",
      "Epoch 721/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 72503528.7541 - val_loss: 1232870539.3973\n",
      "Epoch 722/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 257us/step - loss: 89446225.4876 - val_loss: 1157602975.5616\n",
      "Epoch 723/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 60971324.6667 - val_loss: 1150777407.1233\n",
      "Epoch 724/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 54213841.3231 - val_loss: 1159248794.3014\n",
      "Epoch 725/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 66247552.0514 - val_loss: 1150692487.8904\n",
      "Epoch 726/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 57633501.7001 - val_loss: 1122083592.7671\n",
      "Epoch 727/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 45504991.7601 - val_loss: 1153421238.3562\n",
      "Epoch 728/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 47392585.9195 - val_loss: 1120589578.5205\n",
      "Epoch 729/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 53477080.9614 - val_loss: 1154029218.1918\n",
      "Epoch 730/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 44280823.5647 - val_loss: 1155983442.4110\n",
      "Epoch 731/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 60242134.9854 - val_loss: 1136318430.6849\n",
      "Epoch 732/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 82062732.1474 - val_loss: 1195152687.3425\n",
      "Epoch 733/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 69520221.4533 - val_loss: 1144692151.2329\n",
      "Epoch 734/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 58708522.6941 - val_loss: 1172459374.4658\n",
      "Epoch 735/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 66816445.1825 - val_loss: 1111860409.8630\n",
      "Epoch 736/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 59977244.0994 - val_loss: 1109755112.3288\n",
      "Epoch 737/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 63303820.9186 - val_loss: 1133406319.3425\n",
      "Epoch 738/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 50082675.0111 - val_loss: 1145794839.6712\n",
      "Epoch 739/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 52431356.8021 - val_loss: 1184872822.3562\n",
      "Epoch 740/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 61212649.7892 - val_loss: 1134459207.8904\n",
      "Epoch 741/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 47551140.8398 - val_loss: 1154844035.5068\n",
      "Epoch 742/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 46191491.6161 - val_loss: 1113077940.6027\n",
      "Epoch 743/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 44344656.1131 - val_loss: 1137313125.6986\n",
      "Epoch 744/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 49278305.5630 - val_loss: 1274206569.2055\n",
      "Epoch 745/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 79407278.5433 - val_loss: 1235931306.0822\n",
      "Epoch 746/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 133038722.7421 - val_loss: 1114368661.0411\n",
      "Epoch 747/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 74148271.4722 - val_loss: 1116176640.8767\n",
      "Epoch 748/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 49831416.2262 - val_loss: 1116975512.5479\n",
      "Epoch 749/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 53488848.8980 - val_loss: 1201648412.9315\n",
      "Epoch 750/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 62718638.9374 - val_loss: 1148439010.1918\n",
      "Epoch 751/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 60630521.2579 - val_loss: 1199398903.2329\n",
      "Epoch 752/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 67812568.6204 - val_loss: 1152288208.6575\n",
      "Epoch 753/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 63575434.0223 - val_loss: 1146352960.8767\n",
      "Epoch 754/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 68770122.4370 - val_loss: 1128597471.5616\n",
      "Epoch 755/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 107205836.9083 - val_loss: 1163919594.9589\n",
      "Epoch 756/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 130919066.1662 - val_loss: 1183398919.0137\n",
      "Epoch 757/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 83009357.1071 - val_loss: 1172922250.5205\n",
      "Epoch 758/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 75467655.5201 - val_loss: 1134002435.5068\n",
      "Epoch 759/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 54001106.5159 - val_loss: 1136426480.2192\n",
      "Epoch 760/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 93628716.7781 - val_loss: 1137732862.2466\n",
      "Epoch 761/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 94312078.9203 - val_loss: 1224669989.6986\n",
      "Epoch 762/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 121236207.2254 - val_loss: 1220812347.6164\n",
      "Epoch 763/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 105841632.2399 - val_loss: 1284437383.0137\n",
      "Epoch 764/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 76099872.6718 - val_loss: 1157777173.0411\n",
      "Epoch 765/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 48688098.3513 - val_loss: 1113638747.1781\n",
      "Epoch 766/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 64778896.5690 - val_loss: 1114202061.1507\n",
      "Epoch 767/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 46756325.1277 - val_loss: 1129815427.5068\n",
      "Epoch 768/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 52871661.9434 - val_loss: 1129098595.9452\n",
      "Epoch 769/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 55161607.7412 - val_loss: 1126690812.4932\n",
      "Epoch 770/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 42984215.0094 - val_loss: 1120315761.9726\n",
      "Epoch 771/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 39932926.8260 - val_loss: 1122879788.7123\n",
      "Epoch 772/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 40988991.7635 - val_loss: 1130930621.3699\n",
      "Epoch 773/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 45324338.7626 - val_loss: 1108617937.5342\n",
      "Epoch 774/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 64496770.8552 - val_loss: 1163411638.3562\n",
      "Epoch 775/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 73768359.9554 - val_loss: 1156506196.1644\n",
      "Epoch 776/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 48192861.7258 - val_loss: 1148422859.3973\n",
      "Epoch 777/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 59461484.0891 - val_loss: 1101761755.1781\n",
      "Epoch 778/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 43473131.2082 - val_loss: 1124022857.6438\n",
      "Epoch 779/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 42549545.6710 - val_loss: 1138648810.9589\n",
      "Epoch 780/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 48179451.9692 - val_loss: 1151986187.3973\n",
      "Epoch 781/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 54749957.7412 - val_loss: 1131715164.0548\n",
      "Epoch 782/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 58815498.3993 - val_loss: 1190289130.0822\n",
      "Epoch 783/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 56487639.0214 - val_loss: 1156706474.0822\n",
      "Epoch 784/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 43239776.8723 - val_loss: 1222456832.0000\n",
      "Epoch 785/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 46516840.9117 - val_loss: 1112591931.6164\n",
      "Epoch 786/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 41624146.5741 - val_loss: 1147726905.8630\n",
      "Epoch 787/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 42877838.9272 - val_loss: 1103210541.5890\n",
      "Epoch 788/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 46391846.4404 - val_loss: 1160684119.6712\n",
      "Epoch 789/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 46249580.2776 - val_loss: 1190066712.5479\n",
      "Epoch 790/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 57199101.8578 - val_loss: 1130947932.0548\n",
      "Epoch 791/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 50615960.9940 - val_loss: 1123818275.0685\n",
      "Epoch 792/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 56586222.7112 - val_loss: 1157134115.0685\n",
      "Epoch 793/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 59290868.2057 - val_loss: 1163030072.9863\n",
      "Epoch 794/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 107625277.8612 - val_loss: 1170030069.4795\n",
      "Epoch 795/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 76490520.6272 - val_loss: 1155184478.6849\n",
      "Epoch 796/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 59575181.6144 - val_loss: 1149138638.9041\n",
      "Epoch 797/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 38945197.8063 - val_loss: 1121249871.7808\n",
      "Epoch 798/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 48815238.2862 - val_loss: 1140430054.5753\n",
      "Epoch 799/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 54373637.8646 - val_loss: 1149727251.2877\n",
      "Epoch 800/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 67106257.3470 - val_loss: 1148788379.1781\n",
      "Epoch 801/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 58386074.0805 - val_loss: 1195033460.6027\n",
      "Epoch 802/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 44091858.9614 - val_loss: 1178119182.9041\n",
      "Epoch 803/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 47287437.9572 - val_loss: 1158332243.2877\n",
      "Epoch 804/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 45537343.3282 - val_loss: 1132076295.0137\n",
      "Epoch 805/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 63439877.6007 - val_loss: 1173256837.2603\n",
      "Epoch 806/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 112528422.8003 - val_loss: 1181715199.1233\n",
      "Epoch 807/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 89016013.8612 - val_loss: 1153833102.9041\n",
      "Epoch 808/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 58209600.9220 - val_loss: 1209921874.4110\n",
      "Epoch 809/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 49066575.3590 - val_loss: 1175696022.7945\n",
      "Epoch 810/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 59664849.9794 - val_loss: 1242178032.2192\n",
      "Epoch 811/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 60065545.4122 - val_loss: 1141110449.0959\n",
      "Epoch 812/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 47444490.3959 - val_loss: 1094108464.2192\n",
      "Epoch 813/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 40430376.3633 - val_loss: 1153315233.3151\n",
      "Epoch 814/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 57375264.3479 - val_loss: 1212272392.7671\n",
      "Epoch 815/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 48050927.7035 - val_loss: 1146885937.9726\n",
      "Epoch 816/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 43699006.8963 - val_loss: 1141609253.6986\n",
      "Epoch 817/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 55291893.9674 - val_loss: 1148572255.5616\n",
      "Epoch 818/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 59047653.0677 - val_loss: 1128420534.3562\n",
      "Epoch 819/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 44143087.0094 - val_loss: 1120458268.0548\n",
      "Epoch 820/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 44668222.6624 - val_loss: 1181627118.4658\n",
      "Epoch 821/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 56050760.2931 - val_loss: 1132259399.0137\n",
      "Epoch 822/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 48081129.1517 - val_loss: 1140525164.7123\n",
      "Epoch 823/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 46855956.2211 - val_loss: 1150251475.2877\n",
      "Epoch 824/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 54595182.6290 - val_loss: 1204985657.8630\n",
      "Epoch 825/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 80659329.6521 - val_loss: 1128230889.2055\n",
      "Epoch 826/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 52338482.0497 - val_loss: 1230528825.8630\n",
      "Epoch 827/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 91925747.4893 - val_loss: 1121032949.4795\n",
      "Epoch 828/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 62289023.2117 - val_loss: 1091732031.1233\n",
      "Epoch 829/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 67161087.4019 - val_loss: 1150997581.1507\n",
      "Epoch 830/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 43584590.9683 - val_loss: 1138417293.1507\n",
      "Epoch 831/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 75693846.6255 - val_loss: 1161969934.0274\n",
      "Epoch 832/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 51076876.9769 - val_loss: 1114847098.7397\n",
      "Epoch 833/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 67023132.7266 - val_loss: 1109028248.5479\n",
      "Epoch 834/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 43567784.2399 - val_loss: 1115566597.2603\n",
      "Epoch 835/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 76951391.1842 - val_loss: 1156298341.6986\n",
      "Epoch 836/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 67809185.0077 - val_loss: 1097706623.1233\n",
      "Epoch 837/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 44317212.2913 - val_loss: 1102288003.5068\n",
      "Epoch 838/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 40223802.2639 - val_loss: 1136908913.9726\n",
      "Epoch 839/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 34657426.4473 - val_loss: 1130454424.5479\n",
      "Epoch 840/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 42176770.2416 - val_loss: 1109479574.7945\n",
      "Epoch 841/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 40251789.4293 - val_loss: 1166491440.2192\n",
      "Epoch 842/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 42816705.6932 - val_loss: 1224302614.7945\n",
      "Epoch 843/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 46647097.7961 - val_loss: 1175421645.1507\n",
      "Epoch 844/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 45916875.9109 - val_loss: 1167640944.2192\n",
      "Epoch 845/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 67286334.7147 - val_loss: 1182900620.2740\n",
      "Epoch 846/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 80737702.6632 - val_loss: 1165267633.0959\n",
      "Epoch 847/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 68852206.3393 - val_loss: 1173848054.3562\n",
      "Epoch 848/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 41976581.2237 - val_loss: 1106832308.6027\n",
      "Epoch 849/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 45800054.1457 - val_loss: 1186553370.3014\n",
      "Epoch 850/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 63940646.3822 - val_loss: 1101656901.2603\n",
      "Epoch 851/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 62403364.9803 - val_loss: 1135532161.7534\n",
      "Epoch 852/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 57097970.0223 - val_loss: 1127664517.2603\n",
      "Epoch 853/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 123192024.3428 - val_loss: 1223272888.1096\n",
      "Epoch 854/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 262us/step - loss: 60673052.7798 - val_loss: 1146955850.5205\n",
      "Epoch 855/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 43335037.9863 - val_loss: 1128150837.4795\n",
      "Epoch 856/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 30926461.8235 - val_loss: 1138063112.7671\n",
      "Epoch 857/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 34545611.7464 - val_loss: 1131421459.2877\n",
      "Epoch 858/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 45440722.3753 - val_loss: 1114274467.9452\n",
      "Epoch 859/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 61889801.1722 - val_loss: 1372731358.6849\n",
      "Epoch 860/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 64441385.3642 - val_loss: 1134650388.1644\n",
      "Epoch 861/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 38300500.9666 - val_loss: 1103847460.8219\n",
      "Epoch 862/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 46230091.2082 - val_loss: 1147669391.7808\n",
      "Epoch 863/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 51808642.4027 - val_loss: 1156570203.1781\n",
      "Epoch 864/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 32794138.0780 - val_loss: 1149048208.6575\n",
      "Epoch 865/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 55417233.1208 - val_loss: 1131398917.2603\n",
      "Epoch 866/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 32646273.5253 - val_loss: 1117417477.2603\n",
      "Epoch 867/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 34983124.8055 - val_loss: 1125399921.9726\n",
      "Epoch 868/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 34310329.0043 - val_loss: 1181834629.2603\n",
      "Epoch 869/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37350408.9169 - val_loss: 1172597805.5890\n",
      "Epoch 870/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 34780535.5493 - val_loss: 1082895370.5205\n",
      "Epoch 871/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 38416212.2536 - val_loss: 1182935500.2740\n",
      "Epoch 872/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 51859223.5133 - val_loss: 1146028259.9452\n",
      "Epoch 873/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 42085916.6787 - val_loss: 1138741248.8767\n",
      "Epoch 874/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 48742991.7601 - val_loss: 1098193633.3151\n",
      "Epoch 875/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 54355758.8003 - val_loss: 1163875267.5068\n",
      "Epoch 876/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 38416946.2828 - val_loss: 1120900790.3562\n",
      "Epoch 877/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37778169.4979 - val_loss: 1162474436.3836\n",
      "Epoch 878/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35839107.3693 - val_loss: 1152384521.6438\n",
      "Epoch 879/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 41762854.7044 - val_loss: 1124326509.5890\n",
      "Epoch 880/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35024697.9126 - val_loss: 1148800068.3836\n",
      "Epoch 881/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 38029667.9692 - val_loss: 1124382762.0822\n",
      "Epoch 882/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 34831624.0206 - val_loss: 1087611194.7397\n",
      "Epoch 883/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 38386373.5767 - val_loss: 1108017651.7260\n",
      "Epoch 884/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 63071146.0189 - val_loss: 1194250219.8356\n",
      "Epoch 885/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 85815901.6967 - val_loss: 1153422318.4658\n",
      "Epoch 886/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 94253526.6221 - val_loss: 1165257108.1644\n",
      "Epoch 887/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 60964014.7386 - val_loss: 1134377615.7808\n",
      "Epoch 888/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 43915762.2485 - val_loss: 1169044952.5479\n",
      "Epoch 889/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 38627363.0943 - val_loss: 1123379238.5753\n",
      "Epoch 890/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35638902.6392 - val_loss: 1156536369.0959\n",
      "Epoch 891/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35761716.0720 - val_loss: 1145188053.9178\n",
      "Epoch 892/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 34662012.6341 - val_loss: 1163889460.6027\n",
      "Epoch 893/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 43017883.2494 - val_loss: 1207594334.6849\n",
      "Epoch 894/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 54673494.1422 - val_loss: 1114326482.4110\n",
      "Epoch 895/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 45638727.2751 - val_loss: 1123540972.7123\n",
      "Epoch 896/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 55858673.2716 - val_loss: 1206760356.8219\n",
      "Epoch 897/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 100815979.3933 - val_loss: 1154382523.6164\n",
      "Epoch 898/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 75783331.7532 - val_loss: 1148249272.9863\n",
      "Epoch 899/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 74305179.7943 - val_loss: 1178170897.5342\n",
      "Epoch 900/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 43368192.3822 - val_loss: 1114829798.5753\n",
      "Epoch 901/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 32210189.8612 - val_loss: 1105357161.2055\n",
      "Epoch 902/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 39545982.7009 - val_loss: 1141737233.5342\n",
      "Epoch 903/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 42464865.0626 - val_loss: 1143737597.3699\n",
      "Epoch 904/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 50350460.3753 - val_loss: 1137559097.8630\n",
      "Epoch 905/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37060486.1919 - val_loss: 1136737685.0411\n",
      "Epoch 906/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 33275250.5073 - val_loss: 1136790469.2603\n",
      "Epoch 907/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 27074872.1885 - val_loss: 1094386545.0959\n",
      "Epoch 908/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 33651671.0694 - val_loss: 1175869212.0548\n",
      "Epoch 909/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 26195021.1380 - val_loss: 1127622624.4384\n",
      "Epoch 910/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 25352442.5681 - val_loss: 1128667663.7808\n",
      "Epoch 911/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 29171159.1191 - val_loss: 1153688364.7123\n",
      "Epoch 912/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 47786743.6538 - val_loss: 1125660447.5616\n",
      "Epoch 913/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36788899.3085 - val_loss: 1128411157.0411\n",
      "Epoch 914/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37204272.5553 - val_loss: 1147011489.3151\n",
      "Epoch 915/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35617366.4713 - val_loss: 1127265450.9589\n",
      "Epoch 916/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 115142562.1525 - val_loss: 1609972537.8630\n",
      "Epoch 917/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 114290221.8440 - val_loss: 1130947373.5890\n",
      "Epoch 918/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 80885495.6504 - val_loss: 1173958761.2055\n",
      "Epoch 919/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 38468210.3822 - val_loss: 1104967097.8630\n",
      "Epoch 920/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 31158928.8038 - val_loss: 1130539533.1507\n",
      "Epoch 921/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 28875204.9610 - val_loss: 1094882810.7397\n",
      "Epoch 922/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 24754925.1765 - val_loss: 1136282373.2603\n",
      "Epoch 923/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 27476288.5347 - val_loss: 1120653258.5205\n",
      "Epoch 924/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 24929468.4627 - val_loss: 1114192068.3836\n",
      "Epoch 925/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 30266610.6632 - val_loss: 1194031592.3288\n",
      "Epoch 926/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 30439120.9520 - val_loss: 1128510067.7260\n",
      "Epoch 927/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 27618630.5604 - val_loss: 1146537303.6712\n",
      "Epoch 928/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 60623668.6889 - val_loss: 1141131664.6575\n",
      "Epoch 929/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 154460956.5176 - val_loss: 1142287912.3288\n",
      "Epoch 930/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 81873400.7746 - val_loss: 1175872583.0137\n",
      "Epoch 931/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 69912700.3119 - val_loss: 1152880969.6438\n",
      "Epoch 932/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 47909786.6290 - val_loss: 1106473336.9863\n",
      "Epoch 933/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 56572682.2674 - val_loss: 1173159939.5068\n",
      "Epoch 934/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 31022723.6915 - val_loss: 1139182776.1096\n",
      "Epoch 935/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 30794798.2468 - val_loss: 1139377421.1507\n",
      "Epoch 936/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 29804171.3179 - val_loss: 1124931326.2466\n",
      "Epoch 937/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 41174515.9554 - val_loss: 1097191717.6986\n",
      "Epoch 938/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35454695.8458 - val_loss: 1125331034.3014\n",
      "Epoch 939/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 37587829.4019 - val_loss: 1140978736.2192\n",
      "Epoch 940/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 43215457.0831 - val_loss: 1180787845.2603\n",
      "Epoch 941/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 53645682.0600 - val_loss: 1081250489.8630\n",
      "Epoch 942/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 31925773.9229 - val_loss: 1094552282.3014\n",
      "Epoch 943/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 34365609.9640 - val_loss: 1101344515.5068\n",
      "Epoch 944/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 27331335.4053 - val_loss: 1136359631.7808\n",
      "Epoch 945/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 29303722.4901 - val_loss: 1120275985.5342\n",
      "Epoch 946/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36819962.7918 - val_loss: 1132472668.9315\n",
      "Epoch 947/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 34497198.8946 - val_loss: 1165435165.8082\n",
      "Epoch 948/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26691417.4550 - val_loss: 1138624846.9041\n",
      "Epoch 949/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 27888732.8423 - val_loss: 1104873754.3014\n",
      "Epoch 950/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 28403974.7215 - val_loss: 1086598755.9452\n",
      "Epoch 951/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 32377980.9460 - val_loss: 1137416419.9452\n",
      "Epoch 952/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 56077703.0300 - val_loss: 1185844201.2055\n",
      "Epoch 953/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 65203640.2656 - val_loss: 1185632277.9178\n",
      "Epoch 954/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 33154028.6341 - val_loss: 1118474909.8082\n",
      "Epoch 955/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 26470512.8089 - val_loss: 1128085065.6438\n",
      "Epoch 956/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 27102899.4404 - val_loss: 1139115650.6301\n",
      "Epoch 957/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 27347480.7369 - val_loss: 1151943591.4521\n",
      "Epoch 958/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 42477638.4850 - val_loss: 1123542553.4247\n",
      "Epoch 959/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 42812441.2374 - val_loss: 1125911533.5890\n",
      "Epoch 960/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 72745043.8389 - val_loss: 1202673230.0274\n",
      "Epoch 961/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 114311855.6984 - val_loss: 1164741186.6301\n",
      "Epoch 962/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 190843224.8021 - val_loss: 1173604296.7671\n",
      "Epoch 963/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 114096689.2408 - val_loss: 1121618007.2329\n",
      "Epoch 964/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 73195740.6752 - val_loss: 1072809937.5342\n",
      "Epoch 965/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 70566842.7249 - val_loss: 1110229458.4110\n",
      "Epoch 966/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 41068944.3136 - val_loss: 1096305450.9589\n",
      "Epoch 967/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 31207458.1799 - val_loss: 1082259086.0274\n",
      "Epoch 968/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 29497240.1063 - val_loss: 1120104862.6849\n",
      "Epoch 969/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26583556.7584 - val_loss: 1100991173.2603\n",
      "Epoch 970/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 33289327.2734 - val_loss: 1109542480.6575\n",
      "Epoch 971/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37001073.5047 - val_loss: 1136561053.8082\n",
      "Epoch 972/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 24607920.9220 - val_loss: 1143708712.3288\n",
      "Epoch 973/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 27800696.9443 - val_loss: 1114610008.5479\n",
      "Epoch 974/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 23986393.1405 - val_loss: 1171668917.4795\n",
      "Epoch 975/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 21544601.1097 - val_loss: 1129581689.8630\n",
      "Epoch 976/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 20566647.5707 - val_loss: 1120559532.7123\n",
      "Epoch 977/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 20621300.3428 - val_loss: 1118780576.4384\n",
      "Epoch 978/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 31590426.6941 - val_loss: 1109756763.1781\n",
      "Epoch 979/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 32155085.9657 - val_loss: 1153738574.0274\n",
      "Epoch 980/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 42181270.3136 - val_loss: 1160026832.6575\n",
      "Epoch 981/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 52975959.8115 - val_loss: 1157402983.4521\n",
      "Epoch 982/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 57829232.0617 - val_loss: 1116584713.6438\n",
      "Epoch 983/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 58418334.6118 - val_loss: 1117108241.5342\n",
      "Epoch 984/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 33985534.5133 - val_loss: 1162026995.7260\n",
      "Epoch 985/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35072038.6461 - val_loss: 1098366053.6986\n",
      "Epoch 986/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 238us/step - loss: 49423783.5047 - val_loss: 1204338945.7534\n",
      "Epoch 987/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 69860724.1937 - val_loss: 1195152496.2192\n",
      "Epoch 988/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 56223859.3899 - val_loss: 1125708231.0137\n",
      "Epoch 989/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 33625006.1791 - val_loss: 1121823694.0274\n",
      "Epoch 990/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 22460956.7515 - val_loss: 1101309372.4932\n",
      "Epoch 991/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 24610155.3488 - val_loss: 1125932945.5342\n",
      "Epoch 992/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 22845527.6607 - val_loss: 1124170161.9726\n",
      "Epoch 993/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 27790060.9751 - val_loss: 1128632839.8904\n",
      "Epoch 994/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 28194265.2099 - val_loss: 1140648327.0137\n",
      "Epoch 995/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 33226100.9237 - val_loss: 1125475731.2877\n",
      "Epoch 996/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 20827144.5570 - val_loss: 1115867792.6575\n",
      "Epoch 997/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 23789655.4516 - val_loss: 1157289388.7123\n",
      "Epoch 998/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 44440044.6410 - val_loss: 1128190251.8356\n",
      "Epoch 999/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 30228281.7781 - val_loss: 1115991078.5753\n",
      "Epoch 1000/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 30532246.9751 - val_loss: 1115413842.4110\n",
      "Epoch 1001/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 25185872.6650 - val_loss: 1137965739.8356\n",
      "Epoch 1002/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 29447368.8980 - val_loss: 1137611194.7397\n",
      "Epoch 1003/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 43505471.5064 - val_loss: 1155380013.5890\n",
      "Epoch 1004/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36716433.6075 - val_loss: 1125338327.6712\n",
      "Epoch 1005/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 47106968.3428 - val_loss: 1210265247.5616\n",
      "Epoch 1006/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 53232865.1791 - val_loss: 1221421676.7123\n",
      "Epoch 1007/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 101098825.8715 - val_loss: 1138042577.5342\n",
      "Epoch 1008/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 108669488.1680 - val_loss: 1148537615.7808\n",
      "Epoch 1009/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 48718700.1268 - val_loss: 1137461805.5890\n",
      "Epoch 1010/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 40718253.0009 - val_loss: 1165119439.7808\n",
      "Epoch 1011/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 46270972.7155 - val_loss: 1123790898.8493\n",
      "Epoch 1012/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 31630930.0480 - val_loss: 1135630657.7534\n",
      "Epoch 1013/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 23227154.6392 - val_loss: 1156274576.6575\n",
      "Epoch 1014/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 27208779.7326 - val_loss: 1130306298.7397\n",
      "Epoch 1015/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 26062843.1774 - val_loss: 1146305285.2603\n",
      "Epoch 1016/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 20192692.4010 - val_loss: 1142775439.7808\n",
      "Epoch 1017/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 21509077.1825 - val_loss: 1147994876.4932\n",
      "Epoch 1018/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 24450202.1902 - val_loss: 1181238826.9589\n",
      "Epoch 1019/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 28730247.4653 - val_loss: 1128001143.2329\n",
      "Epoch 1020/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 27565744.2725 - val_loss: 1142557061.2603\n",
      "Epoch 1021/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 22332094.4456 - val_loss: 1126514862.4658\n",
      "Epoch 1022/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 22809790.7661 - val_loss: 1151508490.5205\n",
      "Epoch 1023/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 31203945.5938 - val_loss: 1138929374.6849\n",
      "Epoch 1024/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 30084863.0865 - val_loss: 1145310574.4658\n",
      "Epoch 1025/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 28108124.7129 - val_loss: 1118876962.1918\n",
      "Epoch 1026/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 23243554.2057 - val_loss: 1121548377.4247\n",
      "Epoch 1027/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 24225429.3059 - val_loss: 1112992228.8219\n",
      "Epoch 1028/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 23877844.7995 - val_loss: 1129306534.5753\n",
      "Epoch 1029/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 19400897.3967 - val_loss: 1126100047.7808\n",
      "Epoch 1030/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 23684619.9486 - val_loss: 1133751723.8356\n",
      "Epoch 1031/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 91556386.2348 - val_loss: 1289652150.3562\n",
      "Epoch 1032/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 128770385.0814 - val_loss: 1125085317.2603\n",
      "Epoch 1033/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 145405193.7892 - val_loss: 1293031038.2466\n",
      "Epoch 1034/5000\n",
      "1167/1167 [==============================] - 0s 281us/step - loss: 139764499.8732 - val_loss: 1235160618.9589\n",
      "Epoch 1035/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 77034039.5647 - val_loss: 1169481375.5616\n",
      "Epoch 1036/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 41755417.9572 - val_loss: 1141091872.4384\n",
      "Epoch 1037/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 42610013.3505 - val_loss: 1158825255.4521\n",
      "Epoch 1038/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 36018336.6495 - val_loss: 1154704268.2740\n",
      "Epoch 1039/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 29378540.6392 - val_loss: 1143017402.7397\n",
      "Epoch 1040/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 30687614.5364 - val_loss: 1142654194.8493\n",
      "Epoch 1041/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 27562663.0711 - val_loss: 1118671172.3836\n",
      "Epoch 1042/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 49077861.7241 - val_loss: 1130170689.7534\n",
      "Epoch 1043/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 35241581.8646 - val_loss: 1134116515.9452\n",
      "Epoch 1044/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 23975957.2219 - val_loss: 1120003512.9863\n",
      "Epoch 1045/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 24078855.5578 - val_loss: 1175043077.2603\n",
      "Epoch 1046/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 34381228.6461 - val_loss: 1147454457.8630\n",
      "Epoch 1047/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 23834218.7181 - val_loss: 1128859627.8356\n",
      "Epoch 1048/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 25500390.4499 - val_loss: 1128192925.8082\n",
      "Epoch 1049/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 27981332.6769 - val_loss: 1146872042.9589\n",
      "Epoch 1050/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 25654924.4507 - val_loss: 1143646400.8767\n",
      "Epoch 1051/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 23984840.1902 - val_loss: 1116403283.2877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1052/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 30751270.3616 - val_loss: 1090957604.8219\n",
      "Epoch 1053/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 44963055.0883 - val_loss: 1138325658.3014\n",
      "Epoch 1054/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 46408109.8989 - val_loss: 1158746346.9589\n",
      "Epoch 1055/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 44158484.7386 - val_loss: 1182063275.8356\n",
      "Epoch 1056/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 44843376.1979 - val_loss: 1072552702.2466\n",
      "Epoch 1057/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 28659469.7566 - val_loss: 1110601993.6438\n",
      "Epoch 1058/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 29914593.4019 - val_loss: 1097413845.0411\n",
      "Epoch 1059/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 29539980.3565 - val_loss: 1111294819.0685\n",
      "Epoch 1060/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 21358800.2554 - val_loss: 1112006413.1507\n",
      "Epoch 1061/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 22815258.6684 - val_loss: 1139971388.4932\n",
      "Epoch 1062/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 25498705.3385 - val_loss: 1120089629.8082\n",
      "Epoch 1063/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 19677755.1011 - val_loss: 1136567497.6438\n",
      "Epoch 1064/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 22825405.4602 - val_loss: 1124578456.5479\n",
      "Epoch 1065/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 22725331.4293 - val_loss: 1137672013.1507\n",
      "Epoch 1066/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 17637078.3308 - val_loss: 1106442055.0137\n",
      "Epoch 1067/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 18864708.5124 - val_loss: 1131460585.2055\n",
      "Epoch 1068/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 32204447.7095 - val_loss: 1100028992.0000\n",
      "Epoch 1069/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 23572667.2048 - val_loss: 1138236800.0000\n",
      "Epoch 1070/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 25164947.6138 - val_loss: 1161987776.8767\n",
      "Epoch 1071/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 52927175.6093 - val_loss: 1176749198.0274\n",
      "Epoch 1072/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 108302175.6727 - val_loss: 1153282831.7808\n",
      "Epoch 1073/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 77726747.3145 - val_loss: 1181300216.9863\n",
      "Epoch 1074/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 95194027.9349 - val_loss: 1074609100.2740\n",
      "Epoch 1075/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 46179588.3573 - val_loss: 1194134869.9178\n",
      "Epoch 1076/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 30797651.1422 - val_loss: 1160123136.0000\n",
      "Epoch 1077/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 32010330.8518 - val_loss: 1133333520.6575\n",
      "Epoch 1078/5000\n",
      "1167/1167 [==============================] - 0s 284us/step - loss: 26854621.0111 - val_loss: 1134568275.2877\n",
      "Epoch 1079/5000\n",
      "1167/1167 [==============================] - 0s 281us/step - loss: 37438252.2005 - val_loss: 1164930232.9863\n",
      "Epoch 1080/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 40398240.8192 - val_loss: 1169938361.8630\n",
      "Epoch 1081/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 58471732.3736 - val_loss: 1149360542.6849\n",
      "Epoch 1082/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 58012848.8723 - val_loss: 1158736701.3699\n",
      "Epoch 1083/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 40174876.8706 - val_loss: 1184455071.5616\n",
      "Epoch 1084/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 55558445.1542 - val_loss: 1175497806.0274\n",
      "Epoch 1085/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 27518777.6881 - val_loss: 1144074573.1507\n",
      "Epoch 1086/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 24770390.6067 - val_loss: 1113453525.0411\n",
      "Epoch 1087/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 18846771.2266 - val_loss: 1126329815.6712\n",
      "Epoch 1088/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 15628158.2228 - val_loss: 1116461476.8219\n",
      "Epoch 1089/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 14774926.9769 - val_loss: 1133595055.3425\n",
      "Epoch 1090/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 15718912.6088 - val_loss: 1138498817.7534\n",
      "Epoch 1091/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 17035272.1063 - val_loss: 1139188414.2466\n",
      "Epoch 1092/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 15126223.9649 - val_loss: 1131764939.3973\n",
      "Epoch 1093/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 14928035.8526 - val_loss: 1141926382.4658\n",
      "Epoch 1094/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 18240171.9949 - val_loss: 1143680601.4247\n",
      "Epoch 1095/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 17741609.4482 - val_loss: 1135495178.5205\n",
      "Epoch 1096/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 25309228.3496 - val_loss: 1117577753.4247\n",
      "Epoch 1097/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 26828812.5484 - val_loss: 1173320409.4247\n",
      "Epoch 1098/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 21983057.5801 - val_loss: 1117206516.6027\n",
      "Epoch 1099/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 17592528.2080 - val_loss: 1155452384.4384\n",
      "Epoch 1100/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 17467199.1225 - val_loss: 1119652675.5068\n",
      "Epoch 1101/5000\n",
      "1167/1167 [==============================] - 0s 285us/step - loss: 21508348.9734 - val_loss: 1165592607.5616\n",
      "Epoch 1102/5000\n",
      "1167/1167 [==============================] - 0s 285us/step - loss: 26229695.3762 - val_loss: 1131555356.9315\n",
      "Epoch 1103/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 34760841.8063 - val_loss: 1149544880.2192\n",
      "Epoch 1104/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 32484970.0377 - val_loss: 1115370022.5753\n",
      "Epoch 1105/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35868030.1320 - val_loss: 1123559900.0548\n",
      "Epoch 1106/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 38901627.1448 - val_loss: 1176882102.3562\n",
      "Epoch 1107/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 27335360.6650 - val_loss: 1155000597.9178\n",
      "Epoch 1108/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35855613.8286 - val_loss: 1111159700.1644\n",
      "Epoch 1109/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 57872059.2151 - val_loss: 1203397526.7945\n",
      "Epoch 1110/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 51596569.9683 - val_loss: 1139763184.2192\n",
      "Epoch 1111/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 194308443.1740 - val_loss: 1172061132.2740\n",
      "Epoch 1112/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 142307007.8800 - val_loss: 1216056520.7671\n",
      "Epoch 1113/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 44711083.8937 - val_loss: 1133977884.9315\n",
      "Epoch 1114/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 39960676.2125 - val_loss: 1146774681.4247\n",
      "Epoch 1115/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 44827437.0797 - val_loss: 1192605327.7808\n",
      "Epoch 1116/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 42750526.7763 - val_loss: 1149198570.0822\n",
      "Epoch 1117/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 31105507.6504 - val_loss: 1121098356.6027\n",
      "Epoch 1118/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 29777339.4105 - val_loss: 1119636564.1644\n",
      "Epoch 1119/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 27101680.9323 - val_loss: 1120452327.4521\n",
      "Epoch 1120/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 33318103.8560 - val_loss: 1134532604.4932\n",
      "Epoch 1121/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 34963384.0686 - val_loss: 1150482625.7534\n",
      "Epoch 1122/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 40914926.0857 - val_loss: 1117156046.0274\n",
      "Epoch 1123/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 25017485.8372 - val_loss: 1098182050.1918\n",
      "Epoch 1124/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 22197141.0883 - val_loss: 1096299119.3425\n",
      "Epoch 1125/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 18125987.7087 - val_loss: 1095873038.9041\n",
      "Epoch 1126/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 30564738.2965 - val_loss: 1146315719.8904\n",
      "Epoch 1127/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 20638942.0060 - val_loss: 1112689948.0548\n",
      "Epoch 1128/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 17394140.4709 - val_loss: 1129055523.9452\n",
      "Epoch 1129/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 14004140.4229 - val_loss: 1131512305.0959\n",
      "Epoch 1130/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 15851821.0171 - val_loss: 1111637237.4795\n",
      "Epoch 1131/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 15006434.1153 - val_loss: 1122593737.6438\n",
      "Epoch 1132/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 14177515.1474 - val_loss: 1120554437.2603\n",
      "Epoch 1133/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 13332851.6093 - val_loss: 1099687539.7260\n",
      "Epoch 1134/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 18842962.5964 - val_loss: 1153729146.7397\n",
      "Epoch 1135/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35761544.1919 - val_loss: 1118719149.5890\n",
      "Epoch 1136/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 32052160.1508 - val_loss: 1135452811.3973\n",
      "Epoch 1137/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 24609381.4276 - val_loss: 1129677589.9178\n",
      "Epoch 1138/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 20396569.1894 - val_loss: 1120868808.7671\n",
      "Epoch 1139/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 20995300.0103 - val_loss: 1130105438.6849\n",
      "Epoch 1140/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 28886196.0874 - val_loss: 1156941047.2329\n",
      "Epoch 1141/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 26397052.6727 - val_loss: 1098477860.8219\n",
      "Epoch 1142/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 27979169.8475 - val_loss: 1142066281.2055\n",
      "Epoch 1143/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 47987806.8895 - val_loss: 1122083258.7397\n",
      "Epoch 1144/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 45177550.5570 - val_loss: 1088781675.8356\n",
      "Epoch 1145/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 31015115.6230 - val_loss: 1160105398.3562\n",
      "Epoch 1146/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 30848638.4884 - val_loss: 1112995989.9178\n",
      "Epoch 1147/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 22399223.6367 - val_loss: 1124660067.9452\n",
      "Epoch 1148/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 19215903.0081 - val_loss: 1087527338.0822\n",
      "Epoch 1149/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 19361565.5818 - val_loss: 1124505134.4658\n",
      "Epoch 1150/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 20550393.0240 - val_loss: 1124265837.5890\n",
      "Epoch 1151/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 17115890.9486 - val_loss: 1139066221.5890\n",
      "Epoch 1152/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36449050.0240 - val_loss: 1168202159.3425\n",
      "Epoch 1153/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 24953970.3805 - val_loss: 1146718566.5753\n",
      "Epoch 1154/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 41484960.1919 - val_loss: 1180346292.6027\n",
      "Epoch 1155/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 67879244.5621 - val_loss: 1231995373.5890\n",
      "Epoch 1156/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37845301.6907 - val_loss: 1151984440.1096\n",
      "Epoch 1157/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 42815776.2536 - val_loss: 1147659608.5479\n",
      "Epoch 1158/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 38207116.8458 - val_loss: 1089422920.7671\n",
      "Epoch 1159/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 19807956.3616 - val_loss: 1123491055.3425\n",
      "Epoch 1160/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 22062050.1183 - val_loss: 1132718407.8904\n",
      "Epoch 1161/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 19968105.5900 - val_loss: 1114120916.1644\n",
      "Epoch 1162/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 25469346.1422 - val_loss: 1115315586.6301\n",
      "Epoch 1163/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 41718284.9769 - val_loss: 1241851652.3836\n",
      "Epoch 1164/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 67193214.4182 - val_loss: 1186960794.3014\n",
      "Epoch 1165/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 31208994.8175 - val_loss: 1094643384.1096\n",
      "Epoch 1166/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 26330905.7001 - val_loss: 1119523450.7397\n",
      "Epoch 1167/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 32522631.6367 - val_loss: 1095289351.0137\n",
      "Epoch 1168/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35805292.6375 - val_loss: 1126518189.5890\n",
      "Epoch 1169/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 21715429.5921 - val_loss: 1189239058.4110\n",
      "Epoch 1170/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 18884855.3282 - val_loss: 1075034877.3699\n",
      "Epoch 1171/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 32285124.8312 - val_loss: 1137862647.2329\n",
      "Epoch 1172/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 21891673.6375 - val_loss: 1101476643.0685\n",
      "Epoch 1173/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 26763621.1534 - val_loss: 1139393938.4110\n",
      "Epoch 1174/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 23265815.7224 - val_loss: 1088230499.9452\n",
      "Epoch 1175/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 25274268.1971 - val_loss: 1141593447.4521\n",
      "Epoch 1176/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 27493318.0428 - val_loss: 1128283568.2192\n",
      "Epoch 1177/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 26001930.4027 - val_loss: 1111727161.8630\n",
      "Epoch 1178/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 21738543.1071 - val_loss: 1127099378.8493\n",
      "Epoch 1179/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 40382060.8723 - val_loss: 1175829212.9315\n",
      "Epoch 1180/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 29750693.3025 - val_loss: 1144482111.1233\n",
      "Epoch 1181/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 45955308.7609 - val_loss: 1158492244.1644\n",
      "Epoch 1182/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 245us/step - loss: 42876121.4567 - val_loss: 1084803787.3973\n",
      "Epoch 1183/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 24565584.0814 - val_loss: 1083520358.5753\n",
      "Epoch 1184/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 16331722.8406 - val_loss: 1093156755.2877\n",
      "Epoch 1185/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 14747852.7138 - val_loss: 1115358248.3288\n",
      "Epoch 1186/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13826490.6949 - val_loss: 1119260789.4795\n",
      "Epoch 1187/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13148148.8368 - val_loss: 1104247859.7260\n",
      "Epoch 1188/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 25940449.0506 - val_loss: 1112634352.2192\n",
      "Epoch 1189/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 18607635.2142 - val_loss: 1140165269.0411\n",
      "Epoch 1190/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 18465164.1200 - val_loss: 1130621044.6027\n",
      "Epoch 1191/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 25305071.7943 - val_loss: 1101904967.0137\n",
      "Epoch 1192/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 19397081.3985 - val_loss: 1118383072.4384\n",
      "Epoch 1193/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13979576.5647 - val_loss: 1119990627.0685\n",
      "Epoch 1194/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 19551506.1414 - val_loss: 1147462528.8767\n",
      "Epoch 1195/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 39398400.4627 - val_loss: 1180988801.7534\n",
      "Epoch 1196/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 23754998.9803 - val_loss: 1094763891.7260\n",
      "Epoch 1197/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 15950679.8453 - val_loss: 1115313439.5616\n",
      "Epoch 1198/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 14994410.0557 - val_loss: 1120271424.0000\n",
      "Epoch 1199/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16422905.1962 - val_loss: 1117484011.8356\n",
      "Epoch 1200/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 15410229.8269 - val_loss: 1128591169.7534\n",
      "Epoch 1201/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 23433038.9537 - val_loss: 1117886362.3014\n",
      "Epoch 1202/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 30352556.4696 - val_loss: 1098994112.0000\n",
      "Epoch 1203/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 17719428.0943 - val_loss: 1108163499.8356\n",
      "Epoch 1204/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 25128015.1277 - val_loss: 1076600791.6712\n",
      "Epoch 1205/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 54312868.5827 - val_loss: 1170263697.5342\n",
      "Epoch 1206/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 88408284.8980 - val_loss: 1151039610.7397\n",
      "Epoch 1207/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 46152772.8432 - val_loss: 1139483765.4795\n",
      "Epoch 1208/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 101021285.4773 - val_loss: 1169744910.0274\n",
      "Epoch 1209/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 59687503.6332 - val_loss: 1206255170.6301\n",
      "Epoch 1210/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 82096084.9220 - val_loss: 1133457256.3288\n",
      "Epoch 1211/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 124969557.1654 - val_loss: 1130466531.0685\n",
      "Epoch 1212/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 46402266.1457 - val_loss: 1139498914.1918\n",
      "Epoch 1213/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 49421553.8458 - val_loss: 1130654018.6301\n",
      "Epoch 1214/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26972131.3093 - val_loss: 1081885643.3973\n",
      "Epoch 1215/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 28038691.1662 - val_loss: 1118728604.0548\n",
      "Epoch 1216/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35913713.3847 - val_loss: 1099390865.5342\n",
      "Epoch 1217/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 20046368.8462 - val_loss: 1121173582.0274\n",
      "Epoch 1218/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13176332.2194 - val_loss: 1120605943.2329\n",
      "Epoch 1219/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 16553452.7986 - val_loss: 1099733812.6027\n",
      "Epoch 1220/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 15444406.5690 - val_loss: 1127858459.1781\n",
      "Epoch 1221/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 21294674.6367 - val_loss: 1119606795.3973\n",
      "Epoch 1222/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 21158155.8955 - val_loss: 1125712010.5205\n",
      "Epoch 1223/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 18185700.9015 - val_loss: 1106180415.1233\n",
      "Epoch 1224/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 26876054.7935 - val_loss: 1150306831.7808\n",
      "Epoch 1225/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 25441227.6778 - val_loss: 1104413091.9452\n",
      "Epoch 1226/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 21241197.5424 - val_loss: 1102166789.2603\n",
      "Epoch 1227/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 16587249.4893 - val_loss: 1093755597.1507\n",
      "Epoch 1228/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 18490686.8852 - val_loss: 1123875062.3562\n",
      "Epoch 1229/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 24244239.2693 - val_loss: 1092204416.8767\n",
      "Epoch 1230/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 28463927.9469 - val_loss: 1115953026.6301\n",
      "Epoch 1231/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 25709756.1688 - val_loss: 1142467612.9315\n",
      "Epoch 1232/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 15810187.3680 - val_loss: 1110898256.6575\n",
      "Epoch 1233/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 16130108.3548 - val_loss: 1119273115.1781\n",
      "Epoch 1234/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 18288481.5887 - val_loss: 1088195496.3288\n",
      "Epoch 1235/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 13748642.0069 - val_loss: 1084148155.6164\n",
      "Epoch 1236/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 15563905.5424 - val_loss: 1124504535.6712\n",
      "Epoch 1237/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 47086417.7258 - val_loss: 1109362818.6301\n",
      "Epoch 1238/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 26704487.1431 - val_loss: 1096323662.9041\n",
      "Epoch 1239/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 47937411.0026 - val_loss: 1136450975.5616\n",
      "Epoch 1240/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 34558769.6572 - val_loss: 1161891070.2466\n",
      "Epoch 1241/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 38777360.6572 - val_loss: 1155135003.1781\n",
      "Epoch 1242/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 45251610.8218 - val_loss: 1167993399.2329\n",
      "Epoch 1243/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37649879.6847 - val_loss: 1146305270.7945\n",
      "Epoch 1244/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 39567932.1611 - val_loss: 1119317129.6438\n",
      "Epoch 1245/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 27348482.7121 - val_loss: 1160750352.6575\n",
      "Epoch 1246/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 20753225.6127 - val_loss: 1136980530.8493\n",
      "Epoch 1247/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 28933041.8063 - val_loss: 1187324239.7808\n",
      "Epoch 1248/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 30783929.3950 - val_loss: 1135165614.4658\n",
      "Epoch 1249/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 20319082.6581 - val_loss: 1112639317.9178\n",
      "Epoch 1250/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 25192840.7541 - val_loss: 1141835578.7397\n",
      "Epoch 1251/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 17552724.6898 - val_loss: 1115147565.5890\n",
      "Epoch 1252/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 20066659.7275 - val_loss: 1128108791.2329\n",
      "Epoch 1253/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 30846191.6641 - val_loss: 1154445418.0822\n",
      "Epoch 1254/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 24157389.2896 - val_loss: 1117070257.9726\n",
      "Epoch 1255/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 14277447.1727 - val_loss: 1145038297.4247\n",
      "Epoch 1256/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 20294455.0026 - val_loss: 1116864946.8493\n",
      "Epoch 1257/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 17712376.3993 - val_loss: 1107075650.6301\n",
      "Epoch 1258/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 16512208.3492 - val_loss: 1138257676.2740\n",
      "Epoch 1259/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 16597713.3740 - val_loss: 1120141939.7260\n",
      "Epoch 1260/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 21499879.4413 - val_loss: 1117668932.3836\n",
      "Epoch 1261/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 16921248.4799 - val_loss: 1112293916.0548\n",
      "Epoch 1262/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 13214156.1560 - val_loss: 1114985376.4384\n",
      "Epoch 1263/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 20282177.2048 - val_loss: 1140474645.0411\n",
      "Epoch 1264/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 18509170.5716 - val_loss: 1087386976.4384\n",
      "Epoch 1265/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 19250378.6221 - val_loss: 1150376083.2877\n",
      "Epoch 1266/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 20399183.2579 - val_loss: 1116373319.0137\n",
      "Epoch 1267/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 16943635.0917 - val_loss: 1126978432.8767\n",
      "Epoch 1268/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 20599922.7875 - val_loss: 1101330904.5479\n",
      "Epoch 1269/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 32307360.6418 - val_loss: 1087562710.7945\n",
      "Epoch 1270/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 19289213.8449 - val_loss: 1122468890.3014\n",
      "Epoch 1271/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 21869836.5493 - val_loss: 1155526189.5890\n",
      "Epoch 1272/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 14778422.6778 - val_loss: 1127754139.1781\n",
      "Epoch 1273/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 12877301.2279 - val_loss: 1132951645.8082\n",
      "Epoch 1274/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 27594526.6084 - val_loss: 1135902881.3151\n",
      "Epoch 1275/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 153280956.1645 - val_loss: 1177093405.8082\n",
      "Epoch 1276/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 176941219.6949 - val_loss: 1227321976.9863\n",
      "Epoch 1277/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 154356987.8800 - val_loss: 1232888400.6575\n",
      "Epoch 1278/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 47713079.5064 - val_loss: 1158767732.6027\n",
      "Epoch 1279/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 23263946.8466 - val_loss: 1147092334.4658\n",
      "Epoch 1280/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16107402.3393 - val_loss: 1127247973.6986\n",
      "Epoch 1281/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 14819503.7841 - val_loss: 1154231592.3288\n",
      "Epoch 1282/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 13090509.1058 - val_loss: 1125716174.0274\n",
      "Epoch 1283/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 16056339.8676 - val_loss: 1135306816.8767\n",
      "Epoch 1284/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11726159.2798 - val_loss: 1129410396.0548\n",
      "Epoch 1285/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 11621666.7292 - val_loss: 1143783440.6575\n",
      "Epoch 1286/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 9831441.4554 - val_loss: 1133501681.0959\n",
      "Epoch 1287/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10040490.7177 - val_loss: 1134801280.8767\n",
      "Epoch 1288/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 10352672.2785 - val_loss: 1156797901.1507\n",
      "Epoch 1289/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 12619265.4252 - val_loss: 1115656943.3425\n",
      "Epoch 1290/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 12615679.8267 - val_loss: 1149554689.7534\n",
      "Epoch 1291/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 11404809.3509 - val_loss: 1130797924.8219\n",
      "Epoch 1292/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 9724365.8423 - val_loss: 1129124913.9726\n",
      "Epoch 1293/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 10378831.7198 - val_loss: 1133114474.0822\n",
      "Epoch 1294/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9910377.0908 - val_loss: 1110054198.3562\n",
      "Epoch 1295/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 22525734.4130 - val_loss: 1144465962.9589\n",
      "Epoch 1296/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 48151962.5124 - val_loss: 1138224241.9726\n",
      "Epoch 1297/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 40633303.3128 - val_loss: 1169250519.6712\n",
      "Epoch 1298/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 39016189.2991 - val_loss: 1121140381.8082\n",
      "Epoch 1299/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 72237888.6033 - val_loss: 1112039576.5479\n",
      "Epoch 1300/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 94955649.0865 - val_loss: 1128209528.1096\n",
      "Epoch 1301/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 61770787.4070 - val_loss: 1143279432.7671\n",
      "Epoch 1302/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 59738861.5973 - val_loss: 1236035201.7534\n",
      "Epoch 1303/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 59042679.6949 - val_loss: 1120147119.3425\n",
      "Epoch 1304/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26690957.2202 - val_loss: 1120935223.2329\n",
      "Epoch 1305/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 19615965.2965 - val_loss: 1147464015.7808\n",
      "Epoch 1306/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35164821.2365 - val_loss: 1145479315.2877\n",
      "Epoch 1307/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 42392244.4901 - val_loss: 1106126324.6027\n",
      "Epoch 1308/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 47286855.9957 - val_loss: 1144036310.7945\n",
      "Epoch 1309/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 18356943.3290 - val_loss: 1118247957.0411\n",
      "Epoch 1310/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 11300223.4559 - val_loss: 1111598202.7397\n",
      "Epoch 1311/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13700513.1525 - val_loss: 1097712872.3288\n",
      "Epoch 1312/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 247us/step - loss: 11028606.6418 - val_loss: 1110601646.4658\n",
      "Epoch 1313/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10360257.1444 - val_loss: 1132017834.0822\n",
      "Epoch 1314/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 11442833.6452 - val_loss: 1110544982.7945\n",
      "Epoch 1315/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11030233.2254 - val_loss: 1141942926.0274\n",
      "Epoch 1316/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 13369590.2476 - val_loss: 1107885276.0548\n",
      "Epoch 1317/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 12728887.6967 - val_loss: 1123307478.7945\n",
      "Epoch 1318/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 14082666.5321 - val_loss: 1117360778.5205\n",
      "Epoch 1319/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35082929.7369 - val_loss: 1110599018.9589\n",
      "Epoch 1320/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 22202811.0728 - val_loss: 1130144271.7808\n",
      "Epoch 1321/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 17142382.6135 - val_loss: 1125428632.5479\n",
      "Epoch 1322/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15018862.4781 - val_loss: 1118327452.0548\n",
      "Epoch 1323/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11067768.1684 - val_loss: 1099642822.1370\n",
      "Epoch 1324/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11571400.0977 - val_loss: 1119765562.7397\n",
      "Epoch 1325/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 15029978.3873 - val_loss: 1111582295.6712\n",
      "Epoch 1326/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 22869212.4216 - val_loss: 1146625455.3425\n",
      "Epoch 1327/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 20015439.6778 - val_loss: 1063260249.4247\n",
      "Epoch 1328/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 15060465.9272 - val_loss: 1119820954.3014\n",
      "Epoch 1329/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13969140.6341 - val_loss: 1113475285.0411\n",
      "Epoch 1330/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 15554317.3693 - val_loss: 1126643249.0959\n",
      "Epoch 1331/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11451839.8535 - val_loss: 1097769102.0274\n",
      "Epoch 1332/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 11944814.0433 - val_loss: 1127988855.2329\n",
      "Epoch 1333/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9658797.4319 - val_loss: 1115497633.3151\n",
      "Epoch 1334/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 14143229.5583 - val_loss: 1099534023.8904\n",
      "Epoch 1335/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13258009.2406 - val_loss: 1098885047.2329\n",
      "Epoch 1336/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13486046.9494 - val_loss: 1108538634.5205\n",
      "Epoch 1337/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 13863780.3811 - val_loss: 1091334659.5068\n",
      "Epoch 1338/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 13546499.0908 - val_loss: 1138759667.7260\n",
      "Epoch 1339/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 16652783.5698 - val_loss: 1148552621.5890\n",
      "Epoch 1340/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 21746529.7207 - val_loss: 1124489002.0822\n",
      "Epoch 1341/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 22097508.7455 - val_loss: 1077200718.0274\n",
      "Epoch 1342/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 17388334.9460 - val_loss: 1094967153.9726\n",
      "Epoch 1343/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 16173499.5338 - val_loss: 1097802563.5068\n",
      "Epoch 1344/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 18684262.0870 - val_loss: 1111268985.8630\n",
      "Epoch 1345/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 15255639.2614 - val_loss: 1125652139.8356\n",
      "Epoch 1346/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 21213917.4961 - val_loss: 1113316825.4247\n",
      "Epoch 1347/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 24567719.9109 - val_loss: 1169845919.5616\n",
      "Epoch 1348/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 31138724.4987 - val_loss: 1142132892.0548\n",
      "Epoch 1349/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16630170.6769 - val_loss: 1105970541.5890\n",
      "Epoch 1350/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 19088064.1028 - val_loss: 1161055118.0274\n",
      "Epoch 1351/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 40533078.9220 - val_loss: 1124741877.4795\n",
      "Epoch 1352/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 72744647.3488 - val_loss: 1118574461.3699\n",
      "Epoch 1353/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 274840399.6298 - val_loss: 1258376681.6438\n",
      "Epoch 1354/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 309544743.3213 - val_loss: 1295364296.7671\n",
      "Epoch 1355/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 136545136.6375 - val_loss: 1118380341.9178\n",
      "Epoch 1356/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 55207602.9237 - val_loss: 1138941348.8219\n",
      "Epoch 1357/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 27759070.0840 - val_loss: 1105662936.5479\n",
      "Epoch 1358/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 20066528.9409 - val_loss: 1093796389.6986\n",
      "Epoch 1359/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 15632807.1568 - val_loss: 1121310126.4658\n",
      "Epoch 1360/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 21808215.6949 - val_loss: 1111131192.9863\n",
      "Epoch 1361/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26503896.1594 - val_loss: 1115125895.8904\n",
      "Epoch 1362/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 18918057.3710 - val_loss: 1122656220.0548\n",
      "Epoch 1363/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 13955825.2913 - val_loss: 1100781417.2055\n",
      "Epoch 1364/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 15144912.9297 - val_loss: 1148454924.2740\n",
      "Epoch 1365/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 11505557.6435 - val_loss: 1101313021.3699\n",
      "Epoch 1366/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 11012394.6684 - val_loss: 1104419192.9863\n",
      "Epoch 1367/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8040509.0180 - val_loss: 1117080039.4521\n",
      "Epoch 1368/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8308120.2682 - val_loss: 1110359438.0274\n",
      "Epoch 1369/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 10437558.3346 - val_loss: 1093412856.9863\n",
      "Epoch 1370/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 9716807.7074 - val_loss: 1118892580.8219\n",
      "Epoch 1371/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 7653673.5471 - val_loss: 1113278693.6986\n",
      "Epoch 1372/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 7467085.3560 - val_loss: 1106808560.2192\n",
      "Epoch 1373/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8379073.0630 - val_loss: 1110831985.0959\n",
      "Epoch 1374/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 9763545.2091 - val_loss: 1113550577.9726\n",
      "Epoch 1375/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 11697709.4790 - val_loss: 1112883400.7671\n",
      "Epoch 1376/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13888198.7129 - val_loss: 1112186555.6164\n",
      "Epoch 1377/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 15050331.9195 - val_loss: 1101005089.3151\n",
      "Epoch 1378/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 12653069.9469 - val_loss: 1096993400.9863\n",
      "Epoch 1379/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 17124064.6435 - val_loss: 1115842952.7671\n",
      "Epoch 1380/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 16842715.7635 - val_loss: 1123676968.3288\n",
      "Epoch 1381/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 31427483.3033 - val_loss: 1098728233.2055\n",
      "Epoch 1382/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 22071737.9143 - val_loss: 1148756890.3014\n",
      "Epoch 1383/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 31554385.3659 - val_loss: 1152497870.9041\n",
      "Epoch 1384/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 62585903.3162 - val_loss: 1097929939.2877\n",
      "Epoch 1385/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 27286175.3933 - val_loss: 1115359698.4110\n",
      "Epoch 1386/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 23831095.2254 - val_loss: 1142159203.9452\n",
      "Epoch 1387/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 20304286.6744 - val_loss: 1141037242.7397\n",
      "Epoch 1388/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 33600906.6358 - val_loss: 1110692726.3562\n",
      "Epoch 1389/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 20716566.8085 - val_loss: 1122127262.6849\n",
      "Epoch 1390/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11128028.0111 - val_loss: 1089428733.3699\n",
      "Epoch 1391/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 12985786.4302 - val_loss: 1103682854.5753\n",
      "Epoch 1392/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 14813306.6375 - val_loss: 1112985351.8904\n",
      "Epoch 1393/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 10443268.9109 - val_loss: 1103032451.5068\n",
      "Epoch 1394/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 14029858.3976 - val_loss: 1086662926.9041\n",
      "Epoch 1395/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 12449814.0724 - val_loss: 1119388653.5890\n",
      "Epoch 1396/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12103191.7224 - val_loss: 1098655683.5068\n",
      "Epoch 1397/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 11742347.6362 - val_loss: 1109877281.3151\n",
      "Epoch 1398/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8778836.8175 - val_loss: 1113713045.9178\n",
      "Epoch 1399/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15622155.8655 - val_loss: 1100467925.0411\n",
      "Epoch 1400/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12384446.9871 - val_loss: 1095739479.6712\n",
      "Epoch 1401/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13960439.4023 - val_loss: 1076907932.0548\n",
      "Epoch 1402/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 12325448.3665 - val_loss: 1103802932.6027\n",
      "Epoch 1403/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 10171185.1401 - val_loss: 1103600312.9863\n",
      "Epoch 1404/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 12711669.6140 - val_loss: 1063764809.6438\n",
      "Epoch 1405/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11558430.8226 - val_loss: 1140049758.6849\n",
      "Epoch 1406/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 35308065.9709 - val_loss: 1092765333.0411\n",
      "Epoch 1407/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 38687660.8946 - val_loss: 1147744309.4795\n",
      "Epoch 1408/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 24032247.2168 - val_loss: 1109262865.5342\n",
      "Epoch 1409/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 33708054.5433 - val_loss: 1187000298.9589\n",
      "Epoch 1410/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37166258.2108 - val_loss: 1074713826.1918\n",
      "Epoch 1411/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 20802525.4824 - val_loss: 1113993462.3562\n",
      "Epoch 1412/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 42752601.2442 - val_loss: 1130996050.4110\n",
      "Epoch 1413/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 54066519.1705 - val_loss: 1146258319.7808\n",
      "Epoch 1414/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 92786238.0394 - val_loss: 1122977352.7671\n",
      "Epoch 1415/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 55111112.6512 - val_loss: 1078113917.3699\n",
      "Epoch 1416/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 24486030.2956 - val_loss: 1065403826.8493\n",
      "Epoch 1417/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 13640110.4696 - val_loss: 1088027978.5205\n",
      "Epoch 1418/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 23797515.8479 - val_loss: 1067794557.3699\n",
      "Epoch 1419/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13085170.8783 - val_loss: 1112472602.3014\n",
      "Epoch 1420/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 22514052.8055 - val_loss: 1140592858.3014\n",
      "Epoch 1421/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 18827126.2074 - val_loss: 1097261269.0411\n",
      "Epoch 1422/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 18999586.1071 - val_loss: 1103070188.7123\n",
      "Epoch 1423/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 12318144.0600 - val_loss: 1107739568.2192\n",
      "Epoch 1424/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10773783.7605 - val_loss: 1063428211.7260\n",
      "Epoch 1425/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 11666640.6230 - val_loss: 1065575592.3288\n",
      "Epoch 1426/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9697985.3183 - val_loss: 1100449453.5890\n",
      "Epoch 1427/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7968341.6941 - val_loss: 1084098851.9452\n",
      "Epoch 1428/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 9347250.0484 - val_loss: 1097211912.7671\n",
      "Epoch 1429/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 12631953.4559 - val_loss: 1095759130.3014\n",
      "Epoch 1430/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11313344.5895 - val_loss: 1098675028.1644\n",
      "Epoch 1431/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 12757158.3428 - val_loss: 1083648036.8219\n",
      "Epoch 1432/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10775408.0283 - val_loss: 1091058533.6986\n",
      "Epoch 1433/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9548541.6093 - val_loss: 1070184868.8219\n",
      "Epoch 1434/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 28865184.0925 - val_loss: 1092372669.3699\n",
      "Epoch 1435/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 24078856.4764 - val_loss: 1087972000.4384\n",
      "Epoch 1436/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14938577.2991 - val_loss: 1098488042.0822\n",
      "Epoch 1437/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12005505.5356 - val_loss: 1074221073.5342\n",
      "Epoch 1438/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 17577317.6915 - val_loss: 1096639443.2877\n",
      "Epoch 1439/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 14282265.0900 - val_loss: 1115025043.2877\n",
      "Epoch 1440/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 13183640.2776 - val_loss: 1082125364.6027\n",
      "Epoch 1441/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 10950548.2901 - val_loss: 1113889340.4932\n",
      "Epoch 1442/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 244us/step - loss: 13729251.5338 - val_loss: 1087362012.0548\n",
      "Epoch 1443/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 14963683.6487 - val_loss: 1144302942.6849\n",
      "Epoch 1444/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 27605858.4319 - val_loss: 1086227657.6438\n",
      "Epoch 1445/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 19309229.4542 - val_loss: 1125622855.0137\n",
      "Epoch 1446/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 23378653.5373 - val_loss: 1123775892.1644\n",
      "Epoch 1447/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16100282.0197 - val_loss: 1106991535.3425\n",
      "Epoch 1448/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 13403285.3762 - val_loss: 1088422408.3288\n",
      "Epoch 1449/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 16618211.0240 - val_loss: 1121403676.9315\n",
      "Epoch 1450/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 62257913.4704 - val_loss: 1101134635.8356\n",
      "Epoch 1451/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 72435124.5604 - val_loss: 1163461020.0548\n",
      "Epoch 1452/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 50757623.1088 - val_loss: 1066713046.3562\n",
      "Epoch 1453/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 73913798.5467 - val_loss: 1141006864.6575\n",
      "Epoch 1454/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 56189662.2879 - val_loss: 1104672551.4521\n",
      "Epoch 1455/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 22856697.7901 - val_loss: 1090783924.6027\n",
      "Epoch 1456/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 19387779.3265 - val_loss: 1097780463.3425\n",
      "Epoch 1457/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 11326431.1598 - val_loss: 1123016033.3151\n",
      "Epoch 1458/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 12607379.3530 - val_loss: 1110337329.0959\n",
      "Epoch 1459/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11336023.7513 - val_loss: 1109271224.9863\n",
      "Epoch 1460/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13146114.4422 - val_loss: 1079856057.8630\n",
      "Epoch 1461/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 12304541.5030 - val_loss: 1100091256.9863\n",
      "Epoch 1462/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 8953893.5561 - val_loss: 1083485366.3562\n",
      "Epoch 1463/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 13042141.4906 - val_loss: 1095100861.3699\n",
      "Epoch 1464/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 22391818.3068 - val_loss: 1099699414.7945\n",
      "Epoch 1465/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12542106.7956 - val_loss: 1105710907.6164\n",
      "Epoch 1466/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9229435.0816 - val_loss: 1083337440.4384\n",
      "Epoch 1467/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6795284.6073 - val_loss: 1114954102.3562\n",
      "Epoch 1468/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 8466717.1654 - val_loss: 1068447149.5890\n",
      "Epoch 1469/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 6517606.7326 - val_loss: 1090280097.3151\n",
      "Epoch 1470/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 20785623.2973 - val_loss: 1105090512.6575\n",
      "Epoch 1471/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 19023403.2560 - val_loss: 1077130652.0548\n",
      "Epoch 1472/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 15298746.8303 - val_loss: 1112390755.0685\n",
      "Epoch 1473/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 21341633.5398 - val_loss: 1103852390.5753\n",
      "Epoch 1474/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 20339960.5330 - val_loss: 1073390408.7671\n",
      "Epoch 1475/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11017467.8723 - val_loss: 1117996768.4384\n",
      "Epoch 1476/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 16264099.3770 - val_loss: 1095061890.6301\n",
      "Epoch 1477/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 14447227.0167 - val_loss: 1113023343.3425\n",
      "Epoch 1478/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 12793663.2579 - val_loss: 1092574805.9178\n",
      "Epoch 1479/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 10660637.5077 - val_loss: 1095380522.0822\n",
      "Epoch 1480/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 10161295.2871 - val_loss: 1109377348.3836\n",
      "Epoch 1481/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 8520244.1118 - val_loss: 1095874798.4658\n",
      "Epoch 1482/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8810272.6804 - val_loss: 1092829427.7260\n",
      "Epoch 1483/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 23420090.1525 - val_loss: 1086470855.0137\n",
      "Epoch 1484/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 71538080.6787 - val_loss: 1186069788.9315\n",
      "Epoch 1485/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 122991113.7686 - val_loss: 1061638986.0822\n",
      "Epoch 1486/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 52264186.4953 - val_loss: 1121741671.4521\n",
      "Epoch 1487/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 53636393.8303 - val_loss: 1198436435.2877\n",
      "Epoch 1488/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 72673521.6521 - val_loss: 1107489251.5068\n",
      "Epoch 1489/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 46713845.8338 - val_loss: 1147585078.3562\n",
      "Epoch 1490/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 27904181.2991 - val_loss: 1120043515.6164\n",
      "Epoch 1491/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 22159394.2982 - val_loss: 1098866354.8493\n",
      "Epoch 1492/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 13835313.0386 - val_loss: 1109654419.2877\n",
      "Epoch 1493/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 21464982.1388 - val_loss: 1120942776.1096\n",
      "Epoch 1494/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 15600075.2048 - val_loss: 1090966041.4247\n",
      "Epoch 1495/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9810707.6607 - val_loss: 1098527341.5890\n",
      "Epoch 1496/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8946220.0662 - val_loss: 1104723743.5616\n",
      "Epoch 1497/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8965782.1671 - val_loss: 1100960814.4658\n",
      "Epoch 1498/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8441663.9914 - val_loss: 1096773937.0959\n",
      "Epoch 1499/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12027231.1388 - val_loss: 1094540746.5205\n",
      "Epoch 1500/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8661145.1165 - val_loss: 1114317198.0274\n",
      "Epoch 1501/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12674047.8586 - val_loss: 1076976947.7260\n",
      "Epoch 1502/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 17926741.7763 - val_loss: 1091488312.1096\n",
      "Epoch 1503/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 14138802.7858 - val_loss: 1107076952.5479\n",
      "Epoch 1504/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 11231914.2836 - val_loss: 1101737582.4658\n",
      "Epoch 1505/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12096891.2434 - val_loss: 1098968533.9178\n",
      "Epoch 1506/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11149557.9914 - val_loss: 1112859717.2603\n",
      "Epoch 1507/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13908212.0651 - val_loss: 1114593110.7945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1508/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 13678672.7065 - val_loss: 1113723497.2055\n",
      "Epoch 1509/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 16323103.2665 - val_loss: 1120883825.9726\n",
      "Epoch 1510/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 57884865.8072 - val_loss: 1228788297.6438\n",
      "Epoch 1511/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 60459442.6050 - val_loss: 1147795101.8082\n",
      "Epoch 1512/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 165164216.2674 - val_loss: 1250631815.0137\n",
      "Epoch 1513/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 211534947.5476 - val_loss: 1200890413.5890\n",
      "Epoch 1514/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 75676364.7369 - val_loss: 1113227028.1644\n",
      "Epoch 1515/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 52473151.2459 - val_loss: 1091218991.3425\n",
      "Epoch 1516/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 44188903.1654 - val_loss: 1049431686.1370\n",
      "Epoch 1517/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 16539966.7832 - val_loss: 1087343637.0411\n",
      "Epoch 1518/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 16021845.8149 - val_loss: 1067789724.9315\n",
      "Epoch 1519/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 9886097.8925 - val_loss: 1104078184.3288\n",
      "Epoch 1520/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7782355.9203 - val_loss: 1091485584.6575\n",
      "Epoch 1521/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9760444.3608 - val_loss: 1121387388.4932\n",
      "Epoch 1522/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8616019.6581 - val_loss: 1095709359.3425\n",
      "Epoch 1523/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 10186756.9871 - val_loss: 1095133468.0548\n",
      "Epoch 1524/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9343934.9529 - val_loss: 1088521843.7260\n",
      "Epoch 1525/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8412350.4387 - val_loss: 1090298943.1233\n",
      "Epoch 1526/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 6275219.5343 - val_loss: 1096458649.4247\n",
      "Epoch 1527/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7737673.2485 - val_loss: 1100262894.4658\n",
      "Epoch 1528/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 10465497.2674 - val_loss: 1107825926.1370\n",
      "Epoch 1529/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7722558.8269 - val_loss: 1102670757.6986\n",
      "Epoch 1530/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6466088.0930 - val_loss: 1109106353.0959\n",
      "Epoch 1531/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 5964024.4928 - val_loss: 1102020144.2192\n",
      "Epoch 1532/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6367442.0746 - val_loss: 1086065754.3014\n",
      "Epoch 1533/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5939556.8552 - val_loss: 1105885936.2192\n",
      "Epoch 1534/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6000878.4529 - val_loss: 1098613340.0548\n",
      "Epoch 1535/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 18209749.9057 - val_loss: 1120946552.1096\n",
      "Epoch 1536/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14716308.8655 - val_loss: 1100212954.3014\n",
      "Epoch 1537/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 8674226.0853 - val_loss: 1084726264.1096\n",
      "Epoch 1538/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 8201465.8175 - val_loss: 1098829437.3699\n",
      "Epoch 1539/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 7243082.1650 - val_loss: 1083581508.3836\n",
      "Epoch 1540/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7758841.2468 - val_loss: 1094263395.0685\n",
      "Epoch 1541/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 6064009.7862 - val_loss: 1110113463.2329\n",
      "Epoch 1542/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14701792.5707 - val_loss: 1098576097.3151\n",
      "Epoch 1543/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15951400.5176 - val_loss: 1127659029.0411\n",
      "Epoch 1544/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 18745982.8038 - val_loss: 1088573497.8630\n",
      "Epoch 1545/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 12809495.7901 - val_loss: 1115054450.8493\n",
      "Epoch 1546/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 18688624.9083 - val_loss: 1134890966.7945\n",
      "Epoch 1547/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 17712066.9135 - val_loss: 1165270533.2603\n",
      "Epoch 1548/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 33208431.0077 - val_loss: 1079838661.2603\n",
      "Epoch 1549/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 39006524.9220 - val_loss: 1099307720.7671\n",
      "Epoch 1550/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 26344685.9434 - val_loss: 1099374447.3425\n",
      "Epoch 1551/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 39216067.2082 - val_loss: 1134067518.2466\n",
      "Epoch 1552/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 31011172.3565 - val_loss: 1080685425.9726\n",
      "Epoch 1553/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 19182310.6195 - val_loss: 1111271165.3699\n",
      "Epoch 1554/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 16251032.9340 - val_loss: 1115102715.6164\n",
      "Epoch 1555/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12543749.3207 - val_loss: 1113091018.5205\n",
      "Epoch 1556/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9588571.7470 - val_loss: 1118904890.7397\n",
      "Epoch 1557/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8640312.5626 - val_loss: 1136895332.8219\n",
      "Epoch 1558/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8092247.5144 - val_loss: 1082173973.9178\n",
      "Epoch 1559/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11037163.1063 - val_loss: 1123732500.1644\n",
      "Epoch 1560/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 10424960.0711 - val_loss: 1100980372.1644\n",
      "Epoch 1561/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 8164310.6615 - val_loss: 1100098428.4932\n",
      "Epoch 1562/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 8918377.5231 - val_loss: 1103343127.6712\n",
      "Epoch 1563/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 15977890.5947 - val_loss: 1090950526.2466\n",
      "Epoch 1564/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 30243358.9143 - val_loss: 1109322403.0685\n",
      "Epoch 1565/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 103154549.8509 - val_loss: 1215303751.8904\n",
      "Epoch 1566/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 84281582.8757 - val_loss: 1306804563.2877\n",
      "Epoch 1567/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 136001995.6675 - val_loss: 1123854658.6301\n",
      "Epoch 1568/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 67185417.2665 - val_loss: 1058642733.5890\n",
      "Epoch 1569/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 26635806.1971 - val_loss: 1105284221.3699\n",
      "Epoch 1570/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 16597257.2404 - val_loss: 1092319884.2740\n",
      "Epoch 1571/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 10239462.8899 - val_loss: 1102156516.8219\n",
      "Epoch 1572/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6621736.9666 - val_loss: 1092207537.9726\n",
      "Epoch 1573/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 8262406.5874 - val_loss: 1089886558.6849\n",
      "Epoch 1574/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7551537.0527 - val_loss: 1094759467.8356\n",
      "Epoch 1575/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6659662.5454 - val_loss: 1086499914.5205\n",
      "Epoch 1576/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 7019189.5180 - val_loss: 1083997746.8493\n",
      "Epoch 1577/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7255724.4794 - val_loss: 1105314592.4384\n",
      "Epoch 1578/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 5637661.5360 - val_loss: 1085966110.6849\n",
      "Epoch 1579/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5768298.2905 - val_loss: 1089176949.4795\n",
      "Epoch 1580/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 4896443.8196 - val_loss: 1093667562.9589\n",
      "Epoch 1581/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6795629.2082 - val_loss: 1097412148.6027\n",
      "Epoch 1582/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7651878.3209 - val_loss: 1098971157.0411\n",
      "Epoch 1583/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7126800.2185 - val_loss: 1098536667.1781\n",
      "Epoch 1584/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7789107.2982 - val_loss: 1086644495.7808\n",
      "Epoch 1585/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8456243.0189 - val_loss: 1103226462.6849\n",
      "Epoch 1586/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 9607693.9996 - val_loss: 1097339441.0959\n",
      "Epoch 1587/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 9696580.7284 - val_loss: 1064833525.4795\n",
      "Epoch 1588/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 15536310.7789 - val_loss: 1130633200.2192\n",
      "Epoch 1589/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 9487999.5167 - val_loss: 1087860358.1370\n",
      "Epoch 1590/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 9094465.4867 - val_loss: 1122200545.3151\n",
      "Epoch 1591/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13052155.9692 - val_loss: 1091430692.8219\n",
      "Epoch 1592/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 27482275.9143 - val_loss: 1164356205.5890\n",
      "Epoch 1593/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 34887432.5141 - val_loss: 1135109149.8082\n",
      "Epoch 1594/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 28694883.3599 - val_loss: 1144357876.6027\n",
      "Epoch 1595/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 16878469.8860 - val_loss: 1077087056.6575\n",
      "Epoch 1596/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 13213596.5287 - val_loss: 1118192768.8767\n",
      "Epoch 1597/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 11391574.7515 - val_loss: 1120310572.7123\n",
      "Epoch 1598/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 32942706.5878 - val_loss: 1141876189.8082\n",
      "Epoch 1599/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 18959748.2536 - val_loss: 1130820095.1233\n",
      "Epoch 1600/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 11943619.7237 - val_loss: 1109203732.1644\n",
      "Epoch 1601/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9038316.8147 - val_loss: 1113010266.3014\n",
      "Epoch 1602/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8930728.0771 - val_loss: 1081038890.9589\n",
      "Epoch 1603/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 12396032.0788 - val_loss: 1102099960.9863\n",
      "Epoch 1604/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 40027121.7446 - val_loss: 1109011044.8219\n",
      "Epoch 1605/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 20311375.4276 - val_loss: 1110163694.4658\n",
      "Epoch 1606/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 11401682.2830 - val_loss: 1100006848.0000\n",
      "Epoch 1607/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12101567.9786 - val_loss: 1120051242.9589\n",
      "Epoch 1608/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 61667148.4679 - val_loss: 1161684863.1233\n",
      "Epoch 1609/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 45853381.5424 - val_loss: 1184794382.0274\n",
      "Epoch 1610/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 229562418.0548 - val_loss: 1261376489.2055\n",
      "Epoch 1611/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 212348691.4893 - val_loss: 1181026678.7945\n",
      "Epoch 1612/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 76227542.2382 - val_loss: 1237304530.4110\n",
      "Epoch 1613/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 68066701.9846 - val_loss: 1120523990.7945\n",
      "Epoch 1614/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 56760549.9966 - val_loss: 1123831567.7808\n",
      "Epoch 1615/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 22172902.2087 - val_loss: 1133944435.2877\n",
      "Epoch 1616/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12141981.7506 - val_loss: 1119458600.3288\n",
      "Epoch 1617/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9681944.1176 - val_loss: 1103707702.7945\n",
      "Epoch 1618/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8620403.0176 - val_loss: 1109797386.5205\n",
      "Epoch 1619/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8789612.9546 - val_loss: 1103211761.9726\n",
      "Epoch 1620/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8339511.5454 - val_loss: 1106420767.5616\n",
      "Epoch 1621/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6001279.8329 - val_loss: 1102767861.4795\n",
      "Epoch 1622/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5882921.9966 - val_loss: 1097934759.4521\n",
      "Epoch 1623/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6536080.8265 - val_loss: 1117424973.1507\n",
      "Epoch 1624/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5548725.1450 - val_loss: 1113151541.4795\n",
      "Epoch 1625/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5610011.9332 - val_loss: 1107480879.3425\n",
      "Epoch 1626/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4547387.1943 - val_loss: 1103323199.1233\n",
      "Epoch 1627/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4886826.0129 - val_loss: 1100836800.0000\n",
      "Epoch 1628/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6255910.0977 - val_loss: 1112030203.6164\n",
      "Epoch 1629/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 5360926.3590 - val_loss: 1110382086.1370\n",
      "Epoch 1630/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 6900853.9833 - val_loss: 1120406229.0411\n",
      "Epoch 1631/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7228942.1135 - val_loss: 1117708091.6164\n",
      "Epoch 1632/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8072300.8458 - val_loss: 1112653671.4521\n",
      "Epoch 1633/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5117247.1607 - val_loss: 1111807775.5616\n",
      "Epoch 1634/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8737522.7609 - val_loss: 1114699842.6301\n",
      "Epoch 1635/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9753966.3663 - val_loss: 1126045497.8630\n",
      "Epoch 1636/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14954628.9966 - val_loss: 1117692628.1644\n",
      "Epoch 1637/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 18604009.8698 - val_loss: 1115699463.0137\n",
      "Epoch 1638/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 23106391.0488 - val_loss: 1104537322.0822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1639/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 22330426.3025 - val_loss: 1094460686.0274\n",
      "Epoch 1640/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 24477776.2674 - val_loss: 1104993777.0959\n",
      "Epoch 1641/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 25901277.2434 - val_loss: 1139100338.8493\n",
      "Epoch 1642/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12729128.8021 - val_loss: 1115188092.4932\n",
      "Epoch 1643/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 29592501.4122 - val_loss: 1115371196.4932\n",
      "Epoch 1644/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12554582.1560 - val_loss: 1120507674.3014\n",
      "Epoch 1645/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 19251813.9322 - val_loss: 1081681139.7260\n",
      "Epoch 1646/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11926652.3308 - val_loss: 1112760056.9863\n",
      "Epoch 1647/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 14615488.2159 - val_loss: 1123956344.9863\n",
      "Epoch 1648/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 15408502.5998 - val_loss: 1103647168.8767\n",
      "Epoch 1649/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 13475404.3213 - val_loss: 1108123668.1644\n",
      "Epoch 1650/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 14012733.9597 - val_loss: 1102064868.3836\n",
      "Epoch 1651/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14559509.7939 - val_loss: 1122737523.7260\n",
      "Epoch 1652/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9655219.1165 - val_loss: 1085923155.2877\n",
      "Epoch 1653/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7088209.9822 - val_loss: 1099790432.4384\n",
      "Epoch 1654/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7157954.1307 - val_loss: 1099103206.5753\n",
      "Epoch 1655/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5548066.7631 - val_loss: 1092515490.1918\n",
      "Epoch 1656/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7385916.2637 - val_loss: 1095595450.7397\n",
      "Epoch 1657/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 6830326.7078 - val_loss: 1105069098.0822\n",
      "Epoch 1658/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7804348.1551 - val_loss: 1099214794.5205\n",
      "Epoch 1659/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11898738.5976 - val_loss: 1120101791.5616\n",
      "Epoch 1660/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 7427395.9653 - val_loss: 1078766927.7808\n",
      "Epoch 1661/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6589729.7517 - val_loss: 1096283245.5890\n",
      "Epoch 1662/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6882819.0030 - val_loss: 1094607647.5616\n",
      "Epoch 1663/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8921035.3865 - val_loss: 1100358099.2877\n",
      "Epoch 1664/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 118605886.6564 - val_loss: 1191452539.1781\n",
      "Epoch 1665/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 129279971.4002 - val_loss: 1186611124.6027\n",
      "Epoch 1666/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 57517116.2091 - val_loss: 1145960633.8630\n",
      "Epoch 1667/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 24134951.3488 - val_loss: 1134363690.9589\n",
      "Epoch 1668/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 16308815.5870 - val_loss: 1113635458.6301\n",
      "Epoch 1669/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 12445952.1118 - val_loss: 1110408145.5342\n",
      "Epoch 1670/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 13518119.4027 - val_loss: 1108663121.5342\n",
      "Epoch 1671/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8072986.6392 - val_loss: 1101259178.0822\n",
      "Epoch 1672/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8759940.1919 - val_loss: 1089925235.7260\n",
      "Epoch 1673/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13563388.5544 - val_loss: 1084273020.4932\n",
      "Epoch 1674/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13471732.6358 - val_loss: 1109541766.1370\n",
      "Epoch 1675/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 10131661.1937 - val_loss: 1097856160.4384\n",
      "Epoch 1676/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 9981774.7301 - val_loss: 1104992085.0411\n",
      "Epoch 1677/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 10178418.2091 - val_loss: 1085806879.5616\n",
      "Epoch 1678/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 7768591.7401 - val_loss: 1104692387.9452\n",
      "Epoch 1679/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 7080119.6013 - val_loss: 1106538462.6849\n",
      "Epoch 1680/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5005533.0368 - val_loss: 1093342392.9863\n",
      "Epoch 1681/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 7853105.5621 - val_loss: 1084669830.1370\n",
      "Epoch 1682/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 6845527.1812 - val_loss: 1110782149.2603\n",
      "Epoch 1683/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5524903.5853 - val_loss: 1076076002.1918\n",
      "Epoch 1684/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5698377.3767 - val_loss: 1112053899.3973\n",
      "Epoch 1685/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 7228272.9049 - val_loss: 1076042642.4110\n",
      "Epoch 1686/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 9184216.9424 - val_loss: 1101653077.0411\n",
      "Epoch 1687/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 9778218.0154 - val_loss: 1137011342.9041\n",
      "Epoch 1688/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 18636669.5857 - val_loss: 1098559353.8630\n",
      "Epoch 1689/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9501864.4572 - val_loss: 1093727299.5068\n",
      "Epoch 1690/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7839886.9460 - val_loss: 1081116387.9452\n",
      "Epoch 1691/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8989219.6311 - val_loss: 1106301248.8767\n",
      "Epoch 1692/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8337870.1868 - val_loss: 1080370758.1370\n",
      "Epoch 1693/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 12238219.2808 - val_loss: 1107012664.1096\n",
      "Epoch 1694/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 11524317.8967 - val_loss: 1091363165.8082\n",
      "Epoch 1695/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 11955822.9087 - val_loss: 1110273395.7260\n",
      "Epoch 1696/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 11279420.0043 - val_loss: 1117166442.0822\n",
      "Epoch 1697/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 11917169.8925 - val_loss: 1131230679.6712\n",
      "Epoch 1698/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 8481683.6750 - val_loss: 1080352104.3288\n",
      "Epoch 1699/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 24144666.9083 - val_loss: 1116780487.0137\n",
      "Epoch 1700/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 33740066.7438 - val_loss: 1116465478.1370\n",
      "Epoch 1701/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 26542934.1243 - val_loss: 1105104194.6301\n",
      "Epoch 1702/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 23096424.0990 - val_loss: 1105748430.9041\n",
      "Epoch 1703/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 43548984.8363 - val_loss: 1206437337.4247\n",
      "Epoch 1704/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 52857340.9906 - val_loss: 1053752604.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1705/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 56976710.6084 - val_loss: 1220089849.8630\n",
      "Epoch 1706/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 59202531.6572 - val_loss: 1131359025.0959\n",
      "Epoch 1707/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 29222708.5587 - val_loss: 1133790943.5616\n",
      "Epoch 1708/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 15626075.8235 - val_loss: 1097683382.3562\n",
      "Epoch 1709/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12103535.0394 - val_loss: 1097000155.1781\n",
      "Epoch 1710/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9527770.2502 - val_loss: 1083325219.9452\n",
      "Epoch 1711/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7368943.6979 - val_loss: 1106196304.6575\n",
      "Epoch 1712/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6902295.6422 - val_loss: 1090700335.3425\n",
      "Epoch 1713/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 7253173.5570 - val_loss: 1093705114.3014\n",
      "Epoch 1714/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8455119.3051 - val_loss: 1118054599.8904\n",
      "Epoch 1715/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7594399.9032 - val_loss: 1086739223.6712\n",
      "Epoch 1716/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6526752.8033 - val_loss: 1091544604.0548\n",
      "Epoch 1717/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4894496.7547 - val_loss: 1088988298.5205\n",
      "Epoch 1718/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 5811453.6155 - val_loss: 1107610247.8904\n",
      "Epoch 1719/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8138458.7455 - val_loss: 1068922626.6301\n",
      "Epoch 1720/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 25386618.6341 - val_loss: 1105165321.6438\n",
      "Epoch 1721/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 21116221.1765 - val_loss: 1067989845.9178\n",
      "Epoch 1722/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 21210927.5141 - val_loss: 1105490353.9726\n",
      "Epoch 1723/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12319171.8886 - val_loss: 1143201031.0137\n",
      "Epoch 1724/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 10055619.3753 - val_loss: 1096857737.6438\n",
      "Epoch 1725/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7436775.6568 - val_loss: 1095425994.5205\n",
      "Epoch 1726/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9795818.2014 - val_loss: 1092432904.7671\n",
      "Epoch 1727/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9726442.5283 - val_loss: 1109064626.8493\n",
      "Epoch 1728/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8947497.3331 - val_loss: 1134597173.4795\n",
      "Epoch 1729/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7340160.9530 - val_loss: 1084098810.7397\n",
      "Epoch 1730/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8630512.0913 - val_loss: 1079254045.8082\n",
      "Epoch 1731/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10274370.6384 - val_loss: 1062904132.3836\n",
      "Epoch 1732/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9476251.7815 - val_loss: 1107010610.8493\n",
      "Epoch 1733/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 7365379.3829 - val_loss: 1087299180.7123\n",
      "Epoch 1734/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5881886.8824 - val_loss: 1113081172.1644\n",
      "Epoch 1735/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5205680.9443 - val_loss: 1098707991.6712\n",
      "Epoch 1736/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6359255.5716 - val_loss: 1109878518.3562\n",
      "Epoch 1737/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7260359.9482 - val_loss: 1090603352.5479\n",
      "Epoch 1738/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9381164.1063 - val_loss: 1139748781.5890\n",
      "Epoch 1739/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8746164.7763 - val_loss: 1088074840.5479\n",
      "Epoch 1740/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15330757.2991 - val_loss: 1157979138.6301\n",
      "Epoch 1741/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 77166128.8295 - val_loss: 1223908775.4521\n",
      "Epoch 1742/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 164884748.5518 - val_loss: 1182796564.1644\n",
      "Epoch 1743/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 55673385.6898 - val_loss: 1012073325.1507\n",
      "Epoch 1744/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 47911133.3642 - val_loss: 1103990016.8767\n",
      "Epoch 1745/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 39189715.1782 - val_loss: 1064108241.5342\n",
      "Epoch 1746/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10359143.7123 - val_loss: 1067652043.3973\n",
      "Epoch 1747/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 8243189.8715 - val_loss: 1071833526.3562\n",
      "Epoch 1748/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8685626.8809 - val_loss: 1092747112.3288\n",
      "Epoch 1749/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 6446139.6752 - val_loss: 1080492396.7123\n",
      "Epoch 1750/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6134430.1375 - val_loss: 1068071088.2192\n",
      "Epoch 1751/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6713675.9409 - val_loss: 1073756541.3699\n",
      "Epoch 1752/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8230640.7031 - val_loss: 1087600791.6712\n",
      "Epoch 1753/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5492589.8732 - val_loss: 1070852074.0822\n",
      "Epoch 1754/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10011355.5476 - val_loss: 1131755249.0959\n",
      "Epoch 1755/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 21117793.6607 - val_loss: 1070954106.7397\n",
      "Epoch 1756/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 28817534.0180 - val_loss: 1071608216.5479\n",
      "Epoch 1757/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 18302496.5424 - val_loss: 1064786717.8082\n",
      "Epoch 1758/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11176910.2843 - val_loss: 1045516496.6575\n",
      "Epoch 1759/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 23625067.3582 - val_loss: 1087709589.9178\n",
      "Epoch 1760/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 13833646.3513 - val_loss: 1025918206.2466\n",
      "Epoch 1761/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9476426.8989 - val_loss: 1067431797.4795\n",
      "Epoch 1762/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 11504046.3672 - val_loss: 1078706092.7123\n",
      "Epoch 1763/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6553739.0163 - val_loss: 1066800722.4110\n",
      "Epoch 1764/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5799629.8380 - val_loss: 1091450174.2466\n",
      "Epoch 1765/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7196458.4846 - val_loss: 1063115918.9041\n",
      "Epoch 1766/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5341201.5263 - val_loss: 1097111691.3973\n",
      "Epoch 1767/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5200469.8569 - val_loss: 1063319587.9452\n",
      "Epoch 1768/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 5507731.1148 - val_loss: 1063780278.3562\n",
      "Epoch 1769/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 5442910.1024 - val_loss: 1072158069.4795\n",
      "Epoch 1770/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 15552255.6612 - val_loss: 1100290981.6986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1771/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8205452.3333 - val_loss: 1078098106.7397\n",
      "Epoch 1772/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8119195.0103 - val_loss: 1081697592.9863\n",
      "Epoch 1773/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7314632.1658 - val_loss: 1067105839.3425\n",
      "Epoch 1774/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 7885348.7356 - val_loss: 1070204651.8356\n",
      "Epoch 1775/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5247347.1487 - val_loss: 1081783434.5205\n",
      "Epoch 1776/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4572163.0753 - val_loss: 1072701399.6712\n",
      "Epoch 1777/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6590720.3760 - val_loss: 1076835244.7123\n",
      "Epoch 1778/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10561493.0664 - val_loss: 1085926321.9726\n",
      "Epoch 1779/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10948743.0351 - val_loss: 1103001164.2740\n",
      "Epoch 1780/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 15940006.3590 - val_loss: 1090712712.7671\n",
      "Epoch 1781/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 9216752.6590 - val_loss: 1091086041.4247\n",
      "Epoch 1782/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 14766048.2986 - val_loss: 1123044595.7260\n",
      "Epoch 1783/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 17292992.0120 - val_loss: 1099543244.2740\n",
      "Epoch 1784/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13272198.1611 - val_loss: 1075805827.5068\n",
      "Epoch 1785/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13170353.5848 - val_loss: 1082747111.4521\n",
      "Epoch 1786/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 16611176.8997 - val_loss: 1127444096.0000\n",
      "Epoch 1787/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 14818156.4816 - val_loss: 1088176638.2466\n",
      "Epoch 1788/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13817326.4392 - val_loss: 1116535537.9726\n",
      "Epoch 1789/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 19421827.7901 - val_loss: 1105898743.2329\n",
      "Epoch 1790/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 27261085.0471 - val_loss: 1151585222.1370\n",
      "Epoch 1791/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 59539242.2177 - val_loss: 1131742080.0000\n",
      "Epoch 1792/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 131838409.3368 - val_loss: 1159454430.6849\n",
      "Epoch 1793/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 104335864.2879 - val_loss: 1143174347.3973\n",
      "Epoch 1794/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 78528751.0231 - val_loss: 1025710577.9726\n",
      "Epoch 1795/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 34276871.5818 - val_loss: 1020178960.6575\n",
      "Epoch 1796/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 16777185.7052 - val_loss: 1067159979.8356\n",
      "Epoch 1797/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 21692762.0925 - val_loss: 1049292058.3014\n",
      "Epoch 1798/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 13454853.8329 - val_loss: 1075364409.8630\n",
      "Epoch 1799/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 12595420.9589 - val_loss: 1071188193.3151\n",
      "Epoch 1800/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7544989.8732 - val_loss: 1062705599.1233\n",
      "Epoch 1801/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4383558.2194 - val_loss: 1062914748.4932\n",
      "Epoch 1802/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4979364.6442 - val_loss: 1058182076.4932\n",
      "Epoch 1803/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4934492.0386 - val_loss: 1058552642.6301\n",
      "Epoch 1804/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 6627327.0737 - val_loss: 1061870620.9315\n",
      "Epoch 1805/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7547988.0189 - val_loss: 1056831254.7945\n",
      "Epoch 1806/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8832995.1962 - val_loss: 1034438446.4658\n",
      "Epoch 1807/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 15902649.1945 - val_loss: 1084141302.3562\n",
      "Epoch 1808/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 17312838.2708 - val_loss: 1085771690.9589\n",
      "Epoch 1809/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 16437482.1902 - val_loss: 1055596266.0822\n",
      "Epoch 1810/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 11945782.0274 - val_loss: 1060609922.6301\n",
      "Epoch 1811/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6227613.2811 - val_loss: 1067848087.6712\n",
      "Epoch 1812/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 7244061.8762 - val_loss: 1047939317.4795\n",
      "Epoch 1813/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4635165.3319 - val_loss: 1052123139.5068\n",
      "Epoch 1814/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4080799.4880 - val_loss: 1057890857.2055\n",
      "Epoch 1815/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 4428495.2258 - val_loss: 1059611911.8904\n",
      "Epoch 1816/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 4568262.8500 - val_loss: 1037180162.6301\n",
      "Epoch 1817/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4134416.0900 - val_loss: 1059123697.0959\n",
      "Epoch 1818/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3572869.8713 - val_loss: 1043549345.3151\n",
      "Epoch 1819/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4259158.3282 - val_loss: 1071174016.8767\n",
      "Epoch 1820/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4805313.4891 - val_loss: 1069078196.6027\n",
      "Epoch 1821/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11857527.9263 - val_loss: 1066409503.5616\n",
      "Epoch 1822/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12550290.2348 - val_loss: 1097254110.6849\n",
      "Epoch 1823/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 18969885.7247 - val_loss: 1078622698.0822\n",
      "Epoch 1824/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 9582167.8475 - val_loss: 1042648846.9041\n",
      "Epoch 1825/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8294366.3012 - val_loss: 1052129436.9315\n",
      "Epoch 1826/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7009622.6290 - val_loss: 1034535221.4795\n",
      "Epoch 1827/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9234799.3361 - val_loss: 1050878535.0137\n",
      "Epoch 1828/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 6933751.1954 - val_loss: 1034931560.3288\n",
      "Epoch 1829/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 16808034.9503 - val_loss: 1079276104.7671\n",
      "Epoch 1830/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 74185618.4199 - val_loss: 1119266449.5342\n",
      "Epoch 1831/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 44221425.5664 - val_loss: 1040674516.6027\n",
      "Epoch 1832/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 91683236.2845 - val_loss: 1223886055.4521\n",
      "Epoch 1833/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 60549759.0608 - val_loss: 1100878348.7123\n",
      "Epoch 1834/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 33477328.4302 - val_loss: 1156885434.7397\n",
      "Epoch 1835/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 38574685.8543 - val_loss: 1080776262.1370\n",
      "Epoch 1836/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 18514088.7314 - val_loss: 1095807232.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1837/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 7512702.1645 - val_loss: 1082374723.5068\n",
      "Epoch 1838/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7010214.4677 - val_loss: 1100544652.2740\n",
      "Epoch 1839/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6437318.9083 - val_loss: 1064593837.5890\n",
      "Epoch 1840/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5017906.4431 - val_loss: 1080121648.2192\n",
      "Epoch 1841/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4759776.5908 - val_loss: 1056663438.0274\n",
      "Epoch 1842/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 6905199.0086 - val_loss: 1090110119.4521\n",
      "Epoch 1843/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 7746964.1500 - val_loss: 1103244917.4795\n",
      "Epoch 1844/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8533359.3736 - val_loss: 1086427896.9863\n",
      "Epoch 1845/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8443420.6041 - val_loss: 1068985258.0822\n",
      "Epoch 1846/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6508444.4773 - val_loss: 1091584157.8082\n",
      "Epoch 1847/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5820809.4602 - val_loss: 1051834648.5479\n",
      "Epoch 1848/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 11982525.1791 - val_loss: 1060569831.4521\n",
      "Epoch 1849/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9215726.4936 - val_loss: 1080783048.7671\n",
      "Epoch 1850/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7987330.1317 - val_loss: 1041498987.8356\n",
      "Epoch 1851/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6868444.9160 - val_loss: 1058860369.5342\n",
      "Epoch 1852/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5971927.0120 - val_loss: 1050157401.4247\n",
      "Epoch 1853/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6067941.1018 - val_loss: 1063063687.8904\n",
      "Epoch 1854/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5246290.4739 - val_loss: 1078238271.1233\n",
      "Epoch 1855/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6386009.4850 - val_loss: 1061042589.8082\n",
      "Epoch 1856/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5881340.0936 - val_loss: 1066567313.5342\n",
      "Epoch 1857/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5249140.4458 - val_loss: 1070398239.5616\n",
      "Epoch 1858/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4313358.7738 - val_loss: 1061642328.5479\n",
      "Epoch 1859/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 4317740.8217 - val_loss: 1059936014.9041\n",
      "Epoch 1860/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3680789.1588 - val_loss: 1061726520.1096\n",
      "Epoch 1861/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5453454.2288 - val_loss: 1066525395.2877\n",
      "Epoch 1862/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10381971.6971 - val_loss: 1076855445.9178\n",
      "Epoch 1863/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 12179336.5518 - val_loss: 1084444852.6027\n",
      "Epoch 1864/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 122772603.4756 - val_loss: 1123907862.7945\n",
      "Epoch 1865/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 63459768.2262 - val_loss: 1140627998.6849\n",
      "Epoch 1866/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 49728977.8303 - val_loss: 1072511345.9726\n",
      "Epoch 1867/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37819729.2309 - val_loss: 1115843183.3425\n",
      "Epoch 1868/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 30548096.7069 - val_loss: 1143724380.9315\n",
      "Epoch 1869/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 17193568.6701 - val_loss: 1064398619.1781\n",
      "Epoch 1870/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 9087639.2898 - val_loss: 1072845088.4384\n",
      "Epoch 1871/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 7907558.7515 - val_loss: 1075405037.5890\n",
      "Epoch 1872/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6560024.9673 - val_loss: 1047223391.5616\n",
      "Epoch 1873/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4112496.7246 - val_loss: 1063594478.4658\n",
      "Epoch 1874/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3910768.7704 - val_loss: 1064487397.6986\n",
      "Epoch 1875/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3775835.6868 - val_loss: 1060045882.7397\n",
      "Epoch 1876/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3384288.9429 - val_loss: 1067679573.9178\n",
      "Epoch 1877/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4030005.7965 - val_loss: 1056261357.5890\n",
      "Epoch 1878/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4080002.8479 - val_loss: 1067822134.3562\n",
      "Epoch 1879/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5792329.6482 - val_loss: 1062599503.7808\n",
      "Epoch 1880/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 9507004.9374 - val_loss: 1056770763.3973\n",
      "Epoch 1881/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7319192.5683 - val_loss: 1057602787.0685\n",
      "Epoch 1882/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5192818.2388 - val_loss: 1073699167.5616\n",
      "Epoch 1883/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4806965.2745 - val_loss: 1072749415.4521\n",
      "Epoch 1884/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4354396.4353 - val_loss: 1062155414.7945\n",
      "Epoch 1885/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5579500.4584 - val_loss: 1075582084.3836\n",
      "Epoch 1886/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 10280774.7254 - val_loss: 1040371311.3425\n",
      "Epoch 1887/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12603839.2262 - val_loss: 1067113958.5753\n",
      "Epoch 1888/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8591830.0527 - val_loss: 1079297621.9178\n",
      "Epoch 1889/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8915909.7412 - val_loss: 1060546558.2466\n",
      "Epoch 1890/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 23099622.1988 - val_loss: 1076376662.7945\n",
      "Epoch 1891/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 21442166.8141 - val_loss: 1067962808.1096\n",
      "Epoch 1892/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 26748410.4576 - val_loss: 1079261000.7671\n",
      "Epoch 1893/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 28656327.9122 - val_loss: 1030313679.7808\n",
      "Epoch 1894/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 18840748.4533 - val_loss: 1077250744.9863\n",
      "Epoch 1895/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 13962138.8123 - val_loss: 1037741979.1781\n",
      "Epoch 1896/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 63144979.4876 - val_loss: 1103728606.6849\n",
      "Epoch 1897/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 24304429.9117 - val_loss: 1069175316.1644\n",
      "Epoch 1898/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 12754003.7952 - val_loss: 1083843719.8904\n",
      "Epoch 1899/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7579142.6208 - val_loss: 1055559489.7534\n",
      "Epoch 1900/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7133220.4079 - val_loss: 1076872496.2192\n",
      "Epoch 1901/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4417782.9901 - val_loss: 1063739079.8904\n",
      "Epoch 1902/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5023918.8976 - val_loss: 1038226346.0822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 5887320.4925 - val_loss: 1088944412.0548\n",
      "Epoch 1904/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 9219790.6958 - val_loss: 1082416336.6575\n",
      "Epoch 1905/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 20962851.4567 - val_loss: 1068118939.1781\n",
      "Epoch 1906/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 24325557.6435 - val_loss: 1061872923.1781\n",
      "Epoch 1907/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 13205828.0733 - val_loss: 1077362217.2055\n",
      "Epoch 1908/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 12789830.2305 - val_loss: 1045659214.9041\n",
      "Epoch 1909/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 13824730.7044 - val_loss: 1087424496.2192\n",
      "Epoch 1910/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9537821.4893 - val_loss: 1061353431.6712\n",
      "Epoch 1911/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12221024.8740 - val_loss: 1093499982.9041\n",
      "Epoch 1912/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 16754559.7061 - val_loss: 1044392084.1644\n",
      "Epoch 1913/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 14304696.3350 - val_loss: 1068954143.5616\n",
      "Epoch 1914/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10460334.9152 - val_loss: 1076203595.3973\n",
      "Epoch 1915/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7923645.8522 - val_loss: 1077188049.5342\n",
      "Epoch 1916/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 8180988.2939 - val_loss: 1072229348.8219\n",
      "Epoch 1917/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 8668609.7772 - val_loss: 1075204046.0274\n",
      "Epoch 1918/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9558798.5908 - val_loss: 1089701427.7260\n",
      "Epoch 1919/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12000680.5304 - val_loss: 1084348467.7260\n",
      "Epoch 1920/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 10354050.7772 - val_loss: 1078933909.9178\n",
      "Epoch 1921/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6693907.7256 - val_loss: 1070073944.5479\n",
      "Epoch 1922/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5001762.5664 - val_loss: 1067250733.5890\n",
      "Epoch 1923/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5022985.8869 - val_loss: 1076341085.8082\n",
      "Epoch 1924/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 12016314.8098 - val_loss: 1079972524.7123\n",
      "Epoch 1925/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11409787.2365 - val_loss: 1078980704.4384\n",
      "Epoch 1926/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 17532666.3445 - val_loss: 1102931811.0685\n",
      "Epoch 1927/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 62861394.3445 - val_loss: 1130495716.8219\n",
      "Epoch 1928/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 91584595.1671 - val_loss: 1388374339.5068\n",
      "Epoch 1929/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 239093788.1337 - val_loss: 1194345857.7534\n",
      "Epoch 1930/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 79030287.1020 - val_loss: 1160659623.4521\n",
      "Epoch 1931/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37161202.7009 - val_loss: 1148962851.0685\n",
      "Epoch 1932/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 43752579.5578 - val_loss: 1091577244.4932\n",
      "Epoch 1933/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 19225816.3633 - val_loss: 1139592625.0959\n",
      "Epoch 1934/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9900508.2841 - val_loss: 1074877764.3836\n",
      "Epoch 1935/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 8172596.3955 - val_loss: 1090790169.4247\n",
      "Epoch 1936/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 7000713.5555 - val_loss: 1084240978.4110\n",
      "Epoch 1937/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5949301.7813 - val_loss: 1079146284.7123\n",
      "Epoch 1938/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 4660818.8237 - val_loss: 1084522695.8904\n",
      "Epoch 1939/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 4311586.8361 - val_loss: 1071656909.1507\n",
      "Epoch 1940/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4388916.2436 - val_loss: 1069218602.9589\n",
      "Epoch 1941/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5186275.7288 - val_loss: 1061609457.0959\n",
      "Epoch 1942/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 5574064.8972 - val_loss: 1066761934.0274\n",
      "Epoch 1943/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7059639.6847 - val_loss: 1091470946.1918\n",
      "Epoch 1944/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8887204.5300 - val_loss: 1076119533.5890\n",
      "Epoch 1945/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6398872.0557 - val_loss: 1086241184.4384\n",
      "Epoch 1946/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6923030.8515 - val_loss: 1054160918.7945\n",
      "Epoch 1947/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5889950.4276 - val_loss: 1097130206.6849\n",
      "Epoch 1948/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5013130.8063 - val_loss: 1089595535.7808\n",
      "Epoch 1949/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7426665.4602 - val_loss: 1084051128.9863\n",
      "Epoch 1950/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8801124.7419 - val_loss: 1059044875.3973\n",
      "Epoch 1951/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4383804.6686 - val_loss: 1071818600.3288\n",
      "Epoch 1952/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6437564.9614 - val_loss: 1079696278.7945\n",
      "Epoch 1953/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14054069.7453 - val_loss: 1085386261.9178\n",
      "Epoch 1954/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5755567.1690 - val_loss: 1080189380.3836\n",
      "Epoch 1955/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6145103.1088 - val_loss: 1078017058.1918\n",
      "Epoch 1956/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5851839.3835 - val_loss: 1068550876.9315\n",
      "Epoch 1957/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 5952555.3991 - val_loss: 1065004235.3973\n",
      "Epoch 1958/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6928059.9214 - val_loss: 1059418415.3425\n",
      "Epoch 1959/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7877705.6838 - val_loss: 1085740196.8219\n",
      "Epoch 1960/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8853281.0009 - val_loss: 1063277900.2740\n",
      "Epoch 1961/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7492357.0317 - val_loss: 1083316267.8356\n",
      "Epoch 1962/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6156083.6937 - val_loss: 1064046984.7671\n",
      "Epoch 1963/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4547681.3505 - val_loss: 1086440646.1370\n",
      "Epoch 1964/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4960138.9833 - val_loss: 1084778850.1918\n",
      "Epoch 1965/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 7729576.7162 - val_loss: 1093993694.6849\n",
      "Epoch 1966/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7659055.9687 - val_loss: 1063018480.2192\n",
      "Epoch 1967/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7192655.2018 - val_loss: 1093030077.3699\n",
      "Epoch 1968/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 18000045.5707 - val_loss: 1103155404.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1969/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 15600609.4535 - val_loss: 1103830392.1096\n",
      "Epoch 1970/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 17795639.6495 - val_loss: 1123712847.7808\n",
      "Epoch 1971/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 27160500.6547 - val_loss: 1148149452.2740\n",
      "Epoch 1972/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 31592580.0360 - val_loss: 1087989995.8356\n",
      "Epoch 1973/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 24265599.0326 - val_loss: 1053477165.5890\n",
      "Epoch 1974/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 20358900.2913 - val_loss: 1090115780.3836\n",
      "Epoch 1975/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 21937443.1071 - val_loss: 1049971813.6986\n",
      "Epoch 1976/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 17648567.2279 - val_loss: 998747032.5479\n",
      "Epoch 1977/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 49481595.6230 - val_loss: 1085446221.1507\n",
      "Epoch 1978/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 43532732.5090 - val_loss: 1213561561.4247\n",
      "Epoch 1979/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37428576.2468 - val_loss: 1130605611.8356\n",
      "Epoch 1980/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 28933310.3796 - val_loss: 1056652563.2877\n",
      "Epoch 1981/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 17631866.6877 - val_loss: 1059005565.3699\n",
      "Epoch 1982/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8761318.5467 - val_loss: 1067304378.7397\n",
      "Epoch 1983/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 11526110.7785 - val_loss: 1085393651.7260\n",
      "Epoch 1984/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11514160.3826 - val_loss: 1094540865.7534\n",
      "Epoch 1985/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11786749.1958 - val_loss: 1081376755.7260\n",
      "Epoch 1986/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9781190.5056 - val_loss: 1065021036.7123\n",
      "Epoch 1987/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 7760913.2322 - val_loss: 1060623607.2329\n",
      "Epoch 1988/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9414684.2339 - val_loss: 1072670235.1781\n",
      "Epoch 1989/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 9970511.6354 - val_loss: 1052963544.5479\n",
      "Epoch 1990/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 8721552.3001 - val_loss: 1072181247.1233\n",
      "Epoch 1991/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5658060.5398 - val_loss: 1067013660.0548\n",
      "Epoch 1992/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4689360.3372 - val_loss: 1075207600.2192\n",
      "Epoch 1993/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4272220.6967 - val_loss: 1078072151.6712\n",
      "Epoch 1994/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5347624.9777 - val_loss: 1062503214.4658\n",
      "Epoch 1995/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5132431.3312 - val_loss: 1060351856.2192\n",
      "Epoch 1996/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7551820.3081 - val_loss: 1043443556.8219\n",
      "Epoch 1997/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4457230.6703 - val_loss: 1078086226.4110\n",
      "Epoch 1998/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5059331.7922 - val_loss: 1042535145.2055\n",
      "Epoch 1999/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4575021.6277 - val_loss: 1089237484.7123\n",
      "Epoch 2000/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 6147396.3843 - val_loss: 1066265570.1918\n",
      "Epoch 2001/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12101331.5311 - val_loss: 1100270283.3973\n",
      "Epoch 2002/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 12009032.8509 - val_loss: 1073383654.5753\n",
      "Epoch 2003/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 14625376.5193 - val_loss: 1156435445.4795\n",
      "Epoch 2004/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 40979645.0069 - val_loss: 1097877410.1918\n",
      "Epoch 2005/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 19495720.4156 - val_loss: 1070009280.8767\n",
      "Epoch 2006/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 14079407.6495 - val_loss: 1037228843.8356\n",
      "Epoch 2007/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7018242.0938 - val_loss: 1069074136.5479\n",
      "Epoch 2008/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 5803335.2494 - val_loss: 1073377929.6438\n",
      "Epoch 2009/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7565459.5270 - val_loss: 1049696873.2055\n",
      "Epoch 2010/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 11839202.0686 - val_loss: 1069142471.8904\n",
      "Epoch 2011/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9625885.9657 - val_loss: 1063963513.8630\n",
      "Epoch 2012/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 21208844.2502 - val_loss: 1076797631.1233\n",
      "Epoch 2013/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12868040.9092 - val_loss: 1090459101.8082\n",
      "Epoch 2014/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 10698665.5681 - val_loss: 1045816346.3014\n",
      "Epoch 2015/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 14731407.1251 - val_loss: 1063526924.2740\n",
      "Epoch 2016/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 15094533.6727 - val_loss: 1093255145.2055\n",
      "Epoch 2017/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8944963.3925 - val_loss: 1074392788.1644\n",
      "Epoch 2018/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10138171.5137 - val_loss: 1084391654.5753\n",
      "Epoch 2019/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10302921.3153 - val_loss: 1059081568.4384\n",
      "Epoch 2020/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9020912.5518 - val_loss: 1112645658.3014\n",
      "Epoch 2021/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 28823955.2052 - val_loss: 1101619249.0959\n",
      "Epoch 2022/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 17530939.1003 - val_loss: 1098006976.8767\n",
      "Epoch 2023/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 21693321.9520 - val_loss: 1040288804.8219\n",
      "Epoch 2024/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 101416991.8766 - val_loss: 1183746410.9589\n",
      "Epoch 2025/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 50275795.6555 - val_loss: 1108079639.6712\n",
      "Epoch 2026/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 23878164.9700 - val_loss: 1073750760.3288\n",
      "Epoch 2027/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 14100244.6688 - val_loss: 1057076568.5479\n",
      "Epoch 2028/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 7848706.4653 - val_loss: 1071337920.0000\n",
      "Epoch 2029/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6407692.1007 - val_loss: 1049833382.5753\n",
      "Epoch 2030/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9466677.9923 - val_loss: 1064010925.5890\n",
      "Epoch 2031/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8078050.7991 - val_loss: 1060877724.9315\n",
      "Epoch 2032/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 17406620.4976 - val_loss: 1059647485.3699\n",
      "Epoch 2033/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12885825.5861 - val_loss: 1059853966.0274\n",
      "Epoch 2034/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 11273026.2605 - val_loss: 1075683372.7123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2035/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4747757.4638 - val_loss: 1064577208.9863\n",
      "Epoch 2036/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 4368509.2994 - val_loss: 1063046250.9589\n",
      "Epoch 2037/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4053179.5321 - val_loss: 1067244658.8493\n",
      "Epoch 2038/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3432482.8395 - val_loss: 1078699247.3425\n",
      "Epoch 2039/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3199219.1249 - val_loss: 1058900646.5753\n",
      "Epoch 2040/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3672426.8869 - val_loss: 1080913698.1918\n",
      "Epoch 2041/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4737474.5951 - val_loss: 1058630761.2055\n",
      "Epoch 2042/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3379957.2023 - val_loss: 1073885764.3836\n",
      "Epoch 2043/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3825567.9868 - val_loss: 1057644711.4521\n",
      "Epoch 2044/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4024983.7219 - val_loss: 1064805491.7260\n",
      "Epoch 2045/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6487494.1015 - val_loss: 1054658643.2877\n",
      "Epoch 2046/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6230573.6452 - val_loss: 1073356764.0548\n",
      "Epoch 2047/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5286980.5561 - val_loss: 1058497266.8493\n",
      "Epoch 2048/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7279240.3813 - val_loss: 1060001940.1644\n",
      "Epoch 2049/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7271895.1645 - val_loss: 1084432324.3836\n",
      "Epoch 2050/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6260151.9807 - val_loss: 1071129536.0000\n",
      "Epoch 2051/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 8704381.1688 - val_loss: 1045395399.8904\n",
      "Epoch 2052/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 40941070.7198 - val_loss: 1100945071.3425\n",
      "Epoch 2053/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 38247470.3308 - val_loss: 1150349513.6438\n",
      "Epoch 2054/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 47129127.4979 - val_loss: 1162844416.0000\n",
      "Epoch 2055/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36983648.4216 - val_loss: 1087279571.2877\n",
      "Epoch 2056/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 33299881.8106 - val_loss: 1100492369.5342\n",
      "Epoch 2057/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 16438928.9152 - val_loss: 1081870627.0685\n",
      "Epoch 2058/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11535801.2896 - val_loss: 1069364266.9589\n",
      "Epoch 2059/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14083280.1859 - val_loss: 1097037524.1644\n",
      "Epoch 2060/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 14356510.8278 - val_loss: 1098981379.5068\n",
      "Epoch 2061/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12916915.6727 - val_loss: 1070722979.0685\n",
      "Epoch 2062/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6933544.3046 - val_loss: 1091933554.8493\n",
      "Epoch 2063/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8274998.6560 - val_loss: 1083915129.8630\n",
      "Epoch 2064/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7355825.6744 - val_loss: 1075015964.9315\n",
      "Epoch 2065/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7615259.5895 - val_loss: 1059939107.0685\n",
      "Epoch 2066/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5968478.6975 - val_loss: 1070433637.6986\n",
      "Epoch 2067/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 5380043.0058 - val_loss: 1071671957.0411\n",
      "Epoch 2068/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5503102.7704 - val_loss: 1088188122.3014\n",
      "Epoch 2069/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12297838.2211 - val_loss: 1145434582.7945\n",
      "Epoch 2070/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 30010317.5184 - val_loss: 1121507324.9315\n",
      "Epoch 2071/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 41508862.4130 - val_loss: 1081605771.3973\n",
      "Epoch 2072/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 38491002.4404 - val_loss: 1066198680.5479\n",
      "Epoch 2073/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 12944835.2691 - val_loss: 1062460124.0548\n",
      "Epoch 2074/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 7300174.7939 - val_loss: 1068520202.5205\n",
      "Epoch 2075/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 5480744.2457 - val_loss: 1050039335.4521\n",
      "Epoch 2076/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 5453824.7386 - val_loss: 1075512317.3699\n",
      "Epoch 2077/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 6658331.4622 - val_loss: 1061708732.4932\n",
      "Epoch 2078/5000\n",
      "1167/1167 [==============================] - 0s 309us/step - loss: 6669563.4677 - val_loss: 1089224433.0959\n",
      "Epoch 2079/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 8960928.3265 - val_loss: 1055307867.1781\n",
      "Epoch 2080/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 9891155.4559 - val_loss: 1088560176.2192\n",
      "Epoch 2081/5000\n",
      "1167/1167 [==============================] - 0s 283us/step - loss: 42916145.0471 - val_loss: 1119650609.9726\n",
      "Epoch 2082/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 28648799.2356 - val_loss: 1071387647.1233\n",
      "Epoch 2083/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 39067961.6367 - val_loss: 1062429715.2877\n",
      "Epoch 2084/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 21090541.6332 - val_loss: 1128047774.6849\n",
      "Epoch 2085/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 13910903.2845 - val_loss: 1058485782.7945\n",
      "Epoch 2086/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 12562074.1534 - val_loss: 1069158791.8904\n",
      "Epoch 2087/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 8701084.0184 - val_loss: 1060120295.4521\n",
      "Epoch 2088/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6527546.2065 - val_loss: 1061576367.3425\n",
      "Epoch 2089/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8333982.9160 - val_loss: 1061512052.6027\n",
      "Epoch 2090/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11387552.9173 - val_loss: 1067000421.6986\n",
      "Epoch 2091/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9561148.2862 - val_loss: 1052041321.2055\n",
      "Epoch 2092/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9246203.3813 - val_loss: 1074268550.1370\n",
      "Epoch 2093/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7082746.8490 - val_loss: 1069053353.2055\n",
      "Epoch 2094/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3920252.9494 - val_loss: 1069705521.0959\n",
      "Epoch 2095/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4732426.1761 - val_loss: 1085272090.3014\n",
      "Epoch 2096/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3420277.3497 - val_loss: 1071382997.0411\n",
      "Epoch 2097/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2812680.0747 - val_loss: 1068943686.1370\n",
      "Epoch 2098/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2614015.3434 - val_loss: 1069622917.2603\n",
      "Epoch 2099/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6081336.3728 - val_loss: 1065586250.5205\n",
      "Epoch 2100/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5482921.9139 - val_loss: 1059871913.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2101/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4225093.4124 - val_loss: 1064456705.7534\n",
      "Epoch 2102/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3670482.6401 - val_loss: 1072088176.2192\n",
      "Epoch 2103/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8269422.5347 - val_loss: 1093824701.3699\n",
      "Epoch 2104/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 20867673.6264 - val_loss: 1095428625.5342\n",
      "Epoch 2105/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 18225126.9610 - val_loss: 1076240228.8219\n",
      "Epoch 2106/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 18717917.8440 - val_loss: 1068488493.1507\n",
      "Epoch 2107/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 47533230.4507 - val_loss: 1140180526.4658\n",
      "Epoch 2108/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 38393811.0865 - val_loss: 1063413374.2466\n",
      "Epoch 2109/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36333989.1311 - val_loss: 1143229361.9726\n",
      "Epoch 2110/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36818290.9957 - val_loss: 1121944808.3288\n",
      "Epoch 2111/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 24255667.0964 - val_loss: 1069254045.8082\n",
      "Epoch 2112/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12481915.4070 - val_loss: 1047049669.2603\n",
      "Epoch 2113/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 85604461.5561 - val_loss: 1260624728.5479\n",
      "Epoch 2114/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 51241104.4936 - val_loss: 1105947192.1096\n",
      "Epoch 2115/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 16111831.5364 - val_loss: 1085516940.2740\n",
      "Epoch 2116/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 11056133.7262 - val_loss: 1079106988.7123\n",
      "Epoch 2117/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13063865.2296 - val_loss: 1087750092.2740\n",
      "Epoch 2118/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 16429107.7069 - val_loss: 1115924187.1781\n",
      "Epoch 2119/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 9305088.8695 - val_loss: 1099029511.0137\n",
      "Epoch 2120/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6936631.0069 - val_loss: 1071987864.5479\n",
      "Epoch 2121/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 4265095.1131 - val_loss: 1075086927.7808\n",
      "Epoch 2122/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3833632.2258 - val_loss: 1070156367.7808\n",
      "Epoch 2123/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3140148.2518 - val_loss: 1075078448.2192\n",
      "Epoch 2124/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3752098.9637 - val_loss: 1066663866.7397\n",
      "Epoch 2125/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3500550.8802 - val_loss: 1073543480.1096\n",
      "Epoch 2126/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2902554.1024 - val_loss: 1068173788.0548\n",
      "Epoch 2127/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2958459.8196 - val_loss: 1072911914.0822\n",
      "Epoch 2128/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2577451.2708 - val_loss: 1071104490.9589\n",
      "Epoch 2129/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2716214.7198 - val_loss: 1080618986.0822\n",
      "Epoch 2130/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2581780.5378 - val_loss: 1074695684.3836\n",
      "Epoch 2131/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2826104.0126 - val_loss: 1080844770.1918\n",
      "Epoch 2132/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7464661.9409 - val_loss: 1077993651.7260\n",
      "Epoch 2133/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 20686757.4396 - val_loss: 1124869472.4384\n",
      "Epoch 2134/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 66072257.0720 - val_loss: 1038972187.1781\n",
      "Epoch 2135/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 51199130.6290 - val_loss: 1137606341.2603\n",
      "Epoch 2136/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 36678746.7112 - val_loss: 1079402073.4247\n",
      "Epoch 2137/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 26466274.1217 - val_loss: 1089760408.5479\n",
      "Epoch 2138/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 14392330.4696 - val_loss: 1115654105.4247\n",
      "Epoch 2139/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 9712990.5934 - val_loss: 1060360103.4521\n",
      "Epoch 2140/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 6101164.8001 - val_loss: 1072836097.7534\n",
      "Epoch 2141/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 5198432.3475 - val_loss: 1066281166.9041\n",
      "Epoch 2142/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 5032479.2053 - val_loss: 1071900192.4384\n",
      "Epoch 2143/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 3888865.2647 - val_loss: 1048841489.5342\n",
      "Epoch 2144/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 4350395.2566 - val_loss: 1068540096.8767\n",
      "Epoch 2145/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 4198543.8265 - val_loss: 1048908418.6301\n",
      "Epoch 2146/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 6757839.2142 - val_loss: 1061133910.7945\n",
      "Epoch 2147/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 4808662.2798 - val_loss: 1068370552.9863\n",
      "Epoch 2148/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 5569423.7434 - val_loss: 1077875198.2466\n",
      "Epoch 2149/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 8933869.5690 - val_loss: 1068227062.3562\n",
      "Epoch 2150/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 9160669.0304 - val_loss: 1067257573.6986\n",
      "Epoch 2151/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 5924304.1146 - val_loss: 1092040770.6301\n",
      "Epoch 2152/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 4958838.4190 - val_loss: 1072249059.0685\n",
      "Epoch 2153/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 8845750.3768 - val_loss: 1068555082.5205\n",
      "Epoch 2154/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 6743851.0626 - val_loss: 1085125332.1644\n",
      "Epoch 2155/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 9202800.5531 - val_loss: 1122122539.8356\n",
      "Epoch 2156/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 10853541.1504 - val_loss: 1072812033.7534\n",
      "Epoch 2157/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 5521728.9649 - val_loss: 1061280456.7671\n",
      "Epoch 2158/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 6064426.4522 - val_loss: 1066542459.6164\n",
      "Epoch 2159/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 5388629.6157 - val_loss: 1055446811.1781\n",
      "Epoch 2160/5000\n",
      "1167/1167 [==============================] - 0s 281us/step - loss: 18805466.5690 - val_loss: 1111929610.5205\n",
      "Epoch 2161/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 51937830.1474 - val_loss: 1057952603.1781\n",
      "Epoch 2162/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 28799876.3368 - val_loss: 1082680113.9726\n",
      "Epoch 2163/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 64318476.9289 - val_loss: 1148899423.5616\n",
      "Epoch 2164/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 63138439.8269 - val_loss: 1080082353.9726\n",
      "Epoch 2165/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 25439327.2322 - val_loss: 1060432944.2192\n",
      "Epoch 2166/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 18751049.3757 - val_loss: 1083119365.2603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2167/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12481246.4880 - val_loss: 1052802496.8767\n",
      "Epoch 2168/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8645092.1500 - val_loss: 1066071961.4247\n",
      "Epoch 2169/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 14154892.7018 - val_loss: 1111838689.3151\n",
      "Epoch 2170/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 21093014.3231 - val_loss: 1105910469.2603\n",
      "Epoch 2171/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 19210389.9846 - val_loss: 1092201287.0137\n",
      "Epoch 2172/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 22045188.0823 - val_loss: 1095564749.1507\n",
      "Epoch 2173/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 13531924.5201 - val_loss: 1065214465.7534\n",
      "Epoch 2174/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5659562.5214 - val_loss: 1059395149.1507\n",
      "Epoch 2175/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4406192.8490 - val_loss: 1070761550.0274\n",
      "Epoch 2176/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3908226.5748 - val_loss: 1066576592.6575\n",
      "Epoch 2177/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 3661639.0904 - val_loss: 1057386698.5205\n",
      "Epoch 2178/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2945134.9802 - val_loss: 1055027667.2877\n",
      "Epoch 2179/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3494813.3254 - val_loss: 1069997620.6027\n",
      "Epoch 2180/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2756972.8997 - val_loss: 1057147169.3151\n",
      "Epoch 2181/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3483522.4856 - val_loss: 1056212898.1918\n",
      "Epoch 2182/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 3747819.9489 - val_loss: 1055880896.0000\n",
      "Epoch 2183/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3304918.8509 - val_loss: 1049713476.3836\n",
      "Epoch 2184/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 5051965.0754 - val_loss: 1055325553.9726\n",
      "Epoch 2185/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7617981.8153 - val_loss: 1054328377.8630\n",
      "Epoch 2186/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4908694.6731 - val_loss: 1076800228.8219\n",
      "Epoch 2187/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3622058.5156 - val_loss: 1064318620.0548\n",
      "Epoch 2188/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 3326734.9246 - val_loss: 1069493361.0959\n",
      "Epoch 2189/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3392819.4621 - val_loss: 1068532791.2329\n",
      "Epoch 2190/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3875075.1771 - val_loss: 1069913614.0274\n",
      "Epoch 2191/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 9217581.3111 - val_loss: 1069795957.4795\n",
      "Epoch 2192/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6295870.8578 - val_loss: 1088048856.5479\n",
      "Epoch 2193/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 11321705.1457 - val_loss: 1096798908.4932\n",
      "Epoch 2194/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13305051.0334 - val_loss: 1098612136.3288\n",
      "Epoch 2195/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 54308873.6521 - val_loss: 1131049910.3562\n",
      "Epoch 2196/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 34131577.7181 - val_loss: 1119901188.3836\n",
      "Epoch 2197/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9963573.9372 - val_loss: 1071696844.2740\n",
      "Epoch 2198/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7345756.8689 - val_loss: 1094750082.6301\n",
      "Epoch 2199/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 9127674.7481 - val_loss: 1065471090.8493\n",
      "Epoch 2200/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6251515.2849 - val_loss: 1053612280.9863\n",
      "Epoch 2201/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8538099.9589 - val_loss: 1075326559.5616\n",
      "Epoch 2202/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 10268056.4130 - val_loss: 1089596481.7534\n",
      "Epoch 2203/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7188505.9906 - val_loss: 1055366526.2466\n",
      "Epoch 2204/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7292511.3830 - val_loss: 1063388621.1507\n",
      "Epoch 2205/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5614381.8809 - val_loss: 1077566524.4932\n",
      "Epoch 2206/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5507765.0634 - val_loss: 1060222843.6164\n",
      "Epoch 2207/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5586679.1350 - val_loss: 1088968465.5342\n",
      "Epoch 2208/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 12486224.6128 - val_loss: 1076494170.3014\n",
      "Epoch 2209/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14059022.0249 - val_loss: 1056963134.2466\n",
      "Epoch 2210/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 13624564.9392 - val_loss: 1072881696.4384\n",
      "Epoch 2211/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14642969.9599 - val_loss: 1070461009.5342\n",
      "Epoch 2212/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10130774.1671 - val_loss: 1058144033.3151\n",
      "Epoch 2213/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 16187031.2596 - val_loss: 1101159644.0548\n",
      "Epoch 2214/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 18421482.4259 - val_loss: 1040804004.8219\n",
      "Epoch 2215/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15250526.5840 - val_loss: 1102489415.8904\n",
      "Epoch 2216/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 10282829.0883 - val_loss: 1121059750.5753\n",
      "Epoch 2217/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 15336951.7524 - val_loss: 1066991656.3288\n",
      "Epoch 2218/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14974146.4336 - val_loss: 1046756752.6575\n",
      "Epoch 2219/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37591532.8706 - val_loss: 1053774282.5205\n",
      "Epoch 2220/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 136886410.6735 - val_loss: 1095803950.4658\n",
      "Epoch 2221/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 99856809.3985 - val_loss: 1230988058.3014\n",
      "Epoch 2222/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 45145894.3325 - val_loss: 1057941434.3014\n",
      "Epoch 2223/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 22644848.8899 - val_loss: 1084936282.3014\n",
      "Epoch 2224/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 12838000.6255 - val_loss: 1083655262.6849\n",
      "Epoch 2225/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 9750980.9773 - val_loss: 1054194942.2466\n",
      "Epoch 2226/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3868873.2018 - val_loss: 1068507731.2877\n",
      "Epoch 2227/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4277284.9955 - val_loss: 1072051640.1096\n",
      "Epoch 2228/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3710907.0051 - val_loss: 1064678424.5479\n",
      "Epoch 2229/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4166828.0578 - val_loss: 1065917506.6301\n",
      "Epoch 2230/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3631627.9004 - val_loss: 1049069668.8219\n",
      "Epoch 2231/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3362737.6011 - val_loss: 1058634255.7808\n",
      "Epoch 2232/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2973215.3918 - val_loss: 1072905738.5205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2233/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3167729.7965 - val_loss: 1076046359.6712\n",
      "Epoch 2234/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3240355.4055 - val_loss: 1067197679.3425\n",
      "Epoch 2235/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3144986.2909 - val_loss: 1062592042.9589\n",
      "Epoch 2236/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2552435.2704 - val_loss: 1065833863.0137\n",
      "Epoch 2237/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2393640.3290 - val_loss: 1072423911.4521\n",
      "Epoch 2238/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3503793.3363 - val_loss: 1062529279.1233\n",
      "Epoch 2239/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3134828.6599 - val_loss: 1065037593.4247\n",
      "Epoch 2240/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3675712.2063 - val_loss: 1054588750.0274\n",
      "Epoch 2241/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 3470976.3432 - val_loss: 1072933896.7671\n",
      "Epoch 2242/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4390488.3373 - val_loss: 1052273214.2466\n",
      "Epoch 2243/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4990928.5013 - val_loss: 1084211182.4658\n",
      "Epoch 2244/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3811645.2134 - val_loss: 1047046736.6575\n",
      "Epoch 2245/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6182739.4704 - val_loss: 1110964631.6712\n",
      "Epoch 2246/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 9025943.3033 - val_loss: 1060746341.6986\n",
      "Epoch 2247/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 7328257.3946 - val_loss: 1075094560.4384\n",
      "Epoch 2248/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 7334890.7292 - val_loss: 1056877835.3973\n",
      "Epoch 2249/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4863716.5915 - val_loss: 1071495646.6849\n",
      "Epoch 2250/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4869382.9143 - val_loss: 1051266283.8356\n",
      "Epoch 2251/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6916308.3813 - val_loss: 1059055426.6301\n",
      "Epoch 2252/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 9283488.2682 - val_loss: 1046707557.6986\n",
      "Epoch 2253/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 12459337.5951 - val_loss: 1042638239.5616\n",
      "Epoch 2254/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9091836.3188 - val_loss: 1097118003.7260\n",
      "Epoch 2255/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 44533906.3856 - val_loss: 1162258239.1233\n",
      "Epoch 2256/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 46555703.7892 - val_loss: 1104959730.8493\n",
      "Epoch 2257/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 31603602.5604 - val_loss: 1125310864.6575\n",
      "Epoch 2258/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 15518322.1521 - val_loss: 1079542855.8904\n",
      "Epoch 2259/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 20504379.8937 - val_loss: 1088780361.6438\n",
      "Epoch 2260/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12081451.0780 - val_loss: 1090813139.2877\n",
      "Epoch 2261/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 11856675.8475 - val_loss: 1112864257.7534\n",
      "Epoch 2262/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 18261444.1382 - val_loss: 1067842946.6301\n",
      "Epoch 2263/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 9058472.3218 - val_loss: 1073452337.0959\n",
      "Epoch 2264/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6772256.3141 - val_loss: 1074520165.6986\n",
      "Epoch 2265/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5286713.0406 - val_loss: 1057996614.1370\n",
      "Epoch 2266/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3765747.8286 - val_loss: 1067684849.0959\n",
      "Epoch 2267/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9500316.0051 - val_loss: 1123103950.9041\n",
      "Epoch 2268/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 46839322.0668 - val_loss: 1169915640.9863\n",
      "Epoch 2269/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 22811862.6667 - val_loss: 1055980926.2466\n",
      "Epoch 2270/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13966397.5471 - val_loss: 1096177116.9315\n",
      "Epoch 2271/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10867648.7939 - val_loss: 1046142247.4521\n",
      "Epoch 2272/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7467907.9143 - val_loss: 1082778984.3288\n",
      "Epoch 2273/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5136402.7237 - val_loss: 1081468925.3699\n",
      "Epoch 2274/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5993087.7392 - val_loss: 1073073039.7808\n",
      "Epoch 2275/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 5737494.1710 - val_loss: 1094144562.8493\n",
      "Epoch 2276/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5425729.5398 - val_loss: 1096813122.6301\n",
      "Epoch 2277/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 20073239.8560 - val_loss: 1069506243.5068\n",
      "Epoch 2278/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 42624290.6838 - val_loss: 1075185849.8630\n",
      "Epoch 2279/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 17105361.2513 - val_loss: 1096033244.9315\n",
      "Epoch 2280/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 12846010.1671 - val_loss: 1095069930.9589\n",
      "Epoch 2281/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5913639.9520 - val_loss: 1074803058.8493\n",
      "Epoch 2282/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3570266.4859 - val_loss: 1081658714.3014\n",
      "Epoch 2283/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3668310.7442 - val_loss: 1074189604.8219\n",
      "Epoch 2284/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5012384.8196 - val_loss: 1072328635.6164\n",
      "Epoch 2285/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6134331.5853 - val_loss: 1063966937.4247\n",
      "Epoch 2286/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 12390262.2057 - val_loss: 1101358019.5068\n",
      "Epoch 2287/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11909971.6101 - val_loss: 1061782157.1507\n",
      "Epoch 2288/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 18957895.1602 - val_loss: 1115932326.5753\n",
      "Epoch 2289/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 13699505.9036 - val_loss: 1078255566.0274\n",
      "Epoch 2290/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 16987279.2566 - val_loss: 1133565009.5342\n",
      "Epoch 2291/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16700999.9105 - val_loss: 1104912548.8219\n",
      "Epoch 2292/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 14191610.4490 - val_loss: 1083920236.7123\n",
      "Epoch 2293/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 12335960.9597 - val_loss: 1086166246.5753\n",
      "Epoch 2294/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 25020434.6153 - val_loss: 1099409289.6438\n",
      "Epoch 2295/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 47978745.4293 - val_loss: 1142545567.5616\n",
      "Epoch 2296/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 140396346.1251 - val_loss: 1188146037.4795\n",
      "Epoch 2297/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 83128803.7866 - val_loss: 1068494547.2877\n",
      "Epoch 2298/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 17256117.4096 - val_loss: 1121019587.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2299/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 12393685.4850 - val_loss: 1106670559.5616\n",
      "Epoch 2300/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11272317.5150 - val_loss: 1099438214.1370\n",
      "Epoch 2301/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9346526.8631 - val_loss: 1075226457.4247\n",
      "Epoch 2302/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11902998.4516 - val_loss: 1058113058.1918\n",
      "Epoch 2303/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9959433.6358 - val_loss: 1093078137.8630\n",
      "Epoch 2304/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9896181.4897 - val_loss: 1074612731.6164\n",
      "Epoch 2305/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7016504.5360 - val_loss: 1078803875.0685\n",
      "Epoch 2306/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6681927.2348 - val_loss: 1065397224.3288\n",
      "Epoch 2307/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4458114.1607 - val_loss: 1076898332.0548\n",
      "Epoch 2308/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3426254.7317 - val_loss: 1079602841.4247\n",
      "Epoch 2309/5000\n",
      "1167/1167 [==============================] - 0s 232us/step - loss: 3493990.7028 - val_loss: 1074330175.1233\n",
      "Epoch 2310/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2663947.4439 - val_loss: 1080700358.1370\n",
      "Epoch 2311/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2577513.0184 - val_loss: 1092430407.0137\n",
      "Epoch 2312/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3105492.5135 - val_loss: 1067707260.4932\n",
      "Epoch 2313/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4101209.4122 - val_loss: 1088048315.6164\n",
      "Epoch 2314/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2998384.1939 - val_loss: 1082802696.7671\n",
      "Epoch 2315/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3447959.8072 - val_loss: 1089960161.3151\n",
      "Epoch 2316/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3067435.4145 - val_loss: 1079998658.6301\n",
      "Epoch 2317/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4590182.7781 - val_loss: 1084112979.2877\n",
      "Epoch 2318/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3927248.7009 - val_loss: 1072586828.2740\n",
      "Epoch 2319/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4046901.2847 - val_loss: 1083538410.0822\n",
      "Epoch 2320/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4079938.9649 - val_loss: 1091451031.6712\n",
      "Epoch 2321/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 8572922.3113 - val_loss: 1099002978.1918\n",
      "Epoch 2322/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13075419.1345 - val_loss: 1078098979.0685\n",
      "Epoch 2323/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 17159450.6521 - val_loss: 1094359518.6849\n",
      "Epoch 2324/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 10599586.2931 - val_loss: 1079676107.3973\n",
      "Epoch 2325/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9763024.5141 - val_loss: 1066136353.3151\n",
      "Epoch 2326/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 12717999.5296 - val_loss: 1112762666.9589\n",
      "Epoch 2327/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 12411568.9015 - val_loss: 1095625110.7945\n",
      "Epoch 2328/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10622253.6390 - val_loss: 1119631390.6849\n",
      "Epoch 2329/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 15873120.4567 - val_loss: 1044773347.0685\n",
      "Epoch 2330/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15180714.4859 - val_loss: 1102204610.6301\n",
      "Epoch 2331/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 9093488.2734 - val_loss: 1071768662.7945\n",
      "Epoch 2332/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 5822737.8736 - val_loss: 1105157348.8219\n",
      "Epoch 2333/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8726892.3565 - val_loss: 1084211079.0137\n",
      "Epoch 2334/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 9327645.8749 - val_loss: 1103853069.1507\n",
      "Epoch 2335/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 13702936.9803 - val_loss: 1099785643.8356\n",
      "Epoch 2336/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 11284301.4803 - val_loss: 1074304585.6438\n",
      "Epoch 2337/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6635456.2961 - val_loss: 1072945772.7123\n",
      "Epoch 2338/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3858389.5044 - val_loss: 1079395143.0137\n",
      "Epoch 2339/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3280955.1403 - val_loss: 1077792733.8082\n",
      "Epoch 2340/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4233281.0686 - val_loss: 1080227664.6575\n",
      "Epoch 2341/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3639763.4757 - val_loss: 1075741184.0000\n",
      "Epoch 2342/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4929951.9392 - val_loss: 1075823603.7260\n",
      "Epoch 2343/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4542814.0171 - val_loss: 1072270599.0137\n",
      "Epoch 2344/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 6105972.7751 - val_loss: 1061127331.0685\n",
      "Epoch 2345/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 14493424.4670 - val_loss: 1092841231.7808\n",
      "Epoch 2346/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10586267.2065 - val_loss: 1061580449.3151\n",
      "Epoch 2347/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9869722.8419 - val_loss: 1078697629.8082\n",
      "Epoch 2348/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5112772.7082 - val_loss: 1081300399.3425\n",
      "Epoch 2349/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6481022.1144 - val_loss: 1057418436.3836\n",
      "Epoch 2350/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 14886774.1504 - val_loss: 1095746961.5342\n",
      "Epoch 2351/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11040255.7061 - val_loss: 1089006298.3014\n",
      "Epoch 2352/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8104436.6491 - val_loss: 1084228154.7397\n",
      "Epoch 2353/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3999904.2434 - val_loss: 1074138972.0548\n",
      "Epoch 2354/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3566571.9066 - val_loss: 1073178811.6164\n",
      "Epoch 2355/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5262920.0973 - val_loss: 1082863454.6849\n",
      "Epoch 2356/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6111372.5510 - val_loss: 1072797517.1507\n",
      "Epoch 2357/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8518046.6795 - val_loss: 1088515122.8493\n",
      "Epoch 2358/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 18158144.7746 - val_loss: 1093954495.1233\n",
      "Epoch 2359/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 45545420.0034 - val_loss: 1114317631.1233\n",
      "Epoch 2360/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 49475688.9049 - val_loss: 1115119841.7534\n",
      "Epoch 2361/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 140689562.2725 - val_loss: 1143709647.3425\n",
      "Epoch 2362/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 94917719.4173 - val_loss: 1152963256.1096\n",
      "Epoch 2363/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 32590884.2279 - val_loss: 1151396974.4658\n",
      "Epoch 2364/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 30479701.5253 - val_loss: 1104566463.1233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2365/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 32141030.6272 - val_loss: 1097313441.3151\n",
      "Epoch 2366/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 23070383.4404 - val_loss: 1092718475.3973\n",
      "Epoch 2367/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 13287061.8582 - val_loss: 1077739136.0000\n",
      "Epoch 2368/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 10057998.2819 - val_loss: 1070575314.4110\n",
      "Epoch 2369/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7431632.8740 - val_loss: 1070808034.1918\n",
      "Epoch 2370/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 5177502.2067 - val_loss: 1085523148.2740\n",
      "Epoch 2371/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5223168.5694 - val_loss: 1078881271.2329\n",
      "Epoch 2372/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4154155.5653 - val_loss: 1071586306.6301\n",
      "Epoch 2373/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4085898.6952 - val_loss: 1075963250.8493\n",
      "Epoch 2374/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5322813.3059 - val_loss: 1077451446.3562\n",
      "Epoch 2375/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4600388.4589 - val_loss: 1084510107.1781\n",
      "Epoch 2376/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4194374.8339 - val_loss: 1073067073.7534\n",
      "Epoch 2377/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2912447.3123 - val_loss: 1073764213.4795\n",
      "Epoch 2378/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2801756.0555 - val_loss: 1073534835.7260\n",
      "Epoch 2379/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2426474.7350 - val_loss: 1072680368.2192\n",
      "Epoch 2380/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2033386.2619 - val_loss: 1077492982.3562\n",
      "Epoch 2381/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1904152.2539 - val_loss: 1075157795.0685\n",
      "Epoch 2382/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2125322.1247 - val_loss: 1071706446.0274\n",
      "Epoch 2383/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3238569.6086 - val_loss: 1079332583.4521\n",
      "Epoch 2384/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4493940.6616 - val_loss: 1089930061.1507\n",
      "Epoch 2385/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 17999394.9991 - val_loss: 1107485184.8767\n",
      "Epoch 2386/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 41110832.4062 - val_loss: 1110546364.4932\n",
      "Epoch 2387/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 19602182.6915 - val_loss: 1080459779.5068\n",
      "Epoch 2388/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7110767.9117 - val_loss: 1098474773.0411\n",
      "Epoch 2389/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11940004.2935 - val_loss: 1090874290.8493\n",
      "Epoch 2390/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6587477.8595 - val_loss: 1098413411.0685\n",
      "Epoch 2391/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4313463.3316 - val_loss: 1084053962.5205\n",
      "Epoch 2392/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5319281.3608 - val_loss: 1066763956.6027\n",
      "Epoch 2393/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4269309.9066 - val_loss: 1069786503.8904\n",
      "Epoch 2394/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2897129.5664 - val_loss: 1079231909.6986\n",
      "Epoch 2395/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2717979.5617 - val_loss: 1072284979.7260\n",
      "Epoch 2396/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4491451.2905 - val_loss: 1094135871.1233\n",
      "Epoch 2397/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4672501.2674 - val_loss: 1066678374.5753\n",
      "Epoch 2398/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 12336634.7326 - val_loss: 1096712144.6575\n",
      "Epoch 2399/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8841338.2305 - val_loss: 1077485891.5068\n",
      "Epoch 2400/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6854156.4826 - val_loss: 1090555150.9041\n",
      "Epoch 2401/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4328961.4233 - val_loss: 1078065490.4110\n",
      "Epoch 2402/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5604483.5443 - val_loss: 1079924552.7671\n",
      "Epoch 2403/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3753479.4289 - val_loss: 1081669520.6575\n",
      "Epoch 2404/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 7867981.1945 - val_loss: 1082500956.9315\n",
      "Epoch 2405/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4068250.6005 - val_loss: 1074900153.8630\n",
      "Epoch 2406/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4300144.4430 - val_loss: 1082431121.5342\n",
      "Epoch 2407/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3909288.5577 - val_loss: 1073818750.2466\n",
      "Epoch 2408/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4863178.6326 - val_loss: 1084904230.5753\n",
      "Epoch 2409/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 12477846.4439 - val_loss: 1092872186.7397\n",
      "Epoch 2410/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 12947052.5587 - val_loss: 1067431608.1096\n",
      "Epoch 2411/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 84518304.0686 - val_loss: 1202013874.8493\n",
      "Epoch 2412/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 183888363.5716 - val_loss: 1296991542.3562\n",
      "Epoch 2413/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 75267538.0120 - val_loss: 1098314707.2877\n",
      "Epoch 2414/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 22908772.3256 - val_loss: 1095569966.4658\n",
      "Epoch 2415/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 13334473.4781 - val_loss: 1074148885.9178\n",
      "Epoch 2416/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 8173226.9100 - val_loss: 1071206932.1644\n",
      "Epoch 2417/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5351014.2009 - val_loss: 1078381206.7945\n",
      "Epoch 2418/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6130044.9709 - val_loss: 1070382475.3973\n",
      "Epoch 2419/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5136585.0861 - val_loss: 1071272880.2192\n",
      "Epoch 2420/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5899962.0686 - val_loss: 1081411245.5890\n",
      "Epoch 2421/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3861184.1548 - val_loss: 1073173882.7397\n",
      "Epoch 2422/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2646060.4313 - val_loss: 1067015063.6712\n",
      "Epoch 2423/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2268073.0898 - val_loss: 1074177084.4932\n",
      "Epoch 2424/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2062379.7879 - val_loss: 1076067775.1233\n",
      "Epoch 2425/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2100574.5387 - val_loss: 1059262260.6027\n",
      "Epoch 2426/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2123015.5161 - val_loss: 1067136857.4247\n",
      "Epoch 2427/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2010615.9006 - val_loss: 1061008604.0548\n",
      "Epoch 2428/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2071783.4602 - val_loss: 1065298030.4658\n",
      "Epoch 2429/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2077243.4604 - val_loss: 1063039850.0822\n",
      "Epoch 2430/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2341255.6006 - val_loss: 1067602523.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2431/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3414176.8635 - val_loss: 1085397383.8904\n",
      "Epoch 2432/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3435104.6650 - val_loss: 1068776163.9452\n",
      "Epoch 2433/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3903736.4476 - val_loss: 1077616984.5479\n",
      "Epoch 2434/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3509085.1703 - val_loss: 1084499642.7397\n",
      "Epoch 2435/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2788579.2361 - val_loss: 1049024853.0411\n",
      "Epoch 2436/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2976204.1710 - val_loss: 1080894521.8630\n",
      "Epoch 2437/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3220664.3562 - val_loss: 1055964895.5616\n",
      "Epoch 2438/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8870646.8882 - val_loss: 1075644266.9589\n",
      "Epoch 2439/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5640565.1495 - val_loss: 1067236280.9863\n",
      "Epoch 2440/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5696870.5467 - val_loss: 1083123765.4795\n",
      "Epoch 2441/5000\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 7249561.7003 - val_loss: 1037820804.3836\n",
      "Epoch 2442/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 8641904.0471 - val_loss: 1075016775.8904\n",
      "Epoch 2443/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6634895.3036 - val_loss: 1031744231.4521\n",
      "Epoch 2444/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 5928743.4828 - val_loss: 1058113203.7260\n",
      "Epoch 2445/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 6842816.0463 - val_loss: 1054891293.8082\n",
      "Epoch 2446/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4763912.7893 - val_loss: 1066569375.5616\n",
      "Epoch 2447/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4541113.1431 - val_loss: 1055393912.1096\n",
      "Epoch 2448/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4374995.1705 - val_loss: 1076090313.6438\n",
      "Epoch 2449/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4371665.4366 - val_loss: 1060057841.9726\n",
      "Epoch 2450/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5753517.8303 - val_loss: 1072615204.8219\n",
      "Epoch 2451/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 8479141.1979 - val_loss: 1086257087.1233\n",
      "Epoch 2452/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 18156206.7438 - val_loss: 1085055189.9178\n",
      "Epoch 2453/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 18851457.4756 - val_loss: 1097076072.3288\n",
      "Epoch 2454/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 11231308.5056 - val_loss: 1076985443.0685\n",
      "Epoch 2455/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13080582.0077 - val_loss: 1099785264.2192\n",
      "Epoch 2456/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 9496293.5544 - val_loss: 1068471722.9589\n",
      "Epoch 2457/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 18924083.4494 - val_loss: 1087057339.6164\n",
      "Epoch 2458/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 24736061.5390 - val_loss: 1086500225.7534\n",
      "Epoch 2459/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 57421180.7781 - val_loss: 1072358722.6301\n",
      "Epoch 2460/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 29246991.3813 - val_loss: 1111019297.3151\n",
      "Epoch 2461/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 27579610.2948 - val_loss: 1089608810.0822\n",
      "Epoch 2462/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 12423644.7057 - val_loss: 1069385800.7671\n",
      "Epoch 2463/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8094389.0458 - val_loss: 1077234460.9315\n",
      "Epoch 2464/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 6115436.1296 - val_loss: 1049876600.1096\n",
      "Epoch 2465/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3228845.1817 - val_loss: 1068685882.7397\n",
      "Epoch 2466/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2565212.4732 - val_loss: 1066626358.3562\n",
      "Epoch 2467/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2800266.7024 - val_loss: 1064786247.8904\n",
      "Epoch 2468/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3125661.5017 - val_loss: 1066382295.6712\n",
      "Epoch 2469/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2151447.6671 - val_loss: 1048097370.3014\n",
      "Epoch 2470/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2334892.9773 - val_loss: 1067897120.4384\n",
      "Epoch 2471/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2293722.8300 - val_loss: 1047493373.3699\n",
      "Epoch 2472/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3087602.8059 - val_loss: 1074013278.6849\n",
      "Epoch 2473/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4886285.1354 - val_loss: 1043205352.3288\n",
      "Epoch 2474/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4902410.7772 - val_loss: 1080396974.4658\n",
      "Epoch 2475/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5282378.7506 - val_loss: 1069551126.7945\n",
      "Epoch 2476/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5976145.2097 - val_loss: 1065404631.6712\n",
      "Epoch 2477/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3593514.0835 - val_loss: 1051867096.5479\n",
      "Epoch 2478/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2966911.5915 - val_loss: 1073623394.1918\n",
      "Epoch 2479/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3411267.9113 - val_loss: 1063963635.7260\n",
      "Epoch 2480/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 4610247.9457 - val_loss: 1061856953.8630\n",
      "Epoch 2481/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 10328084.8226 - val_loss: 1092045359.3425\n",
      "Epoch 2482/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 11816138.1782 - val_loss: 1109839694.0274\n",
      "Epoch 2483/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 22439162.8860 - val_loss: 1087041100.2740\n",
      "Epoch 2484/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 46098113.0925 - val_loss: 1158343709.8082\n",
      "Epoch 2485/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 68510931.7704 - val_loss: 1161592589.5890\n",
      "Epoch 2486/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 261933549.1345 - val_loss: 1282764006.1370\n",
      "Epoch 2487/5000\n",
      "1167/1167 [==============================] - 0s 287us/step - loss: 245404102.7318 - val_loss: 1282653538.6301\n",
      "Epoch 2488/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 64689980.1268 - val_loss: 1133333233.5342\n",
      "Epoch 2489/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 25669826.1243 - val_loss: 1141011953.9726\n",
      "Epoch 2490/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12558216.5026 - val_loss: 1113050822.1370\n",
      "Epoch 2491/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7624045.3736 - val_loss: 1104511463.4521\n",
      "Epoch 2492/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7998367.7999 - val_loss: 1123661524.1644\n",
      "Epoch 2493/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6138979.0855 - val_loss: 1098265031.0137\n",
      "Epoch 2494/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5211227.4901 - val_loss: 1092149411.0685\n",
      "Epoch 2495/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4865561.8201 - val_loss: 1085473010.8493\n",
      "Epoch 2496/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5040762.6403 - val_loss: 1100903590.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2497/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3711661.9850 - val_loss: 1085917649.5342\n",
      "Epoch 2498/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4040675.7082 - val_loss: 1087300556.2740\n",
      "Epoch 2499/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3187803.6073 - val_loss: 1087016180.6027\n",
      "Epoch 2500/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3299237.1127 - val_loss: 1093545321.2055\n",
      "Epoch 2501/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2601701.8469 - val_loss: 1081067079.0137\n",
      "Epoch 2502/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2452447.5737 - val_loss: 1086192114.8493\n",
      "Epoch 2503/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2750948.1108 - val_loss: 1089189036.7123\n",
      "Epoch 2504/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3620438.4105 - val_loss: 1091840632.1096\n",
      "Epoch 2505/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2893505.2218 - val_loss: 1085965532.0548\n",
      "Epoch 2506/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 2682974.8687 - val_loss: 1091809117.8082\n",
      "Epoch 2507/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3105875.0257 - val_loss: 1097490240.8767\n",
      "Epoch 2508/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 2192201.7160 - val_loss: 1088450030.4658\n",
      "Epoch 2509/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2378667.2467 - val_loss: 1092857503.5616\n",
      "Epoch 2510/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2715605.7954 - val_loss: 1081236980.6027\n",
      "Epoch 2511/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2324376.9829 - val_loss: 1081119754.5205\n",
      "Epoch 2512/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3435321.1260 - val_loss: 1081194448.6575\n",
      "Epoch 2513/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3842425.4955 - val_loss: 1081037413.6986\n",
      "Epoch 2514/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2774104.4327 - val_loss: 1090532526.4658\n",
      "Epoch 2515/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4331117.8171 - val_loss: 1080135551.1233\n",
      "Epoch 2516/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 19227045.8201 - val_loss: 1082311536.2192\n",
      "Epoch 2517/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 10680437.3865 - val_loss: 1091197858.1918\n",
      "Epoch 2518/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8292169.6397 - val_loss: 1099082041.8630\n",
      "Epoch 2519/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 19367589.5373 - val_loss: 1079898247.0137\n",
      "Epoch 2520/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6994160.5893 - val_loss: 1087814593.7534\n",
      "Epoch 2521/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5228079.5847 - val_loss: 1089145870.9041\n",
      "Epoch 2522/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5079689.9216 - val_loss: 1090039308.2740\n",
      "Epoch 2523/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 4180778.7629 - val_loss: 1083808405.9178\n",
      "Epoch 2524/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3759706.9205 - val_loss: 1070781302.3562\n",
      "Epoch 2525/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3269974.2786 - val_loss: 1069929082.7397\n",
      "Epoch 2526/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2694391.4665 - val_loss: 1074308391.4521\n",
      "Epoch 2527/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2443943.0188 - val_loss: 1062830589.3699\n",
      "Epoch 2528/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3623200.0120 - val_loss: 1079221191.0137\n",
      "Epoch 2529/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5805770.4023 - val_loss: 1058510212.3836\n",
      "Epoch 2530/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3750390.5955 - val_loss: 1079529879.6712\n",
      "Epoch 2531/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3607065.4400 - val_loss: 1065886336.8767\n",
      "Epoch 2532/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2841135.3376 - val_loss: 1076383729.9726\n",
      "Epoch 2533/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3030071.7701 - val_loss: 1071971569.9726\n",
      "Epoch 2534/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2990418.1215 - val_loss: 1078045547.8356\n",
      "Epoch 2535/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3659825.8715 - val_loss: 1083897848.1096\n",
      "Epoch 2536/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5880886.5906 - val_loss: 1069736900.3836\n",
      "Epoch 2537/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5106992.0210 - val_loss: 1095939889.9726\n",
      "Epoch 2538/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3791389.0696 - val_loss: 1070820627.2877\n",
      "Epoch 2539/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6241494.1752 - val_loss: 1082389626.7397\n",
      "Epoch 2540/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5620532.9195 - val_loss: 1065578727.4521\n",
      "Epoch 2541/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4571290.4700 - val_loss: 1058149170.8493\n",
      "Epoch 2542/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3114021.9259 - val_loss: 1077564558.9041\n",
      "Epoch 2543/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6739807.2303 - val_loss: 1079369904.2192\n",
      "Epoch 2544/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 6437777.7624 - val_loss: 1087158569.2055\n",
      "Epoch 2545/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9499285.5287 - val_loss: 1118641551.7808\n",
      "Epoch 2546/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 19396623.3513 - val_loss: 1082625557.0411\n",
      "Epoch 2547/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 22766740.9197 - val_loss: 1097336743.4521\n",
      "Epoch 2548/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 22916947.3625 - val_loss: 1103566536.7671\n",
      "Epoch 2549/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26837274.2725 - val_loss: 1145713974.3562\n",
      "Epoch 2550/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 73536354.9203 - val_loss: 1121817608.7671\n",
      "Epoch 2551/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 66629959.0677 - val_loss: 1154642204.0548\n",
      "Epoch 2552/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 52779881.2408 - val_loss: 1176776002.6301\n",
      "Epoch 2553/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 26146490.6435 - val_loss: 1109086721.7534\n",
      "Epoch 2554/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9958583.3290 - val_loss: 1127562352.2192\n",
      "Epoch 2555/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6417251.2196 - val_loss: 1128880791.6712\n",
      "Epoch 2556/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 4305929.3924 - val_loss: 1109154816.0000\n",
      "Epoch 2557/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3016457.1956 - val_loss: 1107568760.1096\n",
      "Epoch 2558/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3216786.7251 - val_loss: 1099492967.4521\n",
      "Epoch 2559/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3168291.4966 - val_loss: 1112084944.6575\n",
      "Epoch 2560/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2742218.2415 - val_loss: 1097123554.1918\n",
      "Epoch 2561/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2627372.7647 - val_loss: 1099095393.3151\n",
      "Epoch 2562/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2328667.5471 - val_loss: 1098866490.7397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2563/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2254728.1962 - val_loss: 1095901973.9178\n",
      "Epoch 2564/5000\n",
      "1167/1167 [==============================] - 0s 230us/step - loss: 2911290.6896 - val_loss: 1092830287.7808\n",
      "Epoch 2565/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 2715175.2039 - val_loss: 1084302517.4795\n",
      "Epoch 2566/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2969266.1807 - val_loss: 1090353251.9452\n",
      "Epoch 2567/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5313146.7138 - val_loss: 1101466192.6575\n",
      "Epoch 2568/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4922929.2603 - val_loss: 1080488693.4795\n",
      "Epoch 2569/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 12747671.5716 - val_loss: 1101900702.6849\n",
      "Epoch 2570/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7540872.9289 - val_loss: 1080516050.4110\n",
      "Epoch 2571/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 13951012.0737 - val_loss: 1101058102.3562\n",
      "Epoch 2572/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 19327840.3393 - val_loss: 1127029789.8082\n",
      "Epoch 2573/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 14798808.2569 - val_loss: 1083656831.1233\n",
      "Epoch 2574/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 8707581.6555 - val_loss: 1105184662.7945\n",
      "Epoch 2575/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6790253.2207 - val_loss: 1079356930.6301\n",
      "Epoch 2576/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8733228.0060 - val_loss: 1091130355.7260\n",
      "Epoch 2577/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7618415.2536 - val_loss: 1096156096.8767\n",
      "Epoch 2578/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5214572.2500 - val_loss: 1108662506.9589\n",
      "Epoch 2579/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5725683.2896 - val_loss: 1066916147.7260\n",
      "Epoch 2580/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5924625.6247 - val_loss: 1088685986.1918\n",
      "Epoch 2581/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 10222822.1587 - val_loss: 1076332742.1370\n",
      "Epoch 2582/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4881704.9120 - val_loss: 1093048755.7260\n",
      "Epoch 2583/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6153126.9049 - val_loss: 1118293076.1644\n",
      "Epoch 2584/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7433888.1962 - val_loss: 1111531458.6301\n",
      "Epoch 2585/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4114479.8530 - val_loss: 1081809320.3288\n",
      "Epoch 2586/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3827063.2786 - val_loss: 1094855912.3288\n",
      "Epoch 2587/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3049494.4109 - val_loss: 1088677975.6712\n",
      "Epoch 2588/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3056320.4261 - val_loss: 1092237624.1096\n",
      "Epoch 2589/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2808819.3882 - val_loss: 1090790280.7671\n",
      "Epoch 2590/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4564107.6476 - val_loss: 1107677711.7808\n",
      "Epoch 2591/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4644621.9460 - val_loss: 1078426180.3836\n",
      "Epoch 2592/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7865589.7793 - val_loss: 1083682586.3014\n",
      "Epoch 2593/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 8470126.7626 - val_loss: 1104179247.3425\n",
      "Epoch 2594/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9619799.9396 - val_loss: 1091821784.5479\n",
      "Epoch 2595/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 14549172.3942 - val_loss: 1121790755.9452\n",
      "Epoch 2596/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 45514323.8826 - val_loss: 1135563826.8493\n",
      "Epoch 2597/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 29198254.3475 - val_loss: 1119592445.3699\n",
      "Epoch 2598/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 14168943.2014 - val_loss: 1116492375.6712\n",
      "Epoch 2599/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 43794895.3076 - val_loss: 1053314410.9589\n",
      "Epoch 2600/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 38471230.1799 - val_loss: 1046972408.9863\n",
      "Epoch 2601/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 19634234.0146 - val_loss: 1128270780.4932\n",
      "Epoch 2602/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9726944.0865 - val_loss: 1106878140.4932\n",
      "Epoch 2603/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4509178.0330 - val_loss: 1091884577.3151\n",
      "Epoch 2604/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3310850.9174 - val_loss: 1105515143.0137\n",
      "Epoch 2605/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3574936.7985 - val_loss: 1082909456.6575\n",
      "Epoch 2606/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3496052.1371 - val_loss: 1096825289.6438\n",
      "Epoch 2607/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3333255.6611 - val_loss: 1103579000.1096\n",
      "Epoch 2608/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3075869.3935 - val_loss: 1099360782.9041\n",
      "Epoch 2609/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2859130.8339 - val_loss: 1099035319.2329\n",
      "Epoch 2610/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2822703.7550 - val_loss: 1091905402.7397\n",
      "Epoch 2611/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3218660.7438 - val_loss: 1087186649.4247\n",
      "Epoch 2612/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2602769.6161 - val_loss: 1094676693.0411\n",
      "Epoch 2613/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4270173.5656 - val_loss: 1105703203.0685\n",
      "Epoch 2614/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4305193.2500 - val_loss: 1085417598.2466\n",
      "Epoch 2615/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3662324.3882 - val_loss: 1086434041.8630\n",
      "Epoch 2616/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3361717.2299 - val_loss: 1101839454.6849\n",
      "Epoch 2617/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 5199212.4516 - val_loss: 1098253346.1918\n",
      "Epoch 2618/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 8969840.4308 - val_loss: 1113381388.2740\n",
      "Epoch 2619/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9418086.4370 - val_loss: 1106233720.1096\n",
      "Epoch 2620/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 13487985.0784 - val_loss: 1089889448.3288\n",
      "Epoch 2621/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9425783.0840 - val_loss: 1093209454.4658\n",
      "Epoch 2622/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4979051.4409 - val_loss: 1083080020.1644\n",
      "Epoch 2623/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5158708.5870 - val_loss: 1096231957.9178\n",
      "Epoch 2624/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5504923.6056 - val_loss: 1092585329.0959\n",
      "Epoch 2625/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 8735450.7361 - val_loss: 1095804357.2603\n",
      "Epoch 2626/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8622863.6889 - val_loss: 1097577000.3288\n",
      "Epoch 2627/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 13912243.7549 - val_loss: 1074146332.0548\n",
      "Epoch 2628/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 30744927.0917 - val_loss: 1136272510.2466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2629/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 23905522.2382 - val_loss: 1119631131.1781\n",
      "Epoch 2630/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 50972847.1422 - val_loss: 1127954305.7534\n",
      "Epoch 2631/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 80484823.0334 - val_loss: 1207323485.8082\n",
      "Epoch 2632/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 50400693.8869 - val_loss: 1068606823.4521\n",
      "Epoch 2633/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10915312.1748 - val_loss: 1099251622.5753\n",
      "Epoch 2634/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8772807.3993 - val_loss: 1076708400.2192\n",
      "Epoch 2635/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 14074780.6178 - val_loss: 1059861989.6986\n",
      "Epoch 2636/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 8116129.4263 - val_loss: 1083520618.0822\n",
      "Epoch 2637/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6137045.7459 - val_loss: 1089147945.2055\n",
      "Epoch 2638/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 5758085.9641 - val_loss: 1063562380.2740\n",
      "Epoch 2639/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3718333.3432 - val_loss: 1082795231.5616\n",
      "Epoch 2640/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2717977.2562 - val_loss: 1071478859.3973\n",
      "Epoch 2641/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2569473.6659 - val_loss: 1076142654.2466\n",
      "Epoch 2642/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2343840.4619 - val_loss: 1064516237.1507\n",
      "Epoch 2643/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2192186.8146 - val_loss: 1080295955.2877\n",
      "Epoch 2644/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2439174.1115 - val_loss: 1066974570.0822\n",
      "Epoch 2645/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4922875.0934 - val_loss: 1059140346.7397\n",
      "Epoch 2646/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 7550516.3299 - val_loss: 1055672571.6164\n",
      "Epoch 2647/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6815082.5775 - val_loss: 1072328384.0000\n",
      "Epoch 2648/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 5177277.5111 - val_loss: 1065762410.9589\n",
      "Epoch 2649/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 3923624.3817 - val_loss: 1058844245.0411\n",
      "Epoch 2650/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5209711.0876 - val_loss: 1081584329.6438\n",
      "Epoch 2651/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3320446.6757 - val_loss: 1062645938.8493\n",
      "Epoch 2652/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7709511.0985 - val_loss: 1097556360.7671\n",
      "Epoch 2653/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7405264.6446 - val_loss: 1059249582.4658\n",
      "Epoch 2654/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4551177.8219 - val_loss: 1072754542.4658\n",
      "Epoch 2655/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4102781.9878 - val_loss: 1069253485.5890\n",
      "Epoch 2656/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2837796.0666 - val_loss: 1080301527.6712\n",
      "Epoch 2657/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2433133.7303 - val_loss: 1059671042.6301\n",
      "Epoch 2658/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2417200.1388 - val_loss: 1087572141.5890\n",
      "Epoch 2659/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2114394.4877 - val_loss: 1067490694.1370\n",
      "Epoch 2660/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1976750.9295 - val_loss: 1086281583.3425\n",
      "Epoch 2661/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3040179.0829 - val_loss: 1065687189.9178\n",
      "Epoch 2662/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2598918.3109 - val_loss: 1087119607.2329\n",
      "Epoch 2663/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2779851.9160 - val_loss: 1063106954.5205\n",
      "Epoch 2664/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 3076582.2743 - val_loss: 1077131229.8082\n",
      "Epoch 2665/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4761168.0454 - val_loss: 1068265776.2192\n",
      "Epoch 2666/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13275992.7352 - val_loss: 1084257422.9041\n",
      "Epoch 2667/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 112233861.4293 - val_loss: 1195752738.1918\n",
      "Epoch 2668/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 109195236.7986 - val_loss: 1106914396.4932\n",
      "Epoch 2669/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 53373585.9092 - val_loss: 1120398563.9452\n",
      "Epoch 2670/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 28953408.7027 - val_loss: 1106619884.7123\n",
      "Epoch 2671/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 13103729.3543 - val_loss: 1077709338.3014\n",
      "Epoch 2672/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10556481.1671 - val_loss: 1091427932.0548\n",
      "Epoch 2673/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13144191.6251 - val_loss: 1108899655.8904\n",
      "Epoch 2674/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7349245.0473 - val_loss: 1081183875.5068\n",
      "Epoch 2675/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6066320.7849 - val_loss: 1092291472.6575\n",
      "Epoch 2676/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7488074.5501 - val_loss: 1075510791.8904\n",
      "Epoch 2677/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4162619.0126 - val_loss: 1064342705.9726\n",
      "Epoch 2678/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2783264.6771 - val_loss: 1072690332.9315\n",
      "Epoch 2679/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2345956.1645 - val_loss: 1077255901.8082\n",
      "Epoch 2680/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2849847.7774 - val_loss: 1075377697.3151\n",
      "Epoch 2681/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2212793.3091 - val_loss: 1071436324.8219\n",
      "Epoch 2682/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3447528.5949 - val_loss: 1062436889.4247\n",
      "Epoch 2683/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2787779.8355 - val_loss: 1065572956.9315\n",
      "Epoch 2684/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3173405.3505 - val_loss: 1063528968.7671\n",
      "Epoch 2685/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5573248.4884 - val_loss: 1068288013.1507\n",
      "Epoch 2686/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4421863.4999 - val_loss: 1082162970.3014\n",
      "Epoch 2687/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3811809.7712 - val_loss: 1066918242.1918\n",
      "Epoch 2688/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4079342.6817 - val_loss: 1068408729.4247\n",
      "Epoch 2689/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 6822015.8402 - val_loss: 1065943749.2603\n",
      "Epoch 2690/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3513437.1530 - val_loss: 1077722775.6712\n",
      "Epoch 2691/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3925778.6971 - val_loss: 1064772540.4932\n",
      "Epoch 2692/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5793157.6939 - val_loss: 1075311958.7945\n",
      "Epoch 2693/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5319920.0608 - val_loss: 1077516108.2740\n",
      "Epoch 2694/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 8788524.3710 - val_loss: 1053150799.7808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2695/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5663284.7926 - val_loss: 1073521922.6301\n",
      "Epoch 2696/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 14669365.4919 - val_loss: 1109213555.7260\n",
      "Epoch 2697/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 19156369.0771 - val_loss: 1142368173.5890\n",
      "Epoch 2698/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 21716328.9066 - val_loss: 1087712516.3836\n",
      "Epoch 2699/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 18594127.1534 - val_loss: 1145592138.0822\n",
      "Epoch 2700/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 42534202.9983 - val_loss: 1141217992.7671\n",
      "Epoch 2701/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35552703.9237 - val_loss: 1089057437.8082\n",
      "Epoch 2702/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 28009307.2099 - val_loss: 1089115021.1507\n",
      "Epoch 2703/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 18762401.3745 - val_loss: 1130564378.3014\n",
      "Epoch 2704/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 18699500.5424 - val_loss: 1071383990.3562\n",
      "Epoch 2705/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12473291.5763 - val_loss: 1064943466.0822\n",
      "Epoch 2706/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 12345331.8447 - val_loss: 1068296991.5616\n",
      "Epoch 2707/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9445566.5176 - val_loss: 1064497747.2877\n",
      "Epoch 2708/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 10189446.7793 - val_loss: 1090790236.0548\n",
      "Epoch 2709/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8321208.8218 - val_loss: 1078234726.5753\n",
      "Epoch 2710/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4458839.1868 - val_loss: 1075020928.8767\n",
      "Epoch 2711/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3622006.1979 - val_loss: 1070006563.9452\n",
      "Epoch 2712/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2248408.1817 - val_loss: 1071649165.1507\n",
      "Epoch 2713/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1880282.9391 - val_loss: 1064195541.9178\n",
      "Epoch 2714/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2177666.3193 - val_loss: 1067318324.6027\n",
      "Epoch 2715/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1951715.5190 - val_loss: 1060125799.4521\n",
      "Epoch 2716/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1660003.6245 - val_loss: 1065996474.7397\n",
      "Epoch 2717/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1911945.0733 - val_loss: 1064232815.3425\n",
      "Epoch 2718/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2460481.0977 - val_loss: 1055466071.6712\n",
      "Epoch 2719/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2516608.9183 - val_loss: 1062816442.7397\n",
      "Epoch 2720/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1770649.1560 - val_loss: 1061327931.6164\n",
      "Epoch 2721/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1822073.0596 - val_loss: 1067600491.8356\n",
      "Epoch 2722/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4079192.3944 - val_loss: 1066164499.2877\n",
      "Epoch 2723/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5314776.1945 - val_loss: 1074693549.5890\n",
      "Epoch 2724/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 9219918.5536 - val_loss: 1051116014.4658\n",
      "Epoch 2725/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8165027.6737 - val_loss: 1050615738.7397\n",
      "Epoch 2726/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5748900.3389 - val_loss: 1073644773.6986\n",
      "Epoch 2727/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4738283.8858 - val_loss: 1072218583.6712\n",
      "Epoch 2728/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4855059.6919 - val_loss: 1079111922.8493\n",
      "Epoch 2729/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3360831.1249 - val_loss: 1065677940.6027\n",
      "Epoch 2730/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3607936.2868 - val_loss: 1059336433.0959\n",
      "Epoch 2731/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 8593862.4692 - val_loss: 1076875554.1918\n",
      "Epoch 2732/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11615732.5004 - val_loss: 1093390732.2740\n",
      "Epoch 2733/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 63829926.7524 - val_loss: 1272293745.0959\n",
      "Epoch 2734/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 54367237.1071 - val_loss: 1082581437.3699\n",
      "Epoch 2735/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 21871416.9940 - val_loss: 1074394386.4110\n",
      "Epoch 2736/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10876410.6033 - val_loss: 1080253210.3014\n",
      "Epoch 2737/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 10181050.5030 - val_loss: 1090410733.5890\n",
      "Epoch 2738/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5635213.0036 - val_loss: 1079410588.0548\n",
      "Epoch 2739/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4156622.3967 - val_loss: 1054925382.1370\n",
      "Epoch 2740/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3774674.2761 - val_loss: 1079067009.7534\n",
      "Epoch 2741/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 3486345.4926 - val_loss: 1064227260.4932\n",
      "Epoch 2742/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2950230.4659 - val_loss: 1062610487.2329\n",
      "Epoch 2743/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4454851.3955 - val_loss: 1077609040.6575\n",
      "Epoch 2744/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3355954.5863 - val_loss: 1055554799.3425\n",
      "Epoch 2745/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 2952801.7301 - val_loss: 1072596244.1644\n",
      "Epoch 2746/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2708770.1696 - val_loss: 1053733351.4521\n",
      "Epoch 2747/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2347479.6655 - val_loss: 1066606053.6986\n",
      "Epoch 2748/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2958472.4395 - val_loss: 1067794698.5205\n",
      "Epoch 2749/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2886076.6819 - val_loss: 1084616433.0959\n",
      "Epoch 2750/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4081233.1401 - val_loss: 1061195883.8356\n",
      "Epoch 2751/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4070761.4000 - val_loss: 1068462436.8219\n",
      "Epoch 2752/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5860701.7135 - val_loss: 1070611244.7123\n",
      "Epoch 2753/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6959300.4225 - val_loss: 1063362478.4658\n",
      "Epoch 2754/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5811033.5167 - val_loss: 1065207513.4247\n",
      "Epoch 2755/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 109332497.1517 - val_loss: 1330354876.4932\n",
      "Epoch 2756/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 162373749.2168 - val_loss: 1115766800.2192\n",
      "Epoch 2757/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 67758718.2382 - val_loss: 1056318083.5068\n",
      "Epoch 2758/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 38930732.9443 - val_loss: 1075814212.3836\n",
      "Epoch 2759/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14132990.9837 - val_loss: 1071917707.3973\n",
      "Epoch 2760/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12051752.6072 - val_loss: 1064948741.2603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2761/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7601298.1399 - val_loss: 1092551727.3425\n",
      "Epoch 2762/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8163526.0150 - val_loss: 1079540474.7397\n",
      "Epoch 2763/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9862015.5362 - val_loss: 1073254361.4247\n",
      "Epoch 2764/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 10883873.7584 - val_loss: 1059638547.2877\n",
      "Epoch 2765/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 8654916.8655 - val_loss: 1060273206.3562\n",
      "Epoch 2766/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6984099.9062 - val_loss: 1071783341.5890\n",
      "Epoch 2767/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4941307.2391 - val_loss: 1052652953.4247\n",
      "Epoch 2768/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2997787.2179 - val_loss: 1066737556.1644\n",
      "Epoch 2769/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3087371.0829 - val_loss: 1053363301.6986\n",
      "Epoch 2770/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2399753.0521 - val_loss: 1053751431.0137\n",
      "Epoch 2771/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2000903.9795 - val_loss: 1059666958.0274\n",
      "Epoch 2772/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2350620.8722 - val_loss: 1058069995.8356\n",
      "Epoch 2773/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2438159.0895 - val_loss: 1057615787.8356\n",
      "Epoch 2774/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2758704.7549 - val_loss: 1067403584.8767\n",
      "Epoch 2775/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 3163060.7845 - val_loss: 1056765919.5616\n",
      "Epoch 2776/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4005288.1677 - val_loss: 1056705678.0274\n",
      "Epoch 2777/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3545346.6392 - val_loss: 1047251015.8904\n",
      "Epoch 2778/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2967735.6620 - val_loss: 1057961550.9041\n",
      "Epoch 2779/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2614081.8504 - val_loss: 1054971788.2740\n",
      "Epoch 2780/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3012221.9127 - val_loss: 1068230825.2055\n",
      "Epoch 2781/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2886970.2446 - val_loss: 1054022805.9178\n",
      "Epoch 2782/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3282430.1587 - val_loss: 1058073805.1507\n",
      "Epoch 2783/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3270201.1645 - val_loss: 1055796346.7397\n",
      "Epoch 2784/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2535964.3326 - val_loss: 1066942959.3425\n",
      "Epoch 2785/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2667578.6133 - val_loss: 1056236248.5479\n",
      "Epoch 2786/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2421718.1527 - val_loss: 1062070016.8767\n",
      "Epoch 2787/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5544619.5707 - val_loss: 1046898911.5616\n",
      "Epoch 2788/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6756245.2093 - val_loss: 1064980030.2466\n",
      "Epoch 2789/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9734956.4225 - val_loss: 1069265479.8904\n",
      "Epoch 2790/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 18975659.8989 - val_loss: 1063953225.6438\n",
      "Epoch 2791/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16414513.2956 - val_loss: 1069834633.6438\n",
      "Epoch 2792/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12123502.9811 - val_loss: 1065945294.0274\n",
      "Epoch 2793/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 11689858.2793 - val_loss: 1068123085.1507\n",
      "Epoch 2794/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5714940.2624 - val_loss: 1046264728.5479\n",
      "Epoch 2795/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5443146.3569 - val_loss: 1042963602.4110\n",
      "Epoch 2796/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5273046.7736 - val_loss: 1049342745.4247\n",
      "Epoch 2797/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4955747.0934 - val_loss: 1062893637.2603\n",
      "Epoch 2798/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3066865.1452 - val_loss: 1053029999.3425\n",
      "Epoch 2799/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4035862.8483 - val_loss: 1076004778.9589\n",
      "Epoch 2800/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 6348727.4672 - val_loss: 1079555688.3288\n",
      "Epoch 2801/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5927969.7226 - val_loss: 1049868761.4247\n",
      "Epoch 2802/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 6450406.1675 - val_loss: 1046275101.8082\n",
      "Epoch 2803/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8334491.5210 - val_loss: 1048907448.1096\n",
      "Epoch 2804/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6300426.1135 - val_loss: 1072055323.1781\n",
      "Epoch 2805/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4263715.7517 - val_loss: 1043530918.5753\n",
      "Epoch 2806/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3725899.7896 - val_loss: 1064883011.5068\n",
      "Epoch 2807/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2327843.9875 - val_loss: 1065331349.9178\n",
      "Epoch 2808/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3303873.8303 - val_loss: 1050962405.6986\n",
      "Epoch 2809/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 5210387.9773 - val_loss: 1055437606.1370\n",
      "Epoch 2810/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 13736612.2121 - val_loss: 1078785622.7945\n",
      "Epoch 2811/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 23098892.4473 - val_loss: 1062419061.4795\n",
      "Epoch 2812/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 23720655.6628 - val_loss: 1060010318.0274\n",
      "Epoch 2813/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 16733610.7558 - val_loss: 1078893897.6438\n",
      "Epoch 2814/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 21532630.5733 - val_loss: 1070176168.3288\n",
      "Epoch 2815/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37543799.5270 - val_loss: 1117637569.3151\n",
      "Epoch 2816/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 45930491.7558 - val_loss: 1076308457.2055\n",
      "Epoch 2817/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 14784506.7991 - val_loss: 1055441211.6164\n",
      "Epoch 2818/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 15684165.0214 - val_loss: 1148570394.3014\n",
      "Epoch 2819/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 14611495.6170 - val_loss: 1049122034.8493\n",
      "Epoch 2820/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 9617527.0334 - val_loss: 1058644914.8493\n",
      "Epoch 2821/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5312030.6939 - val_loss: 1031378053.2603\n",
      "Epoch 2822/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3823564.1607 - val_loss: 1043215271.4521\n",
      "Epoch 2823/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4950142.8250 - val_loss: 1058734208.0000\n",
      "Epoch 2824/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3220491.8715 - val_loss: 1071209777.0959\n",
      "Epoch 2825/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4094105.5523 - val_loss: 1047712504.1096\n",
      "Epoch 2826/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4175222.4724 - val_loss: 1086946692.3836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2827/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4946660.2044 - val_loss: 1067154531.0685\n",
      "Epoch 2828/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2960540.7077 - val_loss: 1054912487.4521\n",
      "Epoch 2829/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3146832.4293 - val_loss: 1044747217.5342\n",
      "Epoch 2830/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4755317.5296 - val_loss: 1056161217.7534\n",
      "Epoch 2831/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 12238675.2202 - val_loss: 1092436374.7945\n",
      "Epoch 2832/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11735387.6759 - val_loss: 1084107262.2466\n",
      "Epoch 2833/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 9533244.2112 - val_loss: 1071738029.5890\n",
      "Epoch 2834/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 12328892.3599 - val_loss: 1052242567.8904\n",
      "Epoch 2835/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 10070225.4610 - val_loss: 1060383132.9315\n",
      "Epoch 2836/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6286018.5583 - val_loss: 1046793205.4795\n",
      "Epoch 2837/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4714196.5596 - val_loss: 1065653848.5479\n",
      "Epoch 2838/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4471220.6756 - val_loss: 1054198383.3425\n",
      "Epoch 2839/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9605497.6380 - val_loss: 1095731225.8630\n",
      "Epoch 2840/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 26006264.7832 - val_loss: 1086139118.4658\n",
      "Epoch 2841/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 16962068.9237 - val_loss: 1082617041.5342\n",
      "Epoch 2842/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13732699.8890 - val_loss: 1068797943.2329\n",
      "Epoch 2843/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9968747.9053 - val_loss: 1084252334.4658\n",
      "Epoch 2844/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8371587.4884 - val_loss: 1068381388.2740\n",
      "Epoch 2845/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4798869.1418 - val_loss: 1056444530.8493\n",
      "Epoch 2846/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3254253.3278 - val_loss: 1060877443.5068\n",
      "Epoch 2847/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3812152.3506 - val_loss: 1059161348.3836\n",
      "Epoch 2848/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4716617.9417 - val_loss: 1073918523.6164\n",
      "Epoch 2849/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6198346.6037 - val_loss: 1094050936.9863\n",
      "Epoch 2850/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6344722.9760 - val_loss: 1060665018.7397\n",
      "Epoch 2851/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8439206.9794 - val_loss: 1092239397.6986\n",
      "Epoch 2852/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 11590770.8496 - val_loss: 1045401470.2466\n",
      "Epoch 2853/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 12922123.5733 - val_loss: 1101450329.4247\n",
      "Epoch 2854/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 15177760.4490 - val_loss: 1067793456.2192\n",
      "Epoch 2855/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 25076510.0514 - val_loss: 1111222868.1644\n",
      "Epoch 2856/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 18308077.8526 - val_loss: 1097622971.6164\n",
      "Epoch 2857/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 12983592.1504 - val_loss: 1068257278.2466\n",
      "Epoch 2858/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 5999946.1857 - val_loss: 1070593009.9726\n",
      "Epoch 2859/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5150175.0591 - val_loss: 1068705117.8082\n",
      "Epoch 2860/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6870607.0169 - val_loss: 1073056856.5479\n",
      "Epoch 2861/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4127673.8552 - val_loss: 1073310953.2055\n",
      "Epoch 2862/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6732887.8489 - val_loss: 1065783999.1233\n",
      "Epoch 2863/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6534704.5352 - val_loss: 1084218304.8767\n",
      "Epoch 2864/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5494516.3492 - val_loss: 1075184879.3425\n",
      "Epoch 2865/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5197219.2751 - val_loss: 1051205772.2740\n",
      "Epoch 2866/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 11190720.2241 - val_loss: 1069826558.2466\n",
      "Epoch 2867/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 11334862.1954 - val_loss: 1115519984.2192\n",
      "Epoch 2868/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 8789603.6984 - val_loss: 1088096104.3288\n",
      "Epoch 2869/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 5747505.0767 - val_loss: 1075417240.5479\n",
      "Epoch 2870/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5157541.9066 - val_loss: 1077766878.6849\n",
      "Epoch 2871/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3893322.0703 - val_loss: 1073319907.9452\n",
      "Epoch 2872/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2676480.7224 - val_loss: 1068175109.2603\n",
      "Epoch 2873/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 10957659.8164 - val_loss: 1104537473.7534\n",
      "Epoch 2874/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6977263.9786 - val_loss: 1050308622.9041\n",
      "Epoch 2875/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10015027.9811 - val_loss: 1086426417.0959\n",
      "Epoch 2876/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 15276803.6538 - val_loss: 1070374705.9726\n",
      "Epoch 2877/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9206788.0154 - val_loss: 1037334063.3425\n",
      "Epoch 2878/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 10253222.5801 - val_loss: 1069561834.9589\n",
      "Epoch 2879/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 16808603.0900 - val_loss: 1070854012.4932\n",
      "Epoch 2880/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 15216176.7155 - val_loss: 1078517282.1918\n",
      "Epoch 2881/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 9460343.6084 - val_loss: 1055595094.7945\n",
      "Epoch 2882/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 11347115.3672 - val_loss: 1054166673.5342\n",
      "Epoch 2883/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9116460.1208 - val_loss: 1052575663.3425\n",
      "Epoch 2884/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6436242.3813 - val_loss: 1047928780.2740\n",
      "Epoch 2885/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6907474.2781 - val_loss: 1061015767.6712\n",
      "Epoch 2886/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6079393.1937 - val_loss: 1041880467.2877\n",
      "Epoch 2887/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9659759.5004 - val_loss: 1032764902.5753\n",
      "Epoch 2888/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 11319847.9732 - val_loss: 1085498953.6438\n",
      "Epoch 2889/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 45568515.4619 - val_loss: 1081411272.7671\n",
      "Epoch 2890/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 30984858.8723 - val_loss: 1156941011.2877\n",
      "Epoch 2891/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 18553409.1585 - val_loss: 1082243201.7534\n",
      "Epoch 2892/5000\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 23500841.2031 - val_loss: 1075511410.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2893/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 19609952.5767 - val_loss: 1055439057.5342\n",
      "Epoch 2894/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 10767856.3835 - val_loss: 1065231368.7671\n",
      "Epoch 2895/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9905048.3942 - val_loss: 1088288817.9726\n",
      "Epoch 2896/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 11839211.8907 - val_loss: 1070705285.2603\n",
      "Epoch 2897/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4079032.9289 - val_loss: 1059398790.1370\n",
      "Epoch 2898/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3397704.7918 - val_loss: 1061626150.5753\n",
      "Epoch 2899/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3236299.9083 - val_loss: 1048877105.9726\n",
      "Epoch 2900/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3235739.2562 - val_loss: 1057844617.6438\n",
      "Epoch 2901/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3246549.9744 - val_loss: 1067418175.1233\n",
      "Epoch 2902/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2743177.8994 - val_loss: 1046706187.3973\n",
      "Epoch 2903/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 1618567.8318 - val_loss: 1057915583.1233\n",
      "Epoch 2904/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 1597085.7352 - val_loss: 1038744972.2740\n",
      "Epoch 2905/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1843834.2219 - val_loss: 1055983768.5479\n",
      "Epoch 2906/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1865796.0049 - val_loss: 1046972505.4247\n",
      "Epoch 2907/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1757274.7007 - val_loss: 1048445475.0685\n",
      "Epoch 2908/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3369572.1285 - val_loss: 1037467555.9452\n",
      "Epoch 2909/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4833398.9666 - val_loss: 1057759589.6986\n",
      "Epoch 2910/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5798316.2530 - val_loss: 1053921208.1096\n",
      "Epoch 2911/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4715902.6919 - val_loss: 1074513838.4658\n",
      "Epoch 2912/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7032299.2519 - val_loss: 1046892922.7397\n",
      "Epoch 2913/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 8415168.2776 - val_loss: 1084644939.3973\n",
      "Epoch 2914/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6863529.9794 - val_loss: 1069308130.1918\n",
      "Epoch 2915/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 13222626.2159 - val_loss: 1047866906.3014\n",
      "Epoch 2916/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 9667506.1037 - val_loss: 1060299699.7260\n",
      "Epoch 2917/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 9251723.0883 - val_loss: 1095760287.5616\n",
      "Epoch 2918/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 13316604.1195 - val_loss: 1103750261.4795\n",
      "Epoch 2919/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 25407878.4696 - val_loss: 1130630392.9863\n",
      "Epoch 2920/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 52140159.2168 - val_loss: 1140774720.0000\n",
      "Epoch 2921/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 50839114.3308 - val_loss: 1146236147.7260\n",
      "Epoch 2922/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 45893107.2836 - val_loss: 1153213197.1507\n",
      "Epoch 2923/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 29548446.9537 - val_loss: 1088822417.9726\n",
      "Epoch 2924/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 30131743.9122 - val_loss: 1071295634.4110\n",
      "Epoch 2925/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 13410715.1500 - val_loss: 1061866912.4384\n",
      "Epoch 2926/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 13998635.5051 - val_loss: 1082132238.0274\n",
      "Epoch 2927/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8444824.6195 - val_loss: 1061911600.2192\n",
      "Epoch 2928/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5575123.1673 - val_loss: 1080056657.5342\n",
      "Epoch 2929/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2933338.8716 - val_loss: 1078709970.4110\n",
      "Epoch 2930/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3516093.2937 - val_loss: 1081759448.5479\n",
      "Epoch 2931/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2284455.3260 - val_loss: 1074673047.6712\n",
      "Epoch 2932/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1950248.5955 - val_loss: 1073562574.9041\n",
      "Epoch 2933/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1996177.5047 - val_loss: 1069035160.5479\n",
      "Epoch 2934/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2234945.9717 - val_loss: 1069059333.2603\n",
      "Epoch 2935/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3245997.1445 - val_loss: 1079866116.3836\n",
      "Epoch 2936/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3893733.9008 - val_loss: 1060975831.6712\n",
      "Epoch 2937/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2786313.6474 - val_loss: 1069662803.2877\n",
      "Epoch 2938/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3574859.8260 - val_loss: 1063765571.5068\n",
      "Epoch 2939/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2961023.3685 - val_loss: 1069625160.7671\n",
      "Epoch 2940/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 2665682.4143 - val_loss: 1082876757.0411\n",
      "Epoch 2941/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3407039.5428 - val_loss: 1070858827.3973\n",
      "Epoch 2942/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3588248.4293 - val_loss: 1079115425.3151\n",
      "Epoch 2943/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4017751.0508 - val_loss: 1060449855.1233\n",
      "Epoch 2944/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2394108.7138 - val_loss: 1071195934.6849\n",
      "Epoch 2945/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6360151.8252 - val_loss: 1058039948.2740\n",
      "Epoch 2946/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5316211.2215 - val_loss: 1084377429.0411\n",
      "Epoch 2947/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4982625.1326 - val_loss: 1051559590.5753\n",
      "Epoch 2948/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 5818942.5111 - val_loss: 1097640394.5205\n",
      "Epoch 2949/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9491689.6714 - val_loss: 1049211264.0000\n",
      "Epoch 2950/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 10841575.4036 - val_loss: 1100154556.4932\n",
      "Epoch 2951/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 63994128.7472 - val_loss: 1185359035.8356\n",
      "Epoch 2952/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 44498680.6924 - val_loss: 1112157433.8630\n",
      "Epoch 2953/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 26834566.3505 - val_loss: 1115909510.1370\n",
      "Epoch 2954/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13153720.8757 - val_loss: 1056458981.6986\n",
      "Epoch 2955/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7454625.8603 - val_loss: 1066888122.7397\n",
      "Epoch 2956/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4476566.8856 - val_loss: 1062455991.2329\n",
      "Epoch 2957/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4932775.6851 - val_loss: 1067308138.9589\n",
      "Epoch 2958/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3485181.6853 - val_loss: 1050492856.1096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2959/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4066770.0036 - val_loss: 1057357811.7260\n",
      "Epoch 2960/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6228771.7408 - val_loss: 1077596909.5890\n",
      "Epoch 2961/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 4269779.7768 - val_loss: 1082983905.3151\n",
      "Epoch 2962/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2468906.9805 - val_loss: 1061274624.8767\n",
      "Epoch 2963/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3610478.1883 - val_loss: 1071235291.1781\n",
      "Epoch 2964/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6872166.7294 - val_loss: 1058219317.4795\n",
      "Epoch 2965/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5795978.7524 - val_loss: 1080393163.3973\n",
      "Epoch 2966/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 3355337.5891 - val_loss: 1067226285.5890\n",
      "Epoch 2967/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 3961549.3749 - val_loss: 1081484407.2329\n",
      "Epoch 2968/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3570379.7677 - val_loss: 1063080583.8904\n",
      "Epoch 2969/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4630332.9072 - val_loss: 1080559696.6575\n",
      "Epoch 2970/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4606402.8197 - val_loss: 1059517745.0959\n",
      "Epoch 2971/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3393503.5236 - val_loss: 1066516131.0685\n",
      "Epoch 2972/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5592111.8646 - val_loss: 1065876763.1781\n",
      "Epoch 2973/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8144546.0034 - val_loss: 1094020868.3836\n",
      "Epoch 2974/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8882971.7249 - val_loss: 1076853347.9452\n",
      "Epoch 2975/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 7293205.8779 - val_loss: 1061327770.3014\n",
      "Epoch 2976/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 4894323.4314 - val_loss: 1073128960.8767\n",
      "Epoch 2977/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 5938851.1962 - val_loss: 1066968238.4658\n",
      "Epoch 2978/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 4703411.5707 - val_loss: 1079875348.1644\n",
      "Epoch 2979/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 7165979.9850 - val_loss: 1078966279.0137\n",
      "Epoch 2980/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 8569734.1926 - val_loss: 1105738274.1918\n",
      "Epoch 2981/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 8056415.6323 - val_loss: 1056483425.3151\n",
      "Epoch 2982/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8578381.0746 - val_loss: 1078989639.8904\n",
      "Epoch 2983/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 7428958.3869 - val_loss: 1069697098.5205\n",
      "Epoch 2984/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5185649.0450 - val_loss: 1078866111.1233\n",
      "Epoch 2985/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5249929.6911 - val_loss: 1073077845.0411\n",
      "Epoch 2986/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8737621.1628 - val_loss: 1054659597.1507\n",
      "Epoch 2987/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6807065.7446 - val_loss: 1066145273.8630\n",
      "Epoch 2988/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6623710.3723 - val_loss: 1081890116.3836\n",
      "Epoch 2989/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9274791.1264 - val_loss: 1081440348.9315\n",
      "Epoch 2990/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 15008250.8500 - val_loss: 1058594733.5890\n",
      "Epoch 2991/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 14748530.3500 - val_loss: 1061748952.5479\n",
      "Epoch 2992/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 16605698.5161 - val_loss: 1117800519.0137\n",
      "Epoch 2993/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12275207.9937 - val_loss: 1060377808.6575\n",
      "Epoch 2994/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 10999840.5081 - val_loss: 1067873287.8904\n",
      "Epoch 2995/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10929919.1337 - val_loss: 1094056993.3151\n",
      "Epoch 2996/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 20479699.8123 - val_loss: 1132935189.0411\n",
      "Epoch 2997/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 85669970.3171 - val_loss: 1146269371.6164\n",
      "Epoch 2998/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 52115860.0206 - val_loss: 1073976893.3699\n",
      "Epoch 2999/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 22730049.9747 - val_loss: 1054755183.3425\n",
      "Epoch 3000/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 13508466.0673 - val_loss: 1067661514.5205\n",
      "Epoch 3001/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5603756.4891 - val_loss: 1055019459.5068\n",
      "Epoch 3002/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4428828.2646 - val_loss: 1078257920.0000\n",
      "Epoch 3003/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4880221.1924 - val_loss: 1068066801.9726\n",
      "Epoch 3004/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4734474.4846 - val_loss: 1070956810.5205\n",
      "Epoch 3005/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3526066.0197 - val_loss: 1059014875.1781\n",
      "Epoch 3006/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2266440.4537 - val_loss: 1057249937.5342\n",
      "Epoch 3007/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1752298.4425 - val_loss: 1053085878.3562\n",
      "Epoch 3008/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2171550.4600 - val_loss: 1060074504.7671\n",
      "Epoch 3009/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 1751738.1386 - val_loss: 1070455339.8356\n",
      "Epoch 3010/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1725863.3684 - val_loss: 1061969746.4110\n",
      "Epoch 3011/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1613370.1456 - val_loss: 1076442114.6301\n",
      "Epoch 3012/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1513255.6488 - val_loss: 1063714763.3973\n",
      "Epoch 3013/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1293022.4551 - val_loss: 1057726109.8082\n",
      "Epoch 3014/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 1637439.3459 - val_loss: 1068640578.6301\n",
      "Epoch 3015/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2090013.8383 - val_loss: 1065538352.2192\n",
      "Epoch 3016/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2898526.1315 - val_loss: 1070893489.0959\n",
      "Epoch 3017/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2461982.1206 - val_loss: 1077706649.4247\n",
      "Epoch 3018/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 2309478.3755 - val_loss: 1058269927.4521\n",
      "Epoch 3019/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2211198.3992 - val_loss: 1070044942.0274\n",
      "Epoch 3020/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2035753.7121 - val_loss: 1072376048.2192\n",
      "Epoch 3021/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1944968.1509 - val_loss: 1073878843.6164\n",
      "Epoch 3022/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2056081.7905 - val_loss: 1064287033.8630\n",
      "Epoch 3023/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2508450.7399 - val_loss: 1083059889.9726\n",
      "Epoch 3024/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4183537.5189 - val_loss: 1058694694.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3025/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4746145.0557 - val_loss: 1071560257.7534\n",
      "Epoch 3026/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6838261.5506 - val_loss: 1050850972.0548\n",
      "Epoch 3027/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8357311.8858 - val_loss: 1101403971.5068\n",
      "Epoch 3028/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 20532531.9083 - val_loss: 1139642707.2877\n",
      "Epoch 3029/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 43987878.2656 - val_loss: 1225378211.9452\n",
      "Epoch 3030/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 111345894.5878 - val_loss: 1158506730.0822\n",
      "Epoch 3031/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 28942594.8226 - val_loss: 1076657949.8082\n",
      "Epoch 3032/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 15045100.2579 - val_loss: 1043773869.5890\n",
      "Epoch 3033/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 9074713.2648 - val_loss: 1054566320.2192\n",
      "Epoch 3034/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7836633.1268 - val_loss: 1085579681.3151\n",
      "Epoch 3035/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6296081.3342 - val_loss: 1048665548.2740\n",
      "Epoch 3036/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7596427.4409 - val_loss: 1070018666.9589\n",
      "Epoch 3037/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4735425.6829 - val_loss: 1067248944.2192\n",
      "Epoch 3038/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3219026.5662 - val_loss: 1064875345.9726\n",
      "Epoch 3039/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3037832.9532 - val_loss: 1060280371.7260\n",
      "Epoch 3040/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1938261.3905 - val_loss: 1052234419.7260\n",
      "Epoch 3041/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2957842.7196 - val_loss: 1057040477.8082\n",
      "Epoch 3042/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4227480.1868 - val_loss: 1068975392.4384\n",
      "Epoch 3043/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6140973.2018 - val_loss: 1068869245.3699\n",
      "Epoch 3044/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3446244.6547 - val_loss: 1064486487.6712\n",
      "Epoch 3045/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3436465.7137 - val_loss: 1073608153.4247\n",
      "Epoch 3046/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2550145.5266 - val_loss: 1069212163.5068\n",
      "Epoch 3047/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 2329160.8166 - val_loss: 1075774694.5753\n",
      "Epoch 3048/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3731532.4871 - val_loss: 1065353393.0959\n",
      "Epoch 3049/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3513724.2599 - val_loss: 1069943377.5342\n",
      "Epoch 3050/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 2813737.6123 - val_loss: 1068602311.0137\n",
      "Epoch 3051/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4585376.1384 - val_loss: 1089546819.5068\n",
      "Epoch 3052/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4983843.5570 - val_loss: 1063425122.1918\n",
      "Epoch 3053/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 13380571.6332 - val_loss: 1068105929.6438\n",
      "Epoch 3054/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 26413791.3282 - val_loss: 1125858090.0822\n",
      "Epoch 3055/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 12990312.4649 - val_loss: 1081167554.6301\n",
      "Epoch 3056/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6106264.7695 - val_loss: 1066731092.1644\n",
      "Epoch 3057/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4866704.5413 - val_loss: 1090305490.4110\n",
      "Epoch 3058/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 5929880.0214 - val_loss: 1057944778.5205\n",
      "Epoch 3059/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5037761.9254 - val_loss: 1075471938.6301\n",
      "Epoch 3060/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4992834.9254 - val_loss: 1050128775.0137\n",
      "Epoch 3061/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 7085005.9803 - val_loss: 1087037550.0274\n",
      "Epoch 3062/5000\n",
      "1167/1167 [==============================] - 0s 300us/step - loss: 9814256.6954 - val_loss: 1075026527.5616\n",
      "Epoch 3063/5000\n",
      "1167/1167 [==============================] - 0s 292us/step - loss: 8431037.0343 - val_loss: 1054136433.0959\n",
      "Epoch 3064/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 6991230.1272 - val_loss: 1072446343.0137\n",
      "Epoch 3065/5000\n",
      "1167/1167 [==============================] - 0s 291us/step - loss: 6905443.2601 - val_loss: 1087561819.1781\n",
      "Epoch 3066/5000\n",
      "1167/1167 [==============================] - 0s 293us/step - loss: 11677711.9863 - val_loss: 1080473350.1370\n",
      "Epoch 3067/5000\n",
      "1167/1167 [==============================] - 0s 281us/step - loss: 6069083.3428 - val_loss: 1059723732.1644\n",
      "Epoch 3068/5000\n",
      "1167/1167 [==============================] - 0s 301us/step - loss: 5635212.9087 - val_loss: 1059012943.7808\n",
      "Epoch 3069/5000\n",
      "1167/1167 [==============================] - 0s 301us/step - loss: 5417345.6707 - val_loss: 1079202309.2603\n",
      "Epoch 3070/5000\n",
      "1167/1167 [==============================] - 0s 288us/step - loss: 6620339.8843 - val_loss: 1071495250.4110\n",
      "Epoch 3071/5000\n",
      "1167/1167 [==============================] - 0s 289us/step - loss: 17423090.5433 - val_loss: 1095246122.0822\n",
      "Epoch 3072/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 32510518.5604 - val_loss: 1105000412.9315\n",
      "Epoch 3073/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 119938562.8929 - val_loss: 1379667289.4247\n",
      "Epoch 3074/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 158282203.2494 - val_loss: 1193448052.6027\n",
      "Epoch 3075/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 43783903.3008 - val_loss: 1141474039.2329\n",
      "Epoch 3076/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 21987334.8627 - val_loss: 1069025484.2740\n",
      "Epoch 3077/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 13111709.2588 - val_loss: 1077594564.3836\n",
      "Epoch 3078/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11853228.7125 - val_loss: 1065095601.9726\n",
      "Epoch 3079/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6431014.2819 - val_loss: 1083396124.9315\n",
      "Epoch 3080/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4285340.1004 - val_loss: 1082269473.3151\n",
      "Epoch 3081/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3082004.1365 - val_loss: 1071127022.4658\n",
      "Epoch 3082/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1910100.1170 - val_loss: 1081895164.4932\n",
      "Epoch 3083/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1952530.7777 - val_loss: 1076395915.3973\n",
      "Epoch 3084/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1651321.7865 - val_loss: 1071870019.5068\n",
      "Epoch 3085/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1398339.7325 - val_loss: 1075827867.1781\n",
      "Epoch 3086/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1379966.4330 - val_loss: 1071582224.6575\n",
      "Epoch 3087/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1399414.4524 - val_loss: 1069541541.6986\n",
      "Epoch 3088/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1256125.8560 - val_loss: 1077397624.9863\n",
      "Epoch 3089/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1279428.6037 - val_loss: 1072082014.6849\n",
      "Epoch 3090/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1250892.4558 - val_loss: 1071825787.6164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3091/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1532296.7650 - val_loss: 1073259578.7397\n",
      "Epoch 3092/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1317303.9475 - val_loss: 1068739340.2740\n",
      "Epoch 3093/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1671848.9501 - val_loss: 1069130298.7397\n",
      "Epoch 3094/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2093983.4491 - val_loss: 1072271899.1781\n",
      "Epoch 3095/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1508371.7569 - val_loss: 1070290224.2192\n",
      "Epoch 3096/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1251762.0710 - val_loss: 1067456936.3288\n",
      "Epoch 3097/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1131113.8421 - val_loss: 1070868137.2055\n",
      "Epoch 3098/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1449081.9490 - val_loss: 1072456853.9178\n",
      "Epoch 3099/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2340644.2671 - val_loss: 1073083948.7123\n",
      "Epoch 3100/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1975874.8524 - val_loss: 1063808668.0548\n",
      "Epoch 3101/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1440235.7652 - val_loss: 1076986419.7260\n",
      "Epoch 3102/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1621352.3728 - val_loss: 1069443956.6027\n",
      "Epoch 3103/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1421184.7100 - val_loss: 1074681704.3288\n",
      "Epoch 3104/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1437385.7034 - val_loss: 1066933589.0411\n",
      "Epoch 3105/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1368164.4893 - val_loss: 1061479165.3699\n",
      "Epoch 3106/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2720213.6551 - val_loss: 1074192879.3425\n",
      "Epoch 3107/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 5051336.5501 - val_loss: 1064764523.8356\n",
      "Epoch 3108/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 4841245.3134 - val_loss: 1068802541.5890\n",
      "Epoch 3109/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3142887.7562 - val_loss: 1056410709.0411\n",
      "Epoch 3110/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1897676.0117 - val_loss: 1068708776.3288\n",
      "Epoch 3111/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2236131.6848 - val_loss: 1077273070.4658\n",
      "Epoch 3112/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2282124.5626 - val_loss: 1073604650.9589\n",
      "Epoch 3113/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1936779.0268 - val_loss: 1067731755.8356\n",
      "Epoch 3114/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1896331.2025 - val_loss: 1075746034.8493\n",
      "Epoch 3115/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2315325.7838 - val_loss: 1067552806.5753\n",
      "Epoch 3116/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2635081.0310 - val_loss: 1074244758.7945\n",
      "Epoch 3117/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1916707.1323 - val_loss: 1061688882.8493\n",
      "Epoch 3118/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 1521644.2675 - val_loss: 1068987926.7945\n",
      "Epoch 3119/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 2074531.6001 - val_loss: 1078023624.7671\n",
      "Epoch 3120/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 3625761.6796 - val_loss: 1055942200.9863\n",
      "Epoch 3121/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 6699330.0887 - val_loss: 1089051801.4247\n",
      "Epoch 3122/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 25582238.0223 - val_loss: 1137153081.8630\n",
      "Epoch 3123/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 26738646.8192 - val_loss: 1105354743.2329\n",
      "Epoch 3124/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 38149598.4336 - val_loss: 1106151450.7397\n",
      "Epoch 3125/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 25682083.8458 - val_loss: 1106244291.5068\n",
      "Epoch 3126/5000\n",
      "1167/1167 [==============================] - 0s 281us/step - loss: 39684796.4190 - val_loss: 1092703046.1370\n",
      "Epoch 3127/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 36136024.8672 - val_loss: 1090877388.2740\n",
      "Epoch 3128/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 19088915.5253 - val_loss: 1075811265.7534\n",
      "Epoch 3129/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 9360619.1761 - val_loss: 1075589658.3014\n",
      "Epoch 3130/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 5518577.8111 - val_loss: 1065899378.8493\n",
      "Epoch 3131/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 3507714.0312 - val_loss: 1063766936.5479\n",
      "Epoch 3132/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 2478618.0931 - val_loss: 1061802841.4247\n",
      "Epoch 3133/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 2859517.6964 - val_loss: 1061076616.7671\n",
      "Epoch 3134/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 2588662.3861 - val_loss: 1062396738.6301\n",
      "Epoch 3135/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 2845354.6371 - val_loss: 1072544679.4521\n",
      "Epoch 3136/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 10296813.8119 - val_loss: 1073249429.0411\n",
      "Epoch 3137/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8558342.2233 - val_loss: 1076153971.2877\n",
      "Epoch 3138/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7980949.7368 - val_loss: 1074826114.6301\n",
      "Epoch 3139/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 6024756.1397 - val_loss: 1070925653.9178\n",
      "Epoch 3140/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 5321017.3466 - val_loss: 1067709296.2192\n",
      "Epoch 3141/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8204479.5673 - val_loss: 1090170317.1507\n",
      "Epoch 3142/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13066213.4302 - val_loss: 1068822918.1370\n",
      "Epoch 3143/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8724384.8852 - val_loss: 1085658487.2329\n",
      "Epoch 3144/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 4166192.5167 - val_loss: 1070533062.1370\n",
      "Epoch 3145/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4170083.6497 - val_loss: 1065517425.0959\n",
      "Epoch 3146/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7312362.0124 - val_loss: 1086985707.8356\n",
      "Epoch 3147/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6876071.6710 - val_loss: 1055527916.7123\n",
      "Epoch 3148/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 5596482.1637 - val_loss: 1071782258.8493\n",
      "Epoch 3149/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6189398.3614 - val_loss: 1078526305.3151\n",
      "Epoch 3150/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4741266.2723 - val_loss: 1066754108.9315\n",
      "Epoch 3151/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5640815.7382 - val_loss: 1077244592.2192\n",
      "Epoch 3152/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8265822.8800 - val_loss: 1064001753.4247\n",
      "Epoch 3153/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 19536421.8967 - val_loss: 1071904312.9863\n",
      "Epoch 3154/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 26639262.7541 - val_loss: 1113315979.3973\n",
      "Epoch 3155/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 27891088.3685 - val_loss: 1066910301.8082\n",
      "Epoch 3156/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 19009952.1508 - val_loss: 1087552777.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3157/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8364196.3055 - val_loss: 1072474605.5890\n",
      "Epoch 3158/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4143461.9233 - val_loss: 1064647689.6438\n",
      "Epoch 3159/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5091799.2684 - val_loss: 1096539633.9726\n",
      "Epoch 3160/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8806218.8723 - val_loss: 1087284525.5890\n",
      "Epoch 3161/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3957970.4382 - val_loss: 1066217899.8356\n",
      "Epoch 3162/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 10463180.3213 - val_loss: 1094249382.1370\n",
      "Epoch 3163/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9900973.7284 - val_loss: 1077047420.4932\n",
      "Epoch 3164/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5679983.9863 - val_loss: 1078571816.3288\n",
      "Epoch 3165/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3812974.5139 - val_loss: 1071456809.2055\n",
      "Epoch 3166/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2812264.1168 - val_loss: 1080363795.2877\n",
      "Epoch 3167/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2401596.2489 - val_loss: 1059241444.8219\n",
      "Epoch 3168/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3207460.5509 - val_loss: 1072723453.3699\n",
      "Epoch 3169/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3324942.9160 - val_loss: 1076395657.6438\n",
      "Epoch 3170/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6143625.6313 - val_loss: 1063115484.0548\n",
      "Epoch 3171/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 9414357.7913 - val_loss: 1078316921.8630\n",
      "Epoch 3172/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11686884.8128 - val_loss: 1129278869.9178\n",
      "Epoch 3173/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 26421467.5039 - val_loss: 1081993783.2329\n",
      "Epoch 3174/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 12324626.0895 - val_loss: 1084458477.5890\n",
      "Epoch 3175/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 5409309.8537 - val_loss: 1057341408.4384\n",
      "Epoch 3176/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7129988.0857 - val_loss: 1052912096.4384\n",
      "Epoch 3177/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3848771.1990 - val_loss: 1062592584.7671\n",
      "Epoch 3178/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 4198138.4072 - val_loss: 1088803838.2466\n",
      "Epoch 3179/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4692500.3985 - val_loss: 1067438620.9315\n",
      "Epoch 3180/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2633646.6275 - val_loss: 1071735456.4384\n",
      "Epoch 3181/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3406748.9040 - val_loss: 1051014766.4658\n",
      "Epoch 3182/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 3031375.3106 - val_loss: 1058038917.2603\n",
      "Epoch 3183/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 10714585.4859 - val_loss: 1048783990.3562\n",
      "Epoch 3184/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 10781456.6230 - val_loss: 1062794006.7945\n",
      "Epoch 3185/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 8499548.9177 - val_loss: 1047889391.3425\n",
      "Epoch 3186/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5425929.9595 - val_loss: 1053486721.7534\n",
      "Epoch 3187/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3957282.0308 - val_loss: 1062261636.3836\n",
      "Epoch 3188/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2474863.9340 - val_loss: 1060750130.8493\n",
      "Epoch 3189/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1983212.3781 - val_loss: 1061461472.4384\n",
      "Epoch 3190/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 2404537.8847 - val_loss: 1068953792.0000\n",
      "Epoch 3191/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2189685.8621 - val_loss: 1057637378.6301\n",
      "Epoch 3192/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 3354235.0523 - val_loss: 1062145187.9452\n",
      "Epoch 3193/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 16574880.2091 - val_loss: 1064258630.1370\n",
      "Epoch 3194/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 22158595.4944 - val_loss: 1078284752.6575\n",
      "Epoch 3195/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35828365.4606 - val_loss: 1057455082.9589\n",
      "Epoch 3196/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 60932511.6230 - val_loss: 1217255050.5205\n",
      "Epoch 3197/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 71159892.5930 - val_loss: 1167705142.3562\n",
      "Epoch 3198/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 42716887.6847 - val_loss: 1223012911.3425\n",
      "Epoch 3199/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 32336546.3042 - val_loss: 1097342981.2603\n",
      "Epoch 3200/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 8558802.6474 - val_loss: 1084075760.2192\n",
      "Epoch 3201/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 5036504.6784 - val_loss: 1072593371.1781\n",
      "Epoch 3202/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 3709828.3698 - val_loss: 1075877866.9589\n",
      "Epoch 3203/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2648610.0351 - val_loss: 1085173022.6849\n",
      "Epoch 3204/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 2802756.4751 - val_loss: 1080590152.7671\n",
      "Epoch 3205/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 3210573.1759 - val_loss: 1081476178.4110\n",
      "Epoch 3206/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 2162388.1118 - val_loss: 1074011143.0137\n",
      "Epoch 3207/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 4002018.4815 - val_loss: 1088677350.5753\n",
      "Epoch 3208/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 2239111.6916 - val_loss: 1071662684.0548\n",
      "Epoch 3209/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 1665977.1962 - val_loss: 1087366956.7123\n",
      "Epoch 3210/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 1375358.1219 - val_loss: 1073654861.1507\n",
      "Epoch 3211/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 1856327.7766 - val_loss: 1087102528.0000\n",
      "Epoch 3212/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 1936295.0082 - val_loss: 1068570297.8630\n",
      "Epoch 3213/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 1674168.4455 - val_loss: 1071437208.5479\n",
      "Epoch 3214/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 1593404.8196 - val_loss: 1067163641.8630\n",
      "Epoch 3215/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 1519789.6782 - val_loss: 1081872420.8219\n",
      "Epoch 3216/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 1495796.3905 - val_loss: 1072504743.4521\n",
      "Epoch 3217/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 1521357.5748 - val_loss: 1087885580.2740\n",
      "Epoch 3218/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 2079044.5659 - val_loss: 1073346650.3014\n",
      "Epoch 3219/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 2082557.0117 - val_loss: 1077548044.2740\n",
      "Epoch 3220/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 2942584.5283 - val_loss: 1096311185.5342\n",
      "Epoch 3221/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 4927294.9829 - val_loss: 1073143295.1233\n",
      "Epoch 3222/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 3222198.3068 - val_loss: 1073993357.1507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3223/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 5695819.6586 - val_loss: 1097928959.1233\n",
      "Epoch 3224/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 6629923.0998 - val_loss: 1093399019.8356\n",
      "Epoch 3225/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 5515006.8211 - val_loss: 1089643278.9041\n",
      "Epoch 3226/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 7983337.0733 - val_loss: 1073572592.2192\n",
      "Epoch 3227/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 21365067.3642 - val_loss: 1133210651.1781\n",
      "Epoch 3228/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 13640764.3123 - val_loss: 1095636665.8630\n",
      "Epoch 3229/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 8200578.1358 - val_loss: 1107892314.3014\n",
      "Epoch 3230/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 5081680.8732 - val_loss: 1088839125.0411\n",
      "Epoch 3231/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6776566.0334 - val_loss: 1095957300.1644\n",
      "Epoch 3232/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3807387.0950 - val_loss: 1080631120.6575\n",
      "Epoch 3233/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4425275.8045 - val_loss: 1090572854.3562\n",
      "Epoch 3234/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4202541.3526 - val_loss: 1086709895.8904\n",
      "Epoch 3235/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5991366.5495 - val_loss: 1080494193.0959\n",
      "Epoch 3236/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5176272.1577 - val_loss: 1078739210.5205\n",
      "Epoch 3237/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5250140.3860 - val_loss: 1068856408.5479\n",
      "Epoch 3238/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4694814.4871 - val_loss: 1074890580.1644\n",
      "Epoch 3239/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 14548097.0788 - val_loss: 1061499663.7808\n",
      "Epoch 3240/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 8073593.2031 - val_loss: 1085931676.9315\n",
      "Epoch 3241/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 10583883.6907 - val_loss: 1076168586.5205\n",
      "Epoch 3242/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8951085.0895 - val_loss: 1098079878.1370\n",
      "Epoch 3243/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14780341.1431 - val_loss: 1109434008.5479\n",
      "Epoch 3244/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13092877.2678 - val_loss: 1068850519.6712\n",
      "Epoch 3245/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 7270793.5771 - val_loss: 1058426568.7671\n",
      "Epoch 3246/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7643272.5741 - val_loss: 1094804999.0137\n",
      "Epoch 3247/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6339312.0707 - val_loss: 1071705476.3836\n",
      "Epoch 3248/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 9635787.4370 - val_loss: 1062747029.0411\n",
      "Epoch 3249/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6536045.2693 - val_loss: 1089094609.5342\n",
      "Epoch 3250/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6596798.2168 - val_loss: 1101467046.5753\n",
      "Epoch 3251/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5360053.4180 - val_loss: 1074170474.9589\n",
      "Epoch 3252/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5046578.5351 - val_loss: 1077136396.2740\n",
      "Epoch 3253/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3822242.6607 - val_loss: 1065598265.8630\n",
      "Epoch 3254/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3235187.0996 - val_loss: 1087864664.5479\n",
      "Epoch 3255/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3026841.9400 - val_loss: 1092100598.3562\n",
      "Epoch 3256/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3641135.0664 - val_loss: 1091455950.0274\n",
      "Epoch 3257/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2311529.1015 - val_loss: 1074393975.2329\n",
      "Epoch 3258/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1562846.0751 - val_loss: 1071510565.6986\n",
      "Epoch 3259/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2330879.5677 - val_loss: 1085186903.6712\n",
      "Epoch 3260/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2967052.9400 - val_loss: 1096711606.3562\n",
      "Epoch 3261/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5179758.1748 - val_loss: 1086894623.5616\n",
      "Epoch 3262/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6317568.8149 - val_loss: 1068407056.6575\n",
      "Epoch 3263/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6151866.2218 - val_loss: 1093413157.6986\n",
      "Epoch 3264/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4739366.6247 - val_loss: 1078757965.1507\n",
      "Epoch 3265/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6920693.4974 - val_loss: 1075000830.2466\n",
      "Epoch 3266/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5559293.3719 - val_loss: 1093519896.5479\n",
      "Epoch 3267/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 7268331.1078 - val_loss: 1060911256.5479\n",
      "Epoch 3268/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5134774.0167 - val_loss: 1110802855.4521\n",
      "Epoch 3269/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 8260124.0398 - val_loss: 1070170336.4384\n",
      "Epoch 3270/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8732611.8601 - val_loss: 1125515636.6027\n",
      "Epoch 3271/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 14730321.8629 - val_loss: 1089960051.7260\n",
      "Epoch 3272/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 21635466.7207 - val_loss: 1100602072.5479\n",
      "Epoch 3273/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 14872145.3410 - val_loss: 1098580859.6164\n",
      "Epoch 3274/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 41296322.3685 - val_loss: 1079532788.6027\n",
      "Epoch 3275/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 32045948.4010 - val_loss: 1128580544.4384\n",
      "Epoch 3276/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 26965160.5707 - val_loss: 1187538888.7671\n",
      "Epoch 3277/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 63137171.7121 - val_loss: 1141259504.2192\n",
      "Epoch 3278/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 46366274.8929 - val_loss: 1109895651.9452\n",
      "Epoch 3279/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 22411754.7763 - val_loss: 1081133103.3425\n",
      "Epoch 3280/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8377327.3738 - val_loss: 1073217684.1644\n",
      "Epoch 3281/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 4731253.5936 - val_loss: 1084191430.1370\n",
      "Epoch 3282/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2854874.6670 - val_loss: 1076651559.4521\n",
      "Epoch 3283/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2803857.9053 - val_loss: 1080681823.5616\n",
      "Epoch 3284/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6865966.7121 - val_loss: 1079024932.8219\n",
      "Epoch 3285/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 7828464.5716 - val_loss: 1069932795.6164\n",
      "Epoch 3286/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4954278.8920 - val_loss: 1074269876.6027\n",
      "Epoch 3287/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3163467.5360 - val_loss: 1079341942.3562\n",
      "Epoch 3288/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2391786.4180 - val_loss: 1091436521.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3289/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3061799.0084 - val_loss: 1075710449.0959\n",
      "Epoch 3290/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2606622.7380 - val_loss: 1083005728.4384\n",
      "Epoch 3291/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3237590.5981 - val_loss: 1074686707.7260\n",
      "Epoch 3292/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2138476.7792 - val_loss: 1082553857.7534\n",
      "Epoch 3293/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2784260.7778 - val_loss: 1076981086.6849\n",
      "Epoch 3294/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3474689.6535 - val_loss: 1075887179.3973\n",
      "Epoch 3295/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1833224.5157 - val_loss: 1076381979.1781\n",
      "Epoch 3296/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1374566.0371 - val_loss: 1081541152.4384\n",
      "Epoch 3297/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1576937.9024 - val_loss: 1077106324.1644\n",
      "Epoch 3298/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1356067.8914 - val_loss: 1084109575.8904\n",
      "Epoch 3299/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1411531.4987 - val_loss: 1068359255.6712\n",
      "Epoch 3300/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1316983.1438 - val_loss: 1082849920.8767\n",
      "Epoch 3301/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1371802.8865 - val_loss: 1075651655.8904\n",
      "Epoch 3302/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1561469.7788 - val_loss: 1078277731.0685\n",
      "Epoch 3303/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1880319.4663 - val_loss: 1075419143.8904\n",
      "Epoch 3304/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2724215.6149 - val_loss: 1076727850.0822\n",
      "Epoch 3305/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3627781.4621 - val_loss: 1084478101.0411\n",
      "Epoch 3306/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4105524.0744 - val_loss: 1106388579.0685\n",
      "Epoch 3307/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6882426.5047 - val_loss: 1100227506.8493\n",
      "Epoch 3308/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8512169.7093 - val_loss: 1102984665.4247\n",
      "Epoch 3309/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7578230.1898 - val_loss: 1078371038.6849\n",
      "Epoch 3310/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7022530.2335 - val_loss: 1071300059.1781\n",
      "Epoch 3311/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 5688040.4462 - val_loss: 1077548625.5342\n",
      "Epoch 3312/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 3908012.7339 - val_loss: 1079179266.6301\n",
      "Epoch 3313/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 10077439.4807 - val_loss: 1151466624.8767\n",
      "Epoch 3314/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 23637041.8235 - val_loss: 1099841337.8630\n",
      "Epoch 3315/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 14697004.3299 - val_loss: 1110548602.7397\n",
      "Epoch 3316/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 14403124.3248 - val_loss: 1137336363.3973\n",
      "Epoch 3317/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 14667261.5364 - val_loss: 1086966826.0822\n",
      "Epoch 3318/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6254619.6480 - val_loss: 1089618600.3288\n",
      "Epoch 3319/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 12043299.4473 - val_loss: 1088317874.8493\n",
      "Epoch 3320/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 33916571.0591 - val_loss: 1134779363.5068\n",
      "Epoch 3321/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 19617521.7189 - val_loss: 1132985161.2055\n",
      "Epoch 3322/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 19081748.8638 - val_loss: 1107759626.9589\n",
      "Epoch 3323/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 10831017.7114 - val_loss: 1072784505.8630\n",
      "Epoch 3324/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5203740.8826 - val_loss: 1097713815.6712\n",
      "Epoch 3325/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4143916.3032 - val_loss: 1099189212.0548\n",
      "Epoch 3326/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3289125.2890 - val_loss: 1084151369.6438\n",
      "Epoch 3327/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2266687.9278 - val_loss: 1085503430.1370\n",
      "Epoch 3328/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3080066.4521 - val_loss: 1079583478.3562\n",
      "Epoch 3329/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2646140.2124 - val_loss: 1089949424.2192\n",
      "Epoch 3330/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1698361.5581 - val_loss: 1079869938.8493\n",
      "Epoch 3331/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1999100.7466 - val_loss: 1080873738.5205\n",
      "Epoch 3332/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1712930.5844 - val_loss: 1074607291.6164\n",
      "Epoch 3333/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1575202.1052 - val_loss: 1077554304.8767\n",
      "Epoch 3334/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1618177.0917 - val_loss: 1078291059.7260\n",
      "Epoch 3335/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1568850.7564 - val_loss: 1090861627.6164\n",
      "Epoch 3336/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3782487.0488 - val_loss: 1072557006.9041\n",
      "Epoch 3337/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10598907.6937 - val_loss: 1047707326.2466\n",
      "Epoch 3338/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8264068.1902 - val_loss: 1057486656.8767\n",
      "Epoch 3339/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4630366.3021 - val_loss: 1073391367.0137\n",
      "Epoch 3340/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3382105.5094 - val_loss: 1073804037.2603\n",
      "Epoch 3341/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4034838.1881 - val_loss: 1074083651.5068\n",
      "Epoch 3342/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4892319.7755 - val_loss: 1090388145.9726\n",
      "Epoch 3343/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3092771.1735 - val_loss: 1069705486.9041\n",
      "Epoch 3344/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3202552.3674 - val_loss: 1076892067.9452\n",
      "Epoch 3345/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2236934.3794 - val_loss: 1079553287.0137\n",
      "Epoch 3346/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3605349.6296 - val_loss: 1101519588.8219\n",
      "Epoch 3347/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3923177.4503 - val_loss: 1081662358.7945\n",
      "Epoch 3348/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4046062.9567 - val_loss: 1093414942.6849\n",
      "Epoch 3349/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3413023.4795 - val_loss: 1100080693.4795\n",
      "Epoch 3350/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2839487.6440 - val_loss: 1071976127.1233\n",
      "Epoch 3351/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3858434.8912 - val_loss: 1082464537.4247\n",
      "Epoch 3352/5000\n",
      "1167/1167 [==============================] - 0s 232us/step - loss: 2930579.8179 - val_loss: 1084123005.3699\n",
      "Epoch 3353/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4499273.5084 - val_loss: 1089128692.6027\n",
      "Epoch 3354/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 8832623.6701 - val_loss: 1125478504.3288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3355/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 11663374.6200 - val_loss: 1074945991.0137\n",
      "Epoch 3356/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11236173.6204 - val_loss: 1063050377.6438\n",
      "Epoch 3357/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7907815.5236 - val_loss: 1069658899.2877\n",
      "Epoch 3358/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8383052.5553 - val_loss: 1104346549.4795\n",
      "Epoch 3359/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8737072.5296 - val_loss: 1083567660.7123\n",
      "Epoch 3360/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 8960352.0488 - val_loss: 1088690119.8904\n",
      "Epoch 3361/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 19819442.3753 - val_loss: 1226394969.4247\n",
      "Epoch 3362/5000\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 62669619.0300 - val_loss: 1296067103.5616\n",
      "Epoch 3363/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 111645555.1945 - val_loss: 1150838592.0000\n",
      "Epoch 3364/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 40706471.4790 - val_loss: 1113282743.2329\n",
      "Epoch 3365/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 15790933.8792 - val_loss: 1067268312.5479\n",
      "Epoch 3366/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 10061174.4841 - val_loss: 1067185808.2192\n",
      "Epoch 3367/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 14767928.4199 - val_loss: 1035497698.1918\n",
      "Epoch 3368/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8791069.9314 - val_loss: 1061803663.7808\n",
      "Epoch 3369/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6748130.1598 - val_loss: 1075634497.7534\n",
      "Epoch 3370/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5419676.3121 - val_loss: 1071401962.0822\n",
      "Epoch 3371/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3305152.8745 - val_loss: 1068720170.9589\n",
      "Epoch 3372/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 4216181.0167 - val_loss: 1071949409.3151\n",
      "Epoch 3373/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4493864.3256 - val_loss: 1059252263.4521\n",
      "Epoch 3374/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6396604.6119 - val_loss: 1059850389.0411\n",
      "Epoch 3375/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3966926.3179 - val_loss: 1063304828.4932\n",
      "Epoch 3376/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2509152.1219 - val_loss: 1065716244.1644\n",
      "Epoch 3377/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1697779.6350 - val_loss: 1062013347.9452\n",
      "Epoch 3378/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1474338.1844 - val_loss: 1062642685.3699\n",
      "Epoch 3379/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 995593.9531 - val_loss: 1061385059.0685\n",
      "Epoch 3380/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 890728.3340 - val_loss: 1057783570.4110\n",
      "Epoch 3381/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1010681.7269 - val_loss: 1063865510.5753\n",
      "Epoch 3382/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1084717.3655 - val_loss: 1060306293.4795\n",
      "Epoch 3383/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 1039706.6040 - val_loss: 1059518734.9041\n",
      "Epoch 3384/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2334504.6139 - val_loss: 1064746393.4247\n",
      "Epoch 3385/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 3941120.9582 - val_loss: 1072222666.5205\n",
      "Epoch 3386/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3057358.7517 - val_loss: 1071503666.8493\n",
      "Epoch 3387/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2769713.9808 - val_loss: 1066065976.1096\n",
      "Epoch 3388/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5255366.8957 - val_loss: 1050075698.8493\n",
      "Epoch 3389/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 3626550.8779 - val_loss: 1045619654.1370\n",
      "Epoch 3390/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 2499690.2088 - val_loss: 1060944284.9315\n",
      "Epoch 3391/5000\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 1993021.6184 - val_loss: 1050924587.8356\n",
      "Epoch 3392/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3790765.4961 - val_loss: 1079155348.1644\n",
      "Epoch 3393/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3409108.2901 - val_loss: 1074382843.6164\n",
      "Epoch 3394/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6253437.2639 - val_loss: 1083212295.8904\n",
      "Epoch 3395/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 14020642.4953 - val_loss: 1094510662.1370\n",
      "Epoch 3396/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 7498497.7845 - val_loss: 1087213122.6301\n",
      "Epoch 3397/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4111148.7674 - val_loss: 1072755830.3562\n",
      "Epoch 3398/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3729122.5976 - val_loss: 1078082858.0822\n",
      "Epoch 3399/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2434111.5345 - val_loss: 1048704635.6164\n",
      "Epoch 3400/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2471711.6759 - val_loss: 1062844929.7534\n",
      "Epoch 3401/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2434681.0086 - val_loss: 1077179141.2603\n",
      "Epoch 3402/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3792809.8586 - val_loss: 1076347501.5890\n",
      "Epoch 3403/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3263733.2834 - val_loss: 1071249049.4247\n",
      "Epoch 3404/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4335963.2562 - val_loss: 1080259317.4795\n",
      "Epoch 3405/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6019756.1332 - val_loss: 1085914449.5342\n",
      "Epoch 3406/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 6724356.7187 - val_loss: 1073035667.2877\n",
      "Epoch 3407/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 20535980.7352 - val_loss: 1072367644.0548\n",
      "Epoch 3408/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10878934.0635 - val_loss: 1063656713.6438\n",
      "Epoch 3409/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 19487867.6384 - val_loss: 1115066730.0822\n",
      "Epoch 3410/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 53114157.1028 - val_loss: 1090939121.0959\n",
      "Epoch 3411/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 27666722.4287 - val_loss: 1085751558.5753\n",
      "Epoch 3412/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 29355585.8260 - val_loss: 1163058239.1233\n",
      "Epoch 3413/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 44348797.7198 - val_loss: 1151423300.3836\n",
      "Epoch 3414/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 16448619.8783 - val_loss: 1095093964.2740\n",
      "Epoch 3415/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6570377.8042 - val_loss: 1064086745.4247\n",
      "Epoch 3416/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4556716.5321 - val_loss: 1094762871.2329\n",
      "Epoch 3417/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 21742374.6877 - val_loss: 1059139846.1370\n",
      "Epoch 3418/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6045350.3414 - val_loss: 1068517105.9726\n",
      "Epoch 3419/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3453971.0977 - val_loss: 1084709457.5342\n",
      "Epoch 3420/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 2228291.4220 - val_loss: 1076421219.0685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3421/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2150369.1723 - val_loss: 1079451175.4521\n",
      "Epoch 3422/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 1563286.7310 - val_loss: 1078455682.6301\n",
      "Epoch 3423/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2994754.8944 - val_loss: 1071106649.4247\n",
      "Epoch 3424/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5924777.5840 - val_loss: 1100982762.9589\n",
      "Epoch 3425/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5586863.2279 - val_loss: 1083596611.5068\n",
      "Epoch 3426/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2568796.7886 - val_loss: 1076924322.1918\n",
      "Epoch 3427/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2280816.2964 - val_loss: 1079254447.3425\n",
      "Epoch 3428/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1739287.2488 - val_loss: 1082323157.0411\n",
      "Epoch 3429/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3451837.6452 - val_loss: 1082515546.3014\n",
      "Epoch 3430/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3056657.5205 - val_loss: 1076138884.3836\n",
      "Epoch 3431/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2638800.4975 - val_loss: 1064461907.2877\n",
      "Epoch 3432/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2492375.9967 - val_loss: 1090753073.9726\n",
      "Epoch 3433/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2407489.3912 - val_loss: 1070350528.8767\n",
      "Epoch 3434/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5889955.8817 - val_loss: 1078081082.7397\n",
      "Epoch 3435/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5998386.2483 - val_loss: 1072628135.4521\n",
      "Epoch 3436/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3637578.9938 - val_loss: 1064252487.8904\n",
      "Epoch 3437/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3728566.5471 - val_loss: 1086951223.2329\n",
      "Epoch 3438/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2453160.5756 - val_loss: 1073299960.9863\n",
      "Epoch 3439/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3777457.5467 - val_loss: 1076517207.6712\n",
      "Epoch 3440/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3936930.3724 - val_loss: 1075354602.0822\n",
      "Epoch 3441/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2377699.9304 - val_loss: 1075460115.2877\n",
      "Epoch 3442/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2744896.8320 - val_loss: 1066556664.9863\n",
      "Epoch 3443/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2888291.1051 - val_loss: 1073865961.2055\n",
      "Epoch 3444/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1837561.0772 - val_loss: 1073075104.4384\n",
      "Epoch 3445/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2058979.1883 - val_loss: 1069518571.8356\n",
      "Epoch 3446/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2533704.0588 - val_loss: 1076824180.6027\n",
      "Epoch 3447/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2399899.9491 - val_loss: 1074204700.0548\n",
      "Epoch 3448/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3172319.9135 - val_loss: 1077324301.1507\n",
      "Epoch 3449/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3432732.1579 - val_loss: 1060507039.5616\n",
      "Epoch 3450/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 5541707.9210 - val_loss: 1069238320.2192\n",
      "Epoch 3451/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3814544.0951 - val_loss: 1062363975.8904\n",
      "Epoch 3452/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8019802.5994 - val_loss: 1078722984.3288\n",
      "Epoch 3453/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 21843155.8423 - val_loss: 1176624134.1370\n",
      "Epoch 3454/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 27340388.9392 - val_loss: 1098570420.6027\n",
      "Epoch 3455/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11293021.6701 - val_loss: 1128970370.6301\n",
      "Epoch 3456/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11276945.1183 - val_loss: 1110193520.2192\n",
      "Epoch 3457/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9612735.0133 - val_loss: 1085483450.7397\n",
      "Epoch 3458/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6365252.8074 - val_loss: 1067291028.1644\n",
      "Epoch 3459/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5660022.8901 - val_loss: 1069480213.0411\n",
      "Epoch 3460/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4026487.4065 - val_loss: 1088330759.0137\n",
      "Epoch 3461/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4514313.2682 - val_loss: 1066747496.3288\n",
      "Epoch 3462/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 7762472.0073 - val_loss: 1077941222.5753\n",
      "Epoch 3463/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 11956804.2931 - val_loss: 1079174579.7260\n",
      "Epoch 3464/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8770246.9392 - val_loss: 1071933020.9315\n",
      "Epoch 3465/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6975362.8093 - val_loss: 1072937200.2192\n",
      "Epoch 3466/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4959963.3483 - val_loss: 1072743450.3014\n",
      "Epoch 3467/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5737334.6093 - val_loss: 1075083210.5205\n",
      "Epoch 3468/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4729960.6517 - val_loss: 1086492683.3973\n",
      "Epoch 3469/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8322384.8620 - val_loss: 1090319018.9589\n",
      "Epoch 3470/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4482946.5026 - val_loss: 1086249741.1507\n",
      "Epoch 3471/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3773665.1161 - val_loss: 1085799170.6301\n",
      "Epoch 3472/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3762685.7729 - val_loss: 1064998386.8493\n",
      "Epoch 3473/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3918740.0831 - val_loss: 1080660743.8904\n",
      "Epoch 3474/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3360541.8349 - val_loss: 1070668906.9589\n",
      "Epoch 3475/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 4706103.6847 - val_loss: 1068556897.3151\n",
      "Epoch 3476/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6224170.2077 - val_loss: 1067784507.6164\n",
      "Epoch 3477/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 7094247.4871 - val_loss: 1082549581.1507\n",
      "Epoch 3478/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 18210689.6590 - val_loss: 1106354289.0959\n",
      "Epoch 3479/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 19867748.7836 - val_loss: 1047086864.6575\n",
      "Epoch 3480/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 19443339.6641 - val_loss: 1100754537.2055\n",
      "Epoch 3481/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 20038782.6444 - val_loss: 1096361868.2740\n",
      "Epoch 3482/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 23329017.1628 - val_loss: 1124789496.1096\n",
      "Epoch 3483/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 16192263.1500 - val_loss: 1107224311.2329\n",
      "Epoch 3484/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 16832929.2905 - val_loss: 1099543106.6301\n",
      "Epoch 3485/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 8582140.6240 - val_loss: 1091409794.6301\n",
      "Epoch 3486/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 8641869.1534 - val_loss: 1105427600.6575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3487/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5513407.2635 - val_loss: 1111162960.6575\n",
      "Epoch 3488/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4276402.3766 - val_loss: 1080178203.1781\n",
      "Epoch 3489/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6184875.1018 - val_loss: 1082897197.5890\n",
      "Epoch 3490/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5991271.6562 - val_loss: 1100864539.1781\n",
      "Epoch 3491/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3049807.1560 - val_loss: 1091500393.2055\n",
      "Epoch 3492/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3934601.1406 - val_loss: 1074107076.3836\n",
      "Epoch 3493/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 2761743.4071 - val_loss: 1090685381.2603\n",
      "Epoch 3494/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2790346.3012 - val_loss: 1079298501.2603\n",
      "Epoch 3495/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2427039.3319 - val_loss: 1090536639.1233\n",
      "Epoch 3496/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2347612.3869 - val_loss: 1080477842.4110\n",
      "Epoch 3497/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2634321.9863 - val_loss: 1075769936.6575\n",
      "Epoch 3498/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2766661.9733 - val_loss: 1069167225.8630\n",
      "Epoch 3499/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 2058216.2738 - val_loss: 1081470158.9041\n",
      "Epoch 3500/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2143902.7786 - val_loss: 1069444615.0137\n",
      "Epoch 3501/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1821519.1680 - val_loss: 1068618425.8630\n",
      "Epoch 3502/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1830449.5293 - val_loss: 1077799171.5068\n",
      "Epoch 3503/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 1957470.7454 - val_loss: 1067743700.1644\n",
      "Epoch 3504/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2437791.7802 - val_loss: 1068165365.4795\n",
      "Epoch 3505/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3287840.4038 - val_loss: 1071831507.2877\n",
      "Epoch 3506/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3839003.7858 - val_loss: 1087162032.2192\n",
      "Epoch 3507/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4340392.3295 - val_loss: 1086101280.4384\n",
      "Epoch 3508/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6516861.0473 - val_loss: 1088516872.7671\n",
      "Epoch 3509/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6005254.8646 - val_loss: 1105660202.0822\n",
      "Epoch 3510/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5363596.8147 - val_loss: 1094875249.9726\n",
      "Epoch 3511/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9900270.0917 - val_loss: 1101613460.1644\n",
      "Epoch 3512/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7918150.1812 - val_loss: 1105998977.7534\n",
      "Epoch 3513/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 15875137.2614 - val_loss: 1100473622.7945\n",
      "Epoch 3514/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 29910862.8929 - val_loss: 1082344734.6849\n",
      "Epoch 3515/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 18903640.8937 - val_loss: 1134758331.6164\n",
      "Epoch 3516/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 34411252.6135 - val_loss: 1261072053.4795\n",
      "Epoch 3517/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 128436782.8209 - val_loss: 1330778403.9452\n",
      "Epoch 3518/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 70459010.0086 - val_loss: 1118298169.8630\n",
      "Epoch 3519/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 62123172.1440 - val_loss: 1146873595.1781\n",
      "Epoch 3520/5000\n",
      "1167/1167 [==============================] - 0s 285us/step - loss: 16357696.4404 - val_loss: 1107216083.7260\n",
      "Epoch 3521/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 10583705.1320 - val_loss: 1094565365.4795\n",
      "Epoch 3522/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6691621.6761 - val_loss: 1086380406.3562\n",
      "Epoch 3523/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6068735.3740 - val_loss: 1085876089.8630\n",
      "Epoch 3524/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4356178.2879 - val_loss: 1083691604.1644\n",
      "Epoch 3525/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4034453.4284 - val_loss: 1105627833.8630\n",
      "Epoch 3526/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 4157181.6153 - val_loss: 1066611553.3151\n",
      "Epoch 3527/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9491307.1217 - val_loss: 1093754356.6027\n",
      "Epoch 3528/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3860966.5908 - val_loss: 1064394782.6849\n",
      "Epoch 3529/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2293134.4259 - val_loss: 1074315667.2877\n",
      "Epoch 3530/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1617001.8926 - val_loss: 1077762685.3699\n",
      "Epoch 3531/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1376718.1578 - val_loss: 1072900940.2740\n",
      "Epoch 3532/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1211805.7933 - val_loss: 1078642852.8219\n",
      "Epoch 3533/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1077452.3918 - val_loss: 1080749219.0685\n",
      "Epoch 3534/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1020379.4534 - val_loss: 1071182252.7123\n",
      "Epoch 3535/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 1066334.2719 - val_loss: 1077557012.1644\n",
      "Epoch 3536/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 1183036.6101 - val_loss: 1072484001.3151\n",
      "Epoch 3537/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2055478.5795 - val_loss: 1079351374.0274\n",
      "Epoch 3538/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1376130.4109 - val_loss: 1076229580.2740\n",
      "Epoch 3539/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 1657421.2084 - val_loss: 1078559688.7671\n",
      "Epoch 3540/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 2087140.0512 - val_loss: 1072578105.8630\n",
      "Epoch 3541/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2415612.0574 - val_loss: 1083729905.9726\n",
      "Epoch 3542/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5310255.0163 - val_loss: 1073660471.2329\n",
      "Epoch 3543/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2625489.1788 - val_loss: 1075470283.3973\n",
      "Epoch 3544/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3277226.9650 - val_loss: 1077644608.8767\n",
      "Epoch 3545/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1827180.0523 - val_loss: 1075152861.8082\n",
      "Epoch 3546/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1592901.4988 - val_loss: 1078784614.5753\n",
      "Epoch 3547/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1289341.3423 - val_loss: 1078059496.3288\n",
      "Epoch 3548/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1318253.5460 - val_loss: 1069115134.2466\n",
      "Epoch 3549/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1187045.3807 - val_loss: 1082139434.9589\n",
      "Epoch 3550/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1329150.7981 - val_loss: 1077519899.1781\n",
      "Epoch 3551/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2017676.1019 - val_loss: 1062613380.3836\n",
      "Epoch 3552/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3144436.2999 - val_loss: 1073925967.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3553/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5865238.7391 - val_loss: 1068383005.8082\n",
      "Epoch 3554/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 11022825.6632 - val_loss: 1062378040.9863\n",
      "Epoch 3555/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6031135.9023 - val_loss: 1063347460.3836\n",
      "Epoch 3556/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5525543.7736 - val_loss: 1058770294.3562\n",
      "Epoch 3557/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4583806.2491 - val_loss: 1061317403.1781\n",
      "Epoch 3558/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3148002.8436 - val_loss: 1074873033.6438\n",
      "Epoch 3559/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3220083.2185 - val_loss: 1081821986.1918\n",
      "Epoch 3560/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2858061.9878 - val_loss: 1078181441.7534\n",
      "Epoch 3561/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5170201.7601 - val_loss: 1084560473.4247\n",
      "Epoch 3562/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 10372629.6778 - val_loss: 1072434958.9041\n",
      "Epoch 3563/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 12308556.1388 - val_loss: 1133518664.7671\n",
      "Epoch 3564/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 22038566.8106 - val_loss: 1164798532.3836\n",
      "Epoch 3565/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 15663046.4837 - val_loss: 1048652412.0548\n",
      "Epoch 3566/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8785884.2901 - val_loss: 1078195394.6301\n",
      "Epoch 3567/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6557629.6661 - val_loss: 1072600325.2603\n",
      "Epoch 3568/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3651512.4109 - val_loss: 1086311923.7260\n",
      "Epoch 3569/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9271341.2828 - val_loss: 1095676205.5890\n",
      "Epoch 3570/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 22931326.4747 - val_loss: 1094350538.9589\n",
      "Epoch 3571/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 40067229.7584 - val_loss: 1127433932.2740\n",
      "Epoch 3572/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 18878558.8415 - val_loss: 1124033821.8082\n",
      "Epoch 3573/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11044551.5506 - val_loss: 1115068102.1370\n",
      "Epoch 3574/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4802444.2734 - val_loss: 1098958724.3836\n",
      "Epoch 3575/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4970321.0581 - val_loss: 1077195805.8082\n",
      "Epoch 3576/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3258796.8980 - val_loss: 1070301705.6438\n",
      "Epoch 3577/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2323303.7230 - val_loss: 1086044129.3151\n",
      "Epoch 3578/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4264410.2637 - val_loss: 1085549738.9589\n",
      "Epoch 3579/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 10203846.6476 - val_loss: 1075884557.1507\n",
      "Epoch 3580/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5556005.5943 - val_loss: 1060211901.3699\n",
      "Epoch 3581/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4387719.4189 - val_loss: 1098692900.8219\n",
      "Epoch 3582/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3151771.7555 - val_loss: 1084124040.7671\n",
      "Epoch 3583/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2191667.1992 - val_loss: 1090064542.6849\n",
      "Epoch 3584/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3641022.6075 - val_loss: 1084900516.8219\n",
      "Epoch 3585/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 4054439.1371 - val_loss: 1096963392.0000\n",
      "Epoch 3586/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3791218.6817 - val_loss: 1074815798.3562\n",
      "Epoch 3587/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6086958.9100 - val_loss: 1168583909.2603\n",
      "Epoch 3588/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 32734323.5784 - val_loss: 1085952209.5342\n",
      "Epoch 3589/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 19391431.4242 - val_loss: 1131107043.9452\n",
      "Epoch 3590/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 17377600.8372 - val_loss: 1097191090.8493\n",
      "Epoch 3591/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9262793.1748 - val_loss: 1092065007.3425\n",
      "Epoch 3592/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6769235.4348 - val_loss: 1113255289.8630\n",
      "Epoch 3593/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4984318.1945 - val_loss: 1084012201.2055\n",
      "Epoch 3594/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4582437.5719 - val_loss: 1086066519.6712\n",
      "Epoch 3595/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2253737.4069 - val_loss: 1077458055.0137\n",
      "Epoch 3596/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1819686.2461 - val_loss: 1081286924.2740\n",
      "Epoch 3597/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1988768.9025 - val_loss: 1078342026.5205\n",
      "Epoch 3598/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1667643.3981 - val_loss: 1078845529.4247\n",
      "Epoch 3599/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1357621.5815 - val_loss: 1073664340.1644\n",
      "Epoch 3600/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1316769.0358 - val_loss: 1076859541.9178\n",
      "Epoch 3601/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2010968.3858 - val_loss: 1073819987.2877\n",
      "Epoch 3602/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2453020.9100 - val_loss: 1074050725.6986\n",
      "Epoch 3603/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3435228.1130 - val_loss: 1067383527.4521\n",
      "Epoch 3604/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4208711.5360 - val_loss: 1103764890.3014\n",
      "Epoch 3605/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 12651557.9512 - val_loss: 1040852572.9315\n",
      "Epoch 3606/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 23223332.4524 - val_loss: 1112445209.4247\n",
      "Epoch 3607/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 28980114.9195 - val_loss: 1105636298.5205\n",
      "Epoch 3608/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 13641972.6967 - val_loss: 1113758272.8767\n",
      "Epoch 3609/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 12563183.5458 - val_loss: 1123491431.4521\n",
      "Epoch 3610/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 15181590.8980 - val_loss: 1116456682.0822\n",
      "Epoch 3611/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 17436554.1577 - val_loss: 1152948892.9315\n",
      "Epoch 3612/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 15770837.6538 - val_loss: 1084680219.1781\n",
      "Epoch 3613/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 8908580.8903 - val_loss: 1088180164.3836\n",
      "Epoch 3614/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5081478.2453 - val_loss: 1093267291.1781\n",
      "Epoch 3615/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2924200.7958 - val_loss: 1092034913.3151\n",
      "Epoch 3616/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2197034.3980 - val_loss: 1079503247.7808\n",
      "Epoch 3617/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 1584553.5878 - val_loss: 1099007390.6849\n",
      "Epoch 3618/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1517301.1109 - val_loss: 1088205763.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3619/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1293635.9585 - val_loss: 1078944023.6712\n",
      "Epoch 3620/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1654501.3880 - val_loss: 1076350081.7534\n",
      "Epoch 3621/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 1154056.6317 - val_loss: 1077238193.0959\n",
      "Epoch 3622/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2054765.6884 - val_loss: 1095144591.7808\n",
      "Epoch 3623/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2220066.5251 - val_loss: 1089199802.7397\n",
      "Epoch 3624/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2092622.6928 - val_loss: 1095253968.6575\n",
      "Epoch 3625/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2435882.0932 - val_loss: 1081970185.6438\n",
      "Epoch 3626/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 2034045.1796 - val_loss: 1097211158.7945\n",
      "Epoch 3627/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1680581.7554 - val_loss: 1082794562.6301\n",
      "Epoch 3628/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1485673.9199 - val_loss: 1079075291.1781\n",
      "Epoch 3629/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2658082.8262 - val_loss: 1093002798.4658\n",
      "Epoch 3630/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2086488.6096 - val_loss: 1078107456.8767\n",
      "Epoch 3631/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2362405.8740 - val_loss: 1076226080.4384\n",
      "Epoch 3632/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3365667.4864 - val_loss: 1094747877.6986\n",
      "Epoch 3633/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2452244.2631 - val_loss: 1092814422.7945\n",
      "Epoch 3634/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3409244.0751 - val_loss: 1063185429.9178\n",
      "Epoch 3635/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3178756.7926 - val_loss: 1095937488.6575\n",
      "Epoch 3636/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2923563.6869 - val_loss: 1079195271.0137\n",
      "Epoch 3637/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4420304.0523 - val_loss: 1103151375.7808\n",
      "Epoch 3638/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5164935.6392 - val_loss: 1070642914.1918\n",
      "Epoch 3639/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 27643223.1260 - val_loss: 1175094543.7808\n",
      "Epoch 3640/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 47407895.7361 - val_loss: 1164773746.8493\n",
      "Epoch 3641/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 84056249.9880 - val_loss: 1127294500.8219\n",
      "Epoch 3642/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 26508028.4747 - val_loss: 1111732772.8219\n",
      "Epoch 3643/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14600192.9910 - val_loss: 1072592753.0959\n",
      "Epoch 3644/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7533694.9636 - val_loss: 1076068163.5068\n",
      "Epoch 3645/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6404567.2149 - val_loss: 1107413849.4247\n",
      "Epoch 3646/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7115757.3432 - val_loss: 1087253573.2603\n",
      "Epoch 3647/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 12727797.8183 - val_loss: 1066554859.8356\n",
      "Epoch 3648/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 5395486.9794 - val_loss: 1081019316.6027\n",
      "Epoch 3649/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4176359.7588 - val_loss: 1075126330.7397\n",
      "Epoch 3650/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3385011.6063 - val_loss: 1077058829.1507\n",
      "Epoch 3651/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2221320.2684 - val_loss: 1081257798.1370\n",
      "Epoch 3652/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1523878.7287 - val_loss: 1083854804.1644\n",
      "Epoch 3653/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1442564.4754 - val_loss: 1082705155.5068\n",
      "Epoch 3654/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1398743.6219 - val_loss: 1083402790.5753\n",
      "Epoch 3655/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1491573.8992 - val_loss: 1084733745.9726\n",
      "Epoch 3656/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1558287.3287 - val_loss: 1070444077.5890\n",
      "Epoch 3657/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2025578.8929 - val_loss: 1083390299.1781\n",
      "Epoch 3658/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 2811021.5184 - val_loss: 1089656942.4658\n",
      "Epoch 3659/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3533508.1769 - val_loss: 1095459229.8082\n",
      "Epoch 3660/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8566471.4499 - val_loss: 1120076619.3973\n",
      "Epoch 3661/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 14821396.6769 - val_loss: 1088205696.0000\n",
      "Epoch 3662/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 22339404.9015 - val_loss: 1086745040.6575\n",
      "Epoch 3663/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11745836.9580 - val_loss: 1085166281.6438\n",
      "Epoch 3664/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8876935.6195 - val_loss: 1089616602.3014\n",
      "Epoch 3665/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6943101.9240 - val_loss: 1102157881.8630\n",
      "Epoch 3666/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 4685151.3518 - val_loss: 1101051636.6027\n",
      "Epoch 3667/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3849635.2706 - val_loss: 1109127250.4110\n",
      "Epoch 3668/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1857384.3757 - val_loss: 1075037797.6986\n",
      "Epoch 3669/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1879234.6427 - val_loss: 1074074344.3288\n",
      "Epoch 3670/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1644978.6840 - val_loss: 1083029521.5342\n",
      "Epoch 3671/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3618866.0959 - val_loss: 1076925235.7260\n",
      "Epoch 3672/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3579913.7347 - val_loss: 1109771900.4932\n",
      "Epoch 3673/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4194347.6470 - val_loss: 1094854125.5890\n",
      "Epoch 3674/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7298360.7815 - val_loss: 1091097489.9726\n",
      "Epoch 3675/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 6024505.4025 - val_loss: 1060650121.6438\n",
      "Epoch 3676/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2240336.9743 - val_loss: 1087385454.4658\n",
      "Epoch 3677/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2572308.0317 - val_loss: 1104193511.4521\n",
      "Epoch 3678/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2117563.0146 - val_loss: 1079666548.6027\n",
      "Epoch 3679/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 1353934.1526 - val_loss: 1076126745.4247\n",
      "Epoch 3680/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1976802.0829 - val_loss: 1097121683.2877\n",
      "Epoch 3681/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3998015.9898 - val_loss: 1074200986.3014\n",
      "Epoch 3682/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3623480.4725 - val_loss: 1088987694.4658\n",
      "Epoch 3683/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2301081.7835 - val_loss: 1070599463.4521\n",
      "Epoch 3684/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 2515674.5661 - val_loss: 1084119003.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3685/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2557016.6915 - val_loss: 1082795250.8493\n",
      "Epoch 3686/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3217453.4172 - val_loss: 1078680911.7808\n",
      "Epoch 3687/5000\n",
      "1167/1167 [==============================] - 0s 310us/step - loss: 2776901.4158 - val_loss: 1083868619.3973\n",
      "Epoch 3688/5000\n",
      "1167/1167 [==============================] - 0s 284us/step - loss: 3671638.6645 - val_loss: 1109755262.2466\n",
      "Epoch 3689/5000\n",
      "1167/1167 [==============================] - 0s 284us/step - loss: 5533702.9066 - val_loss: 1088316835.9452\n",
      "Epoch 3690/5000\n",
      "1167/1167 [==============================] - 0s 287us/step - loss: 3683882.5195 - val_loss: 1097259704.1096\n",
      "Epoch 3691/5000\n",
      "1167/1167 [==============================] - 0s 293us/step - loss: 3803315.9820 - val_loss: 1086737662.2466\n",
      "Epoch 3692/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 4701842.5111 - val_loss: 1080287613.3699\n",
      "Epoch 3693/5000\n",
      "1167/1167 [==============================] - 0s 324us/step - loss: 6847932.9914 - val_loss: 1064838149.2603\n",
      "Epoch 3694/5000\n",
      "1167/1167 [==============================] - 0s 296us/step - loss: 13556971.0266 - val_loss: 1111078894.0274\n",
      "Epoch 3695/5000\n",
      "1167/1167 [==============================] - 0s 285us/step - loss: 7748395.4156 - val_loss: 1085870827.8356\n",
      "Epoch 3696/5000\n",
      "1167/1167 [==============================] - 0s 291us/step - loss: 8108972.1759 - val_loss: 1107900555.3973\n",
      "Epoch 3697/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 6954420.3882 - val_loss: 1081928714.5205\n",
      "Epoch 3698/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 24158490.4747 - val_loss: 1104240611.9452\n",
      "Epoch 3699/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 91643489.4053 - val_loss: 1273024736.8767\n",
      "Epoch 3700/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 43930630.6864 - val_loss: 1094089728.0000\n",
      "Epoch 3701/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 19729368.7609 - val_loss: 1095895518.6849\n",
      "Epoch 3702/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 12662523.1157 - val_loss: 1084603249.0959\n",
      "Epoch 3703/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 6578575.3999 - val_loss: 1101484842.9589\n",
      "Epoch 3704/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4249369.7993 - val_loss: 1095223527.4521\n",
      "Epoch 3705/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4276417.8031 - val_loss: 1076759108.3836\n",
      "Epoch 3706/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2304862.6294 - val_loss: 1091784378.7397\n",
      "Epoch 3707/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2310973.2359 - val_loss: 1070195363.0685\n",
      "Epoch 3708/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1856714.9178 - val_loss: 1087715364.8219\n",
      "Epoch 3709/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 1310486.5506 - val_loss: 1088809051.1781\n",
      "Epoch 3710/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1219008.3903 - val_loss: 1082385819.1781\n",
      "Epoch 3711/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1696584.8309 - val_loss: 1092419840.8767\n",
      "Epoch 3712/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 2277162.3385 - val_loss: 1094919858.8493\n",
      "Epoch 3713/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 1707799.1248 - val_loss: 1090364765.8082\n",
      "Epoch 3714/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2277970.8144 - val_loss: 1088137705.2055\n",
      "Epoch 3715/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1884768.9593 - val_loss: 1078234918.5753\n",
      "Epoch 3716/5000\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 2066518.2281 - val_loss: 1071416694.3562\n",
      "Epoch 3717/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1350478.3562 - val_loss: 1087785459.7260\n",
      "Epoch 3718/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1405894.5795 - val_loss: 1078557674.9589\n",
      "Epoch 3719/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1245655.9637 - val_loss: 1087069358.4658\n",
      "Epoch 3720/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1675752.5720 - val_loss: 1090163542.7945\n",
      "Epoch 3721/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1729602.8560 - val_loss: 1073116808.7671\n",
      "Epoch 3722/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 1666001.8595 - val_loss: 1084554601.2055\n",
      "Epoch 3723/5000\n",
      "1167/1167 [==============================] - 0s 281us/step - loss: 1375855.4109 - val_loss: 1082868347.6164\n",
      "Epoch 3724/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 1477378.3540 - val_loss: 1082995167.5616\n",
      "Epoch 3725/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1422365.7991 - val_loss: 1078722075.1781\n",
      "Epoch 3726/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1780264.4751 - val_loss: 1086608446.2466\n",
      "Epoch 3727/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 1402043.3955 - val_loss: 1075936949.4795\n",
      "Epoch 3728/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4958236.5290 - val_loss: 1102459778.6301\n",
      "Epoch 3729/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 5095119.1902 - val_loss: 1074244876.2740\n",
      "Epoch 3730/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 4173367.1971 - val_loss: 1057064742.5753\n",
      "Epoch 3731/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4804732.5801 - val_loss: 1089903195.1781\n",
      "Epoch 3732/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6641944.5373 - val_loss: 1087888433.9726\n",
      "Epoch 3733/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6659983.5523 - val_loss: 1089805781.9178\n",
      "Epoch 3734/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5230174.7656 - val_loss: 1098333731.0685\n",
      "Epoch 3735/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 8396857.9010 - val_loss: 1078369268.6027\n",
      "Epoch 3736/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 16156255.1178 - val_loss: 1098276400.2192\n",
      "Epoch 3737/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10291567.5244 - val_loss: 1082279975.4521\n",
      "Epoch 3738/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 11982623.7849 - val_loss: 1120495704.5479\n",
      "Epoch 3739/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 11958809.2468 - val_loss: 1114921005.5890\n",
      "Epoch 3740/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 10002452.8813 - val_loss: 1119108955.1781\n",
      "Epoch 3741/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 14624506.2386 - val_loss: 1146380670.2466\n",
      "Epoch 3742/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 13762623.9966 - val_loss: 1090365876.6027\n",
      "Epoch 3743/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 7068752.3725 - val_loss: 1080344187.6164\n",
      "Epoch 3744/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9159619.9332 - val_loss: 1056755038.6849\n",
      "Epoch 3745/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37462426.3205 - val_loss: 1092991275.8356\n",
      "Epoch 3746/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 24669143.9957 - val_loss: 1169286655.1233\n",
      "Epoch 3747/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 34865766.5578 - val_loss: 1136398404.3836\n",
      "Epoch 3748/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 21081370.7995 - val_loss: 1093821196.2740\n",
      "Epoch 3749/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9673990.3256 - val_loss: 1113403138.6301\n",
      "Epoch 3750/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11771219.8807 - val_loss: 1087790188.7123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3751/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7241855.7584 - val_loss: 1082792976.6575\n",
      "Epoch 3752/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7200178.2185 - val_loss: 1071838970.7397\n",
      "Epoch 3753/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3174526.5195 - val_loss: 1091499352.5479\n",
      "Epoch 3754/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1991372.9448 - val_loss: 1088152175.3425\n",
      "Epoch 3755/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1404798.2260 - val_loss: 1088638223.7808\n",
      "Epoch 3756/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1086167.6470 - val_loss: 1079663881.6438\n",
      "Epoch 3757/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 886785.7321 - val_loss: 1079253685.4795\n",
      "Epoch 3758/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 940630.9407 - val_loss: 1085333556.6027\n",
      "Epoch 3759/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 871926.4921 - val_loss: 1083559896.5479\n",
      "Epoch 3760/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 907583.1130 - val_loss: 1089312160.4384\n",
      "Epoch 3761/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 887608.3354 - val_loss: 1078961309.8082\n",
      "Epoch 3762/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 831267.0270 - val_loss: 1077649247.5616\n",
      "Epoch 3763/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1399016.1132 - val_loss: 1073919922.8493\n",
      "Epoch 3764/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1241530.6842 - val_loss: 1076788559.7808\n",
      "Epoch 3765/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1174889.8162 - val_loss: 1082763975.8904\n",
      "Epoch 3766/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3279981.0110 - val_loss: 1084923837.3699\n",
      "Epoch 3767/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2659779.1966 - val_loss: 1081125999.3425\n",
      "Epoch 3768/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2132634.2836 - val_loss: 1068638204.4932\n",
      "Epoch 3769/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3231344.4985 - val_loss: 1058660419.5068\n",
      "Epoch 3770/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3961168.1335 - val_loss: 1101941016.5479\n",
      "Epoch 3771/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 4567746.0030 - val_loss: 1063831974.5753\n",
      "Epoch 3772/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4638397.7721 - val_loss: 1076555392.8767\n",
      "Epoch 3773/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 5251768.7404 - val_loss: 1090736315.6164\n",
      "Epoch 3774/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7181881.1300 - val_loss: 1094442098.4110\n",
      "Epoch 3775/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7390564.2723 - val_loss: 1064692323.9452\n",
      "Epoch 3776/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8641388.1495 - val_loss: 1111196612.3836\n",
      "Epoch 3777/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6254271.1884 - val_loss: 1080376646.1370\n",
      "Epoch 3778/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9704566.8685 - val_loss: 1071953250.1918\n",
      "Epoch 3779/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 7735717.2434 - val_loss: 1067603498.9589\n",
      "Epoch 3780/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6959114.4254 - val_loss: 1065632978.4110\n",
      "Epoch 3781/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4495666.8320 - val_loss: 1113788680.7671\n",
      "Epoch 3782/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5953411.0323 - val_loss: 1108412465.9726\n",
      "Epoch 3783/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 6096763.9053 - val_loss: 1072750934.7945\n",
      "Epoch 3784/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4383889.1853 - val_loss: 1105287203.0685\n",
      "Epoch 3785/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6698984.5450 - val_loss: 1080948462.4658\n",
      "Epoch 3786/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 15435319.2648 - val_loss: 1099631187.2877\n",
      "Epoch 3787/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 21871151.6752 - val_loss: 1134401895.4521\n",
      "Epoch 3788/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12446044.3646 - val_loss: 1082188989.3699\n",
      "Epoch 3789/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5946230.4833 - val_loss: 1084820489.6438\n",
      "Epoch 3790/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8623709.2768 - val_loss: 1117033355.3973\n",
      "Epoch 3791/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8615215.5176 - val_loss: 1092567108.3836\n",
      "Epoch 3792/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3944513.6802 - val_loss: 1081317380.3836\n",
      "Epoch 3793/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3606414.4884 - val_loss: 1106185896.3288\n",
      "Epoch 3794/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2463293.7752 - val_loss: 1079858940.4932\n",
      "Epoch 3795/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1900259.6371 - val_loss: 1096699686.5753\n",
      "Epoch 3796/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1951490.8374 - val_loss: 1084581944.9863\n",
      "Epoch 3797/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1677832.3958 - val_loss: 1084438164.1644\n",
      "Epoch 3798/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1414039.2879 - val_loss: 1086137629.8082\n",
      "Epoch 3799/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2207808.6998 - val_loss: 1076993839.3425\n",
      "Epoch 3800/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2649152.3252 - val_loss: 1095093979.1781\n",
      "Epoch 3801/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3158811.4404 - val_loss: 1073706053.2603\n",
      "Epoch 3802/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2947968.7134 - val_loss: 1089445377.7534\n",
      "Epoch 3803/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2885510.3980 - val_loss: 1084764995.5068\n",
      "Epoch 3804/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 7048312.8194 - val_loss: 1135797435.6164\n",
      "Epoch 3805/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11187951.3445 - val_loss: 1124304724.1644\n",
      "Epoch 3806/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 16159385.1817 - val_loss: 1094391031.2329\n",
      "Epoch 3807/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 13538231.1088 - val_loss: 1079204023.2329\n",
      "Epoch 3808/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 40841495.4841 - val_loss: 1158904403.2877\n",
      "Epoch 3809/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 38392812.9760 - val_loss: 1098992424.3288\n",
      "Epoch 3810/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 12868557.8273 - val_loss: 1092778795.8356\n",
      "Epoch 3811/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 8956222.8063 - val_loss: 1078980958.6849\n",
      "Epoch 3812/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9896876.6251 - val_loss: 1069375718.5753\n",
      "Epoch 3813/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5835924.6675 - val_loss: 1079273972.6027\n",
      "Epoch 3814/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 7633646.1729 - val_loss: 1083303274.0822\n",
      "Epoch 3815/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 5364171.2481 - val_loss: 1078263381.0411\n",
      "Epoch 3816/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6181340.1979 - val_loss: 1095198369.3151\n",
      "Epoch 3817/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 248us/step - loss: 6199449.0797 - val_loss: 1081124150.3562\n",
      "Epoch 3818/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5093364.2104 - val_loss: 1081689725.3699\n",
      "Epoch 3819/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6406235.3076 - val_loss: 1098281785.8630\n",
      "Epoch 3820/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4668080.8385 - val_loss: 1083503580.0548\n",
      "Epoch 3821/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 4038199.4522 - val_loss: 1107306830.9041\n",
      "Epoch 3822/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 3983142.2388 - val_loss: 1066113692.9315\n",
      "Epoch 3823/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4067778.9419 - val_loss: 1069014811.1781\n",
      "Epoch 3824/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2047944.9540 - val_loss: 1067382275.5068\n",
      "Epoch 3825/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1514860.6460 - val_loss: 1078321055.5616\n",
      "Epoch 3826/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1298605.8873 - val_loss: 1062885580.2740\n",
      "Epoch 3827/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1692593.0982 - val_loss: 1087266303.1233\n",
      "Epoch 3828/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2193904.8112 - val_loss: 1068365717.9178\n",
      "Epoch 3829/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1382798.7449 - val_loss: 1058070548.1644\n",
      "Epoch 3830/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1647568.0504 - val_loss: 1070500779.8356\n",
      "Epoch 3831/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1265891.2084 - val_loss: 1074423269.6986\n",
      "Epoch 3832/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2711015.4587 - val_loss: 1088185993.6438\n",
      "Epoch 3833/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2875713.7648 - val_loss: 1061834261.9178\n",
      "Epoch 3834/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5721181.0122 - val_loss: 1053319129.4247\n",
      "Epoch 3835/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4351605.8264 - val_loss: 1065659510.3562\n",
      "Epoch 3836/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2811372.3483 - val_loss: 1087514961.5342\n",
      "Epoch 3837/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3492416.3723 - val_loss: 1077456385.7534\n",
      "Epoch 3838/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6323658.5977 - val_loss: 1075356046.9041\n",
      "Epoch 3839/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12693384.7622 - val_loss: 1101598533.2603\n",
      "Epoch 3840/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 8390133.3006 - val_loss: 1073973283.5068\n",
      "Epoch 3841/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6346905.9049 - val_loss: 1064433467.6164\n",
      "Epoch 3842/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5504995.5386 - val_loss: 1097221701.2603\n",
      "Epoch 3843/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7563802.7811 - val_loss: 1093883247.3425\n",
      "Epoch 3844/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 11291604.5694 - val_loss: 1097617854.2466\n",
      "Epoch 3845/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 22028225.3890 - val_loss: 1095113279.1233\n",
      "Epoch 3846/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 60801730.3239 - val_loss: 1109147530.5205\n",
      "Epoch 3847/5000\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 30867908.6992 - val_loss: 1105604799.1233\n",
      "Epoch 3848/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 16719903.8916 - val_loss: 1086845646.9041\n",
      "Epoch 3849/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5739689.7828 - val_loss: 1080743873.7534\n",
      "Epoch 3850/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4988873.9289 - val_loss: 1070601405.3699\n",
      "Epoch 3851/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 6808778.0291 - val_loss: 1095876724.6027\n",
      "Epoch 3852/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 7457260.2217 - val_loss: 1089146388.1644\n",
      "Epoch 3853/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4210916.8248 - val_loss: 1085405531.1781\n",
      "Epoch 3854/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2920515.2115 - val_loss: 1065448004.3836\n",
      "Epoch 3855/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1828030.6844 - val_loss: 1077811747.9452\n",
      "Epoch 3856/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1750257.7236 - val_loss: 1080870512.2192\n",
      "Epoch 3857/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1312798.5272 - val_loss: 1073252252.0548\n",
      "Epoch 3858/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1567334.1518 - val_loss: 1082922084.8219\n",
      "Epoch 3859/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1143009.0523 - val_loss: 1064200877.5890\n",
      "Epoch 3860/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 861802.4742 - val_loss: 1074803551.5616\n",
      "Epoch 3861/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 807085.6813 - val_loss: 1063865975.2329\n",
      "Epoch 3862/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 857930.2181 - val_loss: 1073298388.1644\n",
      "Epoch 3863/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 874279.4856 - val_loss: 1072264927.5616\n",
      "Epoch 3864/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1122817.0986 - val_loss: 1074839246.9041\n",
      "Epoch 3865/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1205051.6612 - val_loss: 1059959341.5890\n",
      "Epoch 3866/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 910599.0750 - val_loss: 1066400072.7671\n",
      "Epoch 3867/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2608055.7626 - val_loss: 1076944952.1096\n",
      "Epoch 3868/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3943856.2983 - val_loss: 1078856956.4932\n",
      "Epoch 3869/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2808498.6809 - val_loss: 1073248105.2055\n",
      "Epoch 3870/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2149236.6487 - val_loss: 1072557770.5205\n",
      "Epoch 3871/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3167008.8565 - val_loss: 1061683903.1233\n",
      "Epoch 3872/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4192046.5609 - val_loss: 1085305113.4247\n",
      "Epoch 3873/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2688643.5668 - val_loss: 1054771457.7534\n",
      "Epoch 3874/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2666170.0154 - val_loss: 1090218610.8493\n",
      "Epoch 3875/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 5068369.5090 - val_loss: 1088172266.9589\n",
      "Epoch 3876/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 8805390.6007 - val_loss: 1087586177.7534\n",
      "Epoch 3877/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 12471635.6628 - val_loss: 1084307801.4247\n",
      "Epoch 3878/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 16737959.0703 - val_loss: 1124841184.0000\n",
      "Epoch 3879/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 26862814.5484 - val_loss: 1081068158.2466\n",
      "Epoch 3880/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 25320612.4079 - val_loss: 1120532936.7671\n",
      "Epoch 3881/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 19559694.4165 - val_loss: 1096038867.2877\n",
      "Epoch 3882/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 19995904.1748 - val_loss: 1107825272.1096\n",
      "Epoch 3883/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 16975299.8629 - val_loss: 1139458110.6849\n",
      "Epoch 3884/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 10767913.4233 - val_loss: 1109471330.1918\n",
      "Epoch 3885/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 11896334.6988 - val_loss: 1100389667.0685\n",
      "Epoch 3886/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 6737146.4794 - val_loss: 1088583622.1370\n",
      "Epoch 3887/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5181291.4587 - val_loss: 1104839428.3836\n",
      "Epoch 3888/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3760550.9859 - val_loss: 1105593846.3562\n",
      "Epoch 3889/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3335884.4090 - val_loss: 1078679554.6301\n",
      "Epoch 3890/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2388068.7940 - val_loss: 1091735884.2740\n",
      "Epoch 3891/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2265989.8599 - val_loss: 1089774454.3562\n",
      "Epoch 3892/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1449656.0272 - val_loss: 1085693836.2740\n",
      "Epoch 3893/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1256426.7020 - val_loss: 1089469317.2603\n",
      "Epoch 3894/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 990325.6110 - val_loss: 1085547212.2740\n",
      "Epoch 3895/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 986919.1340 - val_loss: 1087174067.7260\n",
      "Epoch 3896/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1607491.0317 - val_loss: 1089993706.0822\n",
      "Epoch 3897/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2114679.3224 - val_loss: 1085945637.6986\n",
      "Epoch 3898/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3530231.3556 - val_loss: 1089288674.1918\n",
      "Epoch 3899/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2476369.3828 - val_loss: 1094173941.4795\n",
      "Epoch 3900/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3499854.3038 - val_loss: 1075863006.6849\n",
      "Epoch 3901/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2767016.5994 - val_loss: 1091823759.7808\n",
      "Epoch 3902/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3658685.5831 - val_loss: 1067963698.8493\n",
      "Epoch 3903/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3225537.7001 - val_loss: 1093107073.7534\n",
      "Epoch 3904/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3885489.7005 - val_loss: 1107032250.7397\n",
      "Epoch 3905/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9488443.2776 - val_loss: 1127600220.4932\n",
      "Epoch 3906/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11792029.3933 - val_loss: 1100210850.1918\n",
      "Epoch 3907/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6497124.6954 - val_loss: 1104066216.3288\n",
      "Epoch 3908/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5824087.4632 - val_loss: 1092525285.6986\n",
      "Epoch 3909/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 7459329.3760 - val_loss: 1104691521.7534\n",
      "Epoch 3910/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15021396.5707 - val_loss: 1126613212.9315\n",
      "Epoch 3911/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 20905081.3976 - val_loss: 1077229973.0411\n",
      "Epoch 3912/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9902974.9704 - val_loss: 1099070338.6301\n",
      "Epoch 3913/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6729264.2237 - val_loss: 1100788307.2877\n",
      "Epoch 3914/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3654202.9741 - val_loss: 1082750722.6301\n",
      "Epoch 3915/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3099751.3138 - val_loss: 1080231193.4247\n",
      "Epoch 3916/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2608743.0428 - val_loss: 1084369678.0274\n",
      "Epoch 3917/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3224876.5332 - val_loss: 1102756545.7534\n",
      "Epoch 3918/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3317771.7830 - val_loss: 1085411984.6575\n",
      "Epoch 3919/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2916710.2713 - val_loss: 1079455965.8082\n",
      "Epoch 3920/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 2774550.3274 - val_loss: 1064925750.3562\n",
      "Epoch 3921/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1601879.3725 - val_loss: 1079326097.5342\n",
      "Epoch 3922/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2979332.5150 - val_loss: 1086228009.2055\n",
      "Epoch 3923/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3443810.1716 - val_loss: 1084055879.0137\n",
      "Epoch 3924/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 5975561.5698 - val_loss: 1091025615.7808\n",
      "Epoch 3925/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7522596.8668 - val_loss: 1059271715.0685\n",
      "Epoch 3926/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4928300.1630 - val_loss: 1088149138.4110\n",
      "Epoch 3927/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4015727.9105 - val_loss: 1079423733.9178\n",
      "Epoch 3928/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4093739.0460 - val_loss: 1093946397.3699\n",
      "Epoch 3929/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3007140.0015 - val_loss: 1081211796.1644\n",
      "Epoch 3930/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8695191.8183 - val_loss: 1143970136.5479\n",
      "Epoch 3931/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 50527670.6701 - val_loss: 1166488756.6027\n",
      "Epoch 3932/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 70662131.5441 - val_loss: 1158350672.6575\n",
      "Epoch 3933/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 48122398.4439 - val_loss: 1176219290.3014\n",
      "Epoch 3934/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 41017070.9889 - val_loss: 1135687168.0000\n",
      "Epoch 3935/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 28757317.1688 - val_loss: 1121866076.0548\n",
      "Epoch 3936/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 48811608.6118 - val_loss: 1113698206.6849\n",
      "Epoch 3937/5000\n",
      "1167/1167 [==============================] - 0s 232us/step - loss: 13272286.8158 - val_loss: 1104363041.3151\n",
      "Epoch 3938/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 6763521.3479 - val_loss: 1078374820.8219\n",
      "Epoch 3939/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5650571.4799 - val_loss: 1096704083.2877\n",
      "Epoch 3940/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2604061.4527 - val_loss: 1094850808.9863\n",
      "Epoch 3941/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1727155.7351 - val_loss: 1091356560.6575\n",
      "Epoch 3942/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1098573.9023 - val_loss: 1085968903.8904\n",
      "Epoch 3943/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 1008305.1960 - val_loss: 1086055331.0685\n",
      "Epoch 3944/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 893798.8142 - val_loss: 1091154970.3014\n",
      "Epoch 3945/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 977653.6183 - val_loss: 1092021513.6438\n",
      "Epoch 3946/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1166014.7293 - val_loss: 1089163976.7671\n",
      "Epoch 3947/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1072302.0777 - val_loss: 1080608128.8767\n",
      "Epoch 3948/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 941078.3804 - val_loss: 1084638144.0000\n",
      "Epoch 3949/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 245us/step - loss: 1003751.3812 - val_loss: 1089570451.2877\n",
      "Epoch 3950/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 855340.0449 - val_loss: 1083624416.4384\n",
      "Epoch 3951/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 786546.7675 - val_loss: 1088035853.1507\n",
      "Epoch 3952/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 634685.0001 - val_loss: 1091114561.7534\n",
      "Epoch 3953/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 660074.1349 - val_loss: 1085250871.2329\n",
      "Epoch 3954/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 713304.4693 - val_loss: 1086909387.3973\n",
      "Epoch 3955/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 827272.9734 - val_loss: 1088358017.7534\n",
      "Epoch 3956/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 894856.6381 - val_loss: 1074870820.8219\n",
      "Epoch 3957/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 982860.5874 - val_loss: 1092690285.5890\n",
      "Epoch 3958/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 866706.9083 - val_loss: 1080061568.8767\n",
      "Epoch 3959/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1260196.7170 - val_loss: 1086691634.8493\n",
      "Epoch 3960/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1012487.9087 - val_loss: 1082321180.0548\n",
      "Epoch 3961/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 815809.6781 - val_loss: 1090646271.1233\n",
      "Epoch 3962/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 591268.8265 - val_loss: 1085719159.2329\n",
      "Epoch 3963/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 679253.4527 - val_loss: 1083859267.5068\n",
      "Epoch 3964/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 487149.4682 - val_loss: 1079567985.9726\n",
      "Epoch 3965/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 657407.0262 - val_loss: 1087313720.1096\n",
      "Epoch 3966/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 670420.8776 - val_loss: 1082991058.4110\n",
      "Epoch 3967/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 771442.4418 - val_loss: 1079651381.4795\n",
      "Epoch 3968/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 686343.5647 - val_loss: 1082153146.7397\n",
      "Epoch 3969/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 557600.8580 - val_loss: 1090818657.3151\n",
      "Epoch 3970/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 707415.1844 - val_loss: 1078985688.5479\n",
      "Epoch 3971/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1189742.4063 - val_loss: 1083461354.9589\n",
      "Epoch 3972/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1088006.8791 - val_loss: 1077953436.9315\n",
      "Epoch 3973/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1131388.8344 - val_loss: 1082230330.7397\n",
      "Epoch 3974/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1407475.5501 - val_loss: 1085840868.8219\n",
      "Epoch 3975/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1356171.6471 - val_loss: 1085344409.4247\n",
      "Epoch 3976/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1317176.9124 - val_loss: 1094797443.5068\n",
      "Epoch 3977/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2172830.2558 - val_loss: 1095270786.6301\n",
      "Epoch 3978/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1890110.1745 - val_loss: 1084006766.4658\n",
      "Epoch 3979/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2150864.6874 - val_loss: 1092999286.3562\n",
      "Epoch 3980/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2268426.4106 - val_loss: 1080444857.8630\n",
      "Epoch 3981/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6376624.4323 - val_loss: 1060238541.1507\n",
      "Epoch 3982/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 14624231.3830 - val_loss: 1105286135.6712\n",
      "Epoch 3983/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 13622131.8800 - val_loss: 1126502550.7945\n",
      "Epoch 3984/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 32421420.9452 - val_loss: 1146795518.2466\n",
      "Epoch 3985/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 22602288.0497 - val_loss: 1110317134.0274\n",
      "Epoch 3986/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 16500791.7172 - val_loss: 1105348575.5616\n",
      "Epoch 3987/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 10621507.4387 - val_loss: 1111829051.6164\n",
      "Epoch 3988/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6226232.6607 - val_loss: 1082637674.9589\n",
      "Epoch 3989/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7251786.4105 - val_loss: 1082766312.3288\n",
      "Epoch 3990/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5376005.3078 - val_loss: 1082959409.0959\n",
      "Epoch 3991/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4116087.9632 - val_loss: 1105349995.8356\n",
      "Epoch 3992/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4555626.4989 - val_loss: 1087134004.6027\n",
      "Epoch 3993/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4262542.2823 - val_loss: 1085716254.6849\n",
      "Epoch 3994/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4923200.3625 - val_loss: 1088579901.3699\n",
      "Epoch 3995/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5632939.9394 - val_loss: 1072755212.2740\n",
      "Epoch 3996/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4145597.9242 - val_loss: 1092869963.3973\n",
      "Epoch 3997/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2709024.4722 - val_loss: 1074078999.6712\n",
      "Epoch 3998/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2720437.8632 - val_loss: 1092193743.7808\n",
      "Epoch 3999/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3599748.8081 - val_loss: 1100025514.9589\n",
      "Epoch 4000/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3913160.9430 - val_loss: 1094473770.9589\n",
      "Epoch 4001/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3447246.8313 - val_loss: 1068038041.4247\n",
      "Epoch 4002/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3515339.9989 - val_loss: 1067315441.9726\n",
      "Epoch 4003/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2098296.1165 - val_loss: 1086084256.4384\n",
      "Epoch 4004/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1231231.7196 - val_loss: 1077559373.1507\n",
      "Epoch 4005/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1017721.7791 - val_loss: 1094247595.8356\n",
      "Epoch 4006/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1726195.0311 - val_loss: 1085181802.9589\n",
      "Epoch 4007/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2825888.7365 - val_loss: 1086042453.0411\n",
      "Epoch 4008/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3557712.6767 - val_loss: 1085042536.3288\n",
      "Epoch 4009/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4755166.7772 - val_loss: 1072045760.0000\n",
      "Epoch 4010/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3911074.7322 - val_loss: 1092486588.4932\n",
      "Epoch 4011/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 2965169.8192 - val_loss: 1101076663.2329\n",
      "Epoch 4012/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2958924.2391 - val_loss: 1102704622.4658\n",
      "Epoch 4013/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 5705348.9357 - val_loss: 1123250569.6438\n",
      "Epoch 4014/5000\n",
      "1167/1167 [==============================] - 0s 232us/step - loss: 3510506.9644 - val_loss: 1095952261.2603\n",
      "Epoch 4015/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5957194.5491 - val_loss: 1067883402.5205\n",
      "Epoch 4016/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 10196136.3985 - val_loss: 1108701227.8356\n",
      "Epoch 4017/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 22503531.5947 - val_loss: 1220981686.3562\n",
      "Epoch 4018/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 23480800.7986 - val_loss: 1124901144.5479\n",
      "Epoch 4019/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 23849185.1774 - val_loss: 1097477642.5205\n",
      "Epoch 4020/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 13747800.5051 - val_loss: 1105106777.4247\n",
      "Epoch 4021/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 14587584.3685 - val_loss: 1115905565.8082\n",
      "Epoch 4022/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 16270305.6932 - val_loss: 1121127035.6164\n",
      "Epoch 4023/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 39471583.8458 - val_loss: 1084537898.0822\n",
      "Epoch 4024/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 33747997.3865 - val_loss: 1101804650.9589\n",
      "Epoch 4025/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 20197476.5647 - val_loss: 1075249751.6712\n",
      "Epoch 4026/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13715582.1045 - val_loss: 1098407318.7945\n",
      "Epoch 4027/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6924974.1686 - val_loss: 1081490062.9041\n",
      "Epoch 4028/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 4438978.8173 - val_loss: 1101416847.7808\n",
      "Epoch 4029/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2433676.5602 - val_loss: 1079147819.8356\n",
      "Epoch 4030/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1635110.9085 - val_loss: 1087395231.5616\n",
      "Epoch 4031/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1275655.8670 - val_loss: 1079182893.5890\n",
      "Epoch 4032/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1578216.5486 - val_loss: 1080822323.7260\n",
      "Epoch 4033/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1557062.8367 - val_loss: 1083214564.8219\n",
      "Epoch 4034/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1241456.4120 - val_loss: 1085314099.7260\n",
      "Epoch 4035/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1515618.6224 - val_loss: 1085196719.3425\n",
      "Epoch 4036/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1110724.4734 - val_loss: 1080553713.9726\n",
      "Epoch 4037/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 986754.1791 - val_loss: 1082475966.2466\n",
      "Epoch 4038/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 989470.4054 - val_loss: 1088061076.1644\n",
      "Epoch 4039/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2344726.7561 - val_loss: 1093517682.8493\n",
      "Epoch 4040/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1939538.1263 - val_loss: 1089377107.2877\n",
      "Epoch 4041/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 927909.0127 - val_loss: 1087260348.4932\n",
      "Epoch 4042/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 877544.0497 - val_loss: 1087174264.9863\n",
      "Epoch 4043/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 920090.2318 - val_loss: 1080909077.9178\n",
      "Epoch 4044/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 919361.2617 - val_loss: 1082652997.2603\n",
      "Epoch 4045/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1223009.4845 - val_loss: 1097666329.4247\n",
      "Epoch 4046/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1854358.9940 - val_loss: 1078170989.5890\n",
      "Epoch 4047/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1549575.3084 - val_loss: 1081946545.0959\n",
      "Epoch 4048/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1781178.3107 - val_loss: 1080379323.6164\n",
      "Epoch 4049/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1774707.8899 - val_loss: 1091801065.2055\n",
      "Epoch 4050/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3360641.5495 - val_loss: 1113492320.4384\n",
      "Epoch 4051/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 3725732.1958 - val_loss: 1084356465.0959\n",
      "Epoch 4052/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6002828.7798 - val_loss: 1096024719.7808\n",
      "Epoch 4053/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 10235245.1611 - val_loss: 1091902065.0959\n",
      "Epoch 4054/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8785193.3719 - val_loss: 1114629038.4658\n",
      "Epoch 4055/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 11374174.2584 - val_loss: 1109409137.9726\n",
      "Epoch 4056/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 7479797.3937 - val_loss: 1109986142.6849\n",
      "Epoch 4057/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7960758.3763 - val_loss: 1128937676.2740\n",
      "Epoch 4058/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 7834802.8372 - val_loss: 1110540324.8219\n",
      "Epoch 4059/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 11849409.2699 - val_loss: 1134479291.6164\n",
      "Epoch 4060/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 19802546.9700 - val_loss: 1115013048.1096\n",
      "Epoch 4061/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 10166737.6872 - val_loss: 1068581589.9178\n",
      "Epoch 4062/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 7090016.4070 - val_loss: 1075546843.1781\n",
      "Epoch 4063/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7239140.9079 - val_loss: 1088530154.9589\n",
      "Epoch 4064/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 6852939.0979 - val_loss: 1073585415.0137\n",
      "Epoch 4065/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 5358822.5619 - val_loss: 1089887886.0274\n",
      "Epoch 4066/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7154357.1029 - val_loss: 1120735226.7397\n",
      "Epoch 4067/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 8650982.9357 - val_loss: 1068295574.7945\n",
      "Epoch 4068/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 7125250.3552 - val_loss: 1108874692.3836\n",
      "Epoch 4069/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6309866.4818 - val_loss: 1090514482.8493\n",
      "Epoch 4070/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8248849.4674 - val_loss: 1102845721.8630\n",
      "Epoch 4071/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8610581.3398 - val_loss: 1094894273.7534\n",
      "Epoch 4072/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5325179.9293 - val_loss: 1094903736.1096\n",
      "Epoch 4073/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3691354.1877 - val_loss: 1097102581.4795\n",
      "Epoch 4074/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3398314.1386 - val_loss: 1089635989.9178\n",
      "Epoch 4075/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 1740789.5235 - val_loss: 1064564870.1370\n",
      "Epoch 4076/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1880844.3013 - val_loss: 1094724432.6575\n",
      "Epoch 4077/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1686464.4722 - val_loss: 1094839476.6027\n",
      "Epoch 4078/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1506103.5658 - val_loss: 1082468044.2740\n",
      "Epoch 4079/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1355953.2848 - val_loss: 1079946771.2877\n",
      "Epoch 4080/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1460313.2893 - val_loss: 1086277568.8767\n",
      "Epoch 4081/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 245us/step - loss: 1462110.5575 - val_loss: 1090443199.1233\n",
      "Epoch 4082/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1492077.6943 - val_loss: 1073165523.2877\n",
      "Epoch 4083/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1996572.5797 - val_loss: 1084204271.3425\n",
      "Epoch 4084/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1875321.6448 - val_loss: 1091600096.4384\n",
      "Epoch 4085/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1481794.4929 - val_loss: 1090240629.4795\n",
      "Epoch 4086/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2777822.6978 - val_loss: 1092063083.8356\n",
      "Epoch 4087/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 2247565.7320 - val_loss: 1093657979.6164\n",
      "Epoch 4088/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2546209.7472 - val_loss: 1104558830.4658\n",
      "Epoch 4089/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4418708.2734 - val_loss: 1065060521.2055\n",
      "Epoch 4090/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 7334915.3483 - val_loss: 1093592023.6712\n",
      "Epoch 4091/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 7179046.7198 - val_loss: 1109845496.9863\n",
      "Epoch 4092/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 6227798.1210 - val_loss: 1070059343.7808\n",
      "Epoch 4093/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4307791.1506 - val_loss: 1082379061.4795\n",
      "Epoch 4094/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 5570977.2039 - val_loss: 1128664762.7397\n",
      "Epoch 4095/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4885565.3616 - val_loss: 1108518349.1507\n",
      "Epoch 4096/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 6162393.1632 - val_loss: 1079773796.8219\n",
      "Epoch 4097/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5924079.6512 - val_loss: 1114854086.1370\n",
      "Epoch 4098/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 7436577.2207 - val_loss: 1101862668.2740\n",
      "Epoch 4099/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 23948911.4550 - val_loss: 1277604568.5479\n",
      "Epoch 4100/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 56368345.7412 - val_loss: 1195604515.9452\n",
      "Epoch 4101/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 38683470.4010 - val_loss: 1167686613.0411\n",
      "Epoch 4102/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 63176361.9075 - val_loss: 1199968280.5479\n",
      "Epoch 4103/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 157292364.5587 - val_loss: 1285432492.7123\n",
      "Epoch 4104/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 72881036.3256 - val_loss: 1205051197.8082\n",
      "Epoch 4105/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 21067297.1482 - val_loss: 1077995090.4110\n",
      "Epoch 4106/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 18194375.7057 - val_loss: 1055908176.6575\n",
      "Epoch 4107/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8202873.1294 - val_loss: 1077265136.2192\n",
      "Epoch 4108/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11172799.1945 - val_loss: 1060074005.9178\n",
      "Epoch 4109/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6813369.6911 - val_loss: 1056155969.7534\n",
      "Epoch 4110/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3889829.5554 - val_loss: 1072645812.6027\n",
      "Epoch 4111/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2735054.2554 - val_loss: 1066112648.7671\n",
      "Epoch 4112/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2280011.9700 - val_loss: 1068732228.3836\n",
      "Epoch 4113/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1732982.7850 - val_loss: 1073002692.3836\n",
      "Epoch 4114/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1902910.7635 - val_loss: 1074749827.5068\n",
      "Epoch 4115/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1371093.3921 - val_loss: 1068864449.7534\n",
      "Epoch 4116/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1048321.1124 - val_loss: 1074839687.8904\n",
      "Epoch 4117/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 955213.7016 - val_loss: 1073938010.3014\n",
      "Epoch 4118/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1106936.7849 - val_loss: 1073353796.3836\n",
      "Epoch 4119/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 896927.8407 - val_loss: 1075479661.5890\n",
      "Epoch 4120/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 969228.9148 - val_loss: 1067715114.9589\n",
      "Epoch 4121/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 977599.7660 - val_loss: 1073290731.8356\n",
      "Epoch 4122/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1200030.9383 - val_loss: 1082950673.5342\n",
      "Epoch 4123/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1048146.9452 - val_loss: 1080730842.3014\n",
      "Epoch 4124/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 928214.9698 - val_loss: 1070311036.4932\n",
      "Epoch 4125/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 778072.8793 - val_loss: 1073267294.6849\n",
      "Epoch 4126/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 849627.9512 - val_loss: 1071719339.8356\n",
      "Epoch 4127/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 819368.1455 - val_loss: 1074306692.3836\n",
      "Epoch 4128/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 985018.8072 - val_loss: 1073209793.7534\n",
      "Epoch 4129/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 944779.8611 - val_loss: 1071107218.4110\n",
      "Epoch 4130/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 870233.6913 - val_loss: 1075686549.0411\n",
      "Epoch 4131/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1246475.1961 - val_loss: 1068482916.8219\n",
      "Epoch 4132/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2689230.3901 - val_loss: 1093510992.6575\n",
      "Epoch 4133/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3429402.7528 - val_loss: 1080712006.1370\n",
      "Epoch 4134/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2250905.9775 - val_loss: 1096259346.4110\n",
      "Epoch 4135/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 3625213.5953 - val_loss: 1079081422.0274\n",
      "Epoch 4136/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 3989137.4244 - val_loss: 1086993267.7260\n",
      "Epoch 4137/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3319512.1598 - val_loss: 1088600875.8356\n",
      "Epoch 4138/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4207490.3072 - val_loss: 1091686956.7123\n",
      "Epoch 4139/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 6812939.4379 - val_loss: 1098980465.9726\n",
      "Epoch 4140/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 8470621.3363 - val_loss: 1091366178.1918\n",
      "Epoch 4141/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 6163016.5694 - val_loss: 1102098593.3151\n",
      "Epoch 4142/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 17165759.7729 - val_loss: 1052926194.8493\n",
      "Epoch 4143/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9891697.2571 - val_loss: 1093583886.0274\n",
      "Epoch 4144/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 6815481.5724 - val_loss: 1085100401.0959\n",
      "Epoch 4145/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 9523378.4045 - val_loss: 1090499706.7397\n",
      "Epoch 4146/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5108178.2554 - val_loss: 1116474969.4247\n",
      "Epoch 4147/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2786123.6246 - val_loss: 1105936449.7534\n",
      "Epoch 4148/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1510535.3677 - val_loss: 1084283769.8630\n",
      "Epoch 4149/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1499482.3539 - val_loss: 1094755981.1507\n",
      "Epoch 4150/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1818548.0009 - val_loss: 1078899507.7260\n",
      "Epoch 4151/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3102914.3657 - val_loss: 1090131451.6164\n",
      "Epoch 4152/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 1940845.0838 - val_loss: 1083266638.0274\n",
      "Epoch 4153/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2018763.1764 - val_loss: 1102107107.9452\n",
      "Epoch 4154/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 3001856.9824 - val_loss: 1096060006.5753\n",
      "Epoch 4155/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 5699141.6195 - val_loss: 1138127370.5205\n",
      "Epoch 4156/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 5954519.4745 - val_loss: 1095289603.5068\n",
      "Epoch 4157/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 4629277.8490 - val_loss: 1105098771.2877\n",
      "Epoch 4158/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2296993.6355 - val_loss: 1094951222.3562\n",
      "Epoch 4159/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1579315.9520 - val_loss: 1088741111.2329\n",
      "Epoch 4160/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1407109.0239 - val_loss: 1098619846.1370\n",
      "Epoch 4161/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2104237.4549 - val_loss: 1076847529.2055\n",
      "Epoch 4162/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1956576.0349 - val_loss: 1084669020.0548\n",
      "Epoch 4163/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4185365.6435 - val_loss: 1083308271.3425\n",
      "Epoch 4164/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3133124.1108 - val_loss: 1093402561.7534\n",
      "Epoch 4165/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5714001.8036 - val_loss: 1098083477.9178\n",
      "Epoch 4166/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6244628.8828 - val_loss: 1090918577.0959\n",
      "Epoch 4167/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10196284.9477 - val_loss: 1104542898.8493\n",
      "Epoch 4168/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 25462033.5073 - val_loss: 1109163384.9863\n",
      "Epoch 4169/5000\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 53279709.4019 - val_loss: 1594516180.6027\n",
      "Epoch 4170/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 79097773.6195 - val_loss: 1223076190.6849\n",
      "Epoch 4171/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 30216522.0300 - val_loss: 1133677197.1507\n",
      "Epoch 4172/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 17501848.8338 - val_loss: 1110476453.6986\n",
      "Epoch 4173/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 10203914.0823 - val_loss: 1089941139.2877\n",
      "Epoch 4174/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 4541376.7877 - val_loss: 1098169995.3973\n",
      "Epoch 4175/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 3152937.3925 - val_loss: 1097868939.3973\n",
      "Epoch 4176/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 1883888.7159 - val_loss: 1093947748.8219\n",
      "Epoch 4177/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 1538036.7059 - val_loss: 1077067477.9178\n",
      "Epoch 4178/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 2734276.1464 - val_loss: 1106033169.5342\n",
      "Epoch 4179/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 4091335.2586 - val_loss: 1077548702.6849\n",
      "Epoch 4180/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 3604185.6710 - val_loss: 1091151203.9452\n",
      "Epoch 4181/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 2432973.3152 - val_loss: 1104291169.3151\n",
      "Epoch 4182/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 1172470.4996 - val_loss: 1098192120.1096\n",
      "Epoch 4183/5000\n",
      "1167/1167 [==============================] - 0s 276us/step - loss: 776505.5251 - val_loss: 1097825314.1918\n",
      "Epoch 4184/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 839985.1049 - val_loss: 1092742292.1644\n",
      "Epoch 4185/5000\n",
      "1167/1167 [==============================] - 0s 284us/step - loss: 707049.2335 - val_loss: 1096271132.9315\n",
      "Epoch 4186/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 617898.2265 - val_loss: 1095484404.6027\n",
      "Epoch 4187/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 527785.9080 - val_loss: 1090117918.6849\n",
      "Epoch 4188/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 798338.5145 - val_loss: 1093999434.5205\n",
      "Epoch 4189/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 653202.0112 - val_loss: 1094935932.4932\n",
      "Epoch 4190/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1483308.3268 - val_loss: 1090012664.9863\n",
      "Epoch 4191/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1896915.4332 - val_loss: 1098443214.9041\n",
      "Epoch 4192/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1321599.1148 - val_loss: 1095692832.4384\n",
      "Epoch 4193/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 960691.4952 - val_loss: 1093315726.9041\n",
      "Epoch 4194/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 794738.0628 - val_loss: 1095065159.8904\n",
      "Epoch 4195/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 847381.1377 - val_loss: 1091442801.9726\n",
      "Epoch 4196/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1232216.8896 - val_loss: 1094598328.1096\n",
      "Epoch 4197/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1541387.0347 - val_loss: 1099093353.2055\n",
      "Epoch 4198/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2000021.6545 - val_loss: 1094269608.3288\n",
      "Epoch 4199/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2073166.6141 - val_loss: 1090811626.0822\n",
      "Epoch 4200/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1650451.4501 - val_loss: 1093193124.8219\n",
      "Epoch 4201/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1210671.7179 - val_loss: 1101246070.3562\n",
      "Epoch 4202/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1342297.3499 - val_loss: 1105088971.3973\n",
      "Epoch 4203/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2177982.8224 - val_loss: 1093221471.5616\n",
      "Epoch 4204/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4045116.0168 - val_loss: 1126581006.0274\n",
      "Epoch 4205/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 4802683.8136 - val_loss: 1114360686.4658\n",
      "Epoch 4206/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 5619087.4492 - val_loss: 1112778347.8356\n",
      "Epoch 4207/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 7383168.9841 - val_loss: 1091101438.2466\n",
      "Epoch 4208/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 9329276.7524 - val_loss: 1113447325.8082\n",
      "Epoch 4209/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 10906880.1337 - val_loss: 1095625573.6986\n",
      "Epoch 4210/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 24894910.1422 - val_loss: 1100685198.9041\n",
      "Epoch 4211/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 17113632.3633 - val_loss: 1089870631.4521\n",
      "Epoch 4212/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 16401183.0531 - val_loss: 1117524198.5753\n",
      "Epoch 4213/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 239us/step - loss: 15016790.1958 - val_loss: 1138701540.8219\n",
      "Epoch 4214/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 22576528.7138 - val_loss: 1111461554.4110\n",
      "Epoch 4215/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 17151625.4709 - val_loss: 1121037367.2329\n",
      "Epoch 4216/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 7863398.9394 - val_loss: 1108592488.3288\n",
      "Epoch 4217/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 3438304.6834 - val_loss: 1106157365.4795\n",
      "Epoch 4218/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 2934489.4854 - val_loss: 1101249495.6712\n",
      "Epoch 4219/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1894122.9673 - val_loss: 1099266813.3699\n",
      "Epoch 4220/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1774216.7215 - val_loss: 1089205691.6164\n",
      "Epoch 4221/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2128706.2616 - val_loss: 1106738748.4932\n",
      "Epoch 4222/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2003528.0321 - val_loss: 1102640525.1507\n",
      "Epoch 4223/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 998525.0842 - val_loss: 1097869686.3562\n",
      "Epoch 4224/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 917955.8503 - val_loss: 1094433815.6712\n",
      "Epoch 4225/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 897863.7856 - val_loss: 1097042368.0000\n",
      "Epoch 4226/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2180190.8109 - val_loss: 1093466961.5342\n",
      "Epoch 4227/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1231815.4970 - val_loss: 1103167324.0548\n",
      "Epoch 4228/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 990043.6956 - val_loss: 1101146729.2055\n",
      "Epoch 4229/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1270398.8174 - val_loss: 1109082652.0548\n",
      "Epoch 4230/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1671943.1108 - val_loss: 1101112790.7945\n",
      "Epoch 4231/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3100600.5388 - val_loss: 1108767177.6438\n",
      "Epoch 4232/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2221023.0347 - val_loss: 1097179754.0822\n",
      "Epoch 4233/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 5297239.2875 - val_loss: 1093490240.8767\n",
      "Epoch 4234/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3405509.0570 - val_loss: 1117457579.8356\n",
      "Epoch 4235/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5077175.6941 - val_loss: 1104812237.1507\n",
      "Epoch 4236/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5633198.3738 - val_loss: 1123042849.3151\n",
      "Epoch 4237/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3988180.1448 - val_loss: 1093183152.2192\n",
      "Epoch 4238/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4945838.9432 - val_loss: 1124463253.9178\n",
      "Epoch 4239/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5161931.2778 - val_loss: 1123218477.5890\n",
      "Epoch 4240/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 6486581.8552 - val_loss: 1131646649.8630\n",
      "Epoch 4241/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6462268.9734 - val_loss: 1118108109.1507\n",
      "Epoch 4242/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 7394143.8383 - val_loss: 1108789939.7260\n",
      "Epoch 4243/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 6132225.7054 - val_loss: 1138837023.5616\n",
      "Epoch 4244/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 6170714.6712 - val_loss: 1112451706.7397\n",
      "Epoch 4245/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3527655.5464 - val_loss: 1094912940.7123\n",
      "Epoch 4246/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 6910213.8880 - val_loss: 1106249404.4932\n",
      "Epoch 4247/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 20765478.1148 - val_loss: 1142144246.3562\n",
      "Epoch 4248/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 15523769.6487 - val_loss: 1162018158.4658\n",
      "Epoch 4249/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 25261363.1191 - val_loss: 1228507068.4932\n",
      "Epoch 4250/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 274046701.0523 - val_loss: 1379881375.5616\n",
      "Epoch 4251/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 126057952.3290 - val_loss: 1279798345.6438\n",
      "Epoch 4252/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 46599080.0377 - val_loss: 1095778983.4521\n",
      "Epoch 4253/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 14343654.4404 - val_loss: 1105530400.4384\n",
      "Epoch 4254/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6618031.1941 - val_loss: 1113002276.8219\n",
      "Epoch 4255/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 3689956.7713 - val_loss: 1116914264.5479\n",
      "Epoch 4256/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2802053.4409 - val_loss: 1116807069.8082\n",
      "Epoch 4257/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2578330.0563 - val_loss: 1109824158.6849\n",
      "Epoch 4258/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1818054.2171 - val_loss: 1112981386.5205\n",
      "Epoch 4259/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1786982.6881 - val_loss: 1112868991.1233\n",
      "Epoch 4260/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 1481373.1235 - val_loss: 1111936096.4384\n",
      "Epoch 4261/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1327785.2584 - val_loss: 1105218621.3699\n",
      "Epoch 4262/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1291879.3241 - val_loss: 1111512360.3288\n",
      "Epoch 4263/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1175292.0688 - val_loss: 1107161856.0000\n",
      "Epoch 4264/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 747387.0073 - val_loss: 1110374154.5205\n",
      "Epoch 4265/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 799317.0412 - val_loss: 1112274315.3973\n",
      "Epoch 4266/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 768033.0356 - val_loss: 1106218020.8219\n",
      "Epoch 4267/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 841051.1512 - val_loss: 1105812760.5479\n",
      "Epoch 4268/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 907752.3578 - val_loss: 1111500337.9726\n",
      "Epoch 4269/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 1171644.4923 - val_loss: 1111092445.8082\n",
      "Epoch 4270/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 674283.0471 - val_loss: 1102515164.9315\n",
      "Epoch 4271/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 673120.5641 - val_loss: 1102890332.0548\n",
      "Epoch 4272/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 653266.3168 - val_loss: 1114641180.9315\n",
      "Epoch 4273/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 811826.3257 - val_loss: 1108257868.2740\n",
      "Epoch 4274/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 584687.8972 - val_loss: 1106439132.0548\n",
      "Epoch 4275/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 794057.7473 - val_loss: 1108284773.6986\n",
      "Epoch 4276/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 618237.8102 - val_loss: 1106948649.2055\n",
      "Epoch 4277/5000\n",
      "1167/1167 [==============================] - 0s 270us/step - loss: 513261.4053 - val_loss: 1107459806.6849\n",
      "Epoch 4278/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 495186.7091 - val_loss: 1109972303.7808\n",
      "Epoch 4279/5000\n",
      "1167/1167 [==============================] - 0s 280us/step - loss: 480411.3885 - val_loss: 1104235676.9315\n",
      "Epoch 4280/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 494585.0278 - val_loss: 1109942312.3288\n",
      "Epoch 4281/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 414902.9977 - val_loss: 1106590814.6849\n",
      "Epoch 4282/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 428935.7114 - val_loss: 1106279025.9726\n",
      "Epoch 4283/5000\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 451961.0615 - val_loss: 1107609726.2466\n",
      "Epoch 4284/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 478682.6403 - val_loss: 1102500223.1233\n",
      "Epoch 4285/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 639742.2017 - val_loss: 1105749100.7123\n",
      "Epoch 4286/5000\n",
      "1167/1167 [==============================] - 0s 278us/step - loss: 720944.1383 - val_loss: 1113342847.1233\n",
      "Epoch 4287/5000\n",
      "1167/1167 [==============================] - 0s 275us/step - loss: 845583.8876 - val_loss: 1117495002.3014\n",
      "Epoch 4288/5000\n",
      "1167/1167 [==============================] - 0s 267us/step - loss: 687842.8175 - val_loss: 1105266207.5616\n",
      "Epoch 4289/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 804326.6227 - val_loss: 1114744062.2466\n",
      "Epoch 4290/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 1556346.0512 - val_loss: 1099896346.3014\n",
      "Epoch 4291/5000\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 1080129.0660 - val_loss: 1106162375.8904\n",
      "Epoch 4292/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 816740.3682 - val_loss: 1105555430.5753\n",
      "Epoch 4293/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 751206.7014 - val_loss: 1106615205.6986\n",
      "Epoch 4294/5000\n",
      "1167/1167 [==============================] - 0s 269us/step - loss: 794019.5494 - val_loss: 1100011646.2466\n",
      "Epoch 4295/5000\n",
      "1167/1167 [==============================] - 0s 265us/step - loss: 891248.3871 - val_loss: 1107790766.4658\n",
      "Epoch 4296/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1025555.6894 - val_loss: 1108124602.7397\n",
      "Epoch 4297/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 993259.2390 - val_loss: 1102887232.8767\n",
      "Epoch 4298/5000\n",
      "1167/1167 [==============================] - 0s 264us/step - loss: 888719.3564 - val_loss: 1100976206.9041\n",
      "Epoch 4299/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 2098786.1892 - val_loss: 1108252657.0959\n",
      "Epoch 4300/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2870331.2339 - val_loss: 1127162206.6849\n",
      "Epoch 4301/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4771866.7489 - val_loss: 1123059745.3151\n",
      "Epoch 4302/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4422708.9302 - val_loss: 1124011863.6712\n",
      "Epoch 4303/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3590597.8852 - val_loss: 1110712074.5205\n",
      "Epoch 4304/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4575483.5308 - val_loss: 1113088881.9726\n",
      "Epoch 4305/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8421556.9100 - val_loss: 1109283243.8356\n",
      "Epoch 4306/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 10462029.4822 - val_loss: 1127141540.8219\n",
      "Epoch 4307/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 12310963.2939 - val_loss: 1231739918.9041\n",
      "Epoch 4308/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 44698720.9323 - val_loss: 1115886179.9452\n",
      "Epoch 4309/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 117825459.9092 - val_loss: 1152758314.9589\n",
      "Epoch 4310/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 55438462.6084 - val_loss: 1219762872.9863\n",
      "Epoch 4311/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 51457360.0763 - val_loss: 1141551517.8082\n",
      "Epoch 4312/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 23192633.1105 - val_loss: 1175433650.8493\n",
      "Epoch 4313/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 17054596.2913 - val_loss: 1157304286.6849\n",
      "Epoch 4314/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 12782866.0801 - val_loss: 1107245967.7808\n",
      "Epoch 4315/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4338593.1557 - val_loss: 1134529137.0959\n",
      "Epoch 4316/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2413709.0032 - val_loss: 1108090265.4247\n",
      "Epoch 4317/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1272002.2371 - val_loss: 1113040427.8356\n",
      "Epoch 4318/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1081709.3121 - val_loss: 1120249178.3014\n",
      "Epoch 4319/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1273740.6772 - val_loss: 1122241148.4932\n",
      "Epoch 4320/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 974399.1596 - val_loss: 1121864870.5753\n",
      "Epoch 4321/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 799981.0431 - val_loss: 1128299669.9178\n",
      "Epoch 4322/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1305372.6545 - val_loss: 1119203550.6849\n",
      "Epoch 4323/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 953068.7448 - val_loss: 1112826056.7671\n",
      "Epoch 4324/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 805248.1142 - val_loss: 1118468267.8356\n",
      "Epoch 4325/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1022584.7783 - val_loss: 1113549244.4932\n",
      "Epoch 4326/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 816656.9757 - val_loss: 1116682439.0137\n",
      "Epoch 4327/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 728858.9778 - val_loss: 1109573749.4795\n",
      "Epoch 4328/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 640128.4147 - val_loss: 1113486480.6575\n",
      "Epoch 4329/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 638798.1774 - val_loss: 1111723807.5616\n",
      "Epoch 4330/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 504681.7180 - val_loss: 1116509441.7534\n",
      "Epoch 4331/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 560518.4603 - val_loss: 1109298257.5342\n",
      "Epoch 4332/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 481178.8052 - val_loss: 1114610505.6438\n",
      "Epoch 4333/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 824726.2789 - val_loss: 1116158080.0000\n",
      "Epoch 4334/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 820293.5518 - val_loss: 1112279166.2466\n",
      "Epoch 4335/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 916814.5854 - val_loss: 1117317153.3151\n",
      "Epoch 4336/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 649564.2966 - val_loss: 1118978176.0000\n",
      "Epoch 4337/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 502157.8585 - val_loss: 1111862109.8082\n",
      "Epoch 4338/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 502583.7038 - val_loss: 1107269657.4247\n",
      "Epoch 4339/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 501427.9820 - val_loss: 1110487758.0274\n",
      "Epoch 4340/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 881275.3165 - val_loss: 1113910513.0959\n",
      "Epoch 4341/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 700214.5906 - val_loss: 1109799827.2877\n",
      "Epoch 4342/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1286378.0926 - val_loss: 1115269550.4658\n",
      "Epoch 4343/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1335975.7976 - val_loss: 1106857194.9589\n",
      "Epoch 4344/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1142562.8730 - val_loss: 1115419303.4521\n",
      "Epoch 4345/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 235us/step - loss: 952495.9099 - val_loss: 1113600483.9452\n",
      "Epoch 4346/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1088408.4892 - val_loss: 1119037023.5616\n",
      "Epoch 4347/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1675656.4858 - val_loss: 1110511770.3014\n",
      "Epoch 4348/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3147497.6590 - val_loss: 1093534444.7123\n",
      "Epoch 4349/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2910500.4381 - val_loss: 1110750798.0274\n",
      "Epoch 4350/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3473646.5129 - val_loss: 1131275320.1096\n",
      "Epoch 4351/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2562991.5742 - val_loss: 1121802851.0685\n",
      "Epoch 4352/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 2784027.1912 - val_loss: 1096868562.4110\n",
      "Epoch 4353/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 3565033.6822 - val_loss: 1108073164.2740\n",
      "Epoch 4354/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3792041.7549 - val_loss: 1111081363.2877\n",
      "Epoch 4355/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4297027.7222 - val_loss: 1090577297.5342\n",
      "Epoch 4356/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 7728743.2909 - val_loss: 1099913055.5616\n",
      "Epoch 4357/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 9663052.3847 - val_loss: 1100203593.6438\n",
      "Epoch 4358/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 4718678.0840 - val_loss: 1100897602.6301\n",
      "Epoch 4359/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3407939.3522 - val_loss: 1114344800.4384\n",
      "Epoch 4360/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 9829563.5379 - val_loss: 1108950037.9178\n",
      "Epoch 4361/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5225113.4397 - val_loss: 1106408056.9863\n",
      "Epoch 4362/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5053227.6315 - val_loss: 1096636161.7534\n",
      "Epoch 4363/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8793691.2322 - val_loss: 1125045164.7123\n",
      "Epoch 4364/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 6716049.6784 - val_loss: 1129155932.9315\n",
      "Epoch 4365/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4836139.2922 - val_loss: 1092294531.5068\n",
      "Epoch 4366/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 5739854.0441 - val_loss: 1109614063.3425\n",
      "Epoch 4367/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4556895.4544 - val_loss: 1091843926.7945\n",
      "Epoch 4368/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2821846.6009 - val_loss: 1093470294.7945\n",
      "Epoch 4369/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2504652.7791 - val_loss: 1106510768.2192\n",
      "Epoch 4370/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3115373.1133 - val_loss: 1098970306.6301\n",
      "Epoch 4371/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3799283.8488 - val_loss: 1110370536.3288\n",
      "Epoch 4372/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 5967144.5296 - val_loss: 1117136058.7397\n",
      "Epoch 4373/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9495043.2817 - val_loss: 1122843439.3425\n",
      "Epoch 4374/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 6690341.0249 - val_loss: 1116772644.8219\n",
      "Epoch 4375/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 15096413.2014 - val_loss: 1108421703.8904\n",
      "Epoch 4376/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 14472602.8830 - val_loss: 1088378831.7808\n",
      "Epoch 4377/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 14432496.9670 - val_loss: 1098121368.5479\n",
      "Epoch 4378/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 10899053.0664 - val_loss: 1081545701.6986\n",
      "Epoch 4379/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6186941.0450 - val_loss: 1115734455.2329\n",
      "Epoch 4380/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3461673.4167 - val_loss: 1102778478.4658\n",
      "Epoch 4381/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3688885.1251 - val_loss: 1135187428.8219\n",
      "Epoch 4382/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 28016019.2425 - val_loss: 1210165438.2466\n",
      "Epoch 4383/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 45815630.1405 - val_loss: 1125699287.6712\n",
      "Epoch 4384/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 15006466.7078 - val_loss: 1148693738.0822\n",
      "Epoch 4385/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12913954.1243 - val_loss: 1103424515.5068\n",
      "Epoch 4386/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 6363863.0296 - val_loss: 1100041712.2192\n",
      "Epoch 4387/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4397712.5316 - val_loss: 1081726456.9863\n",
      "Epoch 4388/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4171077.9644 - val_loss: 1100270940.9315\n",
      "Epoch 4389/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3004008.2162 - val_loss: 1095180578.1918\n",
      "Epoch 4390/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2457740.1183 - val_loss: 1072960262.1370\n",
      "Epoch 4391/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2403963.6760 - val_loss: 1084045067.3973\n",
      "Epoch 4392/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2050557.0266 - val_loss: 1090970255.7808\n",
      "Epoch 4393/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2581839.3144 - val_loss: 1093940441.4247\n",
      "Epoch 4394/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2820722.7495 - val_loss: 1101643546.3014\n",
      "Epoch 4395/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2490497.5480 - val_loss: 1099359438.0274\n",
      "Epoch 4396/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2596390.7275 - val_loss: 1104950318.4658\n",
      "Epoch 4397/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2347861.9318 - val_loss: 1107696139.3973\n",
      "Epoch 4398/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3078645.4642 - val_loss: 1095139805.8082\n",
      "Epoch 4399/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3347510.4173 - val_loss: 1072389828.3836\n",
      "Epoch 4400/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 4146678.2269 - val_loss: 1098782418.4110\n",
      "Epoch 4401/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2915061.8862 - val_loss: 1092194684.4932\n",
      "Epoch 4402/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1837689.1962 - val_loss: 1088056661.0411\n",
      "Epoch 4403/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 1121045.3823 - val_loss: 1083624573.3699\n",
      "Epoch 4404/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 1316875.7844 - val_loss: 1096026702.0274\n",
      "Epoch 4405/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1466204.7929 - val_loss: 1087203897.8630\n",
      "Epoch 4406/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 1291367.8218 - val_loss: 1096711374.0274\n",
      "Epoch 4407/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1487586.5611 - val_loss: 1072960630.3562\n",
      "Epoch 4408/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3426399.0229 - val_loss: 1090042967.6712\n",
      "Epoch 4409/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 15731776.5724 - val_loss: 1097211164.0548\n",
      "Epoch 4410/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37989125.8063 - val_loss: 1163655182.9041\n",
      "Epoch 4411/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 248us/step - loss: 154053901.5356 - val_loss: 1207292440.5479\n",
      "Epoch 4412/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 77923647.6213 - val_loss: 1140665390.4658\n",
      "Epoch 4413/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 23360778.9237 - val_loss: 1103388836.8219\n",
      "Epoch 4414/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 11962855.2785 - val_loss: 1101357603.9452\n",
      "Epoch 4415/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4865790.4182 - val_loss: 1088970809.8630\n",
      "Epoch 4416/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2922745.4130 - val_loss: 1090906091.8356\n",
      "Epoch 4417/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2100249.5799 - val_loss: 1085843168.4384\n",
      "Epoch 4418/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1576717.4534 - val_loss: 1090247875.5068\n",
      "Epoch 4419/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1200508.1746 - val_loss: 1084511844.8219\n",
      "Epoch 4420/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 987692.7280 - val_loss: 1085578974.6849\n",
      "Epoch 4421/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 767972.4242 - val_loss: 1087451260.4932\n",
      "Epoch 4422/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 734772.0200 - val_loss: 1088834812.4932\n",
      "Epoch 4423/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 726586.0624 - val_loss: 1083523208.7671\n",
      "Epoch 4424/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 981083.0494 - val_loss: 1080795965.3699\n",
      "Epoch 4425/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 866171.9628 - val_loss: 1080141809.9726\n",
      "Epoch 4426/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 669729.7959 - val_loss: 1080163878.5753\n",
      "Epoch 4427/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 766803.5455 - val_loss: 1083493438.2466\n",
      "Epoch 4428/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 511576.6158 - val_loss: 1079059468.2740\n",
      "Epoch 4429/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 444637.5446 - val_loss: 1084235320.9863\n",
      "Epoch 4430/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 504261.9453 - val_loss: 1084223682.6301\n",
      "Epoch 4431/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 456758.9105 - val_loss: 1089910946.1918\n",
      "Epoch 4432/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 486546.3009 - val_loss: 1087158243.0685\n",
      "Epoch 4433/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 423824.9598 - val_loss: 1085214880.4384\n",
      "Epoch 4434/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 364705.3733 - val_loss: 1083386687.1233\n",
      "Epoch 4435/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 391421.8986 - val_loss: 1087468859.6164\n",
      "Epoch 4436/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 492324.7979 - val_loss: 1078475718.1370\n",
      "Epoch 4437/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 767291.1278 - val_loss: 1087074750.2466\n",
      "Epoch 4438/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 660471.4303 - val_loss: 1080038391.2329\n",
      "Epoch 4439/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 583459.4362 - val_loss: 1084001412.3836\n",
      "Epoch 4440/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 636216.8166 - val_loss: 1087996535.2329\n",
      "Epoch 4441/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 677123.3619 - val_loss: 1091016283.1781\n",
      "Epoch 4442/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 839664.5193 - val_loss: 1088522375.8904\n",
      "Epoch 4443/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 489385.6900 - val_loss: 1081885598.6849\n",
      "Epoch 4444/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 472165.7452 - val_loss: 1083832419.9452\n",
      "Epoch 4445/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 538922.1221 - val_loss: 1088750433.3151\n",
      "Epoch 4446/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 493807.6303 - val_loss: 1089065088.8767\n",
      "Epoch 4447/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 526460.2227 - val_loss: 1090093237.4795\n",
      "Epoch 4448/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 594914.9468 - val_loss: 1095807222.3562\n",
      "Epoch 4449/5000\n",
      "1167/1167 [==============================] - 0s 311us/step - loss: 1370999.8811 - val_loss: 1093618793.2055\n",
      "Epoch 4450/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3931686.0411 - val_loss: 1089190763.8356\n",
      "Epoch 4451/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5280468.9389 - val_loss: 1099694640.2192\n",
      "Epoch 4452/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10246292.1294 - val_loss: 1112590903.2329\n",
      "Epoch 4453/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 11659136.0094 - val_loss: 1151080917.0411\n",
      "Epoch 4454/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7005732.7121 - val_loss: 1109145441.3151\n",
      "Epoch 4455/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6827251.1204 - val_loss: 1087816448.0000\n",
      "Epoch 4456/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5917097.5270 - val_loss: 1084008223.1233\n",
      "Epoch 4457/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 8434365.3745 - val_loss: 1098107015.4521\n",
      "Epoch 4458/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 10754643.4053 - val_loss: 1101756049.5342\n",
      "Epoch 4459/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 12098889.4584 - val_loss: 1131961537.7534\n",
      "Epoch 4460/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7518250.2249 - val_loss: 1095379777.7534\n",
      "Epoch 4461/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6426033.2155 - val_loss: 1119976851.2877\n",
      "Epoch 4462/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 6423608.1099 - val_loss: 1088908328.3288\n",
      "Epoch 4463/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 7928274.5735 - val_loss: 1091857847.2329\n",
      "Epoch 4464/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3703738.1722 - val_loss: 1089922899.2877\n",
      "Epoch 4465/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 2238887.1537 - val_loss: 1086347384.1096\n",
      "Epoch 4466/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3291661.6392 - val_loss: 1084714301.3699\n",
      "Epoch 4467/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3030987.6187 - val_loss: 1101177978.7397\n",
      "Epoch 4468/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 3079668.8621 - val_loss: 1097144100.8219\n",
      "Epoch 4469/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2577564.8006 - val_loss: 1099439905.3151\n",
      "Epoch 4470/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2304252.1512 - val_loss: 1093569295.7808\n",
      "Epoch 4471/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2164400.5938 - val_loss: 1090447496.7671\n",
      "Epoch 4472/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2785082.0329 - val_loss: 1090075563.8356\n",
      "Epoch 4473/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2526023.6836 - val_loss: 1092774484.1644\n",
      "Epoch 4474/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2211433.2107 - val_loss: 1099043647.1233\n",
      "Epoch 4475/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 1652570.3744 - val_loss: 1100168535.6712\n",
      "Epoch 4476/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4128747.4711 - val_loss: 1081948337.9726\n",
      "Epoch 4477/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4511455.7909 - val_loss: 1092564077.5890\n",
      "Epoch 4478/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3617862.6281 - val_loss: 1099623886.9041\n",
      "Epoch 4479/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 11447825.8115 - val_loss: 1122213020.0548\n",
      "Epoch 4480/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 46684447.3762 - val_loss: 1279523325.3699\n",
      "Epoch 4481/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 114581215.1397 - val_loss: 1234774787.7260\n",
      "Epoch 4482/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 82821793.9657 - val_loss: 1143771342.0274\n",
      "Epoch 4483/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 20947127.5904 - val_loss: 1162911998.6849\n",
      "Epoch 4484/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 14254925.7759 - val_loss: 1108864925.8082\n",
      "Epoch 4485/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6427436.2138 - val_loss: 1112573825.7534\n",
      "Epoch 4486/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3074297.0729 - val_loss: 1109635689.2055\n",
      "Epoch 4487/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2238978.0490 - val_loss: 1115429226.9589\n",
      "Epoch 4488/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1816226.7577 - val_loss: 1111607217.9726\n",
      "Epoch 4489/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1619346.5900 - val_loss: 1110659019.3973\n",
      "Epoch 4490/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1412486.7065 - val_loss: 1109492522.0822\n",
      "Epoch 4491/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1021445.8379 - val_loss: 1108100605.3699\n",
      "Epoch 4492/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1018000.5500 - val_loss: 1106120696.1096\n",
      "Epoch 4493/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 871599.3769 - val_loss: 1108482454.7945\n",
      "Epoch 4494/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 871152.3737 - val_loss: 1112929353.6438\n",
      "Epoch 4495/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 788002.3866 - val_loss: 1114141465.4247\n",
      "Epoch 4496/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1011499.1191 - val_loss: 1113699162.3014\n",
      "Epoch 4497/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 941636.7637 - val_loss: 1115237407.5616\n",
      "Epoch 4498/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 691386.9606 - val_loss: 1113837817.8630\n",
      "Epoch 4499/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 644264.8679 - val_loss: 1110996367.7808\n",
      "Epoch 4500/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 590609.1361 - val_loss: 1107182811.1781\n",
      "Epoch 4501/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 649025.8503 - val_loss: 1111183742.2466\n",
      "Epoch 4502/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 605903.0001 - val_loss: 1110148724.6027\n",
      "Epoch 4503/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 507625.3852 - val_loss: 1108280982.7945\n",
      "Epoch 4504/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 520008.3887 - val_loss: 1112166820.8219\n",
      "Epoch 4505/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 536592.4247 - val_loss: 1109044316.0548\n",
      "Epoch 4506/5000\n",
      "1167/1167 [==============================] - 0s 234us/step - loss: 788612.6443 - val_loss: 1106623213.5890\n",
      "Epoch 4507/5000\n",
      "1167/1167 [==============================] - 0s 268us/step - loss: 736811.6117 - val_loss: 1115605130.5205\n",
      "Epoch 4508/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 1065276.3026 - val_loss: 1109330586.3014\n",
      "Epoch 4509/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2285762.5360 - val_loss: 1111608757.4795\n",
      "Epoch 4510/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3714514.8436 - val_loss: 1110909289.2055\n",
      "Epoch 4511/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2140210.5486 - val_loss: 1101467758.4658\n",
      "Epoch 4512/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2639051.3704 - val_loss: 1114039552.0000\n",
      "Epoch 4513/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2750453.8818 - val_loss: 1126379855.7808\n",
      "Epoch 4514/5000\n",
      "1167/1167 [==============================] - 0s 271us/step - loss: 4237260.5596 - val_loss: 1106076718.4658\n",
      "Epoch 4515/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4753090.1268 - val_loss: 1106105584.2192\n",
      "Epoch 4516/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 8021133.9019 - val_loss: 1129700204.7123\n",
      "Epoch 4517/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 4298559.0585 - val_loss: 1124964895.5616\n",
      "Epoch 4518/5000\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 3465444.4379 - val_loss: 1126973533.8082\n",
      "Epoch 4519/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4255458.9368 - val_loss: 1111811464.7671\n",
      "Epoch 4520/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2561690.6958 - val_loss: 1115370010.3014\n",
      "Epoch 4521/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4489274.5210 - val_loss: 1119270221.1507\n",
      "Epoch 4522/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 10103730.0368 - val_loss: 1139159921.0959\n",
      "Epoch 4523/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 17019457.1277 - val_loss: 1139219627.8356\n",
      "Epoch 4524/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 12680588.0668 - val_loss: 1144977053.8082\n",
      "Epoch 4525/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 6828511.4653 - val_loss: 1131199515.1781\n",
      "Epoch 4526/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3610234.2429 - val_loss: 1106793730.6301\n",
      "Epoch 4527/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3779725.5596 - val_loss: 1123745609.6438\n",
      "Epoch 4528/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 2815014.0867 - val_loss: 1131036070.5753\n",
      "Epoch 4529/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4098502.8128 - val_loss: 1110562865.0959\n",
      "Epoch 4530/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2605386.4143 - val_loss: 1100738396.9315\n",
      "Epoch 4531/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1399345.0547 - val_loss: 1102033894.5753\n",
      "Epoch 4532/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1401850.9024 - val_loss: 1113489358.9041\n",
      "Epoch 4533/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1066456.8209 - val_loss: 1107829666.1918\n",
      "Epoch 4534/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1384597.4088 - val_loss: 1122916730.7397\n",
      "Epoch 4535/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1050453.9861 - val_loss: 1111692941.1507\n",
      "Epoch 4536/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1552742.9432 - val_loss: 1106215307.3973\n",
      "Epoch 4537/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 1522112.3505 - val_loss: 1123853455.7808\n",
      "Epoch 4538/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2041285.3021 - val_loss: 1127580549.2603\n",
      "Epoch 4539/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1784884.7385 - val_loss: 1123056946.8493\n",
      "Epoch 4540/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3623943.2734 - val_loss: 1125961339.6164\n",
      "Epoch 4541/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 6110989.0017 - val_loss: 1139540497.5342\n",
      "Epoch 4542/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 14099858.6512 - val_loss: 1152727516.0548\n",
      "Epoch 4543/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 248us/step - loss: 10235038.5253 - val_loss: 1141735137.3151\n",
      "Epoch 4544/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8413049.8672 - val_loss: 1116673512.3288\n",
      "Epoch 4545/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 11225043.6701 - val_loss: 1166916780.7123\n",
      "Epoch 4546/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 19987798.3967 - val_loss: 1204433513.2055\n",
      "Epoch 4547/5000\n",
      "1167/1167 [==============================] - 0s 273us/step - loss: 15729441.8982 - val_loss: 1143715362.1918\n",
      "Epoch 4548/5000\n",
      "1167/1167 [==============================] - 0s 284us/step - loss: 7375451.6587 - val_loss: 1112142998.7945\n",
      "Epoch 4549/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 3617926.1692 - val_loss: 1137002914.1918\n",
      "Epoch 4550/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2385383.7722 - val_loss: 1127593614.9041\n",
      "Epoch 4551/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2247627.4110 - val_loss: 1136654617.4247\n",
      "Epoch 4552/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1433699.9620 - val_loss: 1120855523.0685\n",
      "Epoch 4553/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1925788.2687 - val_loss: 1123781681.0959\n",
      "Epoch 4554/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 2841834.0888 - val_loss: 1120912360.3288\n",
      "Epoch 4555/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3101981.1319 - val_loss: 1116221936.2192\n",
      "Epoch 4556/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 7936676.7871 - val_loss: 1109794345.2055\n",
      "Epoch 4557/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3769831.2332 - val_loss: 1123237749.4795\n",
      "Epoch 4558/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 4726859.2264 - val_loss: 1099865854.2466\n",
      "Epoch 4559/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3631245.4186 - val_loss: 1155281771.8356\n",
      "Epoch 4560/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 4076670.0278 - val_loss: 1136143875.5068\n",
      "Epoch 4561/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3880395.8415 - val_loss: 1141637484.7123\n",
      "Epoch 4562/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 3481316.0061 - val_loss: 1142755072.8767\n",
      "Epoch 4563/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3156570.4708 - val_loss: 1117806809.4247\n",
      "Epoch 4564/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2122030.3387 - val_loss: 1105918411.3973\n",
      "Epoch 4565/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1844701.4566 - val_loss: 1117361207.2329\n",
      "Epoch 4566/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 1361303.8854 - val_loss: 1133811426.1918\n",
      "Epoch 4567/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1400529.4282 - val_loss: 1107594219.8356\n",
      "Epoch 4568/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 5863373.5154 - val_loss: 1134418289.0959\n",
      "Epoch 4569/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 8753453.2170 - val_loss: 1119311523.0685\n",
      "Epoch 4570/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6259041.4987 - val_loss: 1135959340.7123\n",
      "Epoch 4571/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 13035902.2476 - val_loss: 1111948840.3288\n",
      "Epoch 4572/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 26074987.0506 - val_loss: 1188409623.6712\n",
      "Epoch 4573/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 30868794.7575 - val_loss: 1210970030.4658\n",
      "Epoch 4574/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 17614882.6324 - val_loss: 1094544256.8767\n",
      "Epoch 4575/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 9325375.0548 - val_loss: 1099324862.2466\n",
      "Epoch 4576/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 7570494.8920 - val_loss: 1116854807.6712\n",
      "Epoch 4577/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4751403.2112 - val_loss: 1116158211.5068\n",
      "Epoch 4578/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1934625.3844 - val_loss: 1120215719.4521\n",
      "Epoch 4579/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1192421.3704 - val_loss: 1112235483.1781\n",
      "Epoch 4580/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1149079.1040 - val_loss: 1120468371.2877\n",
      "Epoch 4581/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1794084.3526 - val_loss: 1115017965.5890\n",
      "Epoch 4582/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1124038.0755 - val_loss: 1099268166.1370\n",
      "Epoch 4583/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 992620.9589 - val_loss: 1113569817.4247\n",
      "Epoch 4584/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 692347.2134 - val_loss: 1109236245.0411\n",
      "Epoch 4585/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 636365.5613 - val_loss: 1111246284.2740\n",
      "Epoch 4586/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 489372.9855 - val_loss: 1108574638.4658\n",
      "Epoch 4587/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1275018.6067 - val_loss: 1101521159.0137\n",
      "Epoch 4588/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 1853960.1390 - val_loss: 1106063106.6301\n",
      "Epoch 4589/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1219423.9417 - val_loss: 1112598365.8082\n",
      "Epoch 4590/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1004014.5259 - val_loss: 1119903845.6986\n",
      "Epoch 4591/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1121806.7926 - val_loss: 1117875109.6986\n",
      "Epoch 4592/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2980946.3140 - val_loss: 1107828165.2603\n",
      "Epoch 4593/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2652987.8484 - val_loss: 1092861816.1096\n",
      "Epoch 4594/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2246446.9311 - val_loss: 1109465864.7671\n",
      "Epoch 4595/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2705927.5844 - val_loss: 1136106215.4521\n",
      "Epoch 4596/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3098594.9282 - val_loss: 1121957900.2740\n",
      "Epoch 4597/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1921740.7751 - val_loss: 1132255115.3973\n",
      "Epoch 4598/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3225754.5943 - val_loss: 1126413635.5068\n",
      "Epoch 4599/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4904584.7952 - val_loss: 1132158655.1233\n",
      "Epoch 4600/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 6607392.3111 - val_loss: 1120481225.6438\n",
      "Epoch 4601/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 16615426.4550 - val_loss: 1164548379.1781\n",
      "Epoch 4602/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 16697768.5488 - val_loss: 1158107492.8219\n",
      "Epoch 4603/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 19428403.0377 - val_loss: 1178238215.8904\n",
      "Epoch 4604/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 15126251.2811 - val_loss: 1097339311.3425\n",
      "Epoch 4605/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 8793123.2301 - val_loss: 1121457941.0411\n",
      "Epoch 4606/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 10205516.6350 - val_loss: 1111277522.4110\n",
      "Epoch 4607/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7234052.9597 - val_loss: 1126547158.7945\n",
      "Epoch 4608/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4421634.4512 - val_loss: 1126393506.1918\n",
      "Epoch 4609/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 249us/step - loss: 3234872.3059 - val_loss: 1104525118.2466\n",
      "Epoch 4610/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3566616.6502 - val_loss: 1126340351.1233\n",
      "Epoch 4611/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2337599.3040 - val_loss: 1126595842.6301\n",
      "Epoch 4612/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3748652.5461 - val_loss: 1136461528.5479\n",
      "Epoch 4613/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2851194.4709 - val_loss: 1122782022.1370\n",
      "Epoch 4614/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1812723.4716 - val_loss: 1117859503.3425\n",
      "Epoch 4615/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1136572.0933 - val_loss: 1118156686.0274\n",
      "Epoch 4616/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 771091.8640 - val_loss: 1117549512.7671\n",
      "Epoch 4617/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2221532.1967 - val_loss: 1113993229.1507\n",
      "Epoch 4618/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2908496.0749 - val_loss: 1141646656.0000\n",
      "Epoch 4619/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2843193.6220 - val_loss: 1103046422.7945\n",
      "Epoch 4620/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4707138.7082 - val_loss: 1106338140.0548\n",
      "Epoch 4621/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 9690272.8183 - val_loss: 1154988228.3836\n",
      "Epoch 4622/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 12841194.1611 - val_loss: 1158230782.2466\n",
      "Epoch 4623/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 31850591.0754 - val_loss: 1108707189.4795\n",
      "Epoch 4624/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 13094045.0985 - val_loss: 1135479474.8493\n",
      "Epoch 4625/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 20355640.9100 - val_loss: 1143721687.6712\n",
      "Epoch 4626/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 51894226.1285 - val_loss: 1246853820.0548\n",
      "Epoch 4627/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 32979330.2382 - val_loss: 1139283347.2877\n",
      "Epoch 4628/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 21627843.2356 - val_loss: 1118931626.0822\n",
      "Epoch 4629/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 14155208.9769 - val_loss: 1104174250.0822\n",
      "Epoch 4630/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 12444022.7112 - val_loss: 1085588570.3014\n",
      "Epoch 4631/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4037103.8462 - val_loss: 1111152249.8630\n",
      "Epoch 4632/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1872380.5296 - val_loss: 1113843177.2055\n",
      "Epoch 4633/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1345826.4404 - val_loss: 1115268452.8219\n",
      "Epoch 4634/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 2073755.1868 - val_loss: 1116029660.9315\n",
      "Epoch 4635/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1521564.7789 - val_loss: 1115766586.7397\n",
      "Epoch 4636/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 949010.1233 - val_loss: 1117992605.8082\n",
      "Epoch 4637/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 716491.9356 - val_loss: 1106653316.3836\n",
      "Epoch 4638/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 885386.1296 - val_loss: 1115302223.7808\n",
      "Epoch 4639/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1005999.6028 - val_loss: 1107970064.6575\n",
      "Epoch 4640/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 605719.3111 - val_loss: 1120666653.8082\n",
      "Epoch 4641/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 458789.6856 - val_loss: 1115234872.9863\n",
      "Epoch 4642/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 496472.7010 - val_loss: 1111539296.4384\n",
      "Epoch 4643/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 563184.4578 - val_loss: 1115016021.0411\n",
      "Epoch 4644/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 528111.9749 - val_loss: 1115293279.5616\n",
      "Epoch 4645/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 499652.8791 - val_loss: 1115307491.9452\n",
      "Epoch 4646/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 399673.4742 - val_loss: 1113194178.6301\n",
      "Epoch 4647/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 556137.1885 - val_loss: 1117947994.3014\n",
      "Epoch 4648/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 599446.0992 - val_loss: 1109272113.0959\n",
      "Epoch 4649/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 544249.7391 - val_loss: 1112633649.0959\n",
      "Epoch 4650/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 611197.5535 - val_loss: 1111035967.1233\n",
      "Epoch 4651/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 700569.5078 - val_loss: 1115740927.1233\n",
      "Epoch 4652/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 733646.2520 - val_loss: 1108615358.2466\n",
      "Epoch 4653/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 706183.8778 - val_loss: 1107427471.7808\n",
      "Epoch 4654/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1789130.9930 - val_loss: 1111551005.8082\n",
      "Epoch 4655/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1271861.9158 - val_loss: 1108951203.9452\n",
      "Epoch 4656/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1926927.6579 - val_loss: 1108614565.6986\n",
      "Epoch 4657/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2044372.4883 - val_loss: 1098551404.7123\n",
      "Epoch 4658/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 3493909.0917 - val_loss: 1125044743.8904\n",
      "Epoch 4659/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4159323.9559 - val_loss: 1118856419.9452\n",
      "Epoch 4660/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 4896507.1101 - val_loss: 1122736146.4110\n",
      "Epoch 4661/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 6694981.7363 - val_loss: 1127463498.5205\n",
      "Epoch 4662/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4992888.4353 - val_loss: 1111845369.8630\n",
      "Epoch 4663/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 7377169.4207 - val_loss: 1164402007.6712\n",
      "Epoch 4664/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 8415968.2836 - val_loss: 1117285755.6164\n",
      "Epoch 4665/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 11314600.1757 - val_loss: 1157061832.3288\n",
      "Epoch 4666/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 13725728.5561 - val_loss: 1138471476.6027\n",
      "Epoch 4667/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 9455612.1864 - val_loss: 1123769542.1370\n",
      "Epoch 4668/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 7191823.9580 - val_loss: 1117811273.6438\n",
      "Epoch 4669/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 10900924.9006 - val_loss: 1147246592.8767\n",
      "Epoch 4670/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 6586380.8914 - val_loss: 1132457585.9726\n",
      "Epoch 4671/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 4153556.2926 - val_loss: 1142316110.0274\n",
      "Epoch 4672/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3991374.1156 - val_loss: 1132427704.1096\n",
      "Epoch 4673/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 2443970.3832 - val_loss: 1126254016.8767\n",
      "Epoch 4674/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1660342.6824 - val_loss: 1135178626.6301\n",
      "Epoch 4675/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 958650.2855 - val_loss: 1125015656.3288\n",
      "Epoch 4676/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 908832.9789 - val_loss: 1129794493.3699\n",
      "Epoch 4677/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2246875.3593 - val_loss: 1129870214.1370\n",
      "Epoch 4678/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 3457132.5775 - val_loss: 1136596124.9315\n",
      "Epoch 4679/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 5548369.6055 - val_loss: 1138729006.4658\n",
      "Epoch 4680/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4186856.3428 - val_loss: 1120130969.4247\n",
      "Epoch 4681/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4301566.6320 - val_loss: 1133435504.2192\n",
      "Epoch 4682/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2452591.4979 - val_loss: 1101035439.3425\n",
      "Epoch 4683/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2014886.4287 - val_loss: 1118545619.2877\n",
      "Epoch 4684/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2131428.2463 - val_loss: 1135118735.7808\n",
      "Epoch 4685/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4344619.3153 - val_loss: 1147852659.7260\n",
      "Epoch 4686/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 5898821.6650 - val_loss: 1145466170.7397\n",
      "Epoch 4687/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 5443147.7318 - val_loss: 1136107498.9589\n",
      "Epoch 4688/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6250695.1851 - val_loss: 1137036044.2740\n",
      "Epoch 4689/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8736744.3505 - val_loss: 1133101383.0137\n",
      "Epoch 4690/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6040685.4438 - val_loss: 1107053871.3425\n",
      "Epoch 4691/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4737321.7027 - val_loss: 1104921782.3562\n",
      "Epoch 4692/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 9585095.8987 - val_loss: 1134012846.4658\n",
      "Epoch 4693/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 14079899.2198 - val_loss: 1102972322.1918\n",
      "Epoch 4694/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 17165729.4987 - val_loss: 1181343177.6438\n",
      "Epoch 4695/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 13807325.4113 - val_loss: 1110357991.4521\n",
      "Epoch 4696/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 10716533.1337 - val_loss: 1130346667.3973\n",
      "Epoch 4697/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 8757882.8175 - val_loss: 1132212829.8082\n",
      "Epoch 4698/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 8107234.1949 - val_loss: 1106595997.8082\n",
      "Epoch 4699/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5471499.6315 - val_loss: 1111173458.4110\n",
      "Epoch 4700/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3082526.7926 - val_loss: 1116222470.1370\n",
      "Epoch 4701/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 4500917.4640 - val_loss: 1092869249.7534\n",
      "Epoch 4702/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5539697.8869 - val_loss: 1117120232.3288\n",
      "Epoch 4703/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 3831181.3830 - val_loss: 1124298722.1918\n",
      "Epoch 4704/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2670906.8386 - val_loss: 1128502053.6986\n",
      "Epoch 4705/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1804086.3016 - val_loss: 1125961604.3836\n",
      "Epoch 4706/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1433292.8193 - val_loss: 1114292807.0137\n",
      "Epoch 4707/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2144075.3655 - val_loss: 1118745834.9589\n",
      "Epoch 4708/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1595548.9144 - val_loss: 1128194095.3425\n",
      "Epoch 4709/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 1397944.1561 - val_loss: 1126143554.6301\n",
      "Epoch 4710/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1440229.9908 - val_loss: 1136826868.6027\n",
      "Epoch 4711/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1363184.4175 - val_loss: 1126751687.0137\n",
      "Epoch 4712/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 1160732.2003 - val_loss: 1134896890.7397\n",
      "Epoch 4713/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1421935.9581 - val_loss: 1137347033.4247\n",
      "Epoch 4714/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1614920.3021 - val_loss: 1132164507.1781\n",
      "Epoch 4715/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2141165.2318 - val_loss: 1113836134.5753\n",
      "Epoch 4716/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2431549.2904 - val_loss: 1129827659.3973\n",
      "Epoch 4717/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1223455.4403 - val_loss: 1120558957.5890\n",
      "Epoch 4718/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 3051345.9758 - val_loss: 1112806871.6712\n",
      "Epoch 4719/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 6075821.7087 - val_loss: 1176890096.2192\n",
      "Epoch 4720/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 19336029.1748 - val_loss: 1114926497.3151\n",
      "Epoch 4721/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 26607846.6650 - val_loss: 1135835375.3425\n",
      "Epoch 4722/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 27659519.0900 - val_loss: 1136586069.9178\n",
      "Epoch 4723/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 13715951.8578 - val_loss: 1087557712.6575\n",
      "Epoch 4724/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 16430504.2926 - val_loss: 1137239381.0411\n",
      "Epoch 4725/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 11582785.6234 - val_loss: 1120588586.9589\n",
      "Epoch 4726/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8219635.6294 - val_loss: 1143136254.2466\n",
      "Epoch 4727/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 7763228.0741 - val_loss: 1129009028.3836\n",
      "Epoch 4728/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 4667514.3916 - val_loss: 1149857148.4932\n",
      "Epoch 4729/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3659575.1504 - val_loss: 1123548733.3699\n",
      "Epoch 4730/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 3177705.3301 - val_loss: 1134163689.2055\n",
      "Epoch 4731/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2099066.7999 - val_loss: 1114897785.8630\n",
      "Epoch 4732/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1900720.2594 - val_loss: 1120113571.0685\n",
      "Epoch 4733/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2815040.8489 - val_loss: 1112978578.4110\n",
      "Epoch 4734/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5227075.3869 - val_loss: 1115575454.6849\n",
      "Epoch 4735/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 7812608.4524 - val_loss: 1096409253.6986\n",
      "Epoch 4736/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3680907.8661 - val_loss: 1097547659.3973\n",
      "Epoch 4737/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1793604.2181 - val_loss: 1114311119.7808\n",
      "Epoch 4738/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 2284746.1271 - val_loss: 1121550306.1918\n",
      "Epoch 4739/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1862448.0910 - val_loss: 1116301381.2603\n",
      "Epoch 4740/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1541591.4517 - val_loss: 1111270973.3699\n",
      "Epoch 4741/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 249us/step - loss: 2220976.2263 - val_loss: 1142121877.0411\n",
      "Epoch 4742/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2361735.2273 - val_loss: 1120076076.7123\n",
      "Epoch 4743/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2353092.7424 - val_loss: 1128427365.6986\n",
      "Epoch 4744/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 1940394.7631 - val_loss: 1117155874.1918\n",
      "Epoch 4745/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1296805.5357 - val_loss: 1115147161.4247\n",
      "Epoch 4746/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 1262976.8505 - val_loss: 1129134574.4658\n",
      "Epoch 4747/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1381072.1699 - val_loss: 1118939348.1644\n",
      "Epoch 4748/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 944981.5877 - val_loss: 1114920138.5205\n",
      "Epoch 4749/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1005224.3991 - val_loss: 1108764273.0959\n",
      "Epoch 4750/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 1126202.3224 - val_loss: 1121425841.0959\n",
      "Epoch 4751/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 967328.7615 - val_loss: 1117337605.2603\n",
      "Epoch 4752/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 1200713.0040 - val_loss: 1121359702.7945\n",
      "Epoch 4753/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1602427.4636 - val_loss: 1112809703.4521\n",
      "Epoch 4754/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3810733.8312 - val_loss: 1107377093.2603\n",
      "Epoch 4755/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2203142.1552 - val_loss: 1129243423.5616\n",
      "Epoch 4756/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2508231.4987 - val_loss: 1142334694.5753\n",
      "Epoch 4757/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 10142210.5630 - val_loss: 1125232960.0000\n",
      "Epoch 4758/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 15547793.2185 - val_loss: 1084704810.0822\n",
      "Epoch 4759/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 17515488.5021 - val_loss: 1116110893.5890\n",
      "Epoch 4760/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 20261619.3273 - val_loss: 1218253859.0685\n",
      "Epoch 4761/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 21534222.8535 - val_loss: 1103172393.2055\n",
      "Epoch 4762/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 8286951.2057 - val_loss: 1109785942.7945\n",
      "Epoch 4763/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 10238890.4559 - val_loss: 1169935722.0822\n",
      "Epoch 4764/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 8950844.1662 - val_loss: 1159707087.7808\n",
      "Epoch 4765/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 14860338.3847 - val_loss: 1084892868.3836\n",
      "Epoch 4766/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 8533060.7997 - val_loss: 1117919068.9315\n",
      "Epoch 4767/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5110818.9085 - val_loss: 1119559619.5068\n",
      "Epoch 4768/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2374130.8994 - val_loss: 1104429076.1644\n",
      "Epoch 4769/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1839656.8817 - val_loss: 1116736928.4384\n",
      "Epoch 4770/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 3319225.2275 - val_loss: 1119032960.0000\n",
      "Epoch 4771/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3497973.2549 - val_loss: 1137408308.6027\n",
      "Epoch 4772/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 2788181.9563 - val_loss: 1125037160.3288\n",
      "Epoch 4773/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 9634300.1609 - val_loss: 1143192711.0137\n",
      "Epoch 4774/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5298789.2811 - val_loss: 1156051704.1096\n",
      "Epoch 4775/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 6016389.0086 - val_loss: 1152586453.9178\n",
      "Epoch 4776/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2612365.1243 - val_loss: 1121429155.0685\n",
      "Epoch 4777/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2201553.1849 - val_loss: 1119566435.9452\n",
      "Epoch 4778/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2746447.8205 - val_loss: 1122007746.6301\n",
      "Epoch 4779/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2650788.3690 - val_loss: 1127924021.4795\n",
      "Epoch 4780/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1426761.0363 - val_loss: 1119953808.6575\n",
      "Epoch 4781/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1725246.8139 - val_loss: 1114175742.2466\n",
      "Epoch 4782/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2038236.3147 - val_loss: 1131477480.3288\n",
      "Epoch 4783/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4908396.7691 - val_loss: 1113565672.3288\n",
      "Epoch 4784/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 6868548.8036 - val_loss: 1161883895.2329\n",
      "Epoch 4785/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6573359.3205 - val_loss: 1147385240.5479\n",
      "Epoch 4786/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 4920635.9696 - val_loss: 1134688874.0822\n",
      "Epoch 4787/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2082382.5295 - val_loss: 1136800684.7123\n",
      "Epoch 4788/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1685229.7019 - val_loss: 1126326494.6849\n",
      "Epoch 4789/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1386756.2023 - val_loss: 1122847063.6712\n",
      "Epoch 4790/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1630343.9434 - val_loss: 1137259259.6164\n",
      "Epoch 4791/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2358619.3161 - val_loss: 1132974589.3699\n",
      "Epoch 4792/5000\n",
      "1167/1167 [==============================] - 0s 262us/step - loss: 1998488.1721 - val_loss: 1135099142.1370\n",
      "Epoch 4793/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2207026.4710 - val_loss: 1125403008.8767\n",
      "Epoch 4794/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1529027.9831 - val_loss: 1138445056.0000\n",
      "Epoch 4795/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2549435.3824 - val_loss: 1146168023.6712\n",
      "Epoch 4796/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3483734.4010 - val_loss: 1128170878.2466\n",
      "Epoch 4797/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3864644.6868 - val_loss: 1128864277.0411\n",
      "Epoch 4798/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 2973005.0441 - val_loss: 1120431251.2877\n",
      "Epoch 4799/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 7409902.4045 - val_loss: 1129172390.5753\n",
      "Epoch 4800/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 7765317.5017 - val_loss: 1110461795.0685\n",
      "Epoch 4801/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 15240038.5638 - val_loss: 1185270202.7397\n",
      "Epoch 4802/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 31081916.8912 - val_loss: 1122354201.4247\n",
      "Epoch 4803/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 11656778.2168 - val_loss: 1089910713.8630\n",
      "Epoch 4804/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 5207893.0690 - val_loss: 1109202560.8767\n",
      "Epoch 4805/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 3322214.8413 - val_loss: 1092314973.8082\n",
      "Epoch 4806/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4137151.8959 - val_loss: 1118415813.2603\n",
      "Epoch 4807/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 3411158.5465 - val_loss: 1119475585.7534\n",
      "Epoch 4808/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2149531.2397 - val_loss: 1095548220.4932\n",
      "Epoch 4809/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1678119.2486 - val_loss: 1111297178.3014\n",
      "Epoch 4810/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 1485956.4035 - val_loss: 1124380231.8904\n",
      "Epoch 4811/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1341929.0436 - val_loss: 1119176633.8630\n",
      "Epoch 4812/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1082499.5510 - val_loss: 1106989519.7808\n",
      "Epoch 4813/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1814534.8248 - val_loss: 1129429555.7260\n",
      "Epoch 4814/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1470615.3022 - val_loss: 1101749070.9041\n",
      "Epoch 4815/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 1263486.0777 - val_loss: 1118942413.1507\n",
      "Epoch 4816/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 796668.0746 - val_loss: 1106704987.1781\n",
      "Epoch 4817/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 748687.6957 - val_loss: 1117367019.8356\n",
      "Epoch 4818/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 890140.0548 - val_loss: 1123502656.8767\n",
      "Epoch 4819/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1465956.2181 - val_loss: 1109515703.2329\n",
      "Epoch 4820/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1875334.2803 - val_loss: 1120453995.8356\n",
      "Epoch 4821/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1249263.6296 - val_loss: 1129047975.4521\n",
      "Epoch 4822/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 1217695.3200 - val_loss: 1120153175.6712\n",
      "Epoch 4823/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2220687.3948 - val_loss: 1098803194.7397\n",
      "Epoch 4824/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2334379.0501 - val_loss: 1113359470.4658\n",
      "Epoch 4825/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 3320258.8303 - val_loss: 1103206699.8356\n",
      "Epoch 4826/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 12095662.9512 - val_loss: 1164315171.9452\n",
      "Epoch 4827/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 139850991.5750 - val_loss: 1430759045.2603\n",
      "Epoch 4828/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 59250919.9254 - val_loss: 1099399022.9041\n",
      "Epoch 4829/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13226340.9336 - val_loss: 1096398483.2877\n",
      "Epoch 4830/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 9806048.3434 - val_loss: 1081605712.6575\n",
      "Epoch 4831/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4465919.3770 - val_loss: 1088660697.4247\n",
      "Epoch 4832/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5006849.6195 - val_loss: 1087670610.4110\n",
      "Epoch 4833/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 3456512.2796 - val_loss: 1070129926.1370\n",
      "Epoch 4834/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1733397.3399 - val_loss: 1080900683.3973\n",
      "Epoch 4835/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1332544.7255 - val_loss: 1068262660.3836\n",
      "Epoch 4836/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 1570790.9269 - val_loss: 1081342549.9178\n",
      "Epoch 4837/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 811433.2209 - val_loss: 1071389538.1918\n",
      "Epoch 4838/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 690561.3983 - val_loss: 1072994313.6438\n",
      "Epoch 4839/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 549415.0958 - val_loss: 1072756721.0959\n",
      "Epoch 4840/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 567752.0311 - val_loss: 1072000604.0548\n",
      "Epoch 4841/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 444890.1151 - val_loss: 1070538516.1644\n",
      "Epoch 4842/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 634962.8461 - val_loss: 1072314270.6849\n",
      "Epoch 4843/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 800229.4431 - val_loss: 1073416111.3425\n",
      "Epoch 4844/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 683667.4792 - val_loss: 1070101093.6986\n",
      "Epoch 4845/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 585980.2286 - val_loss: 1070466097.9726\n",
      "Epoch 4846/5000\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 666771.5717 - val_loss: 1077712321.7534\n",
      "Epoch 4847/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 515169.3599 - val_loss: 1071334596.3836\n",
      "Epoch 4848/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 757041.5302 - val_loss: 1078649447.4521\n",
      "Epoch 4849/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 599092.1250 - val_loss: 1073847360.8767\n",
      "Epoch 4850/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 757547.9542 - val_loss: 1070098330.3014\n",
      "Epoch 4851/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 1152860.8949 - val_loss: 1085172756.1644\n",
      "Epoch 4852/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1615534.5758 - val_loss: 1071709237.4795\n",
      "Epoch 4853/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2171026.1444 - val_loss: 1077359434.5205\n",
      "Epoch 4854/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 1867532.4024 - val_loss: 1089077936.2192\n",
      "Epoch 4855/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1243910.2302 - val_loss: 1069841391.3425\n",
      "Epoch 4856/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1852585.4374 - val_loss: 1084768624.2192\n",
      "Epoch 4857/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 2184486.4543 - val_loss: 1065658651.1781\n",
      "Epoch 4858/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 1442243.1069 - val_loss: 1083489643.8356\n",
      "Epoch 4859/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1110027.0211 - val_loss: 1073150549.0411\n",
      "Epoch 4860/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1224503.1425 - val_loss: 1086792179.7260\n",
      "Epoch 4861/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1108883.3919 - val_loss: 1071436375.6712\n",
      "Epoch 4862/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1136946.0305 - val_loss: 1073258143.5616\n",
      "Epoch 4863/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 1246498.2570 - val_loss: 1072449347.5068\n",
      "Epoch 4864/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1820688.5960 - val_loss: 1092459157.9178\n",
      "Epoch 4865/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2768826.6028 - val_loss: 1081135502.0274\n",
      "Epoch 4866/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 2489593.8985 - val_loss: 1078996300.2740\n",
      "Epoch 4867/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4516044.2195 - val_loss: 1078949331.2877\n",
      "Epoch 4868/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 3530497.1508 - val_loss: 1073158365.8082\n",
      "Epoch 4869/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 3340370.0651 - val_loss: 1085051807.5616\n",
      "Epoch 4870/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 4936975.2009 - val_loss: 1072181191.8904\n",
      "Epoch 4871/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 5250056.4383 - val_loss: 1102070309.6986\n",
      "Epoch 4872/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 8232838.5099 - val_loss: 1096373582.0274\n",
      "Epoch 4873/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 250us/step - loss: 6768784.4776 - val_loss: 1090219695.3425\n",
      "Epoch 4874/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5329114.7350 - val_loss: 1110001780.6027\n",
      "Epoch 4875/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 6715573.0808 - val_loss: 1097775153.0959\n",
      "Epoch 4876/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 5207776.8273 - val_loss: 1079230606.9041\n",
      "Epoch 4877/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 4368360.5538 - val_loss: 1060463296.8767\n",
      "Epoch 4878/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4182094.5017 - val_loss: 1092931285.0411\n",
      "Epoch 4879/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 6961021.1264 - val_loss: 1111781015.6712\n",
      "Epoch 4880/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 11947498.0129 - val_loss: 1109649648.2192\n",
      "Epoch 4881/5000\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 9252774.1954 - val_loss: 1076265337.8630\n",
      "Epoch 4882/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 14566534.9387 - val_loss: 1095614733.1507\n",
      "Epoch 4883/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 29457352.2331 - val_loss: 1205044533.4795\n",
      "Epoch 4884/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 29173598.3565 - val_loss: 1096048254.6849\n",
      "Epoch 4885/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 16734960.3325 - val_loss: 1098078746.3014\n",
      "Epoch 4886/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 8799493.5596 - val_loss: 1100752775.0137\n",
      "Epoch 4887/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 6564981.5876 - val_loss: 1087960932.8219\n",
      "Epoch 4888/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 2189208.9561 - val_loss: 1096764956.9315\n",
      "Epoch 4889/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 1936685.9114 - val_loss: 1095311611.6164\n",
      "Epoch 4890/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 2074718.7972 - val_loss: 1091671019.8356\n",
      "Epoch 4891/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 2330445.3475 - val_loss: 1094341936.2192\n",
      "Epoch 4892/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1858375.2863 - val_loss: 1093985481.6438\n",
      "Epoch 4893/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1191395.6580 - val_loss: 1098724331.8356\n",
      "Epoch 4894/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 985489.2409 - val_loss: 1090756970.9589\n",
      "Epoch 4895/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 699315.6272 - val_loss: 1097431478.3562\n",
      "Epoch 4896/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 585774.5019 - val_loss: 1095235926.7945\n",
      "Epoch 4897/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 609981.2852 - val_loss: 1089428864.8767\n",
      "Epoch 4898/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 601410.1650 - val_loss: 1089418998.3562\n",
      "Epoch 4899/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 589491.9538 - val_loss: 1094503834.3014\n",
      "Epoch 4900/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 721788.2248 - val_loss: 1095924496.6575\n",
      "Epoch 4901/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 574064.0873 - val_loss: 1089012206.4658\n",
      "Epoch 4902/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 774321.7575 - val_loss: 1099539555.9452\n",
      "Epoch 4903/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4976836.6825 - val_loss: 1096992654.9041\n",
      "Epoch 4904/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 7425426.8318 - val_loss: 1128681725.3699\n",
      "Epoch 4905/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 22647061.4362 - val_loss: 1070778259.2877\n",
      "Epoch 4906/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 18107252.6690 - val_loss: 1147019048.3288\n",
      "Epoch 4907/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 9500060.4610 - val_loss: 1091895543.2329\n",
      "Epoch 4908/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 10596417.9700 - val_loss: 1094507558.5753\n",
      "Epoch 4909/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 5995396.9236 - val_loss: 1098541440.8767\n",
      "Epoch 4910/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 2989402.2198 - val_loss: 1084961047.6712\n",
      "Epoch 4911/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 4342591.2434 - val_loss: 1088842480.2192\n",
      "Epoch 4912/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 4977832.1710 - val_loss: 1084797621.4795\n",
      "Epoch 4913/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 4028828.3598 - val_loss: 1090104662.7945\n",
      "Epoch 4914/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 2685977.3253 - val_loss: 1091966278.1370\n",
      "Epoch 4915/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1899970.7262 - val_loss: 1084468739.5068\n",
      "Epoch 4916/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1861878.2440 - val_loss: 1081669560.1096\n",
      "Epoch 4917/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1397924.6947 - val_loss: 1081410204.0548\n",
      "Epoch 4918/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 1214234.5179 - val_loss: 1089206861.1507\n",
      "Epoch 4919/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 900688.7088 - val_loss: 1086989916.0548\n",
      "Epoch 4920/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 620789.4995 - val_loss: 1089848231.4521\n",
      "Epoch 4921/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 811477.7456 - val_loss: 1098708613.2603\n",
      "Epoch 4922/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 891261.7448 - val_loss: 1098858065.5342\n",
      "Epoch 4923/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1314938.6369 - val_loss: 1089837741.5890\n",
      "Epoch 4924/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 4509778.8327 - val_loss: 1120724758.7945\n",
      "Epoch 4925/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 11966686.6872 - val_loss: 1057731697.0959\n",
      "Epoch 4926/5000\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 13605779.8072 - val_loss: 1132112190.6849\n",
      "Epoch 4927/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 13684598.9040 - val_loss: 1085883712.8767\n",
      "Epoch 4928/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 8926334.6041 - val_loss: 1154376039.8904\n",
      "Epoch 4929/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 11995362.0797 - val_loss: 1107050259.2877\n",
      "Epoch 4930/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 11738911.3290 - val_loss: 1134334435.9452\n",
      "Epoch 4931/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 21601685.9542 - val_loss: 1129445100.7123\n",
      "Epoch 4932/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 25027542.8329 - val_loss: 1136712870.5753\n",
      "Epoch 4933/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 21220255.7395 - val_loss: 1148126424.5479\n",
      "Epoch 4934/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 16620093.6577 - val_loss: 1112795964.4932\n",
      "Epoch 4935/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 8831837.8432 - val_loss: 1138287276.7123\n",
      "Epoch 4936/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2914689.0870 - val_loss: 1111035911.8904\n",
      "Epoch 4937/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 2308654.0079 - val_loss: 1135261884.4932\n",
      "Epoch 4938/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 1536153.8319 - val_loss: 1114729339.6164\n",
      "Epoch 4939/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1133853.9922 - val_loss: 1103850348.7123\n",
      "Epoch 4940/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 1045046.5375 - val_loss: 1114478101.9178\n",
      "Epoch 4941/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1425708.7044 - val_loss: 1104342698.9589\n",
      "Epoch 4942/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 865876.0361 - val_loss: 1108983658.9589\n",
      "Epoch 4943/5000\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 845652.3105 - val_loss: 1113027929.4247\n",
      "Epoch 4944/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 699341.6388 - val_loss: 1108493312.0000\n",
      "Epoch 4945/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 580130.3309 - val_loss: 1110544487.4521\n",
      "Epoch 4946/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 436653.0466 - val_loss: 1104379541.9178\n",
      "Epoch 4947/5000\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 392100.6369 - val_loss: 1100741500.4932\n",
      "Epoch 4948/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 443564.2758 - val_loss: 1102515953.9726\n",
      "Epoch 4949/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 491621.6146 - val_loss: 1103309327.7808\n",
      "Epoch 4950/5000\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 366744.1302 - val_loss: 1099261950.2466\n",
      "Epoch 4951/5000\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 360611.3753 - val_loss: 1101564289.7534\n",
      "Epoch 4952/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 365521.1018 - val_loss: 1106235347.2877\n",
      "Epoch 4953/5000\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 805399.1413 - val_loss: 1102961701.6986\n",
      "Epoch 4954/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 737035.6779 - val_loss: 1103611048.3288\n",
      "Epoch 4955/5000\n",
      "1167/1167 [==============================] - 0s 272us/step - loss: 732817.2638 - val_loss: 1102580133.6986\n",
      "Epoch 4956/5000\n",
      "1167/1167 [==============================] - 0s 277us/step - loss: 1266430.0662 - val_loss: 1107498138.3014\n",
      "Epoch 4957/5000\n",
      "1167/1167 [==============================] - 0s 283us/step - loss: 1482017.5831 - val_loss: 1109707088.6575\n",
      "Epoch 4958/5000\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 5174114.4177 - val_loss: 1111480795.1781\n",
      "Epoch 4959/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4740308.3578 - val_loss: 1108797148.0548\n",
      "Epoch 4960/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3890437.4829 - val_loss: 1108965656.5479\n",
      "Epoch 4961/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 7998790.9203 - val_loss: 1132147594.5205\n",
      "Epoch 4962/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 12795395.0977 - val_loss: 1104368455.0137\n",
      "Epoch 4963/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 5546470.0660 - val_loss: 1111450228.6027\n",
      "Epoch 4964/5000\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 3799080.7654 - val_loss: 1092945691.1781\n",
      "Epoch 4965/5000\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 4453422.3970 - val_loss: 1117176549.6986\n",
      "Epoch 4966/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3390932.2020 - val_loss: 1106438674.4110\n",
      "Epoch 4967/5000\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 2036493.8716 - val_loss: 1117218580.1644\n",
      "Epoch 4968/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 1728121.7305 - val_loss: 1107259505.0959\n",
      "Epoch 4969/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 3150251.2353 - val_loss: 1101901112.1096\n",
      "Epoch 4970/5000\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 2021333.9702 - val_loss: 1106871700.1644\n",
      "Epoch 4971/5000\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 7416084.0206 - val_loss: 1099409634.1918\n",
      "Epoch 4972/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 11451738.3016 - val_loss: 1142799530.9589\n",
      "Epoch 4973/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 15084381.8963 - val_loss: 1149403882.0822\n",
      "Epoch 4974/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 30216369.2271 - val_loss: 1204248419.9452\n",
      "Epoch 4975/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 31615776.2451 - val_loss: 1156410297.8630\n",
      "Epoch 4976/5000\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 16398744.4152 - val_loss: 1108129677.1507\n",
      "Epoch 4977/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 7901321.9289 - val_loss: 1107876136.3288\n",
      "Epoch 4978/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 4710065.7536 - val_loss: 1121373042.8493\n",
      "Epoch 4979/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 3532080.1495 - val_loss: 1101406988.2740\n",
      "Epoch 4980/5000\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 3558137.1071 - val_loss: 1108309989.6986\n",
      "Epoch 4981/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 3551698.8766 - val_loss: 1110079146.0822\n",
      "Epoch 4982/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 1491748.3719 - val_loss: 1114764757.0411\n",
      "Epoch 4983/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 2629748.7939 - val_loss: 1109159601.0959\n",
      "Epoch 4984/5000\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 1689290.3688 - val_loss: 1107696912.6575\n",
      "Epoch 4985/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 966165.8494 - val_loss: 1100789771.3973\n",
      "Epoch 4986/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 769603.8372 - val_loss: 1104180575.5616\n",
      "Epoch 4987/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 482676.2027 - val_loss: 1108115035.1781\n",
      "Epoch 4988/5000\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 542552.7955 - val_loss: 1109975242.5205\n",
      "Epoch 4989/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 540687.5204 - val_loss: 1110884880.6575\n",
      "Epoch 4990/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 429600.5807 - val_loss: 1107655064.5479\n",
      "Epoch 4991/5000\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 401780.3517 - val_loss: 1106081684.1644\n",
      "Epoch 4992/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 514439.6128 - val_loss: 1106216035.0685\n",
      "Epoch 4993/5000\n",
      "1167/1167 [==============================] - 0s 260us/step - loss: 597894.8799 - val_loss: 1115783205.6986\n",
      "Epoch 4994/5000\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 584547.1569 - val_loss: 1117709661.8082\n",
      "Epoch 4995/5000\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 985201.3537 - val_loss: 1109089185.3151\n",
      "Epoch 4996/5000\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 1116517.1803 - val_loss: 1110742084.3836\n",
      "Epoch 4997/5000\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 2207488.5158 - val_loss: 1121242439.8904\n",
      "Epoch 4998/5000\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 1219980.5830 - val_loss: 1108659986.4110\n",
      "Epoch 4999/5000\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 1072078.5297 - val_loss: 1112712263.0137\n",
      "Epoch 5000/5000\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 897225.5599 - val_loss: 1110506239.1233\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "newAdam = Adam(learning_rate=0.0005)\n",
    "NN_5000E_SGD.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_SGD.fit(x=X,y=y,epochs=5000,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_5000E_SGD.save('NN_5000E_NewAdam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FHX6wPHPQwi9QwTpiBU75rD3Xk7PO2ynp2c5zit66p33s529n72dh4rtVKwoKoqAoCI19A6hBwIhCYSE9Ozz+2Nma3aTTbKbTbLP+/XKa6d8d+Y7m9155lvmO6KqGGOMMQCtEp0BY4wxTYcFBWOMMT4WFIwxxvhYUDDGGONjQcEYY4yPBQVjjDE+FhSMiYKIDBYRFZHWUaT9vYhMb+h2jEkECwqmxRGRDSJSLiK9QpYvcE/IgxOTM2OaPgsKpqVaD1zhnRGRQ4EOicuOMc2DBQXTUr0LXB0wfw3wTmACEekqIu+IyA4R2Sgi94hIK3ddiog8JSK5IrIOOD/Me98QkWwR2SIiD4tISl0zKSJ9RWS8iOSLSKaI/CFg3QgRyRCR3SKyXUSecZe3E5H/iUieiOwSkbki0ruu+zYmHAsKpqWaBXQRkYPck/XlwP9C0rwIdAX2AU7GCSLXuuv+AFwAHAmkAyND3vsWUAns66Y5C7ihHvkcC2QBfd19PCoip7nrngeeV9UuwFDgI3f5NW6+BwA9gRuBknrs25hqmmVQEJExIpIjIkujSDtIRKaIyGIRmSYi/Rsjj6ZJ8JYWzgRWAFu8KwICxZ2qWqiqG4Cngd+5SS4FnlPVzaqaDzwW8N7ewHnALaq6R1VzgGfd7UVNRAYAxwP/p6qlqroQeB1/CacC2FdEeqlqkarOCljeE9hXVatUdZ6q7q7Lvo2JpFkGBZyrtHOiTPsU8I6qHgY8SMCP27R47wK/BX5PSNUR0AtIBTYGLNsI9HOn+wKbQ9Z5DXLfm+1W3+wC/gvsVcf89QXyVbUwQh6uB/YHVrpVRBcEHNdEYKyIbBWRJ0UktY77NiasZhkUVPVHID9wmYgMFZFvRWSeiPwkIge6q4YB37vTU4GLGjGrJoFUdSNOg/N5wGchq3NxrrgHBSwbiL80kY1TPRO4zmszUAb0UtVu7l8XVT24jlncCvQQkc7h8qCqa1T1Cpxg8wTwiYh0VNUKVX1AVYcBx+FUc12NMTHQLINCBKOBm1T1KOAfwCvu8kXAr93pi4HOItIzAfkziXE9cJqq7glcqKpVOHX0j4hIZxEZBNyGv93hI+BmEekvIt2BOwLemw18BzwtIl1EpJV7UXJyXTKmqpuBGcBjbuPxYW5+/wcgIleJSJqqeoBd7ts8InKqiBzqVoHtxglunrrs25hIWkRQEJFOOFdMH4vIQpyi/N7u6n8AJ4vIApzGxC1AVUIyahqdqq5V1YwIq28C9gDrgOnA+8AYd91rOFU0i4D5VC9pXA20AZYDO4FP8H/n6uIKYDBOqWEccJ+qTnbXnQMsE5EinEbny1W1BOjj7m83TlvJDzhVSsY0mDTXh+y4NyB9paqHiEgXYJWq1vijdIPHSlW1xmZjjAmjRZQU3J4X60XkEgBxHO5O9/L2PQfuxH8laIwxJkSzDAoi8gEwEzhARLJE5HrgSuB6EVkELMPfoHwKsEpEVgO9gUcSkGVjjGkWmm31kTHGmNhrliUFY4wx8dHshu/t1auXDh48ONHZMMaYZmXevHm5qppWW7pmFxQGDx5MRkakHobGGGPCEZGNtaey6iNjjDEBLCgYY4zxsaBgjDHGp9m1KYRTUVFBVlYWpaWlic5Ko2nXrh39+/cnNdUGxzTGxE6LCApZWVl07tyZwYMHIyKJzk7cqSp5eXlkZWUxZMiQRGfHGNOCtIjqo9LSUnr27JkUAQFAROjZs2dSlYyMMY0jbkHBHQp4jogsEpFlIvJAmDRtReRD99m0s91B7uq7v4Zkt9lJtuM1xjSOeJYUynDGsT8cOAI4R0SOCUlzPbBTVffFeZzhE3HMTzD1QHEe2DAfxhjjE7egoI4idzbV/Qs9A18EvO1OfwKcLo11CVyYDbs2QWlBgzeVl5fHEUccwRFHHEGfPn3o16+fb768vDyqbVx77bWsWrWqwXkxxpiGiGtDs/tkqHnAvsDLqjo7JEk/3OfgqmqliBTgPJA8N2Q7o4BRAAMHDiQmqiqdV23483Z69uzJwoULAbj//vvp1KkT//jHP4LSqCqqSqtW4ePwm2++2eB8GGNMQ8W1oVlVq1T1CKA/MEJEDqnndkararqqpqel1Tp0R5ORmZnJsGHDuPLKKzn44IPJzs5m1KhRpKenc/DBB/Pggw/60p5wwgksXLiQyspKunXrxh133MHhhx/OscceS05OTgKPwhiTTBqlS6qq7hKRqTiPF1wasGoLzsPRs0SkNdAVyGvIvh74chnLt+6uPWFlKXgqoXUhtKq5r/+wvl2475d1fSa7Y+XKlbzzzjukp6cD8Pjjj9OjRw8qKys59dRTGTlyJMOGDQt6T0FBASeffDKPP/44t912G2PGjOGOO+4It3ljjImpePY+ShORbu50e+BMYGVIsvHANe70SOB7bWEPeBg6dKgvIAB88MEHDB8+nOHDh7NixQqWL19e7T3t27fn3HPPBeCoo45iw4YNjZVdY0ySi2dJYW/gbbddoRXwkap+JSIPAhmqOh54A3hXRDKBfODyhu406iv6nRuhJB+6DYQOPRu624g6duzom16zZg3PP/88c+bMoVu3blx11VVh7zVo06aNbzolJYXKysq45c8YYwLFLSio6mLgyDDL7w2YLgUuiVceatb4BZLdu3fTuXNnunTpQnZ2NhMnTuScc85p9HwYY0wkLWKYi4ZpvJvAhg8fzrBhwzjwwAMZNGgQxx9/fKPt2xhjotHsntGcnp6uoQ/ZWbFiBQcddFDdNrRzA5TshG6DoEOP2GWwEdXruI0xSUlE5qlqem3pWsTYR8YYY2LDgoIxxhgfCwrGGGN8LCgYY4zxSa6goGqjohpjTA2SKyjkLIdtixOdC2OMabKS6z6FqoBhrGNYYMjLy+P0008HYNu2baSkpOAduG/OnDlBdyjXZMyYMZx33nn06dMndpkzxpg6SK6g4OVp+HDZgaIZOjsaY8aMYfjw4RYUjDEJk5xBYecGkJRG2dXbb7/Nyy+/THl5OccddxwvvfQSHo+Ha6+9loULF6KqjBo1it69e7Nw4UIuu+wy2rdvX6cShjHGxErLCwrf3AHbloRfV17on26VCp4KaN2u1qGz6XMonPt4nbOydOlSxo0bx4wZM2jdujWjRo1i7NixDB06lNzcXJYscfK5a9cuunXrxosvvshLL73EEUccUed9GWNMLLS8oNCETJ48mblz5/qGzi4pKWHAgAGcffbZrFq1iptvvpnzzz+fs846K8E5NcYYR8sLCjVd0W9d4J9u1x1K4zv2kapy3XXX8dBDD1Vbt3jxYr755htefvllPv30U0aPHh2XPBhjTF0kV5fURnbGGWfw0UcfkZvrPHI6Ly+PTZs2sWPHDlSVSy65hAcffJD58+cD0LlzZwoLC2vapDHGxFXLKynU1a6NUFEMXfvHfNOHHnoo9913H2eccQYej4fU1FReffVVUlJSuP7661FVRIQnnngCgGuvvZYbbrjBGpqNMQmTXENnB1UfdYPSXf75vtWeB9Tk2dDZxpho2dDZxhhj6syCgjHGGJ8WExRqrQYrLWicjDSS5lbtZ4xpHlpEUGjXrh15eXk1nygryyOva2ZUlby8PNq1a5forBhjWpgW0fuof//+ZGVlsWPHjsiJygqdZzJ7pRY5vY68ClbEL4Nx0K5dO/r3j32PKWNMcmsRQSE1NZUhQ4bUnGj2aJh4u3/+4Ith2Tj//P0tq3rJGGPqo0VUHxljjImNuAUFERkgIlNFZLmILBORv4VJc4qIFIjIQvfv3njlB5HgeWuoNcaYauJZfVQJ/F1V54tIZ2CeiExS1eUh6X5S1QvimA9jjDFRiltJQVWzVXW+O10IrAD6xWt/xhhjGq5R2hREZDBwJDA7zOpjRWSRiHwjIgdHeP8oEckQkYwaexgZY4xpkLgHBRHpBHwK3KKqu0NWzwcGqerhwIvA5+G2oaqjVTVdVdO9zz6uR0ZCt1q/7RhjTAsW16AgIqk4AeE9Vf0sdL2q7lbVInd6ApAqIr3imSdjjDGRxbP3kQBvACtU9ZkIafq46RCREW5+8uKVpyCeqkbZjTHGNCfx7H10PPA7YImILHSX3QUMBFDVV4GRwJ9EpBIoAS7XuA3qE1J9tPKr+OzGGGOasbgFBVWdTrUzcbU0LwEvxSsPxhhj6iZ57mgu2JzoHBhjTJOXPEEhzZ5QZowxtUmeoNCmQ+1pshfDm+dDRWn882OMMU1Q8gSFvMza03z9d9g4HbIX1p7WGGNaoOQJCrlrokjk7fhUY/u4Mca0WMkTFFLaRJ+22t3PxhiTHCwoBLLhtI0xSS55gkKrlDoktpKCMSY5JU9Q6D44ikRWUjDGJLfkCQq/+EP0aa1NwRiTpJInKLSK4lCtTcEYk+SSJyhEJaBLalUlLPoQPJ6E5sgYYxpTcgWFUdOiSyfAzBdh3ChY/GEcM2SMMU1LcgWFvkdGXjfvreDqo6Ic57UkP65ZMsaYpiS5gkJNvvybf7qqwh7CY4xJSvF8yE4z5JYUxpyd2GwYY0yCJF9JoeuAyOusdGCMSXLJFxTOfDDyuu1LGy8fxhjTBCVfUDj4Yjj1nkTnwhhjmqTkCwoicPLt0ae3G9qMMUkk+YKCMcaYiJI3KJxwa6JzYIwxTU7yBoWu/ROdA2OMaXLiFhREZICITBWR5SKyTET+FiaNiMgLIpIpIotFZHi88lPNUddFl85GTDXGJJF4lhQqgb+r6jDgGOAvIjIsJM25wH7u3yjgP3HMT7BWreCWJbWns4ZmY0wSiVtQUNVsVZ3vThcCK4B+IckuAt5Rxyygm4jsHa88VdNtYKPtyhhjmoNGaVMQkcHAkcDskFX9gM0B81lUDxzxNeKPjbo7Y4xpyuIeFESkE/ApcIuq7q7nNkaJSIaIZOzYsSO2Gdz3jNhuzxhjmrG4BgURScUJCO+p6mdhkmwBAgcj6u8uC6Kqo1U1XVXT09LSYpvJ/umx3Z4xxjRj8ex9JMAbwApVfSZCsvHA1W4vpGOAAlXNjleewrKGZGOM8Ynn0NnHA78DlojIQnfZXcBAAFV9FZgAnAdkAsXAtXHMT3hV5Y2+S2OMaariFhRUdTrOgy1rSqPAX+KVh6h07lPzerXhtI0xySN572j2EoELnou8flsU9zIYY0wLYUEBIL3xa62MMaYpsqBQm5yVic6BMcY0GgsKXuc+GX75dqs+MsYkDwsKXr0PqXn9zJdh0djGyYsxxiRIPLukNi9SS3yceJfzevjl8c+LMcYkiJUUvHrsk+gcGGNMwllQ8OrcGw4ZmehcGGNMQllQCHT2o4nOgTHGJJQFhUCde4dffn/X+O53/Y+QlRHffRhjTBQsKIQ67V+Nv8+3fwmvn974+zXGmBAWFEKlpCY6B8YYkzAWFEKlX5foHBhjTMJYUAjVtnOic2CMMQljQcEYY4yPBYVwjrwq0TkwxpiEsKAQzkUvJzoHxhiTEBYUjDHG+FhQMMYY4xNVUBCRoSLS1p0+RURuFpFu8c1agh14QaJzUDfbl8OaSYnOhTGmmYu2pPApUCUi+wKjgQHA+3HLVVNw5O8SnYO6+c+x8J4N6GdMkLy1sOqbROeiWYn2eQoeVa0UkYuBF1X1RRFZEM+MJdwB5yQ6B8aYhnpxuPN6f0Fi89GMRFtSqBCRK4BrgK/cZTYehDHGtDDRBoVrgWOBR1R1vYgMAd6NX7aMMcYkQlRBQVWXq+rNqvqBiHQHOqvqEzW9R0TGiEiOiCyNsP4UESkQkYXu3731yH98tW6f6BwYY0yjirb30TQR6SIiPYD5wGsi8kwtb3sLqK1i/idVPcL9ezCavDSqC2o7RGOMaVmirT7qqqq7gV8D76jq0cAZNb1BVX8E8huYv8RqVUs7/P1d4ScLHMaYliPaoNBaRPYGLsXf0BwLx4rIIhH5RkQOjpRIREaJSIaIZOzYsSOGu6/FsIsir1N1Xqc80Dh5McaYRhBtUHgQmAisVdW5IrIPsKaB+54PDFLVw4EXgc8jJVTV0aqarqrpaWlpDdxtHbRuC533rr58+Xh4+sDw76kohQm3Q8mu+ObNGGPiINqG5o9V9TBV/ZM7v05Vf9OQHavqblUtcqcnAKki0qsh24yLP80Int88FybeBUXb/MsqSvzTC96FOaNh2mONkz9jjImhaBua+4vIOLc3UY6IfCoi/RuyYxHpIyLiTo9w85LXkG3GRZuOwfNv/7L6Izsf6eOfVo/z6qmq+76qKqBwe93fZ4wxMRJt9dGbwHigr/v3pbssIhH5AJgJHCAiWSJyvYjcKCI3uklGAktFZBHwAnC5qreivglp3TZ4vrIE8tfV8AZxX+txKF/8FZ7eHyrL6/5eY0zzs3EmfHVbonMRJNphLtJUNTAIvCUit9T0BlW9opb1LwEvRbn/xPrFDTD39ZrTzHwZRowCcYNCfeLbivHOq6cCaFP39xtjmpc33V775z/tP3ckWLQlhTwRuUpEUty/q2iKVT3xcto9taeZeBfMfSNgQQMKPU2wwGSMiaMm9JuPNihch9MddRuQjVP18/s45anpad89unRlu6OP9v89GaY9AVnzAhY2jSuFZsPjce4VmWlPygviqYJV3zapE02TsnMjbJmf6FyEaDr/q2h7H21U1QtVNU1V91LVXwEN6n3U4oX7QeascLqsAmQvhGmPwuun1W/7ZYXOCXH5F/XPY3OnbmP+pKY3QkpCzXgRPrgMVsbylqIW5PnD4LVTE52LYN4OKk1AQ5681rRaR+Kt64Da02ycQcSG5j158Mox8EjvyO+XOjRSexu7f/h37WlbOrsiDrZro/NauK3mdKbpaELf4YYEheSq67jxp9rTrJsauaG5vMg/HVRlFKgujdQN6OXU4rSAz6CyDMr3xGhjjfzTtG7UDeD9zbeMkkIL+CXWQbTtCl/d6k4obJoFuzY5V/V7AobnqLXKKIqPtiG9nFqKlnTsrxwLj/ZNdC7qbuXXTjfqtd8nOifNXNP5LtfYJVVECgmfWwGSb1zpu7Lh0TDDXoRTshPGnF2//bTEksKMF+GgX0L3wTHcaDM59mjkr010Dupn82znNXsRDK1n+5hpUhc4NZYUVLWzqnYJ89dZVaO9x6HlaNMBfhdxiKZgK76s+/Yr3eEyQouSZUVQVRm8rC4lhSWfwOtn1j0/kYw5F+bX4RlLRTnw3T3wvxj3TUjUD2naE/DQXsHL6nMHe1P31W3wQY23GwV8V5tIbXJFCezJTXQuoictq/ooOQ1taK+FGn48HvfEX1rgNloDSz+Dx/rBh1dGv51Qn14PWXOcLpyxsGkGjP9r9Om9J8yyoprT1ZkbFBo7OEx7FKrK/PNVlfDkEJj+XP22l70oNvnyitVNUBlvwKoJNafxfvYS5alk9XfVL3Bi6ZE+8O+h8dn23Dfgi7/EZ9tNqNRrQaE+/m9jA94cxT//3YvhzXMhezF8cq2zbPW39d+elyeOP8ZoFeXA94/EJkDVNRisnRqfuu/KUieQf/9Q/d7/35Nim586dVhoIF9QiCIQZU6B9y+BH5+Mb57i5evbYMH/YrxRKym0DO27wX5nxW/7O9c7r4Gjr3ptnOn0UqlPQ3OkoLAnF7Yvr1sea7NxpnMfRVEOQYHry785J4WN02Owkzqe9N79lRNwY00bUHXUhOqS66cOJQVvZ4udG+KWm4Rb9jks/bTu72tC3wMLCvV1/tPQOc69Rb65PXi+YIszVsqjfZ1SBFC3kkJF9WWqTnH7P8eGf8+ycfDtXc4JfuXX0e9rpjus1aaZ/mUiUFHsTFeFyQs4JYjiMA/sKyv03/gXmPdYqKqEyQ+E3280vNVjklL398byCnHnxui6tVZVRv7868qb/2irj5qaqgqY8E8oitHDuz6+Bj65Lvr01qbQgnQbCLcshl77x28foXXNzw7zT48b5bxWlET+ge/Odk7mXoGNoWsmw+KPaxnxFfj49zDLHUZi5sv1qPaR4JO37+QRckL/4d/w8tEw/Rmnfr5gS/D6x/rDq8dH2Ie7rVXfOl2A62rVBGe/395Zt/d5j8tbAqutCiXcZxfLK8TnD4P3Lg3cePh0D/WEh2L06JK6BIVYXw2/chx8dE10aSPte/W3MOe/8NS+/mWlu2HXZuc90eQ5Z4VTfRiNpZ/C+JsCFjSRBvoAFhQaIiUVLnkrsXnYvTX4B+6pcp78NvVReCbk6XBV5c4VUUUpvPcb+OyG6lcorxwLb10QYWcS3RXNuh9gx8qABd4flvhPHt4fm/d16sPOe1Z94x5XSFAAyMsMWRDyg/3gMnj1hNrzF6rKHao8sPE4GqHPzqjpxLhtCTzYHdZMgu3LAhrdY3yi3Di9cUfbTGTvo5xlsDzK3oCReoeFWz76FHjuEHigO7x+euRt/vS081t55RjnOSvR+OQ6mP9O9eWqznfige6wImR4kow3Y9t7sBbJ16001npHfLR04witz35yHyiN8CjQ5eOrV0kFXgmt+wFy3LaFzXNh3lu172/Vt7BtMZz8T//23rnQv14ilBTU41R1PNoXzn0y/PrahLuKKy1wls99HQ6/Atp2qn074cx/x+kBdvGrkdN4qqBVSkBJIaD6SDX45LxplvO64kuY/zbscwpc/UX9r55Xf+c0cA9zP+uGlkK+/jsMPR0OPK9u+ahLQ3MieSogJczpLtz3zHfPiMKWSKMPAFMe9E9nL3KGsglVuB2KtkPvQ4I/I1X48d/+Kl31OG2J6nGe2nhQwIXZVzU+pSDmrKQQC3dmwS1LoF96onMSOSBA9YAAUBFQBx14Mn/jDFgY0tNCBAqzg5d9cBlMfcSZ9v4AQnlvcKoq9zcyqjrtBAA/PhWwjzoEhUhX2ZlTYMI/YOKddW8nKNzu/NjH3wSLPqhl996SgjcouHmvqoQHugWfNHwnaPd1w8/B26ir9y+Bj37nnw/sRJDiPosjXBtSJHNfh7E13JNQUepUq+zc4FRJLv3MWe6rPhKnGjNnhVMt6a3Ge+10GHdj9e2VFTr/92jv77i/K3z6h6gPp1pAjFTFWp/PP1Ke/72Pf7qi1PmsXhwO/z3RKSXOeNG/fvtS/+/GyUjt+22kxmgLCrHQtrPTxnB1MxyxdPQp0afNy4TnD/fPL3jPP1262xnu4Ns7gt+TOdm5TwKgOBdyVzvTrVL8X/LAahvfSSbF34Mpf334/AT+SAKvlL/4s/M6/x2nfSJnJdWU7Kx+k1NxnnMMPz1dPf2OVf4TYWheA0+M4A+0s0dXT1v9IMIvLs53PlOvrQvgk+udxuRFH1ZPHxQU3MfFVtaxOgycNqZtS6ovH30KPD7Av27JJ85rYJvCxLucqpTPboDnDnWqQbZkhA+ukx9wuvB6q39mj3balMLx1tcv+ch5raqsPZiEro/YsSGKbtoej1My820riicjjj7F+a0Ejnk26V/+6dBqTvUEt1EVbncawAPzHc1+Y8Cqj2KpbSe4YqzzYz78Mti2FN4bCfud6a9HvPZb/9OWmpvQUoL35AvwwhHO67JxwWlyQ9sBvMtXwwZ3kMHARrqsOc6rpxLecqsyZgY8oO+Rvs5J9/4Cgk6oPwaMFhtaWnnl6OB7SxaNhc//5PwQ79vl/zHWNKroh1c5eT44oEurtyrNd9OhW0ord3tYtW7rnMA2TvcHCt8Pv8IJeEcGXO0HenIItOkMd2U58x9d7Vx9L/2ketr7u8L+Ad+pFPcRslXlTmBY+hkcfnn1Kp49uc4zyFMDRqx54Ujn9b6QEueOFeHz6S0RLHivehCqdsOll8Dc15zJ8mIoyApfip09GgafAJ1C7h5/qCf0Ocw/r+oMRd/3yIBlVbAn4Bg8Fc53s/uQ4G0FnnRVwwebjDeckmfgex4fFOHYXJE+r0gCL3B2rHQuTsBpBPeqLKv+eOA4sKAQawec65/ucwj83b1KvTCg6Hj7Wqcb6B9/ck6CHdOcH31zVhzhQXyR7keYeFfN23sroG67dTv/dGB1V+APqbZhRZ4I+BGP+6N/+sWj/HXIrVKrv68ox7na85ZwKgO6xYZWH3mVuFVWxbnOCSzQ9qXB8wtqGC6kvDBgppY6+8CbG3943M1rGfzwhFPyadvJOSEG9uD691DoOxyuDBNoZkdoS/GeNFd9DZPuc0pQ4JQI0g6KnL+g0kfA/0098GyYdrmSXeEDhW97i/3T426ExWPh6IBqKk8VjA0ISlvmOT3pAqkGV+k80C38vgo2B8+/fnrdOyXUKoqqoRkvwol/h9R2tadtAAsKidCxl3ulC+x9WM1pTfAVoFf++uAqmcrS6mmiETgQXc6y6uuf2i94/tMb/NPqgZUTYNYrIWlqqPvuPtipCqpJYFXYqm+ddptIpj0eeV1Vhb+KbPFH/meAB9o632k/ChXYHhKoLCBQ/RwyrEdN/4PA6pLAapAvbw5Ot2YSrJ4IayZG3laoxWOd18BAplWweZZ/fuxvq78vUhAIFXqx4L1AiCX1wPRna07z45PO3/1Rdn+tJ9EmdCddNNLT0zUjIyPR2Yi9JZ9Ah57OXbcAh4z0VxUccL5zZVZfl74b3CjZ3Bx2uf+H35T8fbW/mB8r9+Y7N/g91r/h2xrxR6ftJjRo1dUVY+GDy2tP17aL80haU3e//Qjev7T2dIOOh2trGY8qAhGZp6q19oaxoNDU3N8Veu4HN4Uc49YF0KEXTHkAlnwM7bo6RWRvQ1baQdXrMdOvg3OegNZtnDr37x92lksruG8nTLw7uL4+kmP/Ckf8Fv5zXMOPz9Ts/GectpbQthkTW2kHwXn/dkoqFzzrdBF+8zzY+HPt7711mb/9SdWposucFJzmtx9D597OyANf3Vq9J9ivX3ca5GvTMc0ZHqRLf7hhEnSp/ygKFhSaq6pKp0GwVRRDJhTlOI2mR1wJHXs6X9Bv/s/fOBVYzNy9FZ5x63yP+Quc86gzXbLL6TL6/qVO/fLW+c7VyPAxUvU2AAAgAElEQVRrnL7SWRkw+ERo1cp/d/QhI2HkG04DYbj64Npc8JxzD8GYs2I/Qqgx4Qw5Ca4a57QFtOlYc9rvHw7uuADQqbdzsXbGfTBgROT3luyCvLXQ/6jg5UU7nIuzwm3O+Egn/9P5vWZOqrmEcN+umN0DYkEhmZUVOY2f7UPqTAuynC93q9b1+6LNexvW/wAjx/iXjbvR6XLYuj2c/i+n59UPj8ORVzkjSqZ2gLsDhtu4eLTTMytU4HAcTdVBFzp3Wm+ZT9iGwbu3wXOHwZ4cZ/72dfD1rbD8C6e3TGDjaFPQdUBwI+rp9zr3OOSvg4wxkd8X6qALw7dXBNr7CKeH0CEjnZu0Qm8K+9tiZ5iOUFd/Ae/8ClD453qnhPxgD6fRvEs/uPAF6LEP/O/X4UfAPemfcNrd0R+LV/56p1dcn0Oju0BriKcPgsKt/vmb5jsdT7YvjWn7QcKDgoiMAS4AclT1kDDrBXgeOA8oBn6vqvNr264FhWbCU+UMNXzsX6HXfs4YTa1Sw99VCk7X1eI8p+3k5+edZWkHhgyXEUb/X8CZDzr99z8Pc5MUON01S3e7jY+z/cu7DXKK44GD9nn99iPod5TTS2rxh06VQdeAev6KEmfs/kD3F7gD+uU6wbBtJ+eu7ecOdYLhvqc7N9YNPdVpN1jxpXMSXvyhM05VYbbz3toE1t1f+YnTHrV9qb9nU5/DnCvafc/wN2q36+ZcDDzn/hTv2AztujhdQlulBHd1LMqBty90qiYDg8bd2/zdV2f9x9nvH6b4129b6tyncsVY5xkgXfrBbWFG31V1GmtTUqFTH+cz8H4vFvwPhpzsrCvMdjoZqDoXOSlheoeFqix3LlKOvMq5I//IqxqlG2fMVZY7jfode9aeNkpNISicBBQB70QICucBN+EEhaOB51U1wt0rfhYUWrjv/gUzXnCmj/lzcCPpr19zHvlYnAcvj3CuUC99xyn1bF0Io0926mCPutbp3z7kpOolouJ854o18NGRJTud5T2HOsX7ziEn+0jeusAZx+jWZdVPrA1RuN0JjFlznXrkqkrnprDU9k4eR74ZvqRXVQlodCfPaBRkOQ+WOe1fTvVhXeSvc55rHu2zzU3cJTwouJkYDHwVISj8F5imqh+486uAU1Q1OzRtIAsKLdyKL50bxc56xAkK3z8Ev7g++Co9nG1LnG6PvQ+BP0XRWGhMkok2KCTyPoV+QOBdIVnusmpBQURGAaMABg4c2CiZMwly0C/h76v8V+tn3Bfd+7xBI9IdwsaYqDSLm9dUdTQwGpySQoKzY+It2uqbQO27x/2mHmOSQSIHxNsCDAiY7+8uM8YYkyCJDArjgavFcQxQUFt7gjHGmPiKW/WRiHwAnAL0EpEs4D4gFUBVXwUm4PQ8ysTpknptvPISaPvuUtI6taVVqyb+UBBjjEmAuAUFVa3hiR2gTrenv8Rr/+Fk7SzmhCemcusZ+/O3M/ar/Q3GGJNkkuohO9t3O6M4Tludk+CcGGNM05Q0QaHKo/zmP86dq81sZA9jjGk0SRMUisr8D0KxmGCMMeElTVAIvHO7uQ0CaIwxjSWJgkL4aWOMMX5JExQ8gSUFq0AyxpiwkiYozF6f75suq/Awb+NOBt/xNQs27UxgrowxpmlJmqCwdVeJb3pNThHfr9wOwPQ1UYxfb4wxSSJpgkKo7bvLgJg96c4YY1qEpAkKoY3Ln8zLAmBd7h5y3JvajDEm2SVNUKj0hG9c/mz+FkY8OiXsOmOMSTZJExRKyitrT2SMMUkuaYLC8fv2qnH9s5NWU17paaTcGGNM05Q0QeHofXrWuP75KWt4f/bGRsqNMcY0TUkTFAAO7NO5xvWlVlIwxiS5pAoKj1x8SI3rbfgLY0yyS6qgcNSgHonOgjHGNGlJFRQAJt92UsR1NiaSMSbZJV1QSOvcLuI6qz4yxiS7pAsKXdunMuvO0xOdDWOMaZKSLigA9OkaubRgjDHJLCmDgjHGmPCSNii8f8PR1Zb9e+IqBt/xdQJyY4wxTUPSBoUD9+6S6CwYY0yTE9egICLniMgqEckUkTvCrP+9iOwQkYXu3w3xzE+g7h1SG2tXxhjTbMQtKIhICvAycC4wDLhCRIaFSfqhqh7h/r0er/yEyR83njy0sXZnjDHNQjxLCiOATFVdp6rlwFjgojjur86uPHpg2OUzMnNZs72wkXNjjDGJF8+g0A/YHDCf5S4L9RsRWSwin4jIgHAbEpFRIpIhIhk7duyIWQYH9OjArWfsX235b1+fzZnP/hiz/RhjTHOR6IbmL4HBqnoYMAl4O1wiVR2tqumqmp6WlhbTDNx8+r4R1xWWVsR0X8YY09TFMyhsAQKv/Pu7y3xUNU9Vy9zZ14Gj4pifsESEZy49POy6V6atbeTcGGNMYsUzKMwF9hORISLSBrgcGB+YQET2Dpi9EFgRx/xEdFj/rmGX/2faWnYUloVdZ4wxLVHcgoKqVgJ/BSbinOw/UtVlIvKgiFzoJrtZRJaJyCLgZuD38cpPTYamdaJ3l7Zh1y3dUsAFL/7E5vziRs6VMcY0PtFmNjRoenq6ZmRkxHy7VR5l6F0Tqi3/1RF9+XzhVq46ZiAP/+rQmO/XGGMag4jMU9X02tIluqG5yUhpJWGXVzWvmGmMMQ1iQSHAp386rtqyyirnuc3rduxp7OwYY0yjs6AQ4KhB3bnhhCFBy75Zug2AGWvzEpElY4xpVBYUQtxzQbiROIwxJjlYUAjjjyftk+gsGGNMQlhQCOPPp0a+yzkzp5DXflzXiLlpesoqq/B4rAXemJbIgkIYXdun8uBFB1dbPviOrznjmR95ZMIKKqo8PPPdKpZkFSQgh4l1wD3f8rcPFyY6G8aYOLCgEMHVxw6ucX1llfLC95lc9PJ0cgpLKausapyMNRFfLtqa6CwYY+LAgkI9lVY4QcCjMOKRKfz1/QU1pldVrhg9i++Wbau2bkX2bpZuSb4ShzGJ8Nn8LB6dkJARdZoFCwo1mHDziRHXFbtBQdx73iYt385Zz/4QMb0qzFyXxx//N6/aunOf/4kLXpzesMyahKms8jD4jq958+f1ic6KicJtHy1idJK3C9bEgkINhvXtwuTbTgq7ztvYHDhKyOrtRUFp3pm5gUnLtwNQFWE4kRemrGl4RpPY1JU5CR+Xqty9wfGxCSsTmg9jYsGCQi323atz2OVvzdgQdrmqMm5BFiXlVdz7xTL+8I4zTpMnQlB4ZtLqmOSzuVi4eRen/HtqzJ5Vce1bczmzhhJaY6rweBKdBWMazIJCFDY8fn7UaWety+fWDxfx8NfLfctufHcej3/TMq4iox1AcXdpBfd+sZSS8uAG+GcnrWZDXjFzN+THLE+lFYk9GXs/kmY2tqQxYVlQiNK714+IKp33CnhbQalv2bfLtvHmzxuAxjlxbM4vJqewtMY0s9blMXtd3YfuiPb2hJenZvLOzI28P2dT0PLUFKcRprIFjTQYqRRoTHNkQSFKJ+6XxuTbTq413ah3nYbk+pwmdu4p59N5WQBkbMj39XCqqxOfnMqIR6bUmOby0bO4bPSsWre1PncPK7ft9s1HewL0nvQj3eQmEn5U2ubg44zNXPLqDN+8hQTTklhQqIN99+rEm7//RVRpi8srI64rrwxf3XHz2AX8/eNF/LB6ByNfncn945fVK5+xdOpT0zjnuZ9889EGBW+yup77C4oreGbSaqqa8B3Tt3+ymLkbdvrmY1FQ2JxfXK+SWyTJ+sTAKo8m3T1DsWZBoY5OPXAvlj94dq3pZq2LXGd+3/hlXPfWXAbf8XXQcu8Pebtb9bQ8e3e199bk0ldncs/nS6ot311awbKtsbkPItoToEa8fhZ3O+HXP/T1cl6YssbXa6tZiEFQOPHJqVGV3KLxc2Yuv3hkcvP6DGNk1DsZHHDPtzHZ1rVvzuHhr5bXnrCFsaBQDx3atK5T43OoD+Zs4vuVOdWWb9vtBANvL5bySg+fL9jCByH18pHM2ZDP/2ZVT3vr2IWc/8L0eldHBapv/flTE1exYNNOQs+g63P3BOXL2zBdUeWhssrD+EVbo27crq+C4gquGTMnqB3mjk8Xc8A93/jm//huBofeNzHofd6qsabWprDYHXolY2PsGvNrkuguwYGmhPld1dfUVTt4fXp87z157cd11S4OE82CQgOsfOgcpv7jFG47c/+YbG9XsdNI/eHczc72txVyy4cLufOzJbw9YwOqSm6RU5r4btk2Tntqmu8hQNt3R25Y9j4Lori89qDw1/fnc9KTUyOuj6ZW5+JXfubzBVt886rKS1MzufgVfz28iFBe6eHUp6Zx8wfh7wZ/7af13PzBAsYHDKkx6p0M3p25ofZM1MFHGZv5YfUORv/gv6Fp7NzNlAVU801ctp3CsuAqQe+9J3UNCQXFFXEZULCyyhO83QbuorLKE7Gq0+vbpdmc+ORUpsbwZNzYxi3IIqeG349XQUkF63YU1ZquLh5x76xuSgNMWlBogHapKQzp1ZGbT9+Pn/55asy2uzjMIHv3jV/GkDsnkP7wZJZuKeCucUtYl7uH/OJyVm8v5NL/zqz2niqPcuSD31HiXonvLqng2MemMGNtbsR9f7U4m001XPlFc1W8YNMudroBTkR8N3c5/NVHlW6J6IfVO0JXo/ir0wLrx79bvp1/fbHMt41wVJWvFm+NumTUyn0Ua2Udf5jedo+6lGQ8HuXwB7/jH58sqtO+orHv3d8w6t15vnachp5mLv3vTPYPKC2Fs8QdniVW1ZONbVdxObd+uIhr3pxba9pfv/Izpz0dn3tiIt3cmggWFGJkQI8ObHj8fCbcfCL3nH9QXPd1wYvTyS0qB+D92Zs469kf2ZhX/UReUlHlOzkDrN1RRHZBKfd9UfcG7MF3fM2izbvQkAvHVdsKSX94sq/qJbSBWAhtWPevrwpT/eJtl1ZVUls7c2WVHh7+anm1arRIv6OZ6/L46/sLeOLb4HtDMnOKyMwprJa+tS8o1O1+B28Qifbn7ARCJ/Vn87fUkjp68zft9JUUJ6/Yjvdx4w29+py/aVetacT9j0XaVc7uUrbuKgGctq2R/5nBhtz4P9o22kBd4faSq6mk7bU2jo/kbUodKywoxNiwvl244cR92PD4+Wx4/Hy+uukE9t2rU9z299zkyMNkTFkRvqGxoir45Ld2R1FUP4opK7ZXKymMmb6e3KIypqzI4cKXpvPN0uxq7wtXBSEivh9C4A8isKtq29Ypvve/Pn09d34W3Ige6cp+d4kTCLfsLAlafsYzP3DGMz/62i28J47UFOdnUNd7J7xVd6GficejPDtpNXlF/hLOiuzdDLlzQnCpKIz6tJ/8+pUZnB5wBSvU3OVr6ZaCmA3A6A1AkbI94tEpHPf494Dz/cnYuJPnJtf9Lv6fM3ODPs/aeL9To39cy+A7vg77uWqYi5FoxLKNy/t1b0rtUhYU4uyQfl2ZfNvJzLn7dD7/y/EcMaBbo+37b2ODn3ngbVPYEFCq2FFYxulP/8DRj06p9WrFo8FDOaQ/PInZ6532ip3F5SzOKqg2WqwIQdVHrcR785onoKTgXO0+P3lNQEkB2qU6X8/SMF0Mj3tsCi9NzQybT29giXQ0B937LXd+tphfvfwzm/OLfQ385VV1LynM37ST71cE16cv2VLA81PWcEvAMye83U0nLQ8eJVdVGXrXBN98RS2BqaS8ityiMn7/5hwuevln3/KigPaO2qqPLnhxerUBGC96+Wceq2Hk0JzC0rAn5TatI/+PQtVWqgCnOie00V9VufL12WGrSCPxXjA86o5HFe5/W+lR38m4Ll2na/qeFJVVBv0votWECgq0TnQGksVenduxV+d2fP6X433LNucXU1BSQWZOUdAJJF5uCtOge8Yz/ivMXwacKML1iHhpaiaX/WKAbz63qNxXjVVVw8ns9Z/8PTiy3e62u0oqgoLQr91G6F8e3hdwrpy8JYWyMMNYbC0oDRpMsMrjnFz/eNI+bHGrK5ZuKeAXj0ymR4c2HL9vr6D3fzDHacw/MaBRvazSw4hHJpMT0IZR5VFSWvnPGJ/Nzwpa9+uAxnMv74lyy64SNuTu4ZSnpvG7YwYB/qAI8L9ZGzl2aM+gz8E7ffvHizjr4D6cOaw3AHPW5/Nxxma2F5bxYy2lDS/vxed/f1jLlccMolPbyD/3RZt3sWjzLu48L3zVp/dmyNBed53bpQJQVOqcCGety2NoWifSOretto3AYFXlUTbm7WGfNKcUnbWzmFXbClmTU8QPq3fwxk/rfXnxNviHVt8UllawIruQEUN6VNtXeZWHdqkpvvnSco/v++RVUeXxBY/AThjTVuUwYUn1Em9N2/I6/IHvqPJo1L0T26S0oqzSQ1lFVY3/n8YU11yIyDnA80AK8LqqPh6yvi3wDnAUkAdcpqob4pmnpmRAjw4MwClN/OrIflRWedhVUkHX9qlk7Szh1KemAdCnSzvf1WysFZT42xyiuS8i0uBzT0cY2C8zp4j3ZvvbArwNk1NX5lSrDgJ8J7zbPlrEQ786BCCqm5G82/1vwJDI3gC0o7CMVdurtyWEyi8qDwoI4FRdtW/jPwHc9pG/gThc9ZWq/+qzoLiCS9yr23dnbQSCr0jv+Xypb9gPrwqPh7aeVnw8L4uP52XxrwuGcXDfLvz2tVlRX0162ys8qny7NJvHvlnJY9+s5MaTh9KrUxtful3F5bRLTQkan2rqqhyufXMuX910QtAxBU6/9tM6zj+sL9m7Sny9cfaUV1JZ5eFy916LfdI6BvXKW5+7x3ciLa2o4poxc5iemcszlx7OKQfsxTVj5rB2xx5uP/sAX5pXpmVy5dGD2LmnPOj4bng7g0E9OzBv404Wbt7FnLtOp1uHNr5gDNWrAosrKvlmTnbQxUFFpfqqAAODwu9raXQurayiK6l4PE4b0T2fL+HcQ/bmpP3TIpa2P52XxdC9OnFw3y7kFZWzV+e2jHo3wxfw9pRV0a2Dcve4JZxxUG8OH9CNeRvzOXG/NGaszeON6ev44A/HNMpIABKvPuAikgKsBs4EsoC5wBWqujwgzZ+Bw1T1RhG5HLhYVS+rabvp6emakZERlzw3ZVVuUbeVCKrKN0u3+a78+3Vr77s6NvXXtnWroG6otfnjSfsEBaFYuDS9Px9lZNWe0HXCvr2Ynhm+N9kNJwxhSFpH7h63tEF5+uc5B/Dkt6sAuOWM/cK2Y/Xs2AaPalDHhlCnH7gXU1bmcOw+PZnpVqcNH9gtqEHb+13u0CYlbBfqDY+fX60U+5dTh/Ly1LVcMWKgrzPC+384mt++NtuX5sNRx1S7OXDu3WdQUFLhKy2vf+w8rh4zh5/WBH+eSx84m/SHJ/kGXpxw84mc98JP1OSH20/h5H9Po0+XdqS2FjbnO7/Pvbu2I7uglH+ctT9Pfee/kJpw84nk7ynnqjdmB23nqEHdmbfRuXt+/r/OpEfHNtSXiMxT1fRa08UxKBwL3K+qZ7vzdwKo6mMBaSa6aWaKSGtgG5CmNWQqWYNCNFTVdyWxaPMuMnOK2CetI5NXbOfcQ/Zmzvp85m/ayZrtRXTrkEqPjm34ZqlTxx3P0ogxsRLLC6Au7Vqzp7zKd3Vf14uCxtalXWv+fOq+3Hjy0Hq9P9qgEM/qo37A5oD5LODoSGlUtVJECoCeQFCoFpFRwCiAgQMHxiu/zV5g0fLwAd043G3UPnJgd8CpprqOIXXebmCw8U5vzNvD3l3bu3X/rSgqq6Rzu1R+zsxl2N5dqPQorQQ+yshi+MBudGrXmmmrdnDV0YMoq6xi/KKtnDWsD5vyi1m1vZCjh/SgrNLDsq0FdG7XmqKyKvaUVXLWsN5Oz5M95bRp3YrUVq3YUVTGoJ4dGNyzI7uKK5izPo91uXv459kH8uXirfTs2IZj9unJf6at5dJf9GdbQRm5RWVs3VXCsL5dyNiwkx/X7ODeC4bx6fwsjh7SkxP368WUFTn06tSGdbl7GJrWiQE92rMht5jC0koWbt7Jb47qz2fzt/D9yhxGHtWfnMIyenVsw9C9OtGtQyq7iiv4cO5mNuUXc8oBafTu3I5pq3O46uhBrMvdwy8G9+CZSas4ekhPNu8sJq1TWw7r343V2wtJ69wWVaVzu1RWZO+mTetWlFRU0b97e6at2sGIwT0YMaQHu0oqKKvw8Kzbg+eA3p359fB+5O0pp3Ur4cc1O9i+u4xLjurPzuIKVm3bzcF9uzJjba6vTn5gjw4c2r8r+UXlrMkp4rihPdlZXM62glL6dW9Px7atWbBxJ2cO602/7u15dMJKTto/jczthWwtKOXKoweyKb+YIb060ialFSkpwscZWewpq6RDmxQ6tGnNyQekUVbhoXeXtmzKL/bte6/ObdknrSPzNu7knEP68P2KHApKKtgnrSPllR7W5+5hT3kVHdukMKBHB/bbqzMLNu+kpLyKYXt3waPKUdqdDXl72LtrOw7s04WcwlK6d2jDxrxiunVIpUv7VErKq/h6SbbTkeLAvejesQ0d2qSwenshK7ILOXNYb1JEgqoA26a24v3Zm0gf1J0u7VPJ31PO3l3b0S41hQWbdtKve3tydpdRUlHlVO8ekMayrbspr/Jw2gF7sWVXCWWVHg7u24XsglJmrcujuLyK3l3aMqRXR9bt2MN5h+7texbLiCE92HevTsxZn88hfbswe30+Q9M6IeJUfR7WrysKjFuwhSG9OrJ/7070796+zr/fuopnSWEkcI6q3uDO/w44WlX/GpBmqZsmy51f66aJeHeVlRSMMabuoi0pxLNL6hZgQMB8f3dZ2DRu9VFXnAZnY4wxCRDPoDAX2E9EhohIG+ByYHxImvHANe70SOD7mtoTjDHGxFfc2hTcNoK/AhNxuqSOUdVlIvIgkKGq44E3gHdFJBPIxwkcxhhjEiSu9ymo6gRgQsiyewOmS4FL4pkHY4wx0bNhLowxxvhYUDDGGONjQcEYY4yPBQVjjDE+cbt5LV5EZAewsZ5v70XI3dJJwI45OdgxJ4eGHPMgVU2rLVGzCwoNISIZ0dzR15LYMScHO+bk0BjHbNVHxhhjfCwoGGOM8Um2oDA60RlIADvm5GDHnBzifsxJ1aZgjDGmZslWUjDGGFMDCwrGGGN8kiYoiMg5IrJKRDJF5I5E56chRGSMiOS4DynyLushIpNEZI372t1dLiLygnvci0VkeMB7rnHTrxGRa8LtqykQkQEiMlVElovIMhH5m7u8JR9zOxGZIyKL3GN+wF0+RERmu8f2oTssPSLS1p3PdNcPDtjWne7yVSJydmKOKHoikiIiC0TkK3e+RR+ziGwQkSUislBEMtxliftuq2qL/8MZunstsA/QBlgEDEt0vhpwPCcBw4GlAcueBO5wp+8AnnCnzwO+AQQ4BpjtLu8BrHNfu7vT3RN9bBGOd29guDvdGVgNDGvhxyxAJ3c6FZjtHstHwOXu8leBP7nTfwZedacvBz50p4e53/e2wBD3d5CS6OOr5dhvA94HvnLnW/QxAxuAXiHLEvbdTpaSwgggU1XXqWo5MBa4KMF5qjdV/RHn+ROBLgLedqffBn4VsPwddcwCuonI3sDZwCRVzVfVncAk4Jz4577uVDVbVee704XACpzne7fkY1ZVLXJnU90/BU4DPnGXhx6z97P4BDhdRMRdPlZVy1R1PZCJ83tokkSkP3A+8Lo7L7TwY44gYd/tZAkK/YDNAfNZ7rKWpLeqZrvT24De7nSkY2+Wn4lbRXAkzpVziz5mtxplIZCD8yNfC+xS1Uo3SWD+fcfmri8AetLMjhl4Dvgn4HHne9Lyj1mB70RknoiMcpcl7Lsd14fsmMRQVRWRFtfXWEQ6AZ8Ct6jqbuei0NESj1lVq4AjRKQbMA44MMFZiisRuQDIUdV5InJKovPTiE5Q1S0ishcwSURWBq5s7O92spQUtgADAub7u8taku1uMRL3NcddHunYm9VnIiKpOAHhPVX9zF3coo/ZS1V3AVOBY3GqC7wXc4H59x2bu74rkEfzOubjgQtFZANOFe9pwPO07GNGVbe4rzk4wX8ECfxuJ0tQmAvs5/ZiaIPTKDU+wXmKtfGAt8fBNcAXAcuvdnstHAMUuMXSicBZItLd7dlwlrusyXHrid8AVqjqMwGrWvIxp7klBESkPXAmTlvKVGCkmyz0mL2fxUjge3VaIMcDl7s9dYYA+wFzGuco6kZV71TV/qo6GOc3+r2qXkkLPmYR6Sginb3TON/JpSTyu53olvfG+sNptV+NUy97d6Lz08Bj+QDIBipw6g6vx6lLnQKsASYDPdy0ArzsHvcSID1gO9fhNMJlAtcm+rhqON4TcOpdFwML3b/zWvgxHwYscI95KXCvu3wfnBNcJvAx0NZd3s6dz3TX7xOwrbvdz2IVcG6ijy3K4z8Ff++jFnvM7rEtcv+Wec9Nifxu2zAXxhhjfJKl+sgYY0wULCgYY4zxsaBgjDHGx4KCMcYYHwsKxhhjfCwoGBNCRKrcESu9fzEbVVdEBkvA6LbGNDU2zIUx1ZWo6hGJzoQxiWAlBWOi5I57/6Q79v0cEdnXXT5YRL53x7efIiID3eW9RWScOM9EWCQix7mbShGR18R5TsJ37h3LxjQJFhSMqa59SPXRZQHrClT1UOAlnBE9AV4E3lbVw4D3gBfc5S8AP6jq4TjPv1jmLt8PeFlVDwZ2Ab+J8/EYEzW7o9mYECJSpKqdwizfAJymquvcAfq2qWpPEckF9lbVCnd5tqr2EpEdQH9VLQvYxmCcce/3c+f/D0hV1Yfjf2TG1M5KCsbUjUaYrouygOkqrG3PNCEWFIypm8sCXme60zNwRvUEuBL4yZ2eAvwJfA/M6dpYmTSmvuwKxZjq2rtPPPP6VlW93VK7i8hinKv9K9xlNwFvisjtwA7gWnf534DRInI9TongTzij2xrTZFmbgjFRctsU0lU1N9F5MdljwtAAAAA1SURBVCZerPrIGGOMj5UUjDHG+FhJwRhjjI8FBWOMMT4WFIwxxvhYUDDGGONjQcEYY4zP/wM2zbsxoIcvZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model):\n",
    "    return model.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 695,297\n",
      "Trainable params: 695,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_Sig = Sequential()\n",
    "NN_5000E_Adam_Sig.add(Dense(512,input_dim = 330,activation = 'sigmoid'))\n",
    "NN_5000E_Adam_Sig.add(Dense(512,activation = 'sigmoid'))\n",
    "NN_5000E_Adam_Sig.add(Dense(512,activation = 'sigmoid'))\n",
    "NN_5000E_Adam_Sig.add(Dense(1))\n",
    "NN_5000E_Adam_Sig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 364us/step - loss: 37765465534.6290 - val_loss: 38856311962.3014\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37760839083.3248 - val_loss: 38851632927.5616\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37756176252.3805 - val_loss: 38846826748.4931\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37751193261.2991 - val_loss: 38841367622.1370\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37745548971.5441 - val_loss: 38835620204.7123\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37739652777.7892 - val_loss: 38829458361.8630\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37733663901.0660 - val_loss: 38823570894.9041\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37727911614.8483 - val_loss: 38817877006.0274\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37722319242.8586 - val_loss: 38812273734.1370\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37716798786.0291 - val_loss: 38806748174.0274\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37711336034.7147 - val_loss: 38801228168.7671\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37705886606.8072 - val_loss: 38795753387.8356\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37700468985.1997 - val_loss: 38790304978.4110\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37695077452.3393 - val_loss: 38784852697.4247\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37689687407.6572 - val_loss: 38779443452.4931\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37684336289.0146 - val_loss: 38773981127.8904\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 37678964479.7806 - val_loss: 38768613291.8356\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37673629230.9443 - val_loss: 38763233897.2055\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37668293715.3590 - val_loss: 38757846759.4521\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37662964371.8526 - val_loss: 38752457489.5342\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37657637643.1877 - val_loss: 38747105195.8356\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37652331194.4610 - val_loss: 38741736013.1507\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37647024177.1380 - val_loss: 38736370926.4658\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37641713795.6195 - val_loss: 38731015658.9589\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37636415628.3942 - val_loss: 38725684518.5753\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 37631123020.7781 - val_loss: 38720334525.3699\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 37625830946.6598 - val_loss: 38714992836.3836\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37620546639.8492 - val_loss: 38709638915.5069\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37615245229.5184 - val_loss: 38704294140.4931\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37609942443.3248 - val_loss: 38698978486.3562\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37604684702.6015 - val_loss: 38693630008.1096\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37599393523.4961 - val_loss: 38688331186.8493\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37594135414.2382 - val_loss: 38682998924.2740\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37588857109.2785 - val_loss: 38677657515.8356\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 37583581963.1877 - val_loss: 38672350278.1370\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37578291987.9623 - val_loss: 38667061724.9315\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37573038374.8278 - val_loss: 38661679749.2603\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37567736295.8698 - val_loss: 38656375036.4931\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37562480097.7275 - val_loss: 38651053715.2877\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37557219478.9237 - val_loss: 38645727063.6712\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37551939696.3153 - val_loss: 38640386833.5342\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37546659359.1500 - val_loss: 38635104620.7123\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37541417953.2888 - val_loss: 38629788517.6986\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37536160465.2751 - val_loss: 38624502489.4247\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37530913073.3573 - val_loss: 38619158107.1781\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37525648042.6667 - val_loss: 38613881112.5479\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37520407607.2802 - val_loss: 38608596430.9041\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37515154127.5201 - val_loss: 38603312198.1370\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37509925992.4182 - val_loss: 38597969891.9452\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37504646111.5338 - val_loss: 38592705465.8630\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37499414807.0334 - val_loss: 38587396600.9863\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37494167399.3213 - val_loss: 38582122131.2877\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37488929294.4781 - val_loss: 38576804625.5342\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37483697800.4456 - val_loss: 38571488298.0822\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37478438696.1440 - val_loss: 38566246876.9315\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37473214530.6872 - val_loss: 38560950580.6027\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37467961073.7412 - val_loss: 38555669994.9589\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37462729218.1937 - val_loss: 38550376167.4521\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37457483360.0823 - val_loss: 38545103549.3699\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37452250307.6744 - val_loss: 38539755295.5616\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 37446980712.4182 - val_loss: 38534491767.2329\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37441751536.6444 - val_loss: 38529196368.6575\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37436511606.6769 - val_loss: 38523888682.0822\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37431263393.4533 - val_loss: 38518638339.5069\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37426032510.1354 - val_loss: 38513364374.7945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37420806614.3205 - val_loss: 38508010622.2466\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37415536322.3582 - val_loss: 38502743671.2329\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 37410309570.1388 - val_loss: 38497450797.5890\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37405076672.1645 - val_loss: 38492161066.0822\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37399840706.5776 - val_loss: 38486900736.0000\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37394613480.5278 - val_loss: 38481583735.2329\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37389368189.2579 - val_loss: 38476314427.6164\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37384131820.0377 - val_loss: 38471026547.7260\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37378893752.0480 - val_loss: 38465764871.0137\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 37373654076.5450 - val_loss: 38460444840.3288\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37368407909.5664 - val_loss: 38455184285.8082\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37363190939.3111 - val_loss: 38449917334.7945\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37357977947.4756 - val_loss: 38444616044.7123\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 232us/step - loss: 37352746407.8149 - val_loss: 38439353806.9041\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37347513144.8158 - val_loss: 38434082198.7945\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37342292452.3599 - val_loss: 38428770079.5616\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37337063094.0737 - val_loss: 38423503857.9726\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37331837698.4130 - val_loss: 38418243303.4521\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37326635123.8252 - val_loss: 38412945828.8219\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37321405409.2888 - val_loss: 38407698403.9452\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37316182065.1380 - val_loss: 38402445368.1096\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37310959214.1217 - val_loss: 38397139982.0274\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37305726830.3410 - val_loss: 38391896877.5890\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37300516069.0180 - val_loss: 38386602601.2055\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37295286014.0257 - val_loss: 38381376441.8630\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37290090327.5270 - val_loss: 38376056916.1644\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37284859151.1362 - val_loss: 38370802926.4658\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37279636545.8098 - val_loss: 38365580582.5753\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37274431644.1885 - val_loss: 38360293376.0000\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 37269211490.4953 - val_loss: 38355026424.9863\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37263998726.8003 - val_loss: 38349771313.0959\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37258781661.7789 - val_loss: 38344476419.5069\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37253551715.5921 - val_loss: 38339209412.3836\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37248341363.1671 - val_loss: 38333921981.3699\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37243107001.5835 - val_loss: 38328704182.3562\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37237913622.8141 - val_loss: 38323423877.2603\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37232689752.1851 - val_loss: 38318160012.2740\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37227471353.4190 - val_loss: 38312884925.3699\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37222256734.7661 - val_loss: 38307633685.0411\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37217034966.5398 - val_loss: 38302391983.3425\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37211833859.0711 - val_loss: 38297087214.4658\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37206617750.4850 - val_loss: 38291842819.5069\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37201403226.5981 - val_loss: 38286597021.8082\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37196193325.1894 - val_loss: 38281309366.3562\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37190956275.0574 - val_loss: 38276083150.9041\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 37185759844.4696 - val_loss: 38270775239.8904\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37180552915.9075 - val_loss: 38265488706.6301\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37175335580.6273 - val_loss: 38260260190.6849\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37170134476.6684 - val_loss: 38255014841.8630\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37164942464.9871 - val_loss: 38249735434.5205\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37159723299.3179 - val_loss: 38244519655.4521\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37154513106.5913 - val_loss: 38239258652.0548\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37149297175.2528 - val_loss: 38233980310.7945\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37144087101.8612 - val_loss: 38228714481.9726\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37138891680.3565 - val_loss: 38223466888.7671\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 37133700274.1251 - val_loss: 38218225635.9452\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 37128497918.9032 - val_loss: 38212981016.5479\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37123279497.3231 - val_loss: 38207658012.0548\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37118050898.9203 - val_loss: 38202443242.9589\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 37112870410.0908 - val_loss: 38197196996.3836\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37107671666.5090 - val_loss: 38191969883.1781\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37102483220.8398 - val_loss: 38186710170.3014\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37097282608.2605 - val_loss: 38181456629.4795\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37092088992.5758 - val_loss: 38176209316.8219\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37086897475.7841 - val_loss: 38170950782.2466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37081676500.7849 - val_loss: 38165743924.6027\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37076492333.6281 - val_loss: 38160474673.0959\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37071288535.8560 - val_loss: 38155209068.7123\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 37066082467.2082 - val_loss: 38149985097.6438\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 37060892203.4344 - val_loss: 38144735708.9315\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37055698521.0626 - val_loss: 38139490808.9863\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37050510521.1448 - val_loss: 38134242766.9041\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37045310631.5955 - val_loss: 38129019974.1370\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37040122110.4644 - val_loss: 38123787867.1781\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37034932345.0900 - val_loss: 38118537075.7260\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37029733970.0428 - val_loss: 38113249364.1644\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37024533102.9991 - val_loss: 38108021128.7671\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37019349769.4327 - val_loss: 38102786328.5479\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37014152413.9983 - val_loss: 38097569483.3973\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37008977656.7609 - val_loss: 38092310219.3973\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37003781055.9452 - val_loss: 38087067844.3836\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36998602095.6572 - val_loss: 38081815201.3151\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36993409782.1285 - val_loss: 38076591959.6712\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36988220771.3727 - val_loss: 38071369615.7808\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36983046335.2871 - val_loss: 38066106985.2055\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36977850176.7129 - val_loss: 38060896704.8767\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36972665072.4250 - val_loss: 38055629753.8630\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36967467817.0214 - val_loss: 38050398600.7671\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36962292052.4559 - val_loss: 38045169860.3836\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 36957100470.7318 - val_loss: 38039933601.3151\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36951917293.3539 - val_loss: 38034705983.1233\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36946739851.0780 - val_loss: 38029463608.1096\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36941544127.7258 - val_loss: 38024268196.8219\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36936383102.7935 - val_loss: 38019013982.6849\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36931187955.0574 - val_loss: 38013806171.1781\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36926004456.5278 - val_loss: 38008553584.2192\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36920812358.8552 - val_loss: 38003322318.9041\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36915638272.0000 - val_loss: 37998049700.8219\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36910428823.3625 - val_loss: 37992847388.0548\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36905246484.8398 - val_loss: 37987606415.7808\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36900053135.9040 - val_loss: 37982389290.0822\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36894877671.4310 - val_loss: 37977123012.3836\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36889692790.0189 - val_loss: 37971896291.9452\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36884513408.5484 - val_loss: 37966680120.1096\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36879343073.7275 - val_loss: 37961446666.5205\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36874157518.4233 - val_loss: 37956237059.5069\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36868993311.8081 - val_loss: 37950990307.9452\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36863806082.3033 - val_loss: 37945746810.7397\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36858624101.7858 - val_loss: 37940518294.7945\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36853450601.0763 - val_loss: 37935292808.7671\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36848265182.6564 - val_loss: 37930089766.5753\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36843104766.6838 - val_loss: 37924861755.6164\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36837918342.6907 - val_loss: 37919636494.0274\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36832744552.4182 - val_loss: 37914377005.5890\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36827554623.8355 - val_loss: 37909184455.8904\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36822380243.9075 - val_loss: 37903976700.4931\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36817219738.4336 - val_loss: 37898697405.3699\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36812023181.4910 - val_loss: 37893487125.0411\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36806838556.2982 - val_loss: 37888244020.6027\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36801664183.3899 - val_loss: 37883020610.6301\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36796487246.5330 - val_loss: 37877820317.8082\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36791324728.1577 - val_loss: 37872539002.7397\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36786132021.5253 - val_loss: 37867385224.7671\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36780971103.6435 - val_loss: 37862153959.4521\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36775797185.2614 - val_loss: 37856912257.7534\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36770605436.8192 - val_loss: 37851695580.9315\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36765436755.1397 - val_loss: 37846427283.2877\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36760254213.0454 - val_loss: 37841238380.7123\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36755090378.4747 - val_loss: 37836006947.0685\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36749910679.3625 - val_loss: 37830795544.5479\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36744732220.9837 - val_loss: 37825564503.6712\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36739562358.2382 - val_loss: 37820348331.8356\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36734393114.9820 - val_loss: 37815105507.9452\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36729206982.3068 - val_loss: 37809914360.9863\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36724067048.0891 - val_loss: 37804649654.3562\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36718885762.5227 - val_loss: 37799498289.0959\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36713746523.2562 - val_loss: 37794242952.7671\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36708551731.7703 - val_loss: 37789052030.2466\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36703393546.3102 - val_loss: 37783822392.1096\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36698241883.9143 - val_loss: 37778583383.6712\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36693065987.7292 - val_loss: 37773407947.3973\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36687915295.8081 - val_loss: 37768155809.3151\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36682738381.7652 - val_loss: 37762989687.2329\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36677585582.1765 - val_loss: 37757770036.6027\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36672410975.8629 - val_loss: 37752545392.2192\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36667245460.0720 - val_loss: 37747282312.7671\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36662063354.9546 - val_loss: 37742092231.8904\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 36656903969.1243 - val_loss: 37736917749.4795\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36651756141.2442 - val_loss: 37731698996.6027\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36646592547.0985 - val_loss: 37726504707.5069\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36641443396.0034 - val_loss: 37721255262.6849\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 36636271746.7421 - val_loss: 37716065013.4795\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36631113720.9803 - val_loss: 37710830830.4658\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36625949259.9006 - val_loss: 37705623411.7260\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 36620790837.5253 - val_loss: 37700415936.8767\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36615629305.4190 - val_loss: 37695241847.2329\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36610491094.5398 - val_loss: 37690007383.6712\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36605325087.3693 - val_loss: 37684822352.6575\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36600165927.9246 - val_loss: 37679626885.2603\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36595020141.0248 - val_loss: 37674372671.1233\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36589855451.8046 - val_loss: 37669180345.8630\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36584700900.7986 - val_loss: 37664016524.2740\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36579564657.1928 - val_loss: 37658818026.9589\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36574417766.4439 - val_loss: 37653606400.0000\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36569262629.2922 - val_loss: 37648405882.7397\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36564100437.3333 - val_loss: 37643202952.7671\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36558933061.3196 - val_loss: 37638020166.1370\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36553779938.8243 - val_loss: 37632784355.9452\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36548625498.3787 - val_loss: 37627556569.4247\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36543486457.4190 - val_loss: 37622326650.7397\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36538324284.7644 - val_loss: 37617155759.3425\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36533164733.9709 - val_loss: 37611957767.0137\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36528019554.2759 - val_loss: 37606744961.7534\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36522864875.1602 - val_loss: 37601571096.5479\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36517725995.6538 - val_loss: 37596363790.0274\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36512575803.8869 - val_loss: 37591126857.6438\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36507421358.1765 - val_loss: 37585962026.0822\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36502278017.6452 - val_loss: 37580745237.0411\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36497121678.3685 - val_loss: 37575553865.6438\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36491978123.7361 - val_loss: 37570356939.3973\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 36486824550.2245 - val_loss: 37565189021.8082\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36481680878.0120 - val_loss: 37559959327.5616\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36476527276.4216 - val_loss: 37554780973.5890\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36471390760.8021 - val_loss: 37549559695.7808\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36466234447.8492 - val_loss: 37544397894.1370\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36461102354.6461 - val_loss: 37539197208.5479\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36455948382.7661 - val_loss: 37533989397.0411\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36450784237.5733 - val_loss: 37528814577.9726\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36445656654.5330 - val_loss: 37523602277.6986\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36440516439.5270 - val_loss: 37518405856.4384\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36435368501.0865 - val_loss: 37513224248.1096\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36430228265.0214 - val_loss: 37508043088.6575\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36425086474.0908 - val_loss: 37502852615.0137\n",
      "Epoch 259/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 247us/step - loss: 36419954521.2819 - val_loss: 37497654173.8082\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36414807691.9554 - val_loss: 37492467964.4931\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36409664979.6881 - val_loss: 37487280240.2192\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36404526596.8260 - val_loss: 37482079274.0822\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36399381996.2571 - val_loss: 37476889922.6301\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36394242837.7172 - val_loss: 37471721556.1644\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36389099426.9889 - val_loss: 37466531755.8356\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36383964840.0343 - val_loss: 37461280178.8493\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36378782161.0557 - val_loss: 37456092005.6986\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36373650673.3025 - val_loss: 37450890815.1233\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36368516725.1414 - val_loss: 37445692093.3699\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36363371208.5004 - val_loss: 37440529618.4110\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36358231825.3299 - val_loss: 37435357997.5890\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36353113188.9083 - val_loss: 37430156582.5753\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36347975021.9023 - val_loss: 37424993883.1781\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36342831395.3179 - val_loss: 37419799032.9863\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36337682840.8980 - val_loss: 37414648228.8219\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36332569081.4190 - val_loss: 37409404619.3973\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36327413933.7378 - val_loss: 37404236926.2466\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36322267120.2057 - val_loss: 37399056215.6712\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 36317144593.1105 - val_loss: 37393850255.7808\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36312007049.1037 - val_loss: 37388702537.6438\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36306888967.2391 - val_loss: 37383502300.9315\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 36301742188.8055 - val_loss: 37378355256.1096\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36296630752.8500 - val_loss: 37373142001.9726\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36291493768.6650 - val_loss: 37367950350.0274\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36286346165.4156 - val_loss: 37362801958.5753\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36281229922.7147 - val_loss: 37357618105.8630\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36276085910.0463 - val_loss: 37352403505.0959\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36270953609.7618 - val_loss: 37347220718.4658\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36265826140.7918 - val_loss: 37342053923.0685\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36260716063.1500 - val_loss: 37336876579.0685\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36255573484.2571 - val_loss: 37331739409.5342\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36250453226.2828 - val_loss: 37326506965.9178\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36245300365.2716 - val_loss: 37321396167.8904\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36240192421.6213 - val_loss: 37316161760.4384\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36235063878.6358 - val_loss: 37310972128.4384\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36229932043.4070 - val_loss: 37305803930.3014\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36224804581.4567 - val_loss: 37300599317.0411\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36219663954.0428 - val_loss: 37295469890.6301\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36214559337.7344 - val_loss: 37290272739.9452\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36209424078.6427 - val_loss: 37285109535.5616\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36204313581.5733 - val_loss: 37279950932.1644\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36199197549.4636 - val_loss: 37274787615.5616\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36194080402.9752 - val_loss: 37269625308.9315\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36188970758.8003 - val_loss: 37264434105.8630\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36183820054.5947 - val_loss: 37259303052.2740\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36178706607.4927 - val_loss: 37254086824.3288\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36173576018.2622 - val_loss: 37248916325.6986\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36168465096.5004 - val_loss: 37243720633.8630\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36163333740.3668 - val_loss: 37238573140.1644\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36158227646.4096 - val_loss: 37233417454.4658\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36153112465.4396 - val_loss: 37228241513.2055\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36147989039.8218 - val_loss: 37223084032.0000\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36142873855.3419 - val_loss: 37217873976.1096\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36137743181.8749 - val_loss: 37212752966.1370\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36132629762.8518 - val_loss: 37207592679.4521\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36127516654.4507 - val_loss: 37202380323.0685\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36122391075.5373 - val_loss: 37197232604.9315\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36117283753.1311 - val_loss: 37192073103.7808\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36112177306.4336 - val_loss: 37186916295.8904\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36107069568.1097 - val_loss: 37181765435.6164\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36101961087.4516 - val_loss: 37176594488.1096\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36096839739.6675 - val_loss: 37171463378.4110\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36091744656.1234 - val_loss: 37166295685.2603\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36086628704.7404 - val_loss: 37161114750.2466\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36081514371.4002 - val_loss: 37155955641.8630\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36076391449.4464 - val_loss: 37150796589.5890\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36071294519.7189 - val_loss: 37145628391.4521\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36066187707.9966 - val_loss: 37140466758.1370\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36061061009.4396 - val_loss: 37135335480.1096\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36055966892.8603 - val_loss: 37130164083.7260\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36050849756.9015 - val_loss: 37125011147.3973\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36045751152.9734 - val_loss: 37119852039.0137\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36040645327.5201 - val_loss: 37114682045.3699\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36035530141.2853 - val_loss: 37109530680.1096\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 36030408038.8826 - val_loss: 37104350923.3973\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36025288042.3925 - val_loss: 37099204103.0137\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36020182773.2511 - val_loss: 37094054140.4931\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36015077832.2811 - val_loss: 37088886840.1096\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36009970546.7284 - val_loss: 37083726609.5342\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36004866179.6195 - val_loss: 37078559589.6986\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35999757114.5707 - val_loss: 37073407719.4521\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 35994657141.7995 - val_loss: 37068249340.4931\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35989544349.2853 - val_loss: 37063137420.2740\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35984452171.9006 - val_loss: 37057950481.5342\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 35979335090.3445 - val_loss: 37052804166.1370\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35974242051.2905 - val_loss: 37047664696.1096\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35969122398.7661 - val_loss: 37042488025.4247\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35964023993.1448 - val_loss: 37037292277.4795\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 35958906844.9015 - val_loss: 37032160494.4658\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35953812694.9786 - val_loss: 37027038362.3014\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35948723669.4430 - val_loss: 37021897208.9863\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35943625869.2716 - val_loss: 37016731311.3425\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35938517441.2614 - val_loss: 37011590943.5616\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35933419521.7549 - val_loss: 37006443225.4247\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35928322862.2862 - val_loss: 37001298424.9863\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35923230899.0026 - val_loss: 36996116592.2192\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 35918111632.5621 - val_loss: 36990960008.7671\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35912997932.7506 - val_loss: 36985822502.5753\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35907907494.4987 - val_loss: 36980661149.8082\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35902813186.6324 - val_loss: 36975506361.8630\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35897707810.4404 - val_loss: 36970397808.2192\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35892624390.1422 - val_loss: 36965209578.9589\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35887507780.6615 - val_loss: 36960097097.6438\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35882401549.8200 - val_loss: 36954953531.6164\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35877304241.0283 - val_loss: 36949805589.0411\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35872211302.0051 - val_loss: 36944665614.0274\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35867123887.4927 - val_loss: 36939525863.4521\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35862041369.2271 - val_loss: 36934352671.5616\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35856934506.6118 - val_loss: 36929213145.4247\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35851843320.7609 - val_loss: 36924054766.4658\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35846749421.7926 - val_loss: 36918922534.5753\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35841644092.9837 - val_loss: 36913796194.1918\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35836550499.3727 - val_loss: 36908629623.2329\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35831462735.6298 - val_loss: 36903483700.6027\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 35826379034.5433 - val_loss: 36898340527.3425\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35821295631.7943 - val_loss: 36893202852.8219\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35816205391.8492 - val_loss: 36888106587.1781\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35811131095.4173 - val_loss: 36882930870.3562\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35806033077.6350 - val_loss: 36877802958.9041\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 35800944176.6992 - val_loss: 36872693283.0685\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35795864071.4584 - val_loss: 36867565203.2877\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35790777920.4936 - val_loss: 36862427977.6438\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35785704459.4070 - val_loss: 36857280652.2740\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35780618383.9040 - val_loss: 36852153245.8082\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35775528967.0197 - val_loss: 36847042784.4384\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35770445692.3805 - val_loss: 36841861176.1096\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 251us/step - loss: 35765347483.3111 - val_loss: 36836729617.5342\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35760273351.8423 - val_loss: 36831582572.7123\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35755194403.0985 - val_loss: 36826471101.3699\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35750124121.9400 - val_loss: 36821362547.7260\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35745035900.1611 - val_loss: 36816217578.9589\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35739942648.7609 - val_loss: 36811075527.8904\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35734834733.1894 - val_loss: 36805947392.0000\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35729741021.9983 - val_loss: 36800814711.2329\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35724663213.9572 - val_loss: 36795629904.6575\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35719579098.7078 - val_loss: 36790486058.0822\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35714489130.7764 - val_loss: 36785385023.1233\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35709415539.8252 - val_loss: 36780254811.1781\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35704327802.4062 - val_loss: 36775135260.0548\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35699258725.1277 - val_loss: 36769954100.6027\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 35694158269.7515 - val_loss: 36764865185.3151\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35689083655.6778 - val_loss: 36759717467.1781\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35683996683.4070 - val_loss: 36754556226.6301\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35678904488.4730 - val_loss: 36749473258.9589\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35673836708.0857 - val_loss: 36744308595.7260\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 35668745008.0411 - val_loss: 36739190503.4521\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35663668275.7703 - val_loss: 36734087672.9863\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35658611556.6889 - val_loss: 36728949942.3562\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 35653520755.1671 - val_loss: 36723832691.7260\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35648457407.7258 - val_loss: 36718686881.3151\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 35643369354.4199 - val_loss: 36713566881.3151\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35638291914.9135 - val_loss: 36708435547.1781\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35633221717.9914 - val_loss: 36703280254.2466\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35628150201.3642 - val_loss: 36698189094.5753\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35623083852.9974 - val_loss: 36693123801.4247\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35618030750.8209 - val_loss: 36687977822.6849\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35612937648.5895 - val_loss: 36682865678.0274\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35607880897.9194 - val_loss: 36677730696.7671\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35602806747.1465 - val_loss: 36672601887.5616\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35597713997.6555 - val_loss: 36667485141.9178\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35592657273.3093 - val_loss: 36662336638.2466\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35587587899.4482 - val_loss: 36657225166.9041\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35582514327.8012 - val_loss: 36652158471.0137\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35577454069.0317 - val_loss: 36647006937.4247\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35572397202.5364 - val_loss: 36641883570.8493\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35567322527.0403 - val_loss: 36636799817.6438\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35562259679.7532 - val_loss: 36631674655.5616\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35557192122.2416 - val_loss: 36626551906.1918\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35552137461.6898 - val_loss: 36621415353.8630\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35547059857.2202 - val_loss: 36616313196.7123\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35542006239.0951 - val_loss: 36611180010.9589\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35536926546.2622 - val_loss: 36606071906.1918\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35531850363.2836 - val_loss: 36601003022.0274\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35526801437.8338 - val_loss: 36595833589.4795\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35521726370.9889 - val_loss: 36590710952.3288\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35516652451.8663 - val_loss: 36585583938.6301\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35511587179.2699 - val_loss: 36580473308.9315\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35506514967.6915 - val_loss: 36575421874.8493\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35501458917.2374 - val_loss: 36570268209.0959\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35496384141.7104 - val_loss: 36565162909.8082\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35491323591.6230 - val_loss: 36560048184.1096\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35486271693.3265 - val_loss: 36554930933.4795\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35481207020.9152 - val_loss: 36549830066.8493\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35476159750.3616 - val_loss: 36544724038.1370\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35471099326.6290 - val_loss: 36539629343.5616\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35466039962.8723 - val_loss: 36534491164.0548\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35460967370.4747 - val_loss: 36529409935.7808\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35455926868.6752 - val_loss: 36524283819.8356\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35450855652.1405 - val_loss: 36519173919.5616\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35445799019.0506 - val_loss: 36514044829.8082\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 35440737542.3616 - val_loss: 36508967473.0959\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35435686112.6307 - val_loss: 36503862342.1370\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35430633749.2785 - val_loss: 36498744362.0822\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 35425568773.2648 - val_loss: 36493643776.0000\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 35420499499.4344 - val_loss: 36488551606.3562\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35415457114.5981 - val_loss: 36483418196.1644\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35410388198.7729 - val_loss: 36478330403.0685\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35405338076.4627 - val_loss: 36473246369.3151\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35400300394.8312 - val_loss: 36468112622.4658\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35395242656.1371 - val_loss: 36463035882.9589\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35390190262.9512 - val_loss: 36457930471.4521\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35385126452.2091 - val_loss: 36452814848.0000\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35380059610.7078 - val_loss: 36447673021.3699\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35375006833.1928 - val_loss: 36442592690.8493\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 35369961266.6735 - val_loss: 36437487784.3288\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 35364904931.9212 - val_loss: 36432412223.1233\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35359863742.1902 - val_loss: 36427293401.4247\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35354813912.9529 - val_loss: 36422182098.4110\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35349770341.7858 - val_loss: 36417079885.1507\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35344718038.1011 - val_loss: 36412013357.5890\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35339678250.5570 - val_loss: 36406943126.7945\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35334641802.6392 - val_loss: 36401811736.5479\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35329583965.6692 - val_loss: 36396711150.4658\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35324544636.1611 - val_loss: 36391580265.2055\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35319490112.4936 - val_loss: 36386519516.9315\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35314464320.4936 - val_loss: 36381420501.9178\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35309412906.5570 - val_loss: 36376320084.1644\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 35304359018.1731 - val_loss: 36371239304.7671\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35299298892.7781 - val_loss: 36366150108.9315\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35294251901.2579 - val_loss: 36361055414.3562\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35289203860.2913 - val_loss: 36355958419.2877\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35284155377.0831 - val_loss: 36350857384.3288\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35279121379.0437 - val_loss: 36345714603.8356\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 35274053514.4199 - val_loss: 36340652733.3699\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35268997516.6135 - val_loss: 36335577396.6027\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35263954041.9674 - val_loss: 36330432371.7260\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35258905032.2811 - val_loss: 36325316074.9589\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35253852137.1859 - val_loss: 36320239111.0137\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35248827009.4259 - val_loss: 36315141218.1918\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35243785880.2399 - val_loss: 36310123057.0959\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35238769633.2888 - val_loss: 36305036835.0685\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35233713653.0317 - val_loss: 36299925027.0685\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35228673009.0831 - val_loss: 36294811872.4384\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 35223626945.9194 - val_loss: 36289734010.7397\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35218598988.3393 - val_loss: 36284617657.8630\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35213552433.7961 - val_loss: 36279574752.4384\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35208533231.5476 - val_loss: 36274484378.3014\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35203491476.7301 - val_loss: 36269369877.0411\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35198437047.8286 - val_loss: 36264309970.4110\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35193409967.7121 - val_loss: 36259218025.2055\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0005)\n",
    "NN_5000E_Adam_Sig.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_Sig.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,220,609\n",
      "Trainable params: 1,220,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_4H = Sequential()\n",
    "NN_5000E_Adam_4H.add(Dense(512,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(1))\n",
    "NN_5000E_Adam_4H.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 1s 564us/step - loss: 36522277088.6307 - val_loss: 31151011924.1644\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 20591323523.4002 - val_loss: 10548069663.5616\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 14787735020.2571 - val_loss: 9263632727.6712\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 12293208674.7147 - val_loss: 7920128925.8082\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 9516187921.4396 - val_loss: 5965733312.8767\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 6733085789.2853 - val_loss: 4627476713.2055\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 4693404259.3728 - val_loss: 4056714520.5479\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 3240308142.8346 - val_loss: 3607858887.8904\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 2409489225.2956 - val_loss: 3407602991.3425\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 2126030431.5338 - val_loss: 3345038679.6712\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 1923661741.2991 - val_loss: 3390656392.7671\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1856447810.9066 - val_loss: 3235776711.8904\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1840494072.1028 - val_loss: 3213287765.9178\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1782692888.1302 - val_loss: 3306326983.8904\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1750170984.5004 - val_loss: 3425477902.0274\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 417us/step - loss: 1759172968.4730 - val_loss: 3297372075.8356\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1739661912.5141 - val_loss: 3182036495.7808\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1700264707.7292 - val_loss: 3237325718.7945\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1689910471.8423 - val_loss: 3233075962.7397\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1677819253.6898 - val_loss: 3279000328.7671\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1672347774.7935 - val_loss: 3259854074.7397\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1654582417.7686 - val_loss: 3256749399.6712\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1636965410.5501 - val_loss: 3173431262.6849\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1677840963.1260 - val_loss: 3256274823.0137\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1653054868.7301 - val_loss: 3350165290.0822\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 1s 455us/step - loss: 1613606679.4722 - val_loss: 3368744814.4658\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1626568677.2922 - val_loss: 3261663114.5205\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1598763332.2228 - val_loss: 3400512554.0822\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1600926150.6358 - val_loss: 3133992418.1918\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1589578693.8680 - val_loss: 3169283257.8630\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 1558678889.7344 - val_loss: 3343467656.7671\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 1577731098.2416 - val_loss: 3109704747.8356\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1572402602.5570 - val_loss: 3108685816.9863\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1556857881.7755 - val_loss: 3194043000.9863\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1531136180.0171 - val_loss: 3077415045.2603\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1559198172.5724 - val_loss: 3153962674.8493\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1611650858.1731 - val_loss: 3321784872.3288\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1597638399.6710 - val_loss: 3112523512.9863\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1533095930.1868 - val_loss: 3112745910.3562\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1507373505.8098 - val_loss: 3048931233.3151\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 1505514252.2296 - val_loss: 3165863196.0548\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1541081999.5750 - val_loss: 3124507476.1644\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1483151867.5030 - val_loss: 3368232248.1096\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1506677220.6341 - val_loss: 3230176112.2192\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1464773561.9949 - val_loss: 3109345416.7671\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1473269284.3599 - val_loss: 3029772579.0685\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1474278194.2896 - val_loss: 3350865646.4658\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1468301756.8740 - val_loss: 3040980655.3425\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1444248563.2219 - val_loss: 3273193668.3836\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 1441196837.0180 - val_loss: 3289186696.7671\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1465705852.3805 - val_loss: 3054998640.2192\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1445793033.4327 - val_loss: 3009686117.6986\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1448398886.1697 - val_loss: 3376718620.0548\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1442741500.4901 - val_loss: 3039573184.8767\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 1419594656.2468 - val_loss: 3103301109.4795\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1412442016.7952 - val_loss: 3072513343.1233\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1392019265.3710 - val_loss: 2961614932.1644\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1446132969.9263 - val_loss: 2986880175.3425\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1397039893.0591 - val_loss: 2973036999.8904\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 1436366527.5613 - val_loss: 3078874971.1781\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1374469245.4773 - val_loss: 2989103146.0822\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1401208453.1551 - val_loss: 3078489358.0274\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1404507123.8252 - val_loss: 2962517556.6027\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1373522788.4696 - val_loss: 3419958615.6712\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 1s 492us/step - loss: 1412739832.3222 - val_loss: 3066478935.6712\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1385106021.9777 - val_loss: 3052150110.6849\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1385407327.5338 - val_loss: 3518912722.4110\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1387324834.6598 - val_loss: 3015115821.5890\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1360344916.7575 - val_loss: 3181765951.1233\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 414us/step - loss: 1356330097.4670 - val_loss: 2938336606.6849\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1418422828.9152 - val_loss: 3055152359.4521\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 408us/step - loss: 1389436894.1354 - val_loss: 3155283982.0274\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 1375963933.8338 - val_loss: 3211531123.7260\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1515055199.0951 - val_loss: 2916702348.2740\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1378849899.9554 - val_loss: 2923911280.2192\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 413us/step - loss: 1347275776.6581 - val_loss: 2924796110.9041\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 1422471533.0797 - val_loss: 2990133830.1370\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1365481410.7969 - val_loss: 2926225425.5342\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1343566834.6187 - val_loss: 3069888519.0137\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1397603578.7901 - val_loss: 2906680456.7671\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1361736407.0883 - val_loss: 3027433657.8630\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1297740856.8706 - val_loss: 2982782909.3699\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1337794199.0883 - val_loss: 2964935013.6986\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1344212505.8852 - val_loss: 2905368421.6986\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1337217342.8483 - val_loss: 3134342459.6164\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1304985361.0009 - val_loss: 3129265088.8767\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1320477071.2459 - val_loss: 2910153934.9041\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 1357981463.9657 - val_loss: 3150098537.2055\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1373008714.5844 - val_loss: 3004727278.4658\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1327203684.3599 - val_loss: 2886679432.7671\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1354050444.8329 - val_loss: 2916040125.3699\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1443282470.4987 - val_loss: 2858416924.0548\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1274284851.5510 - val_loss: 3335619359.5616\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1332225653.0865 - val_loss: 2850390545.5342\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1297488776.7198 - val_loss: 3218708767.5616\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1288654257.4670 - val_loss: 2883222969.8630\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1315380586.3925 - val_loss: 2911319446.7945\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1277727962.2691 - val_loss: 3091833638.5753\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1351574174.6015 - val_loss: 2860897763.9452\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1283803369.4053 - val_loss: 2917407512.5479\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1269597817.5287 - val_loss: 2836882137.4247\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1277439467.7635 - val_loss: 3185674250.5205\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 1328414660.8260 - val_loss: 2819263295.1233\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1267059175.5955 - val_loss: 3268857722.7397\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1286872024.7335 - val_loss: 2884893134.9041\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1269414652.7644 - val_loss: 2836079342.4658\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1277289148.8740 - val_loss: 3226905796.3836\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1337045110.6769 - val_loss: 2912508700.0548\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1257782190.2314 - val_loss: 2805235824.2192\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 411us/step - loss: 1253752236.4216 - val_loss: 3031019754.9589\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1265631103.5613 - val_loss: 2966189385.6438\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1254794863.3282 - val_loss: 3039772307.2877\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 1273395907.7841 - val_loss: 3015003164.0548\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1253965045.6350 - val_loss: 2833160090.3014\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1248249266.6598 - val_loss: 2793115721.6438\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1235316038.3068 - val_loss: 2814190970.7397\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1242431011.5921 - val_loss: 2917721915.6164\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1215784993.4533 - val_loss: 2791357678.4658\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1227567860.0583 - val_loss: 2799876092.4932\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1204748677.7035 - val_loss: 2772784054.3562\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1241430347.6812 - val_loss: 2829291463.8904\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1203923034.9820 - val_loss: 2980978354.8493\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 1227110923.5167 - val_loss: 2726641320.3288\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1224827167.3693 - val_loss: 2758921773.5890\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1216114306.7695 - val_loss: 2849170474.0822\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1208462259.2219 - val_loss: 2765550206.2466\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1178334835.6058 - val_loss: 3064930535.4521\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1242277517.9846 - val_loss: 2776714061.1507\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1168476084.4284 - val_loss: 2790439487.1233\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1180584411.1465 - val_loss: 2937083875.9452\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1196678562.0566 - val_loss: 2905820500.1644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1228621927.9246 - val_loss: 2713756279.2329\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 410us/step - loss: 1170014581.2511 - val_loss: 2879766373.6986\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1151639312.4524 - val_loss: 2739778556.4932\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1161729214.9032 - val_loss: 2823046936.5479\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1136940189.0660 - val_loss: 2735173772.2740\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1374524349.3402 - val_loss: 2740995797.9178\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1256290006.7592 - val_loss: 2676047721.2055\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1219013163.5441 - val_loss: 3056892068.8219\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1175807710.8209 - val_loss: 2801659167.5616\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1141791732.3188 - val_loss: 2757831231.1233\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 1127327780.1680 - val_loss: 2737458295.2329\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1209805676.1474 - val_loss: 3516409617.5342\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1162274225.1380 - val_loss: 2675946969.4247\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1152418114.4130 - val_loss: 2801360590.9041\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1134924492.1200 - val_loss: 2961354320.6575\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1133271640.2674 - val_loss: 2716638965.4795\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1167033444.5793 - val_loss: 2647884600.1096\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1125002850.0566 - val_loss: 2801871847.4521\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1130881244.7918 - val_loss: 2723554237.3699\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1104355664.7266 - val_loss: 2765979483.1781\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 1s 455us/step - loss: 1124271407.1637 - val_loss: 2821367613.3699\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 1114570797.5733 - val_loss: 3038661454.9041\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1147617141.0317 - val_loss: 2604635970.6301\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1111880157.6692 - val_loss: 3401820396.7123\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1170500358.4713 - val_loss: 2696339080.7671\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1086342238.9032 - val_loss: 2697793108.1644\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1108077620.6478 - val_loss: 2832108351.1233\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1104968992.8775 - val_loss: 2569963520.0000\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1103239603.8800 - val_loss: 2687750305.3151\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1120879070.4370 - val_loss: 2821650165.4795\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1129409480.7198 - val_loss: 2820961201.0959\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1197193376.5210 - val_loss: 2704260963.9452\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1163431229.3128 - val_loss: 2805474561.7534\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1068764773.4019 - val_loss: 2606075844.3836\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1049542469.6761 - val_loss: 2823917047.2329\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1102754081.4259 - val_loss: 2579630518.3562\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1079847800.1851 - val_loss: 2649085930.9589\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1125941684.7849 - val_loss: 2754391592.3288\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1065836692.9494 - val_loss: 2620755960.9863\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1030397758.6290 - val_loss: 2701324843.8356\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1029007056.8912 - val_loss: 2569067470.9041\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1057597332.0720 - val_loss: 2654585500.0548\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1112998012.1611 - val_loss: 2549296867.9452\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1046072091.4207 - val_loss: 2772417765.6986\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1060361687.9109 - val_loss: 2562131704.9863\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1083178665.1585 - val_loss: 2557425727.1233\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1038767162.1868 - val_loss: 2552461753.8630\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1058269719.6915 - val_loss: 2641547583.1233\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1017577372.6547 - val_loss: 2596697991.0137\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1033077963.7087 - val_loss: 2538548981.4795\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1006965434.2965 - val_loss: 2590699842.6301\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1018358084.7164 - val_loss: 2573801826.1918\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1003363456.4936 - val_loss: 2688863068.9315\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 412us/step - loss: 1014420952.3496 - val_loss: 2551687518.6849\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 1018725788.8466 - val_loss: 2528942500.8219\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1052294238.1080 - val_loss: 2584050958.0274\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1031049205.5253 - val_loss: 2567224334.0274\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1025497806.8620 - val_loss: 2614238016.8767\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1003398974.9580 - val_loss: 2518541908.1644\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1057644201.5150 - val_loss: 2615751445.0411\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 981876905.2408 - val_loss: 2585163630.4658\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 1s 451us/step - loss: 1028487203.5373 - val_loss: 2502089194.9589\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1019378153.5698 - val_loss: 2575126538.5205\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 1s 446us/step - loss: 1022293632.3839 - val_loss: 2593028273.0959\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 976082292.1817 - val_loss: 2573779561.2055\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1023460718.6701 - val_loss: 2541961191.4521\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 980955752.5278 - val_loss: 2521318952.3288\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 965736293.1277 - val_loss: 2500116050.4110\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 970083816.7472 - val_loss: 2444630431.5616\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1067123853.9023 - val_loss: 2674072440.9863\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 983837678.5878 - val_loss: 2897060513.3151\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1115245671.2665 - val_loss: 2622692625.5342\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 975434417.5767 - val_loss: 2688465379.9452\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 983308236.1200 - val_loss: 2503049694.6849\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 951119468.0925 - val_loss: 2766748196.8219\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 997028387.5373 - val_loss: 2981307234.1918\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1028715966.8209 - val_loss: 2464263634.4110\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 958872795.0368 - val_loss: 2495568682.0822\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 985832051.2768 - val_loss: 2447847767.6712\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 957202617.5287 - val_loss: 2474049039.7808\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 977453249.3710 - val_loss: 2503193084.4932\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 924376434.8380 - val_loss: 2492283058.8493\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 945514387.5784 - val_loss: 2546149814.3562\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 955767238.1422 - val_loss: 2794607095.2329\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 1s 457us/step - loss: 931387452.5450 - val_loss: 2565829263.7808\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 922580138.2965 - val_loss: 2511601230.9041\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1012442514.9203 - val_loss: 2570016177.0959\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 920826590.2177 - val_loss: 2515948172.2740\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 910687443.0848 - val_loss: 2527533694.2466\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 946499936.6307 - val_loss: 2582226616.1096\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 944178932.6478 - val_loss: 2501055575.6712\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 948697753.0077 - val_loss: 2560802458.3014\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 900709444.2228 - val_loss: 2679332709.6986\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 911544116.8535 - val_loss: 2415079790.4658\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 908810597.2922 - val_loss: 2644379144.7671\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 906620429.2716 - val_loss: 2421240640.8767\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 894227365.2374 - val_loss: 2449338320.6575\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 865456966.4165 - val_loss: 2567168552.3288\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 918058290.1251 - val_loss: 2475005134.9041\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 893168682.9957 - val_loss: 2458523854.9041\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 959278870.4850 - val_loss: 2403692305.5342\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 890078937.2819 - val_loss: 2483831921.9726\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 898361193.2134 - val_loss: 2510960057.8630\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 1s 452us/step - loss: 970780942.3685 - val_loss: 2408832478.6849\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 943779464.6650 - val_loss: 2549861414.5753\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 984472130.1114 - val_loss: 2493290639.7808\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 994768016.8912 - val_loss: 2533802001.5342\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 878162922.3925 - val_loss: 2454324343.2329\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 877589596.6821 - val_loss: 2380361147.6164\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 911282183.6778 - val_loss: 2781867688.3288\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 961077939.0848 - val_loss: 2482427535.7808\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 901307280.8363 - val_loss: 2374933109.4795\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 839346405.7858 - val_loss: 2508189897.6438\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 846065842.2348 - val_loss: 2416079793.0959\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 876929966.2588 - val_loss: 2405825460.6027\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 881971499.5990 - val_loss: 2461471552.8767\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1026497828.0308 - val_loss: 2580763316.6027\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 940188732.6547 - val_loss: 2563567966.6849\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1033726922.0360 - val_loss: 2387850588.9315\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 871534964.1817 - val_loss: 2429442842.3014\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 909385648.9186 - val_loss: 2562697219.5068\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 866050949.8132 - val_loss: 2507730016.4384\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 840345883.2014 - val_loss: 2462088819.7260\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 887160160.9049 - val_loss: 2387740046.0274\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 885163780.9632 - val_loss: 2568999688.7671\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 881363563.9829 - val_loss: 2421478305.3151\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 831474608.9460 - val_loss: 2423309382.1370\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 832505091.6744 - val_loss: 2431839032.1096\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 846284255.7806 - val_loss: 2414436655.3425\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 821298057.5424 - val_loss: 2397715456.0000\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 876104139.5716 - val_loss: 2587999116.2740\n",
      "Epoch 263/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 426us/step - loss: 809903481.3093 - val_loss: 2481664671.5616\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 817842361.8578 - val_loss: 2401059868.0548\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 827466964.1542 - val_loss: 2538248945.9726\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 820705424.0686 - val_loss: 2347676878.9041\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 825997942.4850 - val_loss: 2434173759.1233\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 895748078.3959 - val_loss: 2428477632.8767\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 822585974.5124 - val_loss: 2452980557.1507\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 801043098.4884 - val_loss: 2391332821.9178\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 886114413.7652 - val_loss: 2459997108.6027\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 839023465.8440 - val_loss: 2453516280.9863\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 808831226.3513 - val_loss: 2446906611.7260\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 806534559.4516 - val_loss: 2489390183.4521\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 806042001.1654 - val_loss: 2429343568.6575\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 814260592.5347 - val_loss: 2389523440.2192\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 787634547.3865 - val_loss: 2407609998.0274\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 784523957.5527 - val_loss: 2423837594.3014\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 795087403.8732 - val_loss: 2404417618.4110\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 789063277.5733 - val_loss: 2452517842.4110\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 839851849.6247 - val_loss: 2455173042.8493\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 841785062.7181 - val_loss: 2529570693.2603\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 914266457.2819 - val_loss: 2575414896.2192\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 831771568.6992 - val_loss: 2453789255.8904\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 790015239.2391 - val_loss: 2360814688.4384\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 788207536.3702 - val_loss: 2400364689.5342\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 842039451.2014 - val_loss: 2380899142.1370\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 417us/step - loss: 803941542.1148 - val_loss: 2440020427.3973\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 769553763.8663 - val_loss: 2453919742.2466\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 800665857.0831 - val_loss: 2360788118.7945\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 866723271.1842 - val_loss: 2336134550.7945\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 786412193.4533 - val_loss: 2469033186.1918\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 774387014.5810 - val_loss: 2501145656.1096\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 759279214.9443 - val_loss: 2388313345.7534\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 768833315.2356 - val_loss: 2368530628.3836\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 417us/step - loss: 745396218.1868 - val_loss: 2483869504.8767\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 740539419.3659 - val_loss: 2339098997.4795\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 414us/step - loss: 770241684.8398 - val_loss: 2390654704.2192\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 747615910.5261 - val_loss: 2397503480.9863\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 793495796.1817 - val_loss: 2334234552.1096\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 801730959.5201 - val_loss: 2345727675.6164\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 747542744.1851 - val_loss: 2498170655.5616\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 1s 480us/step - loss: 790751367.3488 - val_loss: 2389159960.5479\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 743665199.4379 - val_loss: 2553739458.6301\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 762377482.5844 - val_loss: 2390248981.0411\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 750283890.0428 - val_loss: 2323665294.0274\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 787193796.1131 - val_loss: 2705346779.1781\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 815940878.4233 - val_loss: 2566856213.0411\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 415us/step - loss: 784603573.2237 - val_loss: 2365077779.2877\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 724795739.8320 - val_loss: 2409498073.4247\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 765429001.7069 - val_loss: 2467798670.0274\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 772722542.5056 - val_loss: 2446749320.7671\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 851150413.6555 - val_loss: 2352762944.8767\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 764232299.9143 - val_loss: 2384771352.5479\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 742819693.8201 - val_loss: 2428034414.4658\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 715300996.8260 - val_loss: 2491498972.9315\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 733766702.9991 - val_loss: 2359009779.7260\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 694370764.8329 - val_loss: 2477721403.6164\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 742151629.6281 - val_loss: 2688429918.6849\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 749009446.8826 - val_loss: 2313789971.2877\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 706460612.0034 - val_loss: 2383975294.2466\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 727507675.3111 - val_loss: 2582766311.4521\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 821800171.7087 - val_loss: 2506657118.6849\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 819613654.5947 - val_loss: 2310187758.4658\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 745200026.4336 - val_loss: 2436599951.7808\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 752391363.0163 - val_loss: 2345429190.1370\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 738840697.9400 - val_loss: 2316779960.1096\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 732201030.4713 - val_loss: 2504809985.7534\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 709335316.8398 - val_loss: 2438000248.9863\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 751711049.6247 - val_loss: 2343722653.8082\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 701395589.7035 - val_loss: 2370005360.2192\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 677976394.5844 - val_loss: 2420657094.1370\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 700541107.2219 - val_loss: 2480075974.1370\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 665851731.3316 - val_loss: 2451428702.6849\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 678998788.0308 - val_loss: 2371011647.1233\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 698614768.1508 - val_loss: 2317950434.1918\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 675414115.5647 - val_loss: 2542269987.0685\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 729897242.7626 - val_loss: 2656059246.4658\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 711171766.2382 - val_loss: 2323855822.9041\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 687465815.4447 - val_loss: 2380172303.7808\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 667565321.4602 - val_loss: 2360235961.8630\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 672494633.0763 - val_loss: 2280649303.6712\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 653599729.9606 - val_loss: 2542033481.6438\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 652296081.4944 - val_loss: 2357716036.3836\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 698488538.9820 - val_loss: 2469881154.6301\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 699070963.6058 - val_loss: 2367242375.0137\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 666605859.0985 - val_loss: 2313763520.8767\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 641228013.9023 - val_loss: 2376246275.5068\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 648157152.9871 - val_loss: 2290733813.4795\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 648029400.2399 - val_loss: 2482713542.1370\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 676783162.9546 - val_loss: 2253589304.1096\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 687731260.4353 - val_loss: 2551187357.8082\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 693525812.6478 - val_loss: 2263384802.1918\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 1s 457us/step - loss: 649249442.8243 - val_loss: 2436736422.5753\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 630722665.3505 - val_loss: 2339113026.6301\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 631198143.6984 - val_loss: 2449198979.5068\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 660726545.2202 - val_loss: 2276557955.5068\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 635180405.9914 - val_loss: 2411087189.9178\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 415us/step - loss: 646835009.1791 - val_loss: 2376843516.4932\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 635925468.1063 - val_loss: 2278746971.1781\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 730552981.5801 - val_loss: 2407490644.1644\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 660039041.1791 - val_loss: 2309187825.9726\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 624311635.0300 - val_loss: 2276247792.2192\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 651175797.7584 - val_loss: 2285672430.4658\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 625971637.5253 - val_loss: 2301243157.0411\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 651141655.4173 - val_loss: 2284701497.8630\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 610031888.0137 - val_loss: 2266322361.8630\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 614614797.6007 - val_loss: 2308266020.8219\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 634982278.9649 - val_loss: 2225863843.0685\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 607783560.9940 - val_loss: 2366102224.6575\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 608315344.6307 - val_loss: 2311168033.3151\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 637371135.3967 - val_loss: 2220983750.1370\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 704354636.6684 - val_loss: 2210336911.7808\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 662216000.7129 - val_loss: 2249227704.1096\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 671174157.4910 - val_loss: 2508978645.9178\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 681831503.8492 - val_loss: 2270667134.2466\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 801104037.2374 - val_loss: 2259342562.1918\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 600770757.0180 - val_loss: 2209300872.7671\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 606772524.9152 - val_loss: 2260240164.8219\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 598738966.7044 - val_loss: 2365470788.3836\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 581708820.7849 - val_loss: 2277087009.3151\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 589641918.3548 - val_loss: 2193358307.9452\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 594558691.2631 - val_loss: 2206415970.1918\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 656423462.5536 - val_loss: 2602849858.6301\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 639719073.6727 - val_loss: 2368870259.7260\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 646062660.7164 - val_loss: 2277231956.1644\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 612187533.1620 - val_loss: 2401172110.0274\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 590911884.9974 - val_loss: 2243274266.3014\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 584990705.1928 - val_loss: 2282490723.9452\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 599397960.3907 - val_loss: 2252540701.8082\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 615689960.3633 - val_loss: 2325972318.6849\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 577663039.8081 - val_loss: 2354439639.6712\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 593966307.3728 - val_loss: 2181883719.8904\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 552265748.2913 - val_loss: 2190654048.4384\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 419us/step - loss: 637857781.4156 - val_loss: 2214793082.7397\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 583126219.6264 - val_loss: 2182806457.8630\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 628089033.9263 - val_loss: 2403850236.4932\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 599288422.6358 - val_loss: 2366905063.4521\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 626103832.1302 - val_loss: 2407291341.1507\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 570548071.0746 - val_loss: 2214153749.0411\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 600729730.2211 - val_loss: 2782370617.8630\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 616668776.5553 - val_loss: 2386182559.5616\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 627390685.6144 - val_loss: 2224731155.2877\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 557893881.9400 - val_loss: 2292105396.6027\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 545144828.6547 - val_loss: 2192441014.3562\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 558283691.4344 - val_loss: 2155195441.0959\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 544811436.0377 - val_loss: 2201508706.1918\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 550698000.5621 - val_loss: 2233732707.9452\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 591090273.2065 - val_loss: 2172412410.7397\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 562197502.7935 - val_loss: 2129002520.5479\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 624774251.9280 - val_loss: 2283998595.5068\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 1s 458us/step - loss: 597099676.4353 - val_loss: 2149478075.6164\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 1s 467us/step - loss: 546849668.2228 - val_loss: 2303420338.8493\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 1s 472us/step - loss: 527472307.1945 - val_loss: 2259343105.7534\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 1s 469us/step - loss: 522604062.8483 - val_loss: 2153799485.3699\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 1s 465us/step - loss: 533793090.4267 - val_loss: 2258412345.8630\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 1s 475us/step - loss: 519035235.7841 - val_loss: 2166524107.3973\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 1s 461us/step - loss: 542402578.3171 - val_loss: 2244855183.7808\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 1s 469us/step - loss: 569013728.3016 - val_loss: 2332655921.0959\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 1s 459us/step - loss: 538103436.0925 - val_loss: 2310023907.9452\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 1s 462us/step - loss: 576505642.6941 - val_loss: 2210883284.1644\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 1s 459us/step - loss: 542632405.9366 - val_loss: 2129097684.1644\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 554214285.9023 - val_loss: 2197056727.6712\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 515045332.5656 - val_loss: 2158640757.4795\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 584308170.8997 - val_loss: 2138831093.4795\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 508733226.8860 - val_loss: 2285831792.2192\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 589167336.1440 - val_loss: 2079473627.1781\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 522222990.7524 - val_loss: 2168033316.8219\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 571651492.4696 - val_loss: 2291274958.9041\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 603015320.4593 - val_loss: 2229901936.2192\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 524343174.9786 - val_loss: 2101377988.3836\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 539728373.8543 - val_loss: 2122909390.9041\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 511874972.2228 - val_loss: 2186072272.6575\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 562759148.3119 - val_loss: 2117983684.3836\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 519693291.8183 - val_loss: 2158459200.8767\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 493881214.0805 - val_loss: 2166377168.6575\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 502078934.1834 - val_loss: 2098739897.8630\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 529026566.9923 - val_loss: 2395801175.6712\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 530601616.3016 - val_loss: 2187134965.4795\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 487350926.5330 - val_loss: 2291397042.8493\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 486936561.5767 - val_loss: 2138136269.1507\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 413us/step - loss: 493159076.7986 - val_loss: 2202595319.2329\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 531578425.1997 - val_loss: 2168301138.4110\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 415us/step - loss: 487667499.3796 - val_loss: 2122696525.1507\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 518301955.1260 - val_loss: 2126776128.8767\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 498038780.9837 - val_loss: 2188954511.7808\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 500780114.0017 - val_loss: 2085714360.1096\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 517685615.8355 - val_loss: 2329906233.8630\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 1s 447us/step - loss: 551063976.7061 - val_loss: 2312218701.1507\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 490981971.3590 - val_loss: 2148451112.3288\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 528969558.9237 - val_loss: 2170177642.9589\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 523604603.7361 - val_loss: 2373947397.2603\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 499428918.2382 - val_loss: 2314304887.2329\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 493898900.0171 - val_loss: 2212574897.0959\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 492465896.5827 - val_loss: 2152268365.1507\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 497642579.1397 - val_loss: 2111886814.6849\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 454758872.5141 - val_loss: 2128725640.7671\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 472131492.2502 - val_loss: 2209085664.4384\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 466152114.4267 - val_loss: 2141905867.3973\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 469449370.2416 - val_loss: 2094584314.7397\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 471798480.6718 - val_loss: 2066637643.3973\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 474862000.7266 - val_loss: 2130776227.0685\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 488551699.7429 - val_loss: 2306299700.6027\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 475858674.9751 - val_loss: 2053234994.8493\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 504993967.1088 - val_loss: 2120908228.3836\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 486189729.8509 - val_loss: 2164837248.0000\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 466126397.9434 - val_loss: 2137085981.8082\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 443284154.0771 - val_loss: 2146301299.7260\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 455077509.4567 - val_loss: 2115810872.1096\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 466901363.0643 - val_loss: 2240322144.4384\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 493800170.4473 - val_loss: 2065612896.4384\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 455589020.4353 - val_loss: 2319207637.9178\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 445601691.5030 - val_loss: 2126078651.6164\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 441519543.4996 - val_loss: 2352376386.6301\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 431745276.0788 - val_loss: 2092260366.0274\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 430217983.4516 - val_loss: 2081458086.5753\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 468114833.5561 - val_loss: 2017135800.1096\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 453311539.0574 - val_loss: 2151033261.5890\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 523021385.1585 - val_loss: 2098038508.7123\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 465422913.1928 - val_loss: 2426776540.9315\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 550481967.5201 - val_loss: 2151403662.0274\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 470275424.1371 - val_loss: 2125608796.9315\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 434303994.8175 - val_loss: 2263325247.1233\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 488932887.2734 - val_loss: 2025614132.6027\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 453335345.7686 - val_loss: 2259035151.7808\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 446069468.8055 - val_loss: 2068731272.7671\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 436329514.4747 - val_loss: 2057267622.5753\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 431849700.5244 - val_loss: 2130841768.3288\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 457425081.9949 - val_loss: 2139316381.8082\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 448494086.4987 - val_loss: 2002187051.8356\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 448693023.7532 - val_loss: 2117843424.4384\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 455686421.2374 - val_loss: 2070145285.2603\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 416661227.8183 - val_loss: 2164533696.8767\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 495962642.2622 - val_loss: 2005678027.3973\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 426483906.4953 - val_loss: 2140407115.3973\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 429844164.6067 - val_loss: 2062513083.6164\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 414us/step - loss: 433833588.0994 - val_loss: 2207829184.8767\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 607598219.4070 - val_loss: 1982930601.2055\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 430218705.5081 - val_loss: 1972770870.3562\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 399483474.8518 - val_loss: 2035059394.6301\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_5000E_Adam_4H.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_4H.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 32)                10592     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,737\n",
      "Trainable params: 12,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_32 = Sequential()\n",
    "NN_5000E_Adam_32.add(Dense(32,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_Adam_32.add(Dense(32,activation = 'relu'))\n",
    "NN_5000E_Adam_32.add(Dense(32,activation = 'relu'))\n",
    "NN_5000E_Adam_32.add(Dense(1))\n",
    "NN_5000E_Adam_32.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 38706398633.5698 - val_loss: 39777723770.7397\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 38636421785.1174 - val_loss: 39698240722.4110\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 38542318570.0634 - val_loss: 39589462240.4384\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 38415337147.3385 - val_loss: 39443433948.9315\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 38248806998.4302 - val_loss: 39249987275.3973\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 38010765052.2708 - val_loss: 38963096646.1370\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 37672731139.9486 - val_loss: 38570601149.3699\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 37220937980.7095 - val_loss: 38052890708.1644\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 36598502590.4096 - val_loss: 37321046773.4795\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 35805219818.0634 - val_loss: 36460606842.7397\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 34872381573.3745 - val_loss: 35419379571.7260\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 33742581523.0848 - val_loss: 34171426282.9589\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 32438129647.3282 - val_loss: 32714959409.0959\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 30893797028.5244 - val_loss: 30992828584.3288\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 29121939647.2871 - val_loss: 29113267073.7534\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 27253701934.7249 - val_loss: 27067186218.0822\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 25301668003.2082 - val_loss: 24952807003.1781\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 23338820777.3505 - val_loss: 22845223921.9726\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 21412865454.8346 - val_loss: 20753600960.8767\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 19594083869.3950 - val_loss: 18759517422.4658\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 17935180062.9306 - val_loss: 16933127967.5616\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 16475649507.4824 - val_loss: 15357747775.1233\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 15268909963.2973 - val_loss: 13884133572.3836\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 14237559091.1123 - val_loss: 12753926494.6849\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 13452300094.9580 - val_loss: 11853913466.7397\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 12808024805.4567 - val_loss: 11034024693.4795\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 12319047574.2656 - val_loss: 10391662409.6438\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 11900296191.1225 - val_loss: 9917871608.9863\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 11603727163.0094 - val_loss: 9430912631.2329\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 11313423176.6101 - val_loss: 9087031239.8904\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 11068894077.2579 - val_loss: 8854256345.4247\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 10853735214.2862 - val_loss: 8725884857.8630\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 10660931209.3231 - val_loss: 8466526853.2603\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 10486329650.2348 - val_loss: 8288456963.5068\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 10292422791.5681 - val_loss: 8086953212.4932\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 10128356060.6821 - val_loss: 7959175459.0685\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 9976599358.5193 - val_loss: 7823500351.1233\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 9809923101.8338 - val_loss: 7669834352.2192\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 9703149746.1251 - val_loss: 7552567930.7397\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 9534539733.4430 - val_loss: 7462937049.4247\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 9383754433.9195 - val_loss: 7324561692.0548\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 9245272851.7429 - val_loss: 7246285809.9726\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 9122447823.5201 - val_loss: 7161663526.5753\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 8975761924.6067 - val_loss: 7036752208.6575\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 8848736644.7164 - val_loss: 6965342043.1781\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 8735802418.6735 - val_loss: 6901014952.3288\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 8607325949.3676 - val_loss: 6790326380.7123\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 8477249712.1508 - val_loss: 6724546279.4521\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 8336319042.6872 - val_loss: 6644477012.1644\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 8235009435.5304 - val_loss: 6559246392.1096\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 8093321635.6470 - val_loss: 6502898835.2877\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 7982328565.4704 - val_loss: 6442004297.6438\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 7857201790.7935 - val_loss: 6377018550.3562\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 7735639634.9203 - val_loss: 6300772453.6986\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 7639975582.8209 - val_loss: 6226937982.2466\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 7512915052.8055 - val_loss: 6183156981.4795\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 7406318823.7601 - val_loss: 6127344668.0548\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 7282975436.4490 - val_loss: 6049111706.3014\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 7178417607.1842 - val_loss: 6007947253.4795\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 7063475700.1542 - val_loss: 5945050960.6575\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 6953709088.4662 - val_loss: 5879241931.3973\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 6847420000.0823 - val_loss: 5820818323.2877\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 6753905585.6864 - val_loss: 5772550256.2192\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 6623230864.3428 - val_loss: 5707564978.8493\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 6525066252.7232 - val_loss: 5657811810.1918\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 6425273773.0797 - val_loss: 5607142968.1096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 6317624499.0026 - val_loss: 5556530887.8904\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 6214892520.7472 - val_loss: 5502116827.1781\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 6116913004.8055 - val_loss: 5452863030.3562\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 6025396548.6615 - val_loss: 5398700131.9452\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 5953267253.3059 - val_loss: 5374689651.7260\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 5810141920.4113 - val_loss: 5317422718.2466\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 5734094331.1740 - val_loss: 5277504990.6849\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5636116918.2931 - val_loss: 5215588639.5616\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 5530374620.9015 - val_loss: 5179111062.7945\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 5449547373.6829 - val_loss: 5137831530.9589\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5341673511.0471 - val_loss: 5091163600.6575\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5265072582.7455 - val_loss: 5050199011.9452\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 5163992398.3136 - val_loss: 5004535776.4384\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5080508594.6187 - val_loss: 4963202773.9178\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4997120554.1183 - val_loss: 4926502570.0822\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4913954565.2648 - val_loss: 4888727716.8219\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4815495078.9374 - val_loss: 4849002865.9726\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4736895983.3282 - val_loss: 4811981357.5890\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 4650270387.4413 - val_loss: 4771804938.5205\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 4571201740.9974 - val_loss: 4734898526.6849\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4488653437.4773 - val_loss: 4699172348.4932\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 4418284794.2965 - val_loss: 4663280436.6027\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 4328052583.3213 - val_loss: 4628027493.6986\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 4247456842.1731 - val_loss: 4593235662.9041\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 4164169424.1782 - val_loss: 4560153840.2192\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 4087768613.5116 - val_loss: 4527197715.2877\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 4018893261.1071 - val_loss: 4496667085.1507\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 3943134419.2494 - val_loss: 4462239614.2466\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 3875217084.6547 - val_loss: 4430877392.6575\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 3805339698.2348 - val_loss: 4400140181.0411\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 3734887477.0865 - val_loss: 4373305508.8219\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 3670403773.6418 - val_loss: 4341492283.6164\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 3607399924.5930 - val_loss: 4312472546.1918\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3540711237.5390 - val_loss: 4283318605.1507\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3472353100.2296 - val_loss: 4259193168.6575\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 3411745480.3907 - val_loss: 4232893983.5616\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3361530084.5793 - val_loss: 4200075370.9589\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3285369875.8526 - val_loss: 4180581216.4384\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 3222169827.7018 - val_loss: 4155386408.3288\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3173382167.3076 - val_loss: 4120383561.6438\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 3103955209.4327 - val_loss: 4099355448.1096\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 3050930032.0960 - val_loss: 4077304104.3288\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2990750478.3685 - val_loss: 4043948764.9315\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2940906004.4010 - val_loss: 4018824591.7808\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 2882607095.2254 - val_loss: 4009177217.7534\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2830177688.1851 - val_loss: 3965381930.0822\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2774880382.2451 - val_loss: 3952398397.3699\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 2730119532.8055 - val_loss: 3926675943.4521\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2679935106.1388 - val_loss: 3909341378.6301\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2640372572.1337 - val_loss: 3888944827.6164\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2588194538.3925 - val_loss: 3874660306.4110\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 2547997006.2039 - val_loss: 3858030118.5753\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2508642872.2674 - val_loss: 3837574517.4795\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2469528089.4464 - val_loss: 3817418906.3014\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 2427632317.7515 - val_loss: 3798146256.6575\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 2396896891.3933 - val_loss: 3799322247.0137\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 2362590387.0026 - val_loss: 3763367294.2466\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 2318120108.4216 - val_loss: 3753669028.8219\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2286852517.0728 - val_loss: 3738668835.0685\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2254323046.0051 - val_loss: 3722019175.4521\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2222012521.0763 - val_loss: 3713085522.4110\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2191895375.5201 - val_loss: 3695300153.8630\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2167147673.6658 - val_loss: 3681623038.2466\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2139802497.3162 - val_loss: 3664703047.8904\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2113456239.4379 - val_loss: 3662482817.7534\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 2085059142.3068 - val_loss: 3639073692.0548\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 52us/step - loss: 2062470155.5167 - val_loss: 3629449210.7397\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2039034682.6804 - val_loss: 3611442688.0000\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 2017470409.5973 - val_loss: 3597317581.1507\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1994395819.6538 - val_loss: 3595217275.6164\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1974552403.7978 - val_loss: 3586392843.3973\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 1971996256.00 - 0s 55us/step - loss: 1957795174.6632 - val_loss: 3578731761.9726\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1939415341.8475 - val_loss: 3568260553.6438\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1922744864.3290 - val_loss: 3552882700.2740\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1905478207.0677 - val_loss: 3553967503.7808\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1890238106.9820 - val_loss: 3538871984.2192\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1877667966.3822 - val_loss: 3536281866.5205\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1864408960.0000 - val_loss: 3516147306.9589\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1850358573.8475 - val_loss: 3512954774.7945\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1837450442.4747 - val_loss: 3505507644.4932\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1829624468.3462 - val_loss: 3491177894.5753\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1815536968.9392 - val_loss: 3500005283.0685\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1807436928.2194 - val_loss: 3495819360.4384\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1795641924.9906 - val_loss: 3479796967.4521\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1787179761.4122 - val_loss: 3471683278.0274\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1780303638.4302 - val_loss: 3469492081.9726\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1771548038.4713 - val_loss: 3463687374.9041\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1764629664.7952 - val_loss: 3461038145.7534\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1757342492.6272 - val_loss: 3456917567.1233\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 1751547446.5124 - val_loss: 3453712243.7260\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1746295093.9640 - val_loss: 3448716894.6849\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1739427787.5716 - val_loss: 3440058282.9589\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1734687408.1508 - val_loss: 3435727543.2329\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1730488431.8766 - val_loss: 3425369769.2055\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1727635935.7532 - val_loss: 3436082506.5205\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1722694381.6829 - val_loss: 3414917388.2740\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1718910985.8166 - val_loss: 3423651845.2603\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1716679538.6735 - val_loss: 3415767932.4932\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1711951244.3942 - val_loss: 3426715008.8767\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1707524151.4996 - val_loss: 3415765361.0959\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1705556316.1337 - val_loss: 3410250505.6438\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1702480068.5518 - val_loss: 3415080218.3014\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1702778834.8106 - val_loss: 3395565839.7808\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1697179953.7961 - val_loss: 3407484970.9589\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1694956684.9426 - val_loss: 3413392680.3288\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1692443871.9177 - val_loss: 3410999443.2877\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1692344402.0428 - val_loss: 3384032043.8356\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1687718659.7292 - val_loss: 3402425109.9178\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1684760729.3368 - val_loss: 3401716743.0137\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 1681913474.6324 - val_loss: 3391241259.8356\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 53us/step - loss: 1681247660.8603 - val_loss: 3390127026.8493\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1679080424.4182 - val_loss: 3398176941.5890\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 53us/step - loss: 1680472277.2648 - val_loss: 3392955113.2055\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1673838683.5853 - val_loss: 3386586562.6301\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1672412963.8663 - val_loss: 3384779902.2466\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1674562137.9949 - val_loss: 3386585903.3425\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 1670759076.8535 - val_loss: 3361329436.0548\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1666544476.0788 - val_loss: 3383822623.5616\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 63us/step - loss: 1666571945.1311 - val_loss: 3396075585.7534\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1664615394.1662 - val_loss: 3384505978.7397\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1666060725.7995 - val_loss: 3386037789.8082\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1661833314.7695 - val_loss: 3399095325.8082\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1659161578.7215 - val_loss: 3369155649.7534\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1659652241.6590 - val_loss: 3366439484.4932\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1655639092.5381 - val_loss: 3383871337.2055\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1655291298.1114 - val_loss: 3378685585.5342\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1653014404.9906 - val_loss: 3394723612.0548\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1651405891.8389 - val_loss: 3376431242.5205\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1650283011.6195 - val_loss: 3382085351.4521\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1647595548.0788 - val_loss: 3367060853.4795\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1645953143.8835 - val_loss: 3363220888.5479\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1646748258.7147 - val_loss: 3364070696.3288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1642946155.7635 - val_loss: 3378011390.2466\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1643436666.3239 - val_loss: 3388817851.6164\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1641126022.1422 - val_loss: 3370086361.4247\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1640486235.0368 - val_loss: 3368569985.7534\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1640567324.9015 - val_loss: 3365025458.8493\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1636792076.9152 - val_loss: 3356467892.6027\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1633960917.0043 - val_loss: 3374617394.8493\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1637340350.7798 - val_loss: 3348085214.6849\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1630970737.5219 - val_loss: 3367064267.3973\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1631393451.5441 - val_loss: 3367508408.1096\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1632107544.2399 - val_loss: 3358085837.1507\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1629815965.2853 - val_loss: 3360494528.8767\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1630682019.4276 - val_loss: 3344180395.8356\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1624866225.4670 - val_loss: 3376202373.2603\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1624640587.6812 - val_loss: 3369888859.1781\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1623777854.1902 - val_loss: 3369012103.0137\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1621197153.0420 - val_loss: 3353191995.6164\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1620273572.5244 - val_loss: 3350942855.0137\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1620673721.1448 - val_loss: 3344478467.5068\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1618500240.5073 - val_loss: 3357727873.7534\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1619188639.9177 - val_loss: 3358749336.5479\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1617198681.3093 - val_loss: 3338672303.3425\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1614507859.2768 - val_loss: 3354863195.1781\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1613196823.1431 - val_loss: 3362721052.0548\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1612524431.9040 - val_loss: 3349652231.0137\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1610517926.9374 - val_loss: 3338402808.9863\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1611139156.2365 - val_loss: 3354705194.0822\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1609206515.0574 - val_loss: 3348781113.8630\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1606634112.7129 - val_loss: 3352287654.5753\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1608319920.2605 - val_loss: 3366012263.4521\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1610905307.0368 - val_loss: 3346298688.8767\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1603822376.4182 - val_loss: 3356487969.3151\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1603342626.7695 - val_loss: 3338179043.9452\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1601124574.5193 - val_loss: 3338147429.6986\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1599499721.4876 - val_loss: 3341876406.3562\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1600386606.7249 - val_loss: 3361123033.4247\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1598714451.1397 - val_loss: 3335292542.2466\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1599877571.1260 - val_loss: 3325158875.1781\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1600471715.9760 - val_loss: 3368318337.7534\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1594547448.1028 - val_loss: 3327266288.2192\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1594258169.6932 - val_loss: 3330957715.2877\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1592677826.7969 - val_loss: 3351511466.0822\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1591808407.5818 - val_loss: 3329061919.5616\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1593877713.9332 - val_loss: 3352627929.4247\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1590893470.5467 - val_loss: 3312453696.8767\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1591728951.3899 - val_loss: 3349289852.4932\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1589881132.4764 - val_loss: 3330775594.0822\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1588658104.3770 - val_loss: 3320039490.6301\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1586497934.1491 - val_loss: 3331378533.6986\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1585370064.3428 - val_loss: 3342122816.8767\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1584601782.9512 - val_loss: 3329291313.0959\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1582765797.2374 - val_loss: 3339787418.3014\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1583465219.6195 - val_loss: 3319001585.9726\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1584579680.6855 - val_loss: 3333327921.0959\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1582124058.7626 - val_loss: 3325263484.4932\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1582069529.6658 - val_loss: 3357233393.9726\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1583155360.7952 - val_loss: 3328286083.5068\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1577047561.6521 - val_loss: 3339482282.0822\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1576756690.4816 - val_loss: 3342498053.2603\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1576185572.5244 - val_loss: 3324439883.3973\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1575592102.7181 - val_loss: 3334397031.4521\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1574631051.4070 - val_loss: 3341170154.9589\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1576035657.3779 - val_loss: 3306831628.2740\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1572128399.4105 - val_loss: 3337726525.3699\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1570996126.9306 - val_loss: 3317617194.0822\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1571672843.1877 - val_loss: 3326764831.5616\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 60us/step - loss: 1570279104.1097 - val_loss: 3324334576.2192\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1568328393.8166 - val_loss: 3333199596.7123\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1569793750.1560 - val_loss: 3337802536.3288\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1566240392.4456 - val_loss: 3336586560.8767\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1568994391.8423 - val_loss: 3313692328.3288\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1567468620.2296 - val_loss: 3312366188.7123\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1564970378.9683 - val_loss: 3312891207.8904\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1566892999.8423 - val_loss: 3317635817.2055\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1561978648.1851 - val_loss: 3338508084.6027\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1564405482.8312 - val_loss: 3323758125.5890\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1565620191.0951 - val_loss: 3338893227.8356\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1561465066.2828 - val_loss: 3313342681.4247\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1568981902.2039 - val_loss: 3330112536.5479\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1560113636.5244 - val_loss: 3294286199.2329\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1558503755.4619 - val_loss: 3318952651.3973\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1556752483.4824 - val_loss: 3303615663.3425\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1559867775.0129 - val_loss: 3317163043.0685\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1555163925.9640 - val_loss: 3310872523.3973\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1554209150.0257 - val_loss: 3302283106.1918\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1554028558.4781 - val_loss: 3298381620.6027\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1554974751.5887 - val_loss: 3307001003.8356\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1557085587.0848 - val_loss: 3302131852.2740\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1552921951.6435 - val_loss: 3312779860.1644\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1553246008.8706 - val_loss: 3301375992.9863\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1549916051.1945 - val_loss: 3301833533.3699\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1550725861.1277 - val_loss: 3305065864.7671\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1548908395.4893 - val_loss: 3305409518.4658\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1547857614.6427 - val_loss: 3300498784.4384\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1548983276.5861 - val_loss: 3314609166.0274\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1547381346.6050 - val_loss: 3294355559.4521\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1546236545.2614 - val_loss: 3310683700.6027\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1545287706.8723 - val_loss: 3297308366.9041\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1544330124.4490 - val_loss: 3294957266.4110\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1545272419.3728 - val_loss: 3303228505.4247\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1546049333.8543 - val_loss: 3294140303.7808\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1542332286.6838 - val_loss: 3306862090.5205\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1543987471.2734 - val_loss: 3297484133.6986\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1542748617.1585 - val_loss: 3326367018.0822\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1542180393.5698 - val_loss: 3288134673.5342\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1539066629.2648 - val_loss: 3276072177.9726\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1542246092.4490 - val_loss: 3305773776.6575\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1539218996.3188 - val_loss: 3279851672.5479\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1537352052.4833 - val_loss: 3308955306.0822\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1537320515.6744 - val_loss: 3291054977.7534\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1539481241.2271 - val_loss: 3305520399.7808\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1536118347.0231 - val_loss: 3288447644.0548\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1534592269.2168 - val_loss: 3284422559.5616\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1537395395.0985 - val_loss: 3270059772.4932\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1531610300.2159 - val_loss: 3312667781.2603\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1533855421.4225 - val_loss: 3305355228.9315\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1535321952.3016 - val_loss: 3298388953.4247\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1538843926.9237 - val_loss: 3288880587.3973\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1532028982.4027 - val_loss: 3284776916.1644\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1531159296.2742 - val_loss: 3282761985.7534\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1531414114.0291 - val_loss: 3274923909.2603\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1529698755.1808 - val_loss: 3292283521.7534\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1529307895.2254 - val_loss: 3278986851.9452\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1529553500.1885 - val_loss: 3279407056.6575\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1529385230.9169 - val_loss: 3287744361.2055\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1529842700.9426 - val_loss: 3311285730.1918\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1525120427.3248 - val_loss: 3271882197.9178\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1526953513.1859 - val_loss: 3286710014.2466\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1524520400.3702 - val_loss: 3291868356.3836\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1524830274.1388 - val_loss: 3299909972.1644\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1525849500.7369 - val_loss: 3275655671.2329\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1522915575.0060 - val_loss: 3283981357.5890\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1521478965.2511 - val_loss: 3273719729.0959\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1525159656.9666 - val_loss: 3279379178.9589\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1523251915.5716 - val_loss: 3289551121.5342\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1520413531.9143 - val_loss: 3284330848.4384\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1521950434.2759 - val_loss: 3275888320.8767\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1519656317.6967 - val_loss: 3271421639.8904\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 1517919038.8483 - val_loss: 3275567707.1781\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1520154150.8278 - val_loss: 3277380253.8082\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1520201249.6727 - val_loss: 3269832893.3699\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1521117311.0129 - val_loss: 3273244414.2466\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1519509877.4704 - val_loss: 3266068923.6164\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1516237902.8895 - val_loss: 3281168811.8356\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1516469935.1637 - val_loss: 3282818002.4110\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1516114923.9280 - val_loss: 3283774890.0822\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1512970700.0651 - val_loss: 3274600013.1507\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1517373470.7112 - val_loss: 3294449583.3425\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1525440964.6615 - val_loss: 3250548818.4110\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1513587383.3899 - val_loss: 3260082093.5890\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1510653332.6204 - val_loss: 3282825591.2329\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1512875770.1868 - val_loss: 3263326285.1507\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 53us/step - loss: 1514542504.8021 - val_loss: 3268497383.4521\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1511196022.0189 - val_loss: 3301923797.9178\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1512069283.8663 - val_loss: 3261537280.0000\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1510187746.2759 - val_loss: 3270397724.0548\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1510388869.7309 - val_loss: 3270987470.9041\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1508622600.9392 - val_loss: 3250580078.4658\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1512035835.7224 - val_loss: 3248653578.5205\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1509030281.7618 - val_loss: 3275158685.8082\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1506152789.1962 - val_loss: 3267227232.4384\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1506064821.1962 - val_loss: 3271577901.5890\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1504672111.4379 - val_loss: 3249588017.0959\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1505568442.0771 - val_loss: 3269657901.5890\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1504521214.1354 - val_loss: 3257113496.5479\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1507002240.2194 - val_loss: 3253819136.0000\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1504684521.4053 - val_loss: 3248412649.2055\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1502914994.3719 - val_loss: 3253278495.5616\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1501579723.3522 - val_loss: 3267931127.2329\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1502474516.6204 - val_loss: 3271842645.9178\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1503408805.9503 - val_loss: 3287094917.2603\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1500035197.1482 - val_loss: 3248584376.1096\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1501230360.4045 - val_loss: 3270496112.2192\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1500860263.1020 - val_loss: 3249280582.1370\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1497934593.0968 - val_loss: 3270298659.0685\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1499776000.3290 - val_loss: 3256270998.7945\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1497232771.8389 - val_loss: 3263570677.4795\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1498850310.2519 - val_loss: 3262840221.8082\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1496281235.4139 - val_loss: 3241033584.2192\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1497488735.3145 - val_loss: 3245896626.8493\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1497479608.9254 - val_loss: 3262576419.0685\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1499584348.5176 - val_loss: 3262936691.7260\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1503448550.2245 - val_loss: 3256721062.5753\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1498932223.4516 - val_loss: 3257401715.7260\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1497135519.4790 - val_loss: 3265295628.2740\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1494110699.8183 - val_loss: 3256117975.6712\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1497377424.5621 - val_loss: 3256655160.1096\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1495445215.1500 - val_loss: 3263472839.8904\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1494065969.7961 - val_loss: 3259768546.1918\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1492116730.6804 - val_loss: 3246462972.4932\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1492950162.5364 - val_loss: 3254962712.5479\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1490286117.2922 - val_loss: 3264291832.9863\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1494607285.1414 - val_loss: 3229488913.5342\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1490344395.7361 - val_loss: 3267381917.8082\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1490028983.4996 - val_loss: 3251606594.6301\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1488713414.8003 - val_loss: 3241056436.6027\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1488494062.5056 - val_loss: 3250394033.0959\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1488652402.5090 - val_loss: 3253074198.7945\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 58us/step - loss: 1486969053.2305 - val_loss: 3231215961.4247\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1485900301.8201 - val_loss: 3240620473.8630\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1490707363.6470 - val_loss: 3247976372.6027\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1488909484.6410 - val_loss: 3274217538.6301\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1495862845.0934 - val_loss: 3234048885.4795\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1485780904.8569 - val_loss: 3238229065.6438\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1487108986.9546 - val_loss: 3245870991.7808\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1490039268.5793 - val_loss: 3216480452.3836\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1480992769.5356 - val_loss: 3258522483.7260\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1484978125.7104 - val_loss: 3243279184.6575\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1486306557.5321 - val_loss: 3250113153.7534\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1482138049.2614 - val_loss: 3218907947.8356\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1482320573.5870 - val_loss: 3224521633.3151\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1479427623.9246 - val_loss: 3247877453.1507\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1485569207.0608 - val_loss: 3228562154.9589\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1485710774.4027 - val_loss: 3276820548.3836\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1481066139.6401 - val_loss: 3236017283.5068\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1479683953.0831 - val_loss: 3231855323.1781\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1478071504.3976 - val_loss: 3243903042.6301\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1482730487.5544 - val_loss: 3248476898.1918\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1478934622.2177 - val_loss: 3222848634.7397\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1479707065.6384 - val_loss: 3217185758.6849\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1479066300.7644 - val_loss: 3234499347.2877\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1479548089.2545 - val_loss: 3219090284.7123\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1475982091.5167 - val_loss: 3255215668.6027\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1475937192.6924 - val_loss: 3239381507.5068\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1474830663.6778 - val_loss: 3232866833.5342\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1475361120.4662 - val_loss: 3245886232.5479\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1481581588.8398 - val_loss: 3225789113.8630\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1475648315.6675 - val_loss: 3253279921.0959\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1474589375.3967 - val_loss: 3225022891.8356\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1473099330.3582 - val_loss: 3230469945.8630\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1475045690.4610 - val_loss: 3217910180.8219\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1473758648.5416 - val_loss: 3231167386.3014\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1471057962.3376 - val_loss: 3233282987.8356\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1473022559.8629 - val_loss: 3220702179.9452\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1471570520.0754 - val_loss: 3220594302.2466\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1469428385.5081 - val_loss: 3233011775.1233\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1472438270.4644 - val_loss: 3222713854.2466\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1470033951.4790 - val_loss: 3241057792.0000\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1470120003.8389 - val_loss: 3212787189.4795\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1474844036.6067 - val_loss: 3229537560.5479\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1472377732.7164 - val_loss: 3205435207.8904\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 1468226268.7918 - val_loss: 3222889137.0959\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1467326716.3805 - val_loss: 3222296444.4932\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1466337237.7172 - val_loss: 3225696613.6986\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1467379493.6213 - val_loss: 3219830079.1233\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1466157290.6118 - val_loss: 3229535917.5890\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1466948386.5501 - val_loss: 3210768203.3973\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1464894467.7292 - val_loss: 3216125906.4110\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1465758578.5090 - val_loss: 3234856998.5753\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1465763920.6170 - val_loss: 3208414521.8630\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1464103865.1448 - val_loss: 3228899152.6575\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1465476036.1131 - val_loss: 3222152968.7671\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1463218183.1294 - val_loss: 3212645158.5753\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1463579299.9760 - val_loss: 3207096763.6164\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1463970871.1705 - val_loss: 3214238935.6712\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1463704969.7618 - val_loss: 3194173436.4932\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1460909807.2185 - val_loss: 3242586289.0959\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1462218206.6564 - val_loss: 3195322410.0822\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1460174671.4105 - val_loss: 3231075243.8356\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1460402533.1277 - val_loss: 3217991138.1918\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1462218801.4670 - val_loss: 3196542492.0548\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1461586358.9512 - val_loss: 3225326230.7945\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 52us/step - loss: 1457585468.8740 - val_loss: 3198147790.9041\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1457424939.3248 - val_loss: 3217194671.3425\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1458521830.3342 - val_loss: 3205390181.6986\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1456691644.4901 - val_loss: 3213111255.6712\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1460065529.7481 - val_loss: 3195573916.0548\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1456073851.9966 - val_loss: 3228109978.3014\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1456722377.5150 - val_loss: 3195960516.3836\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1456343124.6752 - val_loss: 3195000917.9178\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1455973650.8655 - val_loss: 3208429326.0274\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1455483148.7232 - val_loss: 3213158640.2192\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1457038310.1148 - val_loss: 3220148371.2877\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1454206584.1028 - val_loss: 3198300805.2603\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1454387145.5424 - val_loss: 3200413061.2603\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1452827117.5184 - val_loss: 3202696868.8219\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1454262713.9674 - val_loss: 3208549428.6027\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1454195866.1045 - val_loss: 3188978384.6575\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1454608477.0111 - val_loss: 3186756976.2192\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1451465321.1311 - val_loss: 3222083682.1918\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1453027177.6247 - val_loss: 3206809184.4384\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1450490898.7009 - val_loss: 3207057283.5068\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1450616565.7446 - val_loss: 3212872234.0822\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1450770115.0163 - val_loss: 3200044149.4795\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1453509328.5621 - val_loss: 3210151893.9178\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1452355236.9632 - val_loss: 3179999398.5753\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1449791432.3907 - val_loss: 3220240220.9315\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1447590060.8603 - val_loss: 3194245600.4384\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1447647414.8415 - val_loss: 3199469266.4110\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1449048873.8989 - val_loss: 3193018480.2192\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1446570931.8800 - val_loss: 3194738570.5205\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1448366469.0454 - val_loss: 3198471087.3425\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1449191750.9649 - val_loss: 3209340421.2603\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1450744712.4456 - val_loss: 3208845601.3151\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1446352680.2536 - val_loss: 3176652184.5479\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1446298082.1388 - val_loss: 3200123697.0959\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1444904612.8535 - val_loss: 3206175114.5205\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1446772943.5201 - val_loss: 3188714450.4110\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1446655241.8715 - val_loss: 3194649866.5205\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1443726001.1380 - val_loss: 3210666197.9178\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 1443403879.5407 - val_loss: 3194751077.6986\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1448296398.5330 - val_loss: 3211983658.0822\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_5000E_Adam_32.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_32.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 128)               42368     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 75,521\n",
      "Trainable params: 75,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_128 = Sequential()\n",
    "NN_5000E_Adam_128.add(Dense(128,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_Adam_128.add(Dense(128,activation = 'relu'))\n",
    "NN_5000E_Adam_128.add(Dense(128,activation = 'relu'))\n",
    "NN_5000E_Adam_128.add(Dense(1))\n",
    "NN_5000E_Adam_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 187us/step - loss: 38690821717.5527 - val_loss: 39492075295.5616\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 38067167105.6452 - val_loss: 38787898438.1370\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 37190807258.9272 - val_loss: 37712415982.4658\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 35843968595.7978 - val_loss: 36016919930.7397\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 33685374161.7138 - val_loss: 33240283023.7808\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 30315134535.5133 - val_loss: 29067547633.9726\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 25726978767.5201 - val_loss: 23658073130.0822\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 20687751560.2262 - val_loss: 17790178893.1507\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 16332400330.2554 - val_loss: 13507428772.8219\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 13912655913.2408 - val_loss: 10726015200.4384\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 12373337261.7378 - val_loss: 9575326229.0411\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 11631635721.4327 - val_loss: 8843370446.9041\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 10945010183.0197 - val_loss: 7988676488.7671\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 10465418717.9983 - val_loss: 7637861512.7671\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 9926815894.7044 - val_loss: 7271128025.4247\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 9455436974.6153 - val_loss: 6929785249.3151\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 9050618438.8552 - val_loss: 6756696190.2466\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 8458948733.6967 - val_loss: 6462015224.9863\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 8060035825.3025 - val_loss: 6213013760.0000\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 7721604976.3153 - val_loss: 6058501624.9863\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 7373885489.5767 - val_loss: 5837274918.5753\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 7046762151.7052 - val_loss: 5713586190.0274\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 6714713529.8029 - val_loss: 5560544222.6849\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 6362998518.3479 - val_loss: 5411602556.4932\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 6114681818.9272 - val_loss: 5261357199.7808\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 5900298889.7618 - val_loss: 5140693509.2603\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 5516017395.4961 - val_loss: 5024565849.4247\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 5262466807.8835 - val_loss: 4911693916.9315\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 5033685816.8158 - val_loss: 4801774953.2055\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 4785897392.1508 - val_loss: 4711544777.6438\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 4565737980.9289 - val_loss: 4624816354.1918\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 4373846530.4130 - val_loss: 4538253781.9178\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 4170533894.2519 - val_loss: 4471793390.4658\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 4027080239.1637 - val_loss: 4381940913.0959\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 3817368406.1011 - val_loss: 4327780955.1781\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 3671174179.9760 - val_loss: 4255320768.8767\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 3509813862.4439 - val_loss: 4198651961.8630\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 3364312493.4087 - val_loss: 4145323935.5616\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 3233605219.0437 - val_loss: 4083228373.9178\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 3113194758.7455 - val_loss: 4038278405.2603\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 3000024144.7266 - val_loss: 3987423161.8630\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2897044877.8201 - val_loss: 3940047659.8356\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 2794538529.1243 - val_loss: 3898660660.6027\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 2693925538.3308 - val_loss: 3870363409.5342\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 2615841646.3410 - val_loss: 3825830321.0959\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 2525107162.5981 - val_loss: 3806016874.9589\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2449423670.2931 - val_loss: 3767683345.5342\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 2376894208.9323 - val_loss: 3727610050.6301\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 2313798758.7729 - val_loss: 3701340980.6027\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2247536923.4207 - val_loss: 3680367987.7260\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2197614061.7926 - val_loss: 3645921213.3699\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2149296620.4764 - val_loss: 3624097872.6575\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 2101034082.4953 - val_loss: 3586967536.2192\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 2060009782.6221 - val_loss: 3564261879.2329\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2017589945.1448 - val_loss: 3563128867.0685\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1986802820.9906 - val_loss: 3533260000.4384\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1953185707.7635 - val_loss: 3501930897.5342\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1921736022.6495 - val_loss: 3493290848.4384\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1891507887.7395 - val_loss: 3492703905.3151\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1872829801.2408 - val_loss: 3479570442.5205\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1850119845.6213 - val_loss: 3461361009.9726\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1833115860.6752 - val_loss: 3449006435.9452\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1815890317.2716 - val_loss: 3434561678.0274\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1798590653.0934 - val_loss: 3440421863.4521\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1790863390.4919 - val_loss: 3453983845.6986\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1780702719.2871 - val_loss: 3410398958.4658\n",
      "Epoch 67/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 77us/step - loss: 1765073418.6941 - val_loss: 3411879232.8767\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1758582463.3967 - val_loss: 3396047347.7260\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1744228315.3111 - val_loss: 3391115974.1370\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1740766425.8303 - val_loss: 3383109579.3973\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1731204590.8895 - val_loss: 3370837176.1096\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1725354745.0900 - val_loss: 3366179091.2877\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1718979936.6307 - val_loss: 3377862207.1233\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1712693046.8415 - val_loss: 3371860983.2329\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1708490303.5613 - val_loss: 3378068564.1644\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1704787961.7481 - val_loss: 3339882573.1507\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1703973682.1251 - val_loss: 3357356445.8082\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1695298964.4010 - val_loss: 3339705628.0548\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1689236585.5150 - val_loss: 3365038067.7260\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1690931133.9709 - val_loss: 3380680388.3836\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1688811651.5099 - val_loss: 3322751175.8904\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1685057484.7781 - val_loss: 3350533686.3562\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1679914373.8680 - val_loss: 3327800735.5616\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1679541471.7532 - val_loss: 3319176711.0137\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1669090301.0386 - val_loss: 3360757882.7397\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1668658837.2785 - val_loss: 3353300683.3973\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1664280498.7832 - val_loss: 3345946013.8082\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1661486543.7395 - val_loss: 3336027839.1233\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1659604884.7301 - val_loss: 3359719420.4932\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1656503828.5107 - val_loss: 3338508133.6986\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1660222528.0000 - val_loss: 3330688746.9589\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1655388307.1945 - val_loss: 3313850185.6438\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1648768505.3093 - val_loss: 3330929718.3562\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1644764600.8158 - val_loss: 3338596937.6438\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 88us/step - loss: 1646409940.0720 - val_loss: 3339107941.6986\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1643141319.1294 - val_loss: 3353732111.7808\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1636680942.8895 - val_loss: 3323005729.3151\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1635330841.0077 - val_loss: 3323178573.1507\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1634361155.8389 - val_loss: 3359353712.2192\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1631797359.3282 - val_loss: 3318075213.1507\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1629113475.6744 - val_loss: 3319366305.3151\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1627805146.2691 - val_loss: 3334105887.5616\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1629693944.9803 - val_loss: 3318363120.2192\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1626486403.6195 - val_loss: 3317063436.2740\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1618069643.4893 - val_loss: 3336611662.9041\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1619008606.3273 - val_loss: 3334277624.9863\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1617880009.8166 - val_loss: 3302084320.4384\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1610036048.9460 - val_loss: 3332106103.2329\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1617190670.5878 - val_loss: 3321647861.4795\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1608856921.8303 - val_loss: 3330656031.5616\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1607572440.8432 - val_loss: 3327140579.9452\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1607331026.5638 - val_loss: 3349558008.9863\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1610473889.6727 - val_loss: 3352170232.9863\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1606755967.5064 - val_loss: 3293851223.6712\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1602693199.9589 - val_loss: 3327297080.1096\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1597508780.4764 - val_loss: 3291412015.3425\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1595430501.3470 - val_loss: 3300611426.1918\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1596271285.1962 - val_loss: 3320798600.7671\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1604448752.0411 - val_loss: 3320680824.9863\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1590719620.1680 - val_loss: 3327045374.2466\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1587118316.5861 - val_loss: 3304098256.6575\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1587905175.7464 - val_loss: 3322614454.3562\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1590611202.5775 - val_loss: 3312616069.2603\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1599297664.5484 - val_loss: 3298919811.5068\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1585494978.3582 - val_loss: 3293800064.0000\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1579680696.3222 - val_loss: 3337476565.9178\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1579820378.9820 - val_loss: 3313943704.5479\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1575912695.0608 - val_loss: 3332444913.9726\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1571208151.8560 - val_loss: 3292374017.7534\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1570281117.3950 - val_loss: 3293225699.9452\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1567917123.9486 - val_loss: 3292520125.3699\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1566880886.2382 - val_loss: 3258921528.1096\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1570674846.0531 - val_loss: 3255703068.0548\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1563468971.9829 - val_loss: 3270459430.5753\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1562383891.7978 - val_loss: 3266234839.6712\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1558576079.4653 - val_loss: 3267359046.1370\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1557170502.5261 - val_loss: 3324256352.4384\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1558175326.0531 - val_loss: 3227761960.3288\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1556239595.2151 - val_loss: 3343159089.0959\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1555928486.4987 - val_loss: 3265898780.0548\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1549365186.9066 - val_loss: 3272611441.9726\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1550740153.1448 - val_loss: 3262053619.7260\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1545835599.7395 - val_loss: 3290108261.6986\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1555280816.2605 - val_loss: 3227780208.2192\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1546191682.9066 - val_loss: 3286265459.7260\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1543843507.4413 - val_loss: 3246309409.3151\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1546611775.6161 - val_loss: 3236711758.9041\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1543095150.5604 - val_loss: 3265072373.4795\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1544141717.0591 - val_loss: 3252649612.2740\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1549295673.8578 - val_loss: 3208628355.5068\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1537496262.7455 - val_loss: 3269559927.2329\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1538829363.6058 - val_loss: 3275735843.0685\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1534752111.5476 - val_loss: 3240437475.9452\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1528171347.5784 - val_loss: 3299476245.0411\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1527832808.3085 - val_loss: 3271722033.0959\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1526442370.9614 - val_loss: 3302241050.3014\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1521467822.2862 - val_loss: 3237932151.2329\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1525087722.7763 - val_loss: 3292718020.3836\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1521724569.7207 - val_loss: 3232061354.0822\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1524208277.4430 - val_loss: 3227814670.0274\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1521896209.0831 - val_loss: 3244831744.0000\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1515204024.4867 - val_loss: 3241420286.2466\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1514870550.0463 - val_loss: 3225552178.8493\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1518505196.0377 - val_loss: 3297948612.3836\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1519946437.4841 - val_loss: 3275245373.3699\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1511770031.0540 - val_loss: 3264484257.3151\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1508949058.9066 - val_loss: 3265124969.2055\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1508174864.7815 - val_loss: 3237168403.2877\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1506134690.1114 - val_loss: 3192860545.7534\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1509281838.2862 - val_loss: 3215589863.4521\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1502696444.3256 - val_loss: 3241339698.8493\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1518082064.6718 - val_loss: 3235630469.2603\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1505001920.1645 - val_loss: 3217396911.3425\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1502174259.7704 - val_loss: 3263088120.9863\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1498949032.4730 - val_loss: 3163575196.0548\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1500360093.6144 - val_loss: 3210644658.8493\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1499736509.9709 - val_loss: 3279094901.4795\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1489219477.8269 - val_loss: 3204941343.5616\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1492210820.3873 - val_loss: 3206655747.5068\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1494217260.6958 - val_loss: 3257974954.0822\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1487787094.4302 - val_loss: 3234007706.3014\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1485465137.1380 - val_loss: 3218581318.1370\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1483763452.8192 - val_loss: 3198049711.3425\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1481178088.3085 - val_loss: 3204465613.1507\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1482555226.7078 - val_loss: 3261255616.8767\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1482571524.7712 - val_loss: 3194029340.0548\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1478707517.3676 - val_loss: 3224623731.7260\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1480306651.1465 - val_loss: 3186029978.3014\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1478709230.3410 - val_loss: 3159731394.6301\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1479275049.2408 - val_loss: 3250761664.8767\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1482342482.8106 - val_loss: 3267631095.2329\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1471410374.4439 - val_loss: 3162824761.8630\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1471130591.6710 - val_loss: 3203604450.1918\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1470992428.7506 - val_loss: 3156579708.4932\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1465524189.7789 - val_loss: 3270903902.6849\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1479179382.5673 - val_loss: 3171777918.2466\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1465199777.5630 - val_loss: 3167468505.4247\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1468787796.8946 - val_loss: 3259688109.5890\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 76us/step - loss: 1459983632.4524 - val_loss: 3164350236.0548\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1459066925.9023 - val_loss: 3197279603.7260\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1459778316.4490 - val_loss: 3218539085.1507\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1455076517.3470 - val_loss: 3173961978.7397\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1469992295.7601 - val_loss: 3283399466.0822\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1460079372.9426 - val_loss: 3190675250.8493\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1453765550.6427 - val_loss: 3171887473.9726\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1452141877.0865 - val_loss: 3207173442.6301\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 73us/step - loss: 1450308726.2382 - val_loss: 3140537363.2877\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1455467347.7429 - val_loss: 3158695727.3425\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1457097786.8997 - val_loss: 3236488868.8219\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1445272320.2194 - val_loss: 3151867181.5890\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1448726323.8800 - val_loss: 3129861691.6164\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1444694799.0814 - val_loss: 3184161118.6849\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1441820524.3668 - val_loss: 3201284160.8767\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1444807998.5741 - val_loss: 3143746782.6849\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1441310125.6829 - val_loss: 3185047536.2192\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1436894381.1894 - val_loss: 3125299704.9863\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1440056680.4730 - val_loss: 3172982231.6712\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1438581463.6367 - val_loss: 3212501116.4932\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1431788792.8158 - val_loss: 3129181317.2603\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1438056743.3762 - val_loss: 3123997243.6164\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1428388586.1731 - val_loss: 3216173487.3425\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1429461352.5278 - val_loss: 3115027247.3425\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1438753438.6015 - val_loss: 3166862371.0685\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1427598430.6564 - val_loss: 3152806924.2740\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1429185400.9803 - val_loss: 3148019068.4932\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1431519465.1859 - val_loss: 3119732390.5753\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1441836262.3342 - val_loss: 3086973923.9452\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1420599451.0643 - val_loss: 3214283218.4110\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1422123318.1834 - val_loss: 3119011876.8219\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1421013158.7181 - val_loss: 3123354688.8767\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1425210077.2305 - val_loss: 3094355014.1370\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1430701472.5758 - val_loss: 3144101454.9041\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1420990268.7644 - val_loss: 3125365507.5068\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1415673226.4747 - val_loss: 3117257035.3973\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1413499840.6033 - val_loss: 3131148209.0959\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1414287335.1568 - val_loss: 3151103903.5616\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1410445226.8312 - val_loss: 3162833341.3699\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1411216462.7524 - val_loss: 3115704568.9863\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1408967594.5570 - val_loss: 3227565624.1096\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1417664557.2991 - val_loss: 3155346859.8356\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1412325827.9486 - val_loss: 3121459501.5890\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1414032368.9734 - val_loss: 3254407434.5205\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1408156286.3548 - val_loss: 3089405517.1507\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1407466827.2425 - val_loss: 3110096759.2329\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1423163069.5321 - val_loss: 3061301426.8493\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1398782519.2802 - val_loss: 3228339350.7945\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1407763370.0086 - val_loss: 3123664224.4384\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1404778553.9126 - val_loss: 3122049402.7397\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1402358232.0754 - val_loss: 3097738089.2055\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1395852786.7284 - val_loss: 3121076334.4658\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1392871868.3256 - val_loss: 3106225716.6027\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1396617313.1791 - val_loss: 3104958130.8493\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1402070312.3633 - val_loss: 3217251138.6301\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1396243119.6024 - val_loss: 3119514148.8219\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1392088711.2391 - val_loss: 3108879517.8082\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1393486394.5707 - val_loss: 3202783826.4110\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1407678321.7961 - val_loss: 3086451079.0137\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1394161979.2288 - val_loss: 3044552004.3836\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1383245954.0840 - val_loss: 3163632622.4658\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1394473553.8783 - val_loss: 3175485191.0137\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1392112947.6607 - val_loss: 3116972316.0548\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1381544879.6572 - val_loss: 3075198071.2329\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1387125735.4310 - val_loss: 3122764186.3014\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1388404438.6495 - val_loss: 3135612026.7397\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1380272853.8817 - val_loss: 3126829838.0274\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1385263274.1183 - val_loss: 3088221492.6027\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1379664126.6290 - val_loss: 3028957592.5479\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1385406710.7318 - val_loss: 3115687194.3014\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1374478207.6161 - val_loss: 3038248479.5616\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1381103564.4490 - val_loss: 3060688012.2740\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1376695011.8663 - val_loss: 3045779603.2877\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1371959017.6247 - val_loss: 3077756873.6438\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1382485112.2125 - val_loss: 3040809156.3836\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1375180540.3805 - val_loss: 3061841941.0411\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1381865727.2322 - val_loss: 3099671299.5068\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1375198702.1765 - val_loss: 3029189533.8082\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1371808962.6872 - val_loss: 3086926825.2055\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1365922099.9075 - val_loss: 3010399744.0000\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1371698134.3205 - val_loss: 3078232810.9589\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1361941808.5895 - val_loss: 3045185141.4795\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1363065444.6341 - val_loss: 3083774732.2740\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1363375714.9340 - val_loss: 3082717962.5205\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1362878025.3779 - val_loss: 3060259324.4932\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1361047722.5021 - val_loss: 3080823986.8493\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1365214802.8106 - val_loss: 3106728784.6575\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1362335999.2871 - val_loss: 3081102300.9315\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1357606438.4987 - val_loss: 3061972636.0548\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1359639439.8492 - val_loss: 3090892526.4658\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1353645182.7935 - val_loss: 3084135718.5753\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1354111368.7746 - val_loss: 3073343224.9863\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1354369310.4919 - val_loss: 3113130583.6712\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1354708760.7883 - val_loss: 3015799327.5616\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1362132809.2682 - val_loss: 3126767104.0000\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1357877152.2468 - val_loss: 3057918451.7260\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1352642612.2091 - val_loss: 3166298865.9726\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1360120600.2399 - val_loss: 3050691349.0411\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1346302341.7035 - val_loss: 3017302001.9726\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1341032707.5167 - val_loss: 3101190776.9863\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1343770026.8312 - val_loss: 3016246910.2466\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1345521843.2219 - val_loss: 3070906932.6027\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1345454852.4422 - val_loss: 3087084437.0411\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1347558890.1731 - val_loss: 3026717827.5068\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1336329178.9272 - val_loss: 3026385308.0548\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1333413089.1243 - val_loss: 3061588067.9452\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1334000292.6889 - val_loss: 3001451218.4110\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1343190219.7361 - val_loss: 3088089372.0548\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1337866588.3530 - val_loss: 3053700671.1233\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1338517866.2828 - val_loss: 3043050360.9863\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1340747394.4953 - val_loss: 2988757214.6849\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1330004558.4233 - val_loss: 3081226380.2740\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1332904437.0865 - val_loss: 3025844413.3699\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1328083447.8835 - val_loss: 3135792119.2329\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1337228534.7318 - val_loss: 3028174865.5342\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1330163055.6572 - val_loss: 2984515168.4384\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1349279007.9177 - val_loss: 3102535371.3973\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1341520307.9897 - val_loss: 3098223803.6164\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1325636692.8946 - val_loss: 3060485095.4521\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1325307057.6864 - val_loss: 3037452056.5479\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1324753657.4739 - val_loss: 2951958235.1781\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1316794146.3582 - val_loss: 3109231149.5890\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1324125157.4567 - val_loss: 2990095093.4795\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1332797153.5630 - val_loss: 2964578309.2603\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1320622854.6358 - val_loss: 3006426827.3973\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1328548622.5330 - val_loss: 3057665690.3014\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1322097556.8946 - val_loss: 2994948404.6027\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1316253060.9357 - val_loss: 3069805233.0959\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1321836734.7386 - val_loss: 3024580665.8630\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1310083821.0249 - val_loss: 2984159621.2603\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1312768183.1979 - val_loss: 2956205994.0822\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1316037687.3350 - val_loss: 3075665685.0411\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 75us/step - loss: 1318095657.1585 - val_loss: 3072681147.6164\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1310741673.5698 - val_loss: 2991538752.8767\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1304317506.9066 - val_loss: 3077951677.3699\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1308258751.0677 - val_loss: 3022073233.5342\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1305852619.5716 - val_loss: 2977221335.6712\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1301489061.0180 - val_loss: 3007367178.5205\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1307269222.9923 - val_loss: 2974396563.2877\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 83us/step - loss: 1311471675.5578 - val_loss: 2942342524.4932\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1313529684.9494 - val_loss: 2958171923.2877\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1316290481.0283 - val_loss: 3017989852.9315\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1302944480.9597 - val_loss: 2998342955.8356\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1306564665.9949 - val_loss: 2908773049.8630\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1290980283.5578 - val_loss: 3123779135.1233\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1308742390.5124 - val_loss: 2935492285.3699\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1297373274.5433 - val_loss: 3005975734.3562\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1292808827.4482 - val_loss: 2978460682.5205\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1293763687.2117 - val_loss: 2950951525.6986\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1295543918.9991 - val_loss: 2993230232.5479\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1291041840.2605 - val_loss: 2999319848.3288\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1296490945.7001 - val_loss: 3029567340.7123\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1291783669.4704 - val_loss: 3000805719.6712\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1297742858.6392 - val_loss: 2913414792.7671\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1291499661.4910 - val_loss: 2970454889.2055\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1284413575.5681 - val_loss: 3019385172.1644\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1282621840.0137 - val_loss: 2978971733.9178\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1286484404.8946 - val_loss: 2917488555.8356\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1288201781.7446 - val_loss: 3014019899.6164\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1280858378.0908 - val_loss: 2941398133.4795\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1283020353.5904 - val_loss: 2960164555.3973\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1281955410.4267 - val_loss: 2927155918.9041\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1285965594.1594 - val_loss: 2958851633.0959\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1278120962.8518 - val_loss: 2974425696.4384\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1278688157.1757 - val_loss: 3002447468.7123\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1282968973.2716 - val_loss: 2908233389.5890\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1270675301.3470 - val_loss: 3042337748.1644\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1275843168.0823 - val_loss: 2916194828.2740\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1275324840.4319 - val_loss: 2984403573.4795\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1277021424.4250 - val_loss: 2966258325.0411\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1272731812.1954 - val_loss: 2982504847.7808\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1278813451.0780 - val_loss: 3013950954.9589\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1274804810.5844 - val_loss: 2907470065.9726\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1291251532.9974 - val_loss: 2910986667.8356\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1267836301.7104 - val_loss: 2943999021.5890\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1265071365.7584 - val_loss: 2990992748.7123\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1265105959.4310 - val_loss: 2928455160.9863\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1266203766.3479 - val_loss: 3033253621.4795\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1265334329.6110 - val_loss: 2946811788.2740\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1264504616.7472 - val_loss: 2947762929.9726\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1263734859.0231 - val_loss: 3080744739.0685\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1276775422.0531 - val_loss: 2946494548.1644\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1258152897.3710 - val_loss: 2991523173.6986\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1259881912.5690 - val_loss: 2951391042.6301\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1259461874.3445 - val_loss: 2968980723.7260\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1256595616.4662 - val_loss: 2917681232.6575\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1258324576.4662 - val_loss: 2987782436.8219\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1260789038.5604 - val_loss: 3012164927.1233\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1258888362.7763 - val_loss: 2899332646.5753\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1247820202.4473 - val_loss: 2984323282.4110\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1254597403.7498 - val_loss: 2971140271.3425\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1266001405.7515 - val_loss: 2992339782.1370\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1253539477.9914 - val_loss: 3001430494.6849\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1253713981.4225 - val_loss: 2976922604.7123\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1247123562.8312 - val_loss: 2948899569.9726\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1252074047.9452 - val_loss: 2891783206.5753\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1256808549.8406 - val_loss: 2901894648.9863\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1251228532.2639 - val_loss: 2918974471.0137\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1265526109.1757 - val_loss: 2994700487.8904\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1249477696.9323 - val_loss: 2923473774.4658\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1263228350.1902 - val_loss: 2841196572.0548\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1253857367.0060 - val_loss: 3006037844.1644\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1257952915.9623 - val_loss: 2984407609.8630\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1238504395.4619 - val_loss: 2906402198.7945\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1241806175.0951 - val_loss: 2927156844.7123\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1243983053.4087 - val_loss: 2927357115.6164\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1237128931.4824 - val_loss: 2926511282.8493\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1233665872.1234 - val_loss: 2997228852.6027\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1238511880.0891 - val_loss: 2904200455.0137\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1235477104.9734 - val_loss: 2920015459.9452\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1234618984.7746 - val_loss: 2934325523.2877\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1240989484.4216 - val_loss: 3020602385.5342\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1236627842.3033 - val_loss: 2869569036.2740\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1226983362.6324 - val_loss: 3001148559.7808\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1224360613.1551 - val_loss: 2843035321.8630\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1249337101.1620 - val_loss: 2879421618.8493\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1232299887.9314 - val_loss: 2968840810.9589\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1232177238.3205 - val_loss: 3011360599.6712\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1232062966.0189 - val_loss: 2900132120.5479\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1226646518.8963 - val_loss: 2925581280.4384\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1227932505.0626 - val_loss: 2856132620.2740\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1231789232.5895 - val_loss: 2927484873.6438\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1219139068.9563 - val_loss: 2877281948.0548\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1224683678.2725 - val_loss: 2996278755.9452\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1229758011.5578 - val_loss: 2897336609.3151\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1214978020.7986 - val_loss: 2977064635.6164\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1223068926.4507 - val_loss: 2916446541.1507\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1221659319.0608 - val_loss: 2912431905.3151\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1217538875.2562 - val_loss: 2869864540.9315\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1217142348.9152 - val_loss: 2930624545.3151\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1222312499.9897 - val_loss: 2867450592.4384\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1209137791.8903 - val_loss: 2937896367.3425\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1215404177.8235 - val_loss: 2858437553.0959\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1218568101.6761 - val_loss: 2907695489.7534\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1216943899.8595 - val_loss: 2931543352.1096\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1219653819.9966 - val_loss: 2864201936.6575\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1224183054.5330 - val_loss: 2963660305.5342\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1209737774.9169 - val_loss: 2867739323.6164\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1219377380.8809 - val_loss: 2924813738.0822\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1221337511.5407 - val_loss: 2903357704.7671\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1204105478.4713 - val_loss: 2853729185.3151\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1218430043.1465 - val_loss: 2856052581.6986\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1211704926.3273 - val_loss: 2870568556.7123\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1209801040.0411 - val_loss: 2869554891.3973\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1203635385.9126 - val_loss: 2876667469.1507\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1199343002.5433 - val_loss: 2954341232.2192\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1216482433.9743 - val_loss: 2825529194.9589\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1199646071.3350 - val_loss: 2913399094.3562\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1210088481.2888 - val_loss: 2925798184.3288\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1199240831.1774 - val_loss: 2845141917.8082\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1199894547.7155 - val_loss: 2878760011.3973\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1195495279.7121 - val_loss: 2953202502.1370\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1200559536.6992 - val_loss: 2889595114.9589\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1197830189.2442 - val_loss: 2844562000.6575\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1189756686.9169 - val_loss: 2963656702.2466\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1199854526.4096 - val_loss: 2889451176.3288\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1191452364.0103 - val_loss: 2902736387.5068\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1190887908.1954 - val_loss: 2897406898.8493\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1196029999.8766 - val_loss: 2829632066.6301\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1197924567.9657 - val_loss: 2974215927.2329\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1198655793.3573 - val_loss: 2865318622.6849\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1185361183.9314 - val_loss: 2905817503.5616\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1193657399.2528 - val_loss: 2888334469.2603\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1184990142.3548 - val_loss: 2863090505.6438\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 78us/step - loss: 1188486239.4790 - val_loss: 2842957252.3836\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1188595814.2245 - val_loss: 2892383512.5479\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1190590372.5244 - val_loss: 2827251631.3425\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1198473161.7069 - val_loss: 2877694178.1918\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1182912518.0326 - val_loss: 2909647379.2877\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1181008338.1525 - val_loss: 2894570378.5205\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1180401603.0163 - val_loss: 2903558436.8219\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1187769878.9237 - val_loss: 2938208680.3288\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1170512352.6855 - val_loss: 2805979788.2740\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1187661252.0583 - val_loss: 2866597125.2603\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1173947475.3042 - val_loss: 2886037191.8904\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1167690929.0283 - val_loss: 2787052300.2740\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1190646753.1243 - val_loss: 2852057607.0137\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1175442687.8081 - val_loss: 2914026687.1233\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1173763821.4636 - val_loss: 2841390635.8356\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1172965924.4970 - val_loss: 2829201697.3151\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1171807578.5159 - val_loss: 2849873688.5479\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1168474988.3668 - val_loss: 2839483623.4521\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1177092422.4987 - val_loss: 2769246840.9863\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1206495235.0163 - val_loss: 2831547923.2877\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1170958137.0900 - val_loss: 2852846818.1918\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1170009483.6264 - val_loss: 2905960951.2329\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1168014905.3368 - val_loss: 2824092203.8356\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1160493215.6984 - val_loss: 2959308070.5753\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1175736961.6452 - val_loss: 2825483765.4795\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1178672316.4901 - val_loss: 2936679169.7534\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1169963932.7095 - val_loss: 2838038087.8904\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1166746205.2853 - val_loss: 2896109929.2055\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1162822181.2922 - val_loss: 2814668561.5342\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1156284524.8877 - val_loss: 2876832206.9041\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1179239352.5416 - val_loss: 2936843397.2603\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1160361078.4850 - val_loss: 2809424945.0959\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1153918058.1183 - val_loss: 2836176119.2329\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1157276527.2734 - val_loss: 2823545093.2603\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1159490228.2091 - val_loss: 2866422954.0822\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1159725948.1611 - val_loss: 2816017116.9315\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1158251411.9623 - val_loss: 2893251059.7260\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1163715978.4199 - val_loss: 2830939967.1233\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_5000E_Adam_128.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_128.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 432,641\n",
      "Trainable params: 432,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_500E_1H = Sequential()\n",
    "NN_500E_1H.add(Dense(512,input_dim = 330,activation = 'relu'))\n",
    "NN_500E_1H.add(Dense(512,activation = 'relu'))\n",
    "NN_500E_1H.add(Dense(1))\n",
    "NN_500E_1H.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 37315028674.3582 - val_loss: 37191868359.8904\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 34670875241.7344 - val_loss: 34077835656.7671\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 30991707826.5638 - val_loss: 29510343750.1370\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 181us/step - loss: 26036271552.3839 - val_loss: 23620228306.4110\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 20506454550.3753 - val_loss: 17563180817.5342\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 16197170727.9246 - val_loss: 13097517168.2192\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 13490555313.4670 - val_loss: 10542575125.0411\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 11950503666.6187 - val_loss: 9014504882.8493\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 10914384783.6847 - val_loss: 7763919468.7123\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 10067454718.4644 - val_loss: 7220150450.8493\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 9136653946.1320 - val_loss: 6749834225.9726\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 8366443936.5758 - val_loss: 6327585886.6849\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 180us/step - loss: 7717556697.8303 - val_loss: 6000714986.9589\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 7186532844.9152 - val_loss: 5706583201.3151\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 6515859842.7421 - val_loss: 5414860233.6438\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 5978292068.9083 - val_loss: 5178900264.3288\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 5542993590.0737 - val_loss: 4983877091.9452\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 5032659067.4207 - val_loss: 4799289342.2466\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 4665423896.8980 - val_loss: 4645329190.5753\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 4353698071.9109 - val_loss: 4495737047.6712\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 4054433321.0214 - val_loss: 4392187577.8630\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 3749640709.5938 - val_loss: 4272741889.7534\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 3536665930.6941 - val_loss: 4174349447.0137\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 3297821516.3393 - val_loss: 4096969671.8904\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 3110048505.9674 - val_loss: 4052673525.4795\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 2935378196.4010 - val_loss: 3961064462.0274\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 2779042569.0488 - val_loss: 3905559702.7945\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 180us/step - loss: 2652014658.9066 - val_loss: 3842299432.3288\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 2531300596.7027 - val_loss: 3798827141.2603\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 2430988893.7241 - val_loss: 3745671564.2740\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 2338622697.1859 - val_loss: 3720047421.3699\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 2260526976.9871 - val_loss: 3665621954.6301\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 2187125384.8843 - val_loss: 3631143564.2740\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 2132022882.8243 - val_loss: 3617098813.3699\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 2076032572.4353 - val_loss: 3576360938.9589\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 2024760738.1114 - val_loss: 3555087389.8082\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1986936308.3736 - val_loss: 3552991342.4658\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1949047595.7635 - val_loss: 3503962915.0685\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 1917269984.5210 - val_loss: 3509827701.4795\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1887271394.7147 - val_loss: 3503179740.9315\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1862797180.8192 - val_loss: 3470618148.8219\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1838407799.1157 - val_loss: 3456655587.9452\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1821753861.9229 - val_loss: 3451772394.9589\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1806544170.7763 - val_loss: 3431800449.7534\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1787762029.2442 - val_loss: 3431017857.7534\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1772413779.3042 - val_loss: 3415600562.8493\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1758605655.5270 - val_loss: 3421956329.2055\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1754524641.2888 - val_loss: 3403857846.3562\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1743829941.3059 - val_loss: 3417888590.9041\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1733097519.4927 - val_loss: 3393846142.2466\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1722630336.8226 - val_loss: 3380560606.6849\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1714408404.2365 - val_loss: 3376155770.7397\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1709978285.9023 - val_loss: 3375490689.7534\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1704343698.6461 - val_loss: 3366487829.0411\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1702087523.7018 - val_loss: 3356079570.4110\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1691812845.7378 - val_loss: 3360359315.2877\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1685336782.4781 - val_loss: 3375123894.3562\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1686588384.9049 - val_loss: 3359355602.4110\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1681345133.0249 - val_loss: 3333076779.8356\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1675188586.1731 - val_loss: 3370475821.5890\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1667915564.4764 - val_loss: 3356171025.5342\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1667027711.8903 - val_loss: 3388621645.1507\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1657937805.7104 - val_loss: 3342111945.6438\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1663353738.2005 - val_loss: 3348182754.1918\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1653331115.1054 - val_loss: 3366345747.2877\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1655902098.5364 - val_loss: 3379900068.8219\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1648449816.3496 - val_loss: 3355527729.0959\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1643874144.0823 - val_loss: 3337687820.2740\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1640827852.7781 - val_loss: 3353097636.8219\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1639270160.3976 - val_loss: 3337490688.0000\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1634624033.5630 - val_loss: 3343139952.2192\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1631566120.5827 - val_loss: 3341120948.6027\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1635436093.4225 - val_loss: 3305758039.6712\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1622641392.2057 - val_loss: 3348590930.4110\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1625013358.5604 - val_loss: 3349232969.6438\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1622145831.3762 - val_loss: 3320904789.9178\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1617142902.3479 - val_loss: 3345644933.2603\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1614403354.1045 - val_loss: 3372705511.4521\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1612069741.7378 - val_loss: 3293882510.0274\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1608827022.4781 - val_loss: 3325956581.6986\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1607301779.5236 - val_loss: 3352520817.9726\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1604683141.8132 - val_loss: 3338757952.8767\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1604178378.1183 - val_loss: 3336159556.3836\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1599913849.7481 - val_loss: 3297213664.4384\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1594738597.1825 - val_loss: 3366801141.4795\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1591738433.1517 - val_loss: 3329352926.6849\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1591458210.8792 - val_loss: 3318909029.6986\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1590982046.3822 - val_loss: 3308497811.2877\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1588919537.9057 - val_loss: 3323234640.6575\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1589014372.7301 - val_loss: 3307856873.2055\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1581768065.7549 - val_loss: 3309634752.8767\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1584813957.7035 - val_loss: 3298508785.9726\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1579001397.8543 - val_loss: 3272298894.0274\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1572653457.8783 - val_loss: 3333281609.6438\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1574142408.7198 - val_loss: 3285592177.9726\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1576762191.9589 - val_loss: 3314581454.9041\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1572271445.0591 - val_loss: 3342638886.5753\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1564947625.2956 - val_loss: 3285431837.8082\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1565575662.2314 - val_loss: 3279120340.1644\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1560303332.5793 - val_loss: 3278397857.3151\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1567668225.2065 - val_loss: 3365976786.4110\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1557275402.5296 - val_loss: 3265063264.4384\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1558877992.6924 - val_loss: 3354253952.0000\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1552700832.3565 - val_loss: 3266758706.8493\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1553089813.0591 - val_loss: 3320114624.8767\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1546484455.9794 - val_loss: 3285040417.3151\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1546580004.8535 - val_loss: 3326570366.2466\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1544759771.4207 - val_loss: 3273808839.8904\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1549289305.0626 - val_loss: 3277493314.6301\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1539036359.8423 - val_loss: 3260876477.3699\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1542860901.2374 - val_loss: 3282846078.2466\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1534709017.4464 - val_loss: 3269854865.5342\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1534751264.8500 - val_loss: 3296201457.9726\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1528887551.3419 - val_loss: 3261128533.9178\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1528385593.4739 - val_loss: 3274377991.0137\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1533527148.8055 - val_loss: 3271168042.0822\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1522830240.1919 - val_loss: 3245230220.2740\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1523892837.2374 - val_loss: 3237864956.4932\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1522261966.0394 - val_loss: 3284612741.2603\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1522785384.0891 - val_loss: 3262917102.4658\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1519165144.1165 - val_loss: 3298911586.1918\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1529299856.2879 - val_loss: 3278141496.1096\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1522754574.2588 - val_loss: 3263848749.5890\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1513285360.0960 - val_loss: 3278229623.2329\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1514650125.2716 - val_loss: 3201067363.9452\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1511519014.7181 - val_loss: 3299334919.0137\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1509639659.4619 - val_loss: 3265399362.6301\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1504056791.2528 - val_loss: 3230316549.2603\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1500614732.2296 - val_loss: 3269410938.7397\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1498183694.9169 - val_loss: 3235858393.4247\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1500985989.1003 - val_loss: 3227157684.6027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1499194769.6590 - val_loss: 3228848405.0411\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1494834233.9126 - val_loss: 3203703075.0685\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1493585565.2853 - val_loss: 3217558794.5205\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1496104212.6204 - val_loss: 3188617789.3699\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1494191274.8312 - val_loss: 3298419843.5068\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1487912581.0454 - val_loss: 3203506900.1644\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1495450916.8535 - val_loss: 3238017388.7123\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1487215100.0514 - val_loss: 3229990629.6986\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1484912450.1937 - val_loss: 3185915483.1781\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1481396838.9374 - val_loss: 3199070316.7123\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1480322579.9349 - val_loss: 3209328999.4521\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1477870024.2811 - val_loss: 3218827420.0548\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1476194067.0848 - val_loss: 3214861838.0274\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1476328917.3333 - val_loss: 3222851275.3973\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1473758148.3325 - val_loss: 3204257483.3973\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1473763765.9092 - val_loss: 3167591762.4110\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1468890786.3719 - val_loss: 3249749333.9178\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1466296010.4747 - val_loss: 3184588740.3836\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1479339953.0831 - val_loss: 3257148735.1233\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1459738126.9717 - val_loss: 3155807203.9452\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1468020457.8989 - val_loss: 3230487455.5616\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1467576966.5810 - val_loss: 3208534713.8630\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1459418274.2211 - val_loss: 3203149312.0000\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1467769116.6272 - val_loss: 3221557642.5205\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1458138971.2836 - val_loss: 3126444642.1918\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1457023278.3136 - val_loss: 3189015031.2329\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1452216593.3299 - val_loss: 3221237842.4110\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1463663629.9297 - val_loss: 3234237727.5616\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1456292125.1757 - val_loss: 3201688453.2603\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1448378137.9126 - val_loss: 3173139971.5068\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1450147078.8003 - val_loss: 3207035353.4247\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1449656834.3582 - val_loss: 3195080924.9315\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1446053675.9829 - val_loss: 3176446840.9863\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1448684265.8440 - val_loss: 3207829398.7945\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1441257053.0111 - val_loss: 3134001546.5205\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1442477649.6041 - val_loss: 3180028721.0959\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1438727716.0857 - val_loss: 3181341624.1096\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1437855169.5904 - val_loss: 3183206371.9452\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1436665262.8346 - val_loss: 3190770396.9315\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1438779932.7918 - val_loss: 3175425834.0822\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1437544903.6230 - val_loss: 3147711533.5890\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1431401924.8535 - val_loss: 3160866731.8356\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1430647362.7421 - val_loss: 3162103627.3973\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1438471647.8629 - val_loss: 3080320263.0137\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1427229249.3162 - val_loss: 3151083239.4521\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1429403859.0848 - val_loss: 3099396525.5890\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1434836707.4824 - val_loss: 3152029385.6438\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1427304010.8038 - val_loss: 3138980679.8904\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1430047138.6598 - val_loss: 3183665506.1918\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1424476048.1234 - val_loss: 3104112087.6712\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1418332255.8629 - val_loss: 3247054963.7260\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1420282364.0514 - val_loss: 3087104087.6712\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1421974227.2494 - val_loss: 3136672613.6986\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1415499252.9220 - val_loss: 3144995750.5753\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1416346929.0831 - val_loss: 3119313169.5342\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1413025078.6221 - val_loss: 3118817448.3288\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1409323811.7566 - val_loss: 3143995865.4247\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1408828644.5793 - val_loss: 3125622117.6986\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1416309831.0746 - val_loss: 3177310183.4521\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1409511477.0865 - val_loss: 3128015984.2192\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1405851288.4045 - val_loss: 3170470042.3014\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1404473893.7309 - val_loss: 3084152369.0959\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1406922148.5518 - val_loss: 3083450050.6301\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1403853702.1971 - val_loss: 3111937008.2192\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1400905794.6324 - val_loss: 3103091245.5890\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1396826188.5587 - val_loss: 3098127440.6575\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1397424325.6487 - val_loss: 3104948420.3836\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1394368216.9529 - val_loss: 3130412942.0274\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1399225521.6864 - val_loss: 3037778556.4932\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1401163106.7969 - val_loss: 3152657278.2466\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1395044963.8115 - val_loss: 3071270368.4384\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1391320107.8732 - val_loss: 3112499575.2329\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1388457493.6898 - val_loss: 3100581118.2466\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1389107352.6787 - val_loss: 3101615866.7397\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1387113397.1962 - val_loss: 3123269554.8493\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1388549245.8063 - val_loss: 3093736062.2466\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1389706529.5630 - val_loss: 3162695736.1096\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1386238145.4259 - val_loss: 3087381155.0685\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1382074242.3033 - val_loss: 3093986693.2603\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1381908823.4173 - val_loss: 3075597987.0685\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1387165900.0925 - val_loss: 3031338225.9726\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1395195432.2536 - val_loss: 3107067234.1918\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1380676580.8535 - val_loss: 3108179841.7534\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1391910216.2262 - val_loss: 3155716341.4795\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1375506934.5398 - val_loss: 3053554724.8219\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1386063965.3402 - val_loss: 3121331087.7808\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1374614086.5261 - val_loss: 3055813235.7260\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1378252734.2999 - val_loss: 3108765056.0000\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1375893148.4627 - val_loss: 3070547697.9726\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1380307815.1020 - val_loss: 3127550990.0274\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1367932035.1808 - val_loss: 3066910870.7945\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1365885398.6495 - val_loss: 3068394497.7534\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1378019126.0463 - val_loss: 3034665966.4658\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1373355156.4010 - val_loss: 3073423796.6027\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1364225923.1808 - val_loss: 3095787670.7945\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1367264075.2973 - val_loss: 3144637317.2603\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1364112170.0086 - val_loss: 3010497653.4795\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1369643733.2237 - val_loss: 3005151482.7397\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1359913242.5433 - val_loss: 3032340928.8767\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1364319435.5716 - val_loss: 3063132154.7397\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1361290383.4653 - val_loss: 3044027251.7260\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1355220255.2048 - val_loss: 3037863781.6986\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1351072918.0463 - val_loss: 3065345930.5205\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1363206585.8303 - val_loss: 3063245441.7534\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1351144082.3171 - val_loss: 3052489652.6027\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1368458748.2708 - val_loss: 3102289928.7671\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1362870192.8089 - val_loss: 3016290407.4521\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1347241756.6821 - val_loss: 3036717748.6027\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1345427874.3856 - val_loss: 2997531214.9041\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1342691961.4739 - val_loss: 3122720469.9178\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1359942157.8201 - val_loss: 3077138090.0822\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1344189502.6290 - val_loss: 3064088216.5479\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1339096164.8260 - val_loss: 2997879210.0822\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1346550806.9512 - val_loss: 2995009921.7534\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1345517716.8946 - val_loss: 3138842161.0959\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1347399486.0257 - val_loss: 3054075013.2603\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1339446634.5021 - val_loss: 2960078034.4110\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1344987320.2125 - val_loss: 3038697237.0411\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1339969448.3085 - val_loss: 3088044126.6849\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1336182689.5630 - val_loss: 2975944120.1096\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1341513526.5124 - val_loss: 3030476545.7534\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1341409879.4722 - val_loss: 3064799081.2055\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1333578372.9357 - val_loss: 3016648251.6164\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1335303471.1088 - val_loss: 3038118813.8082\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1325362177.8646 - val_loss: 2981165999.3425\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1330154972.5724 - val_loss: 3070005761.7534\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1332356265.3505 - val_loss: 3014303875.5068\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1323182665.6795 - val_loss: 2995376853.9178\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1325399349.3608 - val_loss: 3039482706.4110\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1323853158.4439 - val_loss: 2972400126.2466\n",
      "Epoch 262/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 175us/step - loss: 1331742575.9040 - val_loss: 2983347953.9726\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1322969068.1474 - val_loss: 2999233437.8082\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1325709812.3736 - val_loss: 2948871111.8904\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1319454295.1705 - val_loss: 3027924883.2877\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1319151775.4790 - val_loss: 2978417109.9178\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1316628719.1637 - val_loss: 2983793849.8630\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1324831273.9537 - val_loss: 3020292837.6986\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1319023766.7592 - val_loss: 2923802243.5068\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1314177399.4996 - val_loss: 3019780404.6027\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1317192751.3830 - val_loss: 2940756032.8767\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1317408587.3522 - val_loss: 2965475229.8082\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1311329999.6572 - val_loss: 3033924343.2329\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1313409653.5801 - val_loss: 3009352467.2877\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1312649425.7138 - val_loss: 3073956322.1918\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1320635826.8380 - val_loss: 2988136314.7397\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1304978835.4687 - val_loss: 2914882991.3425\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1310697930.4747 - val_loss: 3021648403.2877\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1306578379.7909 - val_loss: 2992599409.9726\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1304749285.2374 - val_loss: 2997729367.6712\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1305360851.1397 - val_loss: 3054258596.8219\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1302241478.8826 - val_loss: 2973233916.4932\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1301173095.1568 - val_loss: 3034198931.2877\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1296778896.0686 - val_loss: 2893460650.0822\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 1304081349.7584 - val_loss: 3044056584.7671\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 190us/step - loss: 1307546485.8543 - val_loss: 2904137501.8082\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 191us/step - loss: 1301135578.3787 - val_loss: 2934102077.3699\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 186us/step - loss: 1302715198.9854 - val_loss: 2940728409.4247\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1292220500.2365 - val_loss: 2975911737.8630\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1294294835.8800 - val_loss: 3026599834.3014\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1295697770.1183 - val_loss: 2921296426.0822\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1288709267.6332 - val_loss: 2981139771.6164\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1292714257.2202 - val_loss: 2983060436.1644\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1292512649.4327 - val_loss: 2971155313.9726\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1298626690.9614 - val_loss: 2937800774.1370\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1289446185.3505 - val_loss: 2925798617.4247\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1283740500.5656 - val_loss: 2992090240.0000\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1286734162.8106 - val_loss: 2966588396.7123\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1287027812.9083 - val_loss: 2953481577.2055\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1292886082.2485 - val_loss: 2926363100.9315\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1280676051.1397 - val_loss: 2985889136.2192\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1305777941.4979 - val_loss: 3059140937.6438\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1293633796.1680 - val_loss: 2981515888.2192\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1279606451.7704 - val_loss: 2876981006.0274\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1273897293.4636 - val_loss: 3064936339.2877\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1282833342.1354 - val_loss: 2915763689.2055\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1275759232.9871 - val_loss: 2917104559.3425\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1271161642.8312 - val_loss: 2913697653.4795\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1280673440.5758 - val_loss: 2882323215.7808\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1267589126.1971 - val_loss: 2960895763.2877\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1271020445.3950 - val_loss: 2900114602.0822\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1270690873.6932 - val_loss: 2924173790.6849\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1269123571.9349 - val_loss: 2898760111.3425\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1274095231.1225 - val_loss: 2882125105.0959\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1272002406.4439 - val_loss: 2878777275.6164\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1268666860.3668 - val_loss: 2903444699.1781\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1267449707.3796 - val_loss: 2874975317.9178\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1266572173.9846 - val_loss: 2880182734.9041\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1265637773.1620 - val_loss: 2948092503.6712\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1263553088.0548 - val_loss: 2879617700.8219\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1261248178.7832 - val_loss: 2963113410.6301\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1255773775.4105 - val_loss: 2865518763.8356\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1267417911.9109 - val_loss: 2931513121.3151\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1258263824.0686 - val_loss: 2938248986.3014\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1254945253.8406 - val_loss: 2879494678.7945\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1260733119.3419 - val_loss: 2949298361.8630\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1253375998.2451 - val_loss: 2905074081.3151\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1263154684.3805 - val_loss: 2955825062.5753\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1254281836.3668 - val_loss: 2912716538.7397\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1250946054.2519 - val_loss: 2922847789.5890\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1254447664.4799 - val_loss: 2961930769.5342\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1253670352.5073 - val_loss: 2863370872.9863\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1248950893.0249 - val_loss: 2853797747.7260\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1254028187.8046 - val_loss: 3003580763.1781\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1256037022.2725 - val_loss: 2908640815.3425\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1259318683.4756 - val_loss: 2842734609.5342\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1264734909.4773 - val_loss: 2839478536.7671\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1242764779.2699 - val_loss: 2888942840.9863\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1242306391.0883 - val_loss: 2834431638.7945\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1242636591.6024 - val_loss: 2915873255.4521\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1243641610.7489 - val_loss: 2855332581.6986\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1240285475.7566 - val_loss: 2848123176.3288\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1242308943.1911 - val_loss: 2898200674.1918\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1238495101.0386 - val_loss: 2900130461.8082\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1241199578.6530 - val_loss: 2832159284.6027\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1235823598.3136 - val_loss: 2844795453.3699\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1245936585.2682 - val_loss: 2846639542.3562\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1238163026.3719 - val_loss: 2824456528.6575\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1239989174.0737 - val_loss: 2857422416.6575\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1235677960.9940 - val_loss: 2928574348.2740\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1232735735.9931 - val_loss: 2869492679.8904\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1240868395.9829 - val_loss: 2827326483.2877\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1228010216.3085 - val_loss: 2863481084.4932\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1227188903.5955 - val_loss: 2865763142.1370\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1225744499.7155 - val_loss: 2821229688.9863\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1231328016.5347 - val_loss: 2918150119.4521\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1244080364.2571 - val_loss: 2813549192.7671\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1235131676.9563 - val_loss: 2853226131.2877\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1222747815.5955 - val_loss: 2837830068.6027\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1218564204.7506 - val_loss: 2907235177.2055\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1230142663.8423 - val_loss: 2840624029.8082\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1216783149.7378 - val_loss: 2835447369.6438\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1220425965.0249 - val_loss: 2807666619.6164\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1220695535.3282 - val_loss: 2838438296.5479\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1220780544.6033 - val_loss: 2878642477.5890\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1217090689.3710 - val_loss: 2855982250.0822\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1213924091.1740 - val_loss: 2843535907.0685\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1219327932.9837 - val_loss: 2774986350.4658\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1218864004.4970 - val_loss: 2793300429.1507\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1212229949.6967 - val_loss: 2831930737.9726\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1211667747.0985 - val_loss: 2852982601.6438\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1213747994.9272 - val_loss: 2805749505.7534\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1207991295.5613 - val_loss: 2794501393.5342\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1205371672.1302 - val_loss: 2821225438.6849\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1204352147.0300 - val_loss: 2906593716.6027\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1208957601.1243 - val_loss: 2819471949.1507\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1203188959.4790 - val_loss: 2779140890.3014\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1219976639.7258 - val_loss: 2748292750.0274\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1216865482.5844 - val_loss: 2767301097.2055\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1203462797.0523 - val_loss: 2845217637.6986\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1198210961.2202 - val_loss: 2815441457.0959\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1198454603.4619 - val_loss: 2870674684.4932\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1198387118.6153 - val_loss: 2794913521.9726\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1199062104.4319 - val_loss: 2783874996.6027\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1199923650.4679 - val_loss: 2854769905.9726\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1192066503.7875 - val_loss: 2778701944.9863\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1194436834.6050 - val_loss: 2785146143.5616\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1210357915.2014 - val_loss: 2770981518.0274\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1196198321.7412 - val_loss: 2809237987.9452\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1190510725.4841 - val_loss: 2769142254.4658\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1195550978.4679 - val_loss: 2754038622.6849\n",
      "Epoch 392/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 167us/step - loss: 1194996301.6555 - val_loss: 2860333389.1507\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1187779177.9537 - val_loss: 2812116793.8630\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1186398046.2725 - val_loss: 2826688878.4658\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1189064424.7198 - val_loss: 2785884032.0000\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1188443536.5621 - val_loss: 2836600046.4658\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1185510655.2322 - val_loss: 2776230901.4795\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1187375549.3128 - val_loss: 2809821203.2877\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1180257150.9580 - val_loss: 2774626161.9726\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1181016472.2399 - val_loss: 2853340526.4658\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1180045217.2888 - val_loss: 2741655937.7534\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1181592951.2802 - val_loss: 2819270608.6575\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1175301321.3231 - val_loss: 2775820109.1507\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1180646243.5921 - val_loss: 2746420702.6849\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1177251809.6178 - val_loss: 2782180085.4795\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1171888328.3907 - val_loss: 2781179200.8767\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1174505434.5433 - val_loss: 2800674368.8767\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1177882332.7918 - val_loss: 2814586997.4795\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1173492407.3762 - val_loss: 2766070936.5479\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1179875054.5604 - val_loss: 2744561909.4795\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1174554510.1491 - val_loss: 2736749667.9452\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1171589981.0111 - val_loss: 2745053953.7534\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1166020395.8458 - val_loss: 2809257733.2603\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1166949792.9049 - val_loss: 2779700383.5616\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1174294388.8123 - val_loss: 2768061720.5479\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1167368243.9349 - val_loss: 2892913295.7808\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 1172740965.9503 - val_loss: 2753840739.9452\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1165217020.1611 - val_loss: 2703913491.2877\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1173349306.7901 - val_loss: 2793832118.3562\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1162344795.3659 - val_loss: 2772192119.2329\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1163219127.9383 - val_loss: 2833508399.3425\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1167402177.4533 - val_loss: 2785251086.0274\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1157276278.1285 - val_loss: 2774923884.7123\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1160454854.9649 - val_loss: 2750381678.4658\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1153314921.6247 - val_loss: 2761940039.8904\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1162512417.1791 - val_loss: 2757364306.4110\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1154348778.0360 - val_loss: 2735159820.2740\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1156092964.2502 - val_loss: 2756811258.7397\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1160378365.3676 - val_loss: 2696211238.5753\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1164571595.9829 - val_loss: 2830658128.6575\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1158279900.3805 - val_loss: 2781469382.1370\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1148499736.2399 - val_loss: 2717235117.5890\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1150633840.3702 - val_loss: 2773992328.7671\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1146513381.3745 - val_loss: 2717910899.7260\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1146350182.5536 - val_loss: 2709895185.5342\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1152961658.0223 - val_loss: 2772352322.6301\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1145670806.8963 - val_loss: 2758604992.8767\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1142615517.6692 - val_loss: 2734153098.5205\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1157493938.3376 - val_loss: 2800605462.7945\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1138191524.1954 - val_loss: 2688267379.7260\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1146616604.4079 - val_loss: 2715024245.4795\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1150861615.5201 - val_loss: 2837676724.6027\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1145849471.0129 - val_loss: 2718175209.2055\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1145488372.3736 - val_loss: 2652436608.0000\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1164997228.4216 - val_loss: 2775186291.7260\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1135284835.9760 - val_loss: 2751465933.1507\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1137593442.4953 - val_loss: 2735837638.1370\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1132006251.7361 - val_loss: 2708203386.7397\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1138115343.6847 - val_loss: 2683439391.5616\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1139765243.2836 - val_loss: 2728276522.0822\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1132071740.3256 - val_loss: 2718741155.0685\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1130127707.8046 - val_loss: 2712132436.1644\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1145174902.0463 - val_loss: 2658424153.4247\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1134574207.0129 - val_loss: 2705778723.0685\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1130904981.0043 - val_loss: 2710782251.8356\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1139274133.6624 - val_loss: 2794782509.5890\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1151135686.8003 - val_loss: 2754844763.1781\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1131579318.6221 - val_loss: 2659550974.2466\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1116771861.9914 - val_loss: 2782558399.1233\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1130127745.1517 - val_loss: 2713946674.8493\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1120211946.1731 - val_loss: 2700679653.6986\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1128732453.6761 - val_loss: 2766594328.5479\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1123788964.7986 - val_loss: 2709428238.0274\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1119661451.6812 - val_loss: 2770372464.2192\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1126740613.4841 - val_loss: 2699937313.3151\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1122872063.1225 - val_loss: 2657749944.1096\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1124363109.5664 - val_loss: 2656557343.5616\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1122707196.8740 - val_loss: 2668460640.4384\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1118526203.0643 - val_loss: 2660293842.4110\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1115871453.8338 - val_loss: 2689540097.7534\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1115483877.8955 - val_loss: 2736692207.3425\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1111898191.9589 - val_loss: 2651729849.8630\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1101995607.3076 - val_loss: 2825248943.3425\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1116079575.1979 - val_loss: 2649945166.9041\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1120136125.4773 - val_loss: 2676112843.3973\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1104416788.1817 - val_loss: 2765490617.8630\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1119598747.3111 - val_loss: 2676602434.6301\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1115953851.3933 - val_loss: 2684436091.6164\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1111801332.9220 - val_loss: 2747725692.4932\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1108185286.5261 - val_loss: 2711726090.5205\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1104744101.6213 - val_loss: 2700173410.1918\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1103761732.6615 - val_loss: 2675744471.6712\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1100812274.1799 - val_loss: 2721587943.4521\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1101844595.9349 - val_loss: 2725707306.0822\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1104896594.8655 - val_loss: 2631405182.2466\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1102339366.6084 - val_loss: 2681277388.2740\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1102172249.3642 - val_loss: 2615350475.3973\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1092507479.1842 - val_loss: 2779674129.5342\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1111013321.9263 - val_loss: 2667322356.6027\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1097216608.3016 - val_loss: 2713862548.1644\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1102458905.1174 - val_loss: 2683880463.7808\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1099997836.5587 - val_loss: 2662023864.1096\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1097724972.0925 - val_loss: 2626973273.4247\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1087307654.2519 - val_loss: 2726045308.4932\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1097397482.9409 - val_loss: 2700623652.8219\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1094706161.6315 - val_loss: 2691211351.6712\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1094648169.7344 - val_loss: 2704708844.7123\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1089752727.3625 - val_loss: 2664464984.5479\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1093873680.2879 - val_loss: 2682409014.3562\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1085849150.7386 - val_loss: 2679263491.5068\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_500E_1H.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_500E_1H.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = pred(NN_5000E_Adam_32)\n",
    "y_df = pd.DataFrame(predic)\n",
    "y_df = y_df.rename(columns={0:'SalePrice'})\n",
    "out = Id.copy()\n",
    "out = out.join(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(r'~/Datas/KaggleHouse/NN_5000E_Adam_32_Out.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>110793.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>174216.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>198150.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>204857.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>181808.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>70096.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>77745.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>207597.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>120721.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>220982.218750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  110793.195312\n",
       "1     1462  174216.468750\n",
       "2     1463  198150.968750\n",
       "3     1464  204857.046875\n",
       "4     1465  181808.875000\n",
       "...    ...            ...\n",
       "1454  2915   70096.789062\n",
       "1455  2916   77745.460938\n",
       "1456  2917  207597.968750\n",
       "1457  2918  120721.679688\n",
       "1458  2919  220982.218750\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
