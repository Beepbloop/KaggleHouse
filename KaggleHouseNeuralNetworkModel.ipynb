{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1456, 405)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('~/Datas/KaggleHouse/X_train_V2.csv',header=None).to_numpy()\n",
    "y = pd.read_csv('~/Datas/KaggleHouse/Y_train_V2_Nolog.csv',header=None).to_numpy()\n",
    "X_final = pd.read_csv('~/Datas/KaggleHouse/X_test_V2.csv',header=None).to_numpy()\n",
    "Id = pd.read_csv('~/Datas/KaggleHouse/Id.csv',header=None,names=['Id'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 405)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_DIM = X.shape[1]\n",
    "TRAIN_LEN = X.shape[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model):\n",
    "    return model.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 512)               207872    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 733,697\n",
      "Trainable params: 733,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_500E_Adam = Sequential()\n",
    "NN_500E_Adam.add(Dense(512,input_dim = IN_DIM,activation = 'relu'))\n",
    "NN_500E_Adam.add(Dense(512,activation = 'relu'))\n",
    "NN_500E_Adam.add(Dense(512,activation = 'relu'))\n",
    "NN_500E_Adam.add(Dense(1))\n",
    "NN_500E_Adam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_500E_Adam.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1164 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 565731520.0000 - val_loss: 1700189440.0000\n",
      "Epoch 2/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 558624896.0000 - val_loss: 1647930752.0000\n",
      "Epoch 3/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 553870592.0000 - val_loss: 1681796352.0000\n",
      "Epoch 4/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 549378240.0000 - val_loss: 1660008704.0000\n",
      "Epoch 5/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 547132736.0000 - val_loss: 1662769280.0000\n",
      "Epoch 6/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 546537984.0000 - val_loss: 1676002688.0000\n",
      "Epoch 7/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 547090560.0000 - val_loss: 1653298816.0000\n",
      "Epoch 8/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 548797760.0000 - val_loss: 1692359168.0000\n",
      "Epoch 9/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 550990400.0000 - val_loss: 1644562816.0000\n",
      "Epoch 10/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 555714112.0000 - val_loss: 1709161984.0000\n",
      "Epoch 11/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 559377728.0000 - val_loss: 1641915264.0000\n",
      "Epoch 12/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 568065344.0000 - val_loss: 1735285248.0000\n",
      "Epoch 13/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 572894848.0000 - val_loss: 1647841152.0000\n",
      "Epoch 14/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 583626880.0000 - val_loss: 1751561344.0000\n",
      "Epoch 15/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 583137280.0000 - val_loss: 1647565312.0000\n",
      "Epoch 16/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 586532032.0000 - val_loss: 1734944512.0000\n",
      "Epoch 17/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 574437568.0000 - val_loss: 1641032064.0000\n",
      "Epoch 18/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 565840704.0000 - val_loss: 1699077632.0000\n",
      "Epoch 19/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 553401344.0000 - val_loss: 1648558080.0000\n",
      "Epoch 20/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 546386880.0000 - val_loss: 1664888960.0000\n",
      "Epoch 21/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 542691392.0000 - val_loss: 1671723264.0000\n",
      "Epoch 22/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 543095232.0000 - val_loss: 1647756672.0000\n",
      "Epoch 23/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 547162816.0000 - val_loss: 1704325120.0000\n",
      "Epoch 24/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 552306304.0000 - val_loss: 1646581504.0000\n",
      "Epoch 25/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 560751872.0000 - val_loss: 1735786624.0000\n",
      "Epoch 26/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 566613120.0000 - val_loss: 1651343488.0000\n",
      "Epoch 27/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 576470848.0000 - val_loss: 1752758272.0000\n",
      "Epoch 28/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 576237056.0000 - val_loss: 1651111680.0000\n",
      "Epoch 29/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 579792896.0000 - val_loss: 1739646976.0000\n",
      "Epoch 30/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 569244352.0000 - val_loss: 1648594944.0000\n",
      "Epoch 31/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 560972672.0000 - val_loss: 1704671360.0000\n",
      "Epoch 32/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 549033920.0000 - val_loss: 1658179328.0000\n",
      "Epoch 33/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 542123456.0000 - val_loss: 1669919616.0000\n",
      "Epoch 34/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 539251200.0000 - val_loss: 1690234752.0000\n",
      "Epoch 35/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 541562752.0000 - val_loss: 1653932544.0000\n",
      "Epoch 36/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 548348352.0000 - val_loss: 1724224640.0000\n",
      "Epoch 37/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 555651520.0000 - val_loss: 1648895744.0000\n",
      "Epoch 38/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 566951552.0000 - val_loss: 1744299392.0000\n",
      "Epoch 39/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 568962048.0000 - val_loss: 1649131776.0000\n",
      "Epoch 40/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 573562624.0000 - val_loss: 1739194880.0000\n",
      "Epoch 41/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 566164224.0000 - val_loss: 1644700032.0000\n",
      "Epoch 42/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 560954752.0000 - val_loss: 1706665472.0000\n",
      "Epoch 43/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 549924160.0000 - val_loss: 1647953024.0000\n",
      "Epoch 44/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 542918272.0000 - val_loss: 1678442880.0000\n",
      "Epoch 45/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 537537472.0000 - val_loss: 1678350848.0000\n",
      "Epoch 46/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 536416448.0000 - val_loss: 1662353408.0000\n",
      "Epoch 47/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 539059584.0000 - val_loss: 1708756096.0000\n",
      "Epoch 48/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 544718208.0000 - val_loss: 1647663488.0000\n",
      "Epoch 49/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 555336256.0000 - val_loss: 1736665216.0000\n",
      "Epoch 50/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 561234624.0000 - val_loss: 1653374848.0000\n",
      "Epoch 51/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 568255168.0000 - val_loss: 1750574336.0000\n",
      "Epoch 52/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 564479552.0000 - val_loss: 1651862528.0000\n",
      "Epoch 53/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 563363328.0000 - val_loss: 1726157952.0000\n",
      "Epoch 54/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 554206336.0000 - val_loss: 1649798272.0000\n",
      "Epoch 55/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 547616256.0000 - val_loss: 1700632832.0000\n",
      "Epoch 56/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 538824000.0000 - val_loss: 1675133952.0000\n",
      "Epoch 57/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 534099264.0000 - val_loss: 1682771456.0000\n",
      "Epoch 58/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 533465920.0000 - val_loss: 1690595840.0000\n",
      "Epoch 59/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 534234720.0000 - val_loss: 1656135936.0000\n",
      "Epoch 60/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 537539584.0000 - val_loss: 1701754752.0000\n",
      "Epoch 61/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 539387712.0000 - val_loss: 1660897408.0000\n",
      "Epoch 62/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 540537408.0000 - val_loss: 1719497344.0000\n",
      "Epoch 63/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 541902656.0000 - val_loss: 1655144704.0000\n",
      "Epoch 64/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 542692992.0000 - val_loss: 1708545024.0000\n",
      "Epoch 65/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 543243584.0000 - val_loss: 1645695360.0000\n",
      "Epoch 66/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 545406912.0000 - val_loss: 1714027904.0000\n",
      "Epoch 67/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 542685888.0000 - val_loss: 1657289600.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 543241984.0000 - val_loss: 1718320640.0000\n",
      "Epoch 69/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 541965504.0000 - val_loss: 1649645824.0000\n",
      "Epoch 70/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 544416896.0000 - val_loss: 1708962816.0000\n",
      "Epoch 71/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 543121408.0000 - val_loss: 1654775936.0000\n",
      "Epoch 72/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 539929664.0000 - val_loss: 1712803584.0000\n",
      "Epoch 73/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 536571904.0000 - val_loss: 1662488448.0000\n",
      "Epoch 74/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 535169216.0000 - val_loss: 1699766912.0000\n",
      "Epoch 75/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 533861600.0000 - val_loss: 1660661376.0000\n",
      "Epoch 76/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 532596384.0000 - val_loss: 1697955968.0000\n",
      "Epoch 77/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 530756480.0000 - val_loss: 1669425152.0000\n",
      "Epoch 78/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 530532672.0000 - val_loss: 1703887360.0000\n",
      "Epoch 79/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 531004608.0000 - val_loss: 1663928576.0000\n",
      "Epoch 80/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 533136704.0000 - val_loss: 1712828416.0000\n",
      "Epoch 81/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 534739008.0000 - val_loss: 1661776384.0000\n",
      "Epoch 82/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 538554496.0000 - val_loss: 1734407296.0000\n",
      "Epoch 83/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 542311168.0000 - val_loss: 1661551872.0000\n",
      "Epoch 84/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 553309248.0000 - val_loss: 1762846080.0000\n",
      "Epoch 85/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 560992000.0000 - val_loss: 1665752832.0000\n",
      "Epoch 86/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 578147584.0000 - val_loss: 1787324672.0000\n",
      "Epoch 87/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 576906176.0000 - val_loss: 1668950784.0000\n",
      "Epoch 88/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 584104000.0000 - val_loss: 1774331264.0000\n",
      "Epoch 89/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 568485440.0000 - val_loss: 1657345280.0000\n",
      "Epoch 90/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 560496512.0000 - val_loss: 1728751872.0000\n",
      "Epoch 91/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 542221440.0000 - val_loss: 1664277760.0000\n",
      "Epoch 92/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 530385280.0000 - val_loss: 1689127552.0000\n",
      "Epoch 93/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 524669888.0000 - val_loss: 1701921920.0000\n",
      "Epoch 94/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 526265056.0000 - val_loss: 1665048192.0000\n",
      "Epoch 95/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 533812448.0000 - val_loss: 1739466752.0000\n",
      "Epoch 96/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 542767552.0000 - val_loss: 1662429440.0000\n",
      "Epoch 97/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 557629504.0000 - val_loss: 1770446464.0000\n",
      "Epoch 98/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 559657408.0000 - val_loss: 1665811456.0000\n",
      "Epoch 99/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 564199232.0000 - val_loss: 1759969152.0000\n",
      "Epoch 100/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 554313856.0000 - val_loss: 1655491328.0000\n",
      "Epoch 101/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 548557760.0000 - val_loss: 1717806208.0000\n",
      "Epoch 102/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 535728320.0000 - val_loss: 1669323392.0000\n",
      "Epoch 103/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 525421024.0000 - val_loss: 1688764800.0000\n",
      "Epoch 104/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 522261056.0000 - val_loss: 1714150912.0000\n",
      "Epoch 105/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 526108640.0000 - val_loss: 1662447360.0000\n",
      "Epoch 106/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 537707136.0000 - val_loss: 1750809088.0000\n",
      "Epoch 107/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 547727488.0000 - val_loss: 1666530816.0000\n",
      "Epoch 108/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 558186752.0000 - val_loss: 1774509568.0000\n",
      "Epoch 109/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 554274560.0000 - val_loss: 1667126144.0000\n",
      "Epoch 110/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 553616064.0000 - val_loss: 1745379328.0000\n",
      "Epoch 111/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 542597568.0000 - val_loss: 1655073024.0000\n",
      "Epoch 112/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 535688896.0000 - val_loss: 1703332864.0000\n",
      "Epoch 113/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 525199264.0000 - val_loss: 1686693760.0000\n",
      "Epoch 114/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 519677280.0000 - val_loss: 1688120448.0000\n",
      "Epoch 115/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 521421536.0000 - val_loss: 1716705408.0000\n",
      "Epoch 116/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 524904576.0000 - val_loss: 1656706816.0000\n",
      "Epoch 117/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 533854176.0000 - val_loss: 1727379072.0000\n",
      "Epoch 118/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 536757984.0000 - val_loss: 1666654464.0000\n",
      "Epoch 119/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 533646688.0000 - val_loss: 1739854208.0000\n",
      "Epoch 120/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 532346464.0000 - val_loss: 1662710400.0000\n",
      "Epoch 121/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 528993024.0000 - val_loss: 1703422464.0000\n",
      "Epoch 122/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 527051200.0000 - val_loss: 1652172544.0000\n",
      "Epoch 123/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 523613824.0000 - val_loss: 1695348352.0000\n",
      "Epoch 124/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 518745408.0000 - val_loss: 1681678976.0000\n",
      "Epoch 125/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 517357856.0000 - val_loss: 1690158080.0000\n",
      "Epoch 126/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 516488416.0000 - val_loss: 1673674368.0000\n",
      "Epoch 127/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 516195040.0000 - val_loss: 1673426304.0000\n",
      "Epoch 128/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 516221504.0000 - val_loss: 1681907200.0000\n",
      "Epoch 129/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 515317952.0000 - val_loss: 1690460160.0000\n",
      "Epoch 130/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 515635456.0000 - val_loss: 1687451008.0000\n",
      "Epoch 131/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 514826144.0000 - val_loss: 1685471360.0000\n",
      "Epoch 132/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 514814176.0000 - val_loss: 1676793088.0000\n",
      "Epoch 133/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 514697216.0000 - val_loss: 1693819648.0000\n",
      "Epoch 134/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 514565856.0000 - val_loss: 1680192896.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 515125856.0000 - val_loss: 1708052224.0000\n",
      "Epoch 136/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 516282208.0000 - val_loss: 1670301312.0000\n",
      "Epoch 137/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 519166496.0000 - val_loss: 1725854464.0000\n",
      "Epoch 138/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 522807456.0000 - val_loss: 1665618048.0000\n",
      "Epoch 139/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 530636896.0000 - val_loss: 1758579328.0000\n",
      "Epoch 140/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 538422272.0000 - val_loss: 1665372032.0000\n",
      "Epoch 141/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 556102464.0000 - val_loss: 1793191552.0000\n",
      "Epoch 142/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 564253696.0000 - val_loss: 1673916416.0000\n",
      "Epoch 143/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 583028224.0000 - val_loss: 1815446656.0000\n",
      "Epoch 144/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 577331648.0000 - val_loss: 1674001280.0000\n",
      "Epoch 145/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 580680448.0000 - val_loss: 1783439104.0000\n",
      "Epoch 146/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 558719552.0000 - val_loss: 1655657984.0000\n",
      "Epoch 147/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 542433728.0000 - val_loss: 1715010176.0000\n",
      "Epoch 148/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 521297280.0000 - val_loss: 1678270080.0000\n",
      "Epoch 149/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 511344416.0000 - val_loss: 1678872832.0000\n",
      "Epoch 150/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 513224416.0000 - val_loss: 1732378880.0000\n",
      "Epoch 151/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 522348896.0000 - val_loss: 1661273472.0000\n",
      "Epoch 152/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 539438592.0000 - val_loss: 1767851008.0000\n",
      "Epoch 153/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 547123456.0000 - val_loss: 1667353984.0000\n",
      "Epoch 154/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 550800128.0000 - val_loss: 1769236352.0000\n",
      "Epoch 155/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 539042368.0000 - val_loss: 1664545152.0000\n",
      "Epoch 156/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 531012128.0000 - val_loss: 1720472576.0000\n",
      "Epoch 157/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 519597056.0000 - val_loss: 1667310592.0000\n",
      "Epoch 158/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 512153824.0000 - val_loss: 1689442304.0000\n",
      "Epoch 159/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 508533632.0000 - val_loss: 1712899840.0000\n",
      "Epoch 160/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 510284256.0000 - val_loss: 1682163840.0000\n",
      "Epoch 161/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 515574976.0000 - val_loss: 1745412352.0000\n",
      "Epoch 162/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 521718528.0000 - val_loss: 1668455552.0000\n",
      "Epoch 163/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 532360800.0000 - val_loss: 1759913216.0000\n",
      "Epoch 164/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 532848288.0000 - val_loss: 1673886336.0000\n",
      "Epoch 165/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 531773120.0000 - val_loss: 1756586240.0000\n",
      "Epoch 166/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 524345536.0000 - val_loss: 1671284608.0000\n",
      "Epoch 167/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 519869376.0000 - val_loss: 1716773376.0000\n",
      "Epoch 168/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 513707488.0000 - val_loss: 1678329088.0000\n",
      "Epoch 169/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 508098240.0000 - val_loss: 1700080000.0000\n",
      "Epoch 170/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 505831168.0000 - val_loss: 1719205632.0000\n",
      "Epoch 171/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 507632736.0000 - val_loss: 1681600128.0000\n",
      "Epoch 172/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 512574016.0000 - val_loss: 1743200640.0000\n",
      "Epoch 173/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 519650976.0000 - val_loss: 1670784000.0000\n",
      "Epoch 174/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 528567392.0000 - val_loss: 1765698176.0000\n",
      "Epoch 175/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 529933504.0000 - val_loss: 1669803904.0000\n",
      "Epoch 176/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 534275200.0000 - val_loss: 1758230400.0000\n",
      "Epoch 177/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 529002368.0000 - val_loss: 1661853568.0000\n",
      "Epoch 178/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 525807616.0000 - val_loss: 1727614336.0000\n",
      "Epoch 179/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 515873056.0000 - val_loss: 1677235968.0000\n",
      "Epoch 180/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 507632352.0000 - val_loss: 1703679360.0000\n",
      "Epoch 181/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 503673152.0000 - val_loss: 1708832256.0000\n",
      "Epoch 182/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 503924544.0000 - val_loss: 1679020672.0000\n",
      "Epoch 183/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 508346016.0000 - val_loss: 1739249280.0000\n",
      "Epoch 184/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 514174912.0000 - val_loss: 1676478464.0000\n",
      "Epoch 185/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 523404224.0000 - val_loss: 1772859648.0000\n",
      "Epoch 186/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 527688544.0000 - val_loss: 1673390848.0000\n",
      "Epoch 187/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 534670272.0000 - val_loss: 1768698496.0000\n",
      "Epoch 188/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 531299968.0000 - val_loss: 1665787904.0000\n",
      "Epoch 189/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 529418880.0000 - val_loss: 1743425024.0000\n",
      "Epoch 190/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 517483296.0000 - val_loss: 1682598528.0000\n",
      "Epoch 191/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 507355552.0000 - val_loss: 1714040192.0000\n",
      "Epoch 192/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 501673408.0000 - val_loss: 1710520704.0000\n",
      "Epoch 193/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 501065408.0000 - val_loss: 1682791296.0000\n",
      "Epoch 194/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 505200864.0000 - val_loss: 1742021888.0000\n",
      "Epoch 195/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 510923264.0000 - val_loss: 1682316800.0000\n",
      "Epoch 196/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 519485568.0000 - val_loss: 1779807232.0000\n",
      "Epoch 197/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 524551200.0000 - val_loss: 1679670912.0000\n",
      "Epoch 198/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 531099008.0000 - val_loss: 1774425984.0000\n",
      "Epoch 199/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 529123520.0000 - val_loss: 1667294336.0000\n",
      "Epoch 200/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 529587008.0000 - val_loss: 1752403328.0000\n",
      "Epoch 201/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 518753088.0000 - val_loss: 1681268224.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/500\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 508920384.0000 - val_loss: 1729333376.0000\n",
      "Epoch 203/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 502035552.0000 - val_loss: 1690937216.0000\n",
      "Epoch 204/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 498986880.0000 - val_loss: 1695344768.0000\n",
      "Epoch 205/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 498299328.0000 - val_loss: 1704565888.0000\n",
      "Epoch 206/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 497945632.0000 - val_loss: 1700073856.0000\n",
      "Epoch 207/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 498584480.0000 - val_loss: 1730191104.0000\n",
      "Epoch 208/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 500159712.0000 - val_loss: 1685306880.0000\n",
      "Epoch 209/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 502164032.0000 - val_loss: 1731103872.0000\n",
      "Epoch 210/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 505056096.0000 - val_loss: 1675472768.0000\n",
      "Epoch 211/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 508411968.0000 - val_loss: 1750944512.0000\n",
      "Epoch 212/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 509731008.0000 - val_loss: 1679141120.0000\n",
      "Epoch 213/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 514079808.0000 - val_loss: 1763313408.0000\n",
      "Epoch 214/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 516598048.0000 - val_loss: 1672189696.0000\n",
      "Epoch 215/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 523764160.0000 - val_loss: 1768497664.0000\n",
      "Epoch 216/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 522445440.0000 - val_loss: 1675376000.0000\n",
      "Epoch 217/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 524412160.0000 - val_loss: 1769503488.0000\n",
      "Epoch 218/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 519091840.0000 - val_loss: 1671767424.0000\n",
      "Epoch 219/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 517994176.0000 - val_loss: 1742595840.0000\n",
      "Epoch 220/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 511331072.0000 - val_loss: 1668984832.0000\n",
      "Epoch 221/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 505409344.0000 - val_loss: 1719352704.0000\n",
      "Epoch 222/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 498421056.0000 - val_loss: 1692266112.0000\n",
      "Epoch 223/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 494595744.0000 - val_loss: 1702092160.0000\n",
      "Epoch 224/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 493379840.0000 - val_loss: 1707346816.0000\n",
      "Epoch 225/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 493694752.0000 - val_loss: 1684236160.0000\n",
      "Epoch 226/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 495921504.0000 - val_loss: 1730722688.0000\n",
      "Epoch 227/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 498293408.0000 - val_loss: 1685347840.0000\n",
      "Epoch 228/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 503761152.0000 - val_loss: 1766958080.0000\n",
      "Epoch 229/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 510641888.0000 - val_loss: 1678004352.0000\n",
      "Epoch 230/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 524193088.0000 - val_loss: 1793673088.0000\n",
      "Epoch 231/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 532469536.0000 - val_loss: 1679348992.0000\n",
      "Epoch 232/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 546746304.0000 - val_loss: 1812998400.0000\n",
      "Epoch 233/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 541877696.0000 - val_loss: 1682990464.0000\n",
      "Epoch 234/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 541624960.0000 - val_loss: 1786796544.0000\n",
      "Epoch 235/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 525873760.0000 - val_loss: 1672211200.0000\n",
      "Epoch 236/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 515863712.0000 - val_loss: 1733755264.0000\n",
      "Epoch 237/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 501703936.0000 - val_loss: 1690732544.0000\n",
      "Epoch 238/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 492537600.0000 - val_loss: 1704462592.0000\n",
      "Epoch 239/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 490968192.0000 - val_loss: 1731623680.0000\n",
      "Epoch 240/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 494478976.0000 - val_loss: 1677456000.0000\n",
      "Epoch 241/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 504061376.0000 - val_loss: 1765051776.0000\n",
      "Epoch 242/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 512646400.0000 - val_loss: 1680180480.0000\n",
      "Epoch 243/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 522759712.0000 - val_loss: 1794591232.0000\n",
      "Epoch 244/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 523017600.0000 - val_loss: 1678568576.0000\n",
      "Epoch 245/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 529832928.0000 - val_loss: 1780457600.0000\n",
      "Epoch 246/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 522631872.0000 - val_loss: 1672746240.0000\n",
      "Epoch 247/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 514792384.0000 - val_loss: 1745728256.0000\n",
      "Epoch 248/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 500110784.0000 - val_loss: 1691684224.0000\n",
      "Epoch 249/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 491685376.0000 - val_loss: 1710458624.0000\n",
      "Epoch 250/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 488073888.0000 - val_loss: 1717784448.0000\n",
      "Epoch 251/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 489128768.0000 - val_loss: 1684339584.0000\n",
      "Epoch 252/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 493834752.0000 - val_loss: 1748037504.0000\n",
      "Epoch 253/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 498868352.0000 - val_loss: 1682637824.0000\n",
      "Epoch 254/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 505839456.0000 - val_loss: 1774893312.0000\n",
      "Epoch 255/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 509534304.0000 - val_loss: 1677565312.0000\n",
      "Epoch 256/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 516836192.0000 - val_loss: 1774320256.0000\n",
      "Epoch 257/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 515318176.0000 - val_loss: 1671098624.0000\n",
      "Epoch 258/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 516611264.0000 - val_loss: 1761101312.0000\n",
      "Epoch 259/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 506766976.0000 - val_loss: 1678459392.0000\n",
      "Epoch 260/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 501250752.0000 - val_loss: 1740577920.0000\n",
      "Epoch 261/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 493378496.0000 - val_loss: 1687067136.0000\n",
      "Epoch 262/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 489707456.0000 - val_loss: 1716921088.0000\n",
      "Epoch 263/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 486707552.0000 - val_loss: 1703448448.0000\n",
      "Epoch 264/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 485016352.0000 - val_loss: 1708704128.0000\n",
      "Epoch 265/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 484673920.0000 - val_loss: 1723862016.0000\n",
      "Epoch 266/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 485228928.0000 - val_loss: 1692893312.0000\n",
      "Epoch 267/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 487564128.0000 - val_loss: 1738381568.0000\n",
      "Epoch 268/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 490367776.0000 - val_loss: 1683447680.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 495682720.0000 - val_loss: 1767097472.0000\n",
      "Epoch 270/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 501735552.0000 - val_loss: 1679179392.0000\n",
      "Epoch 271/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 514330240.0000 - val_loss: 1799836288.0000\n",
      "Epoch 272/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 523073120.0000 - val_loss: 1682797824.0000\n",
      "Epoch 273/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 540194816.0000 - val_loss: 1818120960.0000\n",
      "Epoch 274/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 535488512.0000 - val_loss: 1682998912.0000\n",
      "Epoch 275/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 535154464.0000 - val_loss: 1788734592.0000\n",
      "Epoch 276/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 516596032.0000 - val_loss: 1674318976.0000\n",
      "Epoch 277/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 505243264.0000 - val_loss: 1732366720.0000\n",
      "Epoch 278/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 490885920.0000 - val_loss: 1694609408.0000\n",
      "Epoch 279/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 482799616.0000 - val_loss: 1700071808.0000\n",
      "Epoch 280/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 482806592.0000 - val_loss: 1744722176.0000\n",
      "Epoch 281/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 488825664.0000 - val_loss: 1680113152.0000\n",
      "Epoch 282/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 502540640.0000 - val_loss: 1788639104.0000\n",
      "Epoch 283/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 513263104.0000 - val_loss: 1686454656.0000\n",
      "Epoch 284/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 526463744.0000 - val_loss: 1812061312.0000\n",
      "Epoch 285/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 521482624.0000 - val_loss: 1683909504.0000\n",
      "Epoch 286/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 521063040.0000 - val_loss: 1779947136.0000\n",
      "Epoch 287/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 507762752.0000 - val_loss: 1674898560.0000\n",
      "Epoch 288/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 498957984.0000 - val_loss: 1737715328.0000\n",
      "Epoch 289/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 487146720.0000 - val_loss: 1701349504.0000\n",
      "Epoch 290/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 480496896.0000 - val_loss: 1712067456.0000\n",
      "Epoch 291/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 479364704.0000 - val_loss: 1731202176.0000\n",
      "Epoch 292/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 481681984.0000 - val_loss: 1686006784.0000\n",
      "Epoch 293/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 486984448.0000 - val_loss: 1754750848.0000\n",
      "Epoch 294/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 491292256.0000 - val_loss: 1685204096.0000\n",
      "Epoch 295/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 497574816.0000 - val_loss: 1781220992.0000\n",
      "Epoch 296/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 500449792.0000 - val_loss: 1680433024.0000\n",
      "Epoch 297/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 507913472.0000 - val_loss: 1782031104.0000\n",
      "Epoch 298/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 507504192.0000 - val_loss: 1673304704.0000\n",
      "Epoch 299/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 510359968.0000 - val_loss: 1769841280.0000\n",
      "Epoch 300/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 500211168.0000 - val_loss: 1681417728.0000\n",
      "Epoch 301/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 493668320.0000 - val_loss: 1748861312.0000\n",
      "Epoch 302/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 485482752.0000 - val_loss: 1690033408.0000\n",
      "Epoch 303/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 481245376.0000 - val_loss: 1721030784.0000\n",
      "Epoch 304/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 478094304.0000 - val_loss: 1703090688.0000\n",
      "Epoch 305/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 476203648.0000 - val_loss: 1712973568.0000\n",
      "Epoch 306/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 475587872.0000 - val_loss: 1723360000.0000\n",
      "Epoch 307/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 475886048.0000 - val_loss: 1696180480.0000\n",
      "Epoch 308/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 477415168.0000 - val_loss: 1732436480.0000\n",
      "Epoch 309/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 479754720.0000 - val_loss: 1684544384.0000\n",
      "Epoch 310/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 483241248.0000 - val_loss: 1754029568.0000\n",
      "Epoch 311/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 486718240.0000 - val_loss: 1679623552.0000\n",
      "Epoch 312/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 494492416.0000 - val_loss: 1779056128.0000\n",
      "Epoch 313/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 500155776.0000 - val_loss: 1679420928.0000\n",
      "Epoch 314/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 511488608.0000 - val_loss: 1799321984.0000\n",
      "Epoch 315/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 510761632.0000 - val_loss: 1682932224.0000\n",
      "Epoch 316/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 516212448.0000 - val_loss: 1794494208.0000\n",
      "Epoch 317/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 507465728.0000 - val_loss: 1677709440.0000\n",
      "Epoch 318/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 505398208.0000 - val_loss: 1763697792.0000\n",
      "Epoch 319/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 493029920.0000 - val_loss: 1686978432.0000\n",
      "Epoch 320/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 482080576.0000 - val_loss: 1731390080.0000\n",
      "Epoch 321/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 475081056.0000 - val_loss: 1702775040.0000\n",
      "Epoch 322/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 472266976.0000 - val_loss: 1702632960.0000\n",
      "Epoch 323/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 471997152.0000 - val_loss: 1723384576.0000\n",
      "Epoch 324/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 472667744.0000 - val_loss: 1702798720.0000\n",
      "Epoch 325/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 474520736.0000 - val_loss: 1750522752.0000\n",
      "Epoch 326/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 477967680.0000 - val_loss: 1684189184.0000\n",
      "Epoch 327/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 485979520.0000 - val_loss: 1773990912.0000\n",
      "Epoch 328/500\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 494477344.0000 - val_loss: 1682102912.0000\n",
      "Epoch 329/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 510228096.0000 - val_loss: 1822255104.0000\n",
      "Epoch 330/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 515893536.0000 - val_loss: 1691985152.0000\n",
      "Epoch 331/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 533721632.0000 - val_loss: 1831177600.0000\n",
      "Epoch 332/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 528521280.0000 - val_loss: 1682753792.0000\n",
      "Epoch 333/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 526857376.0000 - val_loss: 1786249600.0000\n",
      "Epoch 334/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 501664288.0000 - val_loss: 1691611008.0000\n",
      "Epoch 335/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 481020896.0000 - val_loss: 1729551104.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/500\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 471172736.0000 - val_loss: 1717960192.0000\n",
      "Epoch 337/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 470043328.0000 - val_loss: 1684623744.0000\n",
      "Epoch 338/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 475526048.0000 - val_loss: 1752696192.0000\n",
      "Epoch 339/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 480491808.0000 - val_loss: 1692029056.0000\n",
      "Epoch 340/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 487694592.0000 - val_loss: 1794596608.0000\n",
      "Epoch 341/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 493544128.0000 - val_loss: 1684447360.0000\n",
      "Epoch 342/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 504700736.0000 - val_loss: 1796796032.0000\n",
      "Epoch 343/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 506822656.0000 - val_loss: 1678003968.0000\n",
      "Epoch 344/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 510691200.0000 - val_loss: 1786535168.0000\n",
      "Epoch 345/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 495456608.0000 - val_loss: 1688053120.0000\n",
      "Epoch 346/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 486684704.0000 - val_loss: 1754658944.0000\n",
      "Epoch 347/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 476787232.0000 - val_loss: 1689057024.0000\n",
      "Epoch 348/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 471923712.0000 - val_loss: 1715964416.0000\n",
      "Epoch 349/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 468499872.0000 - val_loss: 1710102784.0000\n",
      "Epoch 350/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 466568096.0000 - val_loss: 1713940992.0000\n",
      "Epoch 351/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 467185600.0000 - val_loss: 1740685184.0000\n",
      "Epoch 352/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 469178336.0000 - val_loss: 1689264128.0000\n",
      "Epoch 353/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 473797568.0000 - val_loss: 1749988224.0000\n",
      "Epoch 354/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 478614656.0000 - val_loss: 1682094592.0000\n",
      "Epoch 355/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 484018112.0000 - val_loss: 1779133312.0000\n",
      "Epoch 356/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 486554176.0000 - val_loss: 1683529728.0000\n",
      "Epoch 357/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 493904704.0000 - val_loss: 1787085696.0000\n",
      "Epoch 358/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 495836416.0000 - val_loss: 1675834368.0000\n",
      "Epoch 359/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 502196640.0000 - val_loss: 1783100160.0000\n",
      "Epoch 360/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 493604256.0000 - val_loss: 1684093824.0000\n",
      "Epoch 361/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 488453024.0000 - val_loss: 1768417280.0000\n",
      "Epoch 362/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 479876896.0000 - val_loss: 1685102464.0000\n",
      "Epoch 363/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 476270720.0000 - val_loss: 1737114240.0000\n",
      "Epoch 364/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 471465280.0000 - val_loss: 1696178688.0000\n",
      "Epoch 365/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 466688384.0000 - val_loss: 1726360320.0000\n",
      "Epoch 366/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 463933440.0000 - val_loss: 1721493120.0000\n",
      "Epoch 367/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 463160480.0000 - val_loss: 1704179840.0000\n",
      "Epoch 368/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 463849952.0000 - val_loss: 1730054912.0000\n",
      "Epoch 369/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 465747424.0000 - val_loss: 1695719808.0000\n",
      "Epoch 370/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 467477024.0000 - val_loss: 1750384000.0000\n",
      "Epoch 371/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 469365408.0000 - val_loss: 1690082304.0000\n",
      "Epoch 372/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 474124704.0000 - val_loss: 1764123776.0000\n",
      "Epoch 373/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 478541056.0000 - val_loss: 1679692032.0000\n",
      "Epoch 374/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 487408352.0000 - val_loss: 1786829824.0000\n",
      "Epoch 375/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 490037504.0000 - val_loss: 1683620352.0000\n",
      "Epoch 376/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 498769152.0000 - val_loss: 1803805056.0000\n",
      "Epoch 377/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 498613216.0000 - val_loss: 1680640896.0000\n",
      "Epoch 378/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 508240288.0000 - val_loss: 1793575040.0000\n",
      "Epoch 379/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 499977184.0000 - val_loss: 1679264896.0000\n",
      "Epoch 380/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 491277728.0000 - val_loss: 1765777408.0000\n",
      "Epoch 381/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 477499744.0000 - val_loss: 1682936576.0000\n",
      "Epoch 382/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 470947680.0000 - val_loss: 1724861184.0000\n",
      "Epoch 383/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 464958112.0000 - val_loss: 1695362688.0000\n",
      "Epoch 384/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 460861664.0000 - val_loss: 1712218496.0000\n",
      "Epoch 385/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 459552192.0000 - val_loss: 1726878976.0000\n",
      "Epoch 386/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 460682112.0000 - val_loss: 1690001408.0000\n",
      "Epoch 387/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 464611264.0000 - val_loss: 1747629312.0000\n",
      "Epoch 388/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 470201248.0000 - val_loss: 1682223104.0000\n",
      "Epoch 389/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 479001952.0000 - val_loss: 1789633280.0000\n",
      "Epoch 390/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 485571072.0000 - val_loss: 1686180992.0000\n",
      "Epoch 391/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 499757824.0000 - val_loss: 1814403200.0000\n",
      "Epoch 392/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 504793024.0000 - val_loss: 1681839872.0000\n",
      "Epoch 393/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 518223264.0000 - val_loss: 1807255040.0000\n",
      "Epoch 394/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 504497984.0000 - val_loss: 1684960896.0000\n",
      "Epoch 395/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 489492384.0000 - val_loss: 1766028032.0000\n",
      "Epoch 396/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 472282656.0000 - val_loss: 1689214336.0000\n",
      "Epoch 397/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 463378976.0000 - val_loss: 1709739264.0000\n",
      "Epoch 398/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 458927488.0000 - val_loss: 1710682752.0000\n",
      "Epoch 399/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 457572160.0000 - val_loss: 1704926848.0000\n",
      "Epoch 400/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 459663488.0000 - val_loss: 1756616192.0000\n",
      "Epoch 401/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 465047424.0000 - val_loss: 1683900800.0000\n",
      "Epoch 402/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 474820384.0000 - val_loss: 1776978176.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 484137952.0000 - val_loss: 1680066304.0000\n",
      "Epoch 404/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 492833376.0000 - val_loss: 1802514432.0000\n",
      "Epoch 405/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 490160416.0000 - val_loss: 1686894592.0000\n",
      "Epoch 406/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 493301760.0000 - val_loss: 1790073472.0000\n",
      "Epoch 407/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 486800000.0000 - val_loss: 1676530560.0000\n",
      "Epoch 408/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 483086464.0000 - val_loss: 1758510464.0000\n",
      "Epoch 409/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 470926912.0000 - val_loss: 1695370880.0000\n",
      "Epoch 410/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 462020160.0000 - val_loss: 1733826560.0000\n",
      "Epoch 411/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 456782240.0000 - val_loss: 1708347008.0000\n",
      "Epoch 412/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 454691936.0000 - val_loss: 1700226560.0000\n",
      "Epoch 413/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 454996000.0000 - val_loss: 1722865152.0000\n",
      "Epoch 414/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 455822528.0000 - val_loss: 1698920192.0000\n",
      "Epoch 415/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 457805376.0000 - val_loss: 1747662976.0000\n",
      "Epoch 416/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 461071488.0000 - val_loss: 1678631808.0000\n",
      "Epoch 417/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 468291104.0000 - val_loss: 1760456704.0000\n",
      "Epoch 418/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 474272480.0000 - val_loss: 1679093888.0000\n",
      "Epoch 419/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 478650400.0000 - val_loss: 1785246592.0000\n",
      "Epoch 420/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 478302560.0000 - val_loss: 1683393152.0000\n",
      "Epoch 421/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 482670208.0000 - val_loss: 1782130176.0000\n",
      "Epoch 422/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 481750848.0000 - val_loss: 1675417984.0000\n",
      "Epoch 423/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 483936224.0000 - val_loss: 1771501184.0000\n",
      "Epoch 424/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 474204416.0000 - val_loss: 1688131328.0000\n",
      "Epoch 425/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 467749856.0000 - val_loss: 1748864768.0000\n",
      "Epoch 426/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 459993856.0000 - val_loss: 1688226560.0000\n",
      "Epoch 427/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 456017696.0000 - val_loss: 1713114496.0000\n",
      "Epoch 428/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 453161376.0000 - val_loss: 1701174784.0000\n",
      "Epoch 429/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 451320064.0000 - val_loss: 1711115136.0000\n",
      "Epoch 430/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 451128096.0000 - val_loss: 1721594880.0000\n",
      "Epoch 431/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 451352416.0000 - val_loss: 1697067520.0000\n",
      "Epoch 432/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 451912896.0000 - val_loss: 1723287936.0000\n",
      "Epoch 433/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 453032128.0000 - val_loss: 1690685056.0000\n",
      "Epoch 434/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 454285856.0000 - val_loss: 1741224320.0000\n",
      "Epoch 435/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 456176704.0000 - val_loss: 1685528704.0000\n",
      "Epoch 436/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 460256640.0000 - val_loss: 1756185984.0000\n",
      "Epoch 437/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 464696352.0000 - val_loss: 1674556800.0000\n",
      "Epoch 438/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 473754496.0000 - val_loss: 1778462592.0000\n",
      "Epoch 439/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 477303072.0000 - val_loss: 1678223616.0000\n",
      "Epoch 440/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 486792512.0000 - val_loss: 1797750272.0000\n",
      "Epoch 441/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 486708128.0000 - val_loss: 1677216128.0000\n",
      "Epoch 442/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 495713920.0000 - val_loss: 1795120896.0000\n",
      "Epoch 443/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 488710560.0000 - val_loss: 1679473280.0000\n",
      "Epoch 444/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 482129728.0000 - val_loss: 1770514176.0000\n",
      "Epoch 445/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 468181664.0000 - val_loss: 1681405824.0000\n",
      "Epoch 446/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 460952448.0000 - val_loss: 1730865408.0000\n",
      "Epoch 447/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 453647328.0000 - val_loss: 1695209728.0000\n",
      "Epoch 448/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 449063232.0000 - val_loss: 1713871104.0000\n",
      "Epoch 449/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 447440928.0000 - val_loss: 1721946752.0000\n",
      "Epoch 450/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 447914240.0000 - val_loss: 1696539904.0000\n",
      "Epoch 451/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 449429632.0000 - val_loss: 1734851584.0000\n",
      "Epoch 452/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 451973664.0000 - val_loss: 1683099264.0000\n",
      "Epoch 453/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 456635808.0000 - val_loss: 1756356736.0000\n",
      "Epoch 454/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 460288832.0000 - val_loss: 1679872768.0000\n",
      "Epoch 455/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 468462400.0000 - val_loss: 1782790912.0000\n",
      "Epoch 456/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 474203904.0000 - val_loss: 1675212160.0000\n",
      "Epoch 457/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 489886624.0000 - val_loss: 1803295360.0000\n",
      "Epoch 458/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 492204928.0000 - val_loss: 1679152768.0000\n",
      "Epoch 459/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 496563680.0000 - val_loss: 1800780288.0000\n",
      "Epoch 460/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 484785952.0000 - val_loss: 1675238272.0000\n",
      "Epoch 461/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 482602208.0000 - val_loss: 1764360320.0000\n",
      "Epoch 462/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 469222016.0000 - val_loss: 1679170176.0000\n",
      "Epoch 463/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 457136640.0000 - val_loss: 1730895232.0000\n",
      "Epoch 464/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 448474752.0000 - val_loss: 1707044736.0000\n",
      "Epoch 465/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 444815776.0000 - val_loss: 1695277312.0000\n",
      "Epoch 466/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 445534624.0000 - val_loss: 1732707840.0000\n",
      "Epoch 467/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 449965440.0000 - val_loss: 1683876608.0000\n",
      "Epoch 468/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 456640384.0000 - val_loss: 1770211840.0000\n",
      "Epoch 469/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 462554144.0000 - val_loss: 1679858304.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 474781568.0000 - val_loss: 1793127168.0000\n",
      "Epoch 471/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 480002848.0000 - val_loss: 1676683520.0000\n",
      "Epoch 472/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 490147168.0000 - val_loss: 1798806656.0000\n",
      "Epoch 473/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 482699040.0000 - val_loss: 1678492032.0000\n",
      "Epoch 474/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 480005984.0000 - val_loss: 1772056064.0000\n",
      "Epoch 475/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 466030848.0000 - val_loss: 1681033344.0000\n",
      "Epoch 476/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 456033088.0000 - val_loss: 1730385408.0000\n",
      "Epoch 477/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 447169280.0000 - val_loss: 1701302144.0000\n",
      "Epoch 478/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 443041984.0000 - val_loss: 1703679744.0000\n",
      "Epoch 479/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 442738496.0000 - val_loss: 1732070400.0000\n",
      "Epoch 480/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 445340512.0000 - val_loss: 1689635840.0000\n",
      "Epoch 481/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 449983872.0000 - val_loss: 1755829760.0000\n",
      "Epoch 482/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 454246304.0000 - val_loss: 1678702720.0000\n",
      "Epoch 483/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 462404800.0000 - val_loss: 1774156032.0000\n",
      "Epoch 484/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 465095776.0000 - val_loss: 1677988736.0000\n",
      "Epoch 485/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 472172480.0000 - val_loss: 1783691008.0000\n",
      "Epoch 486/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 469349056.0000 - val_loss: 1677737344.0000\n",
      "Epoch 487/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 472021056.0000 - val_loss: 1772851584.0000\n",
      "Epoch 488/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 464319264.0000 - val_loss: 1681480832.0000\n",
      "Epoch 489/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 458524960.0000 - val_loss: 1749323008.0000\n",
      "Epoch 490/500\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 449932608.0000 - val_loss: 1695771520.0000\n",
      "Epoch 491/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 444110240.0000 - val_loss: 1719397120.0000\n",
      "Epoch 492/500\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 440760512.0000 - val_loss: 1708952192.0000\n",
      "Epoch 493/500\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 439812032.0000 - val_loss: 1698925952.0000\n",
      "Epoch 494/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 440426368.0000 - val_loss: 1726547456.0000\n",
      "Epoch 495/500\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 441923968.0000 - val_loss: 1687611520.0000\n",
      "Epoch 496/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 444475808.0000 - val_loss: 1737933312.0000\n",
      "Epoch 497/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 446930304.0000 - val_loss: 1672778368.0000\n",
      "Epoch 498/500\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 453090976.0000 - val_loss: 1755318784.0000\n",
      "Epoch 499/500\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 456686592.0000 - val_loss: 1673179136.0000\n",
      "Epoch 500/500\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 464838016.0000 - val_loss: 1780658176.0000\n"
     ]
    }
   ],
   "source": [
    "history = NN_5000E_Adam.fit(x=X,y=y,batch_size=TRAIN_LEN,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_500E_Adam.save('/home/louisliu2096/Models/KaggleHouse/NN_500E_Adam_V2_Nolog.h5')\n",
    "plt = plotHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 512)               207872    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 733,697\n",
      "Trainable params: 733,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_500E_NewAdam = Sequential()\n",
    "NN_500E_NewAdam.add(Dense(512,input_dim = IN_DIM,activation = 'relu'))\n",
    "NN_500E_NewAdam.add(Dense(512,activation = 'relu'))\n",
    "NN_500E_NewAdam.add(Dense(512,activation = 'relu'))\n",
    "NN_500E_NewAdam.add(Dense(1))\n",
    "NN_500E_NewAdam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1164 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1164/1164 [==============================] - 0s 401us/step - loss: 26921049478.5979 - val_loss: 8013320661.9178\n",
      "Epoch 2/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 12087157761.7595 - val_loss: 6324370151.4521\n",
      "Epoch 3/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 5261817798.5979 - val_loss: 2708360530.4110\n",
      "Epoch 4/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 3570958395.3814 - val_loss: 2385208284.9315\n",
      "Epoch 5/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 2488312874.2268 - val_loss: 2246189269.9178\n",
      "Epoch 6/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 2239893529.2921 - val_loss: 2127969160.7671\n",
      "Epoch 7/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 2075671150.4055 - val_loss: 1988349254.1370\n",
      "Epoch 8/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1937726558.9003 - val_loss: 1875655164.4932\n",
      "Epoch 9/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1845102173.2509 - val_loss: 1808960417.3151\n",
      "Epoch 10/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1743572196.7285 - val_loss: 1744446036.1644\n",
      "Epoch 11/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1684236573.4708 - val_loss: 1673167672.1096\n",
      "Epoch 12/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1691863027.6838 - val_loss: 1647540764.0548\n",
      "Epoch 13/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 1636324532.3436 - val_loss: 1642724187.1781\n",
      "Epoch 14/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1590021402.7216 - val_loss: 1629386394.3014\n",
      "Epoch 15/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1586756913.2646 - val_loss: 1631019520.0000\n",
      "Epoch 16/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1588928781.6357 - val_loss: 1632063526.5753\n",
      "Epoch 17/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1542729446.4880 - val_loss: 1576265489.5342\n",
      "Epoch 18/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1621009283.9588 - val_loss: 1609826044.4932\n",
      "Epoch 19/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1533013076.4536 - val_loss: 1602218159.3425\n",
      "Epoch 20/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1526499157.3333 - val_loss: 1568813802.9589\n",
      "Epoch 21/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1503969946.8316 - val_loss: 1629929924.3836\n",
      "Epoch 22/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1502214941.6907 - val_loss: 1568780456.3288\n",
      "Epoch 23/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1498086809.0722 - val_loss: 1631514427.6164\n",
      "Epoch 24/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1493599151.0653 - val_loss: 1695700627.2877\n",
      "Epoch 25/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1515170514.8041 - val_loss: 1603566362.3014\n",
      "Epoch 26/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1538401755.0515 - val_loss: 1567474775.6712\n",
      "Epoch 27/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1536818625.5395 - val_loss: 1619323756.7123\n",
      "Epoch 28/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1498508098.6392 - val_loss: 1607215109.2603\n",
      "Epoch 29/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1522718910.0206 - val_loss: 1691109056.8767\n",
      "Epoch 30/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1471042745.6220 - val_loss: 1565558405.2603\n",
      "Epoch 31/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1464837425.9244 - val_loss: 1818869542.5753\n",
      "Epoch 32/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1484623175.2577 - val_loss: 1556425126.5753\n",
      "Epoch 33/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 1522424006.3780 - val_loss: 1553465614.0274\n",
      "Epoch 34/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1467742186.8866 - val_loss: 1593727466.9589\n",
      "Epoch 35/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 1450176999.5876 - val_loss: 1571877710.9041\n",
      "Epoch 36/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1448051911.0378 - val_loss: 1788300256.4384\n",
      "Epoch 37/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1480557955.0790 - val_loss: 1559517653.9178\n",
      "Epoch 38/500\n",
      "1164/1164 [==============================] - 0s 253us/step - loss: 1447979638.1031 - val_loss: 1542272915.2877\n",
      "Epoch 39/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1448803474.2543 - val_loss: 1574767703.6712\n",
      "Epoch 40/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 1405946725.1684 - val_loss: 1746834758.1370\n",
      "Epoch 41/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1515854624.7698 - val_loss: 1850464459.3973\n",
      "Epoch 42/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 1416545603.2990 - val_loss: 1527918577.9726\n",
      "Epoch 43/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1439673298.6942 - val_loss: 1539543646.6849\n",
      "Epoch 44/500\n",
      "1164/1164 [==============================] - 0s 274us/step - loss: 1404297598.6804 - val_loss: 1536192389.2603\n",
      "Epoch 45/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1417598158.9553 - val_loss: 1561585195.8356\n",
      "Epoch 46/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1373704621.3058 - val_loss: 1541261436.4932\n",
      "Epoch 47/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1387769418.5567 - val_loss: 1546597053.3699\n",
      "Epoch 48/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 1369118669.7457 - val_loss: 1552936574.2466\n",
      "Epoch 49/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1403225525.1134 - val_loss: 1804896017.5342\n",
      "Epoch 50/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1392211226.3918 - val_loss: 1616538501.2603\n",
      "Epoch 51/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 1445013553.7045 - val_loss: 1749587591.0137\n",
      "Epoch 52/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1374667990.8729 - val_loss: 1535359477.4795\n",
      "Epoch 53/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1369860929.9794 - val_loss: 1555898560.8767\n",
      "Epoch 54/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1352402561.3196 - val_loss: 1555959099.6164\n",
      "Epoch 55/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1397567016.4674 - val_loss: 1598655715.9452\n",
      "Epoch 56/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1358840541.6907 - val_loss: 1545870493.8082\n",
      "Epoch 57/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1394368019.3540 - val_loss: 1651181953.7534\n",
      "Epoch 58/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1436737468.7010 - val_loss: 1564640084.1644\n",
      "Epoch 59/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1373082076.8110 - val_loss: 1863194848.4384\n",
      "Epoch 60/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 1393553706.4467 - val_loss: 1544380754.4110\n",
      "Epoch 61/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1434727851.5464 - val_loss: 1530931499.8356\n",
      "Epoch 62/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1378503657.7869 - val_loss: 1548522895.7808\n",
      "Epoch 63/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1343479731.9038 - val_loss: 1558306817.7534\n",
      "Epoch 64/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1332531931.0515 - val_loss: 1530528385.7534\n",
      "Epoch 65/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1419993480.3574 - val_loss: 1674256760.9863\n",
      "Epoch 66/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1373463993.6220 - val_loss: 1722270844.4932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 1348124225.0997 - val_loss: 1563155466.5205\n",
      "Epoch 68/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1297025550.0756 - val_loss: 1524922311.8904\n",
      "Epoch 69/500\n",
      "1164/1164 [==============================] - 0s 253us/step - loss: 1294395859.5739 - val_loss: 1548357516.2740\n",
      "Epoch 70/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1282826629.2784 - val_loss: 1561915020.2740\n",
      "Epoch 71/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1329251412.0137 - val_loss: 1725624211.2877\n",
      "Epoch 72/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1290660138.6667 - val_loss: 1527696999.4521\n",
      "Epoch 73/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1263850360.0825 - val_loss: 1698919990.3562\n",
      "Epoch 74/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1351308112.9347 - val_loss: 1524659415.6712\n",
      "Epoch 75/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1294274952.3574 - val_loss: 1615411471.7808\n",
      "Epoch 76/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1286739126.9828 - val_loss: 1609117080.5479\n",
      "Epoch 77/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 1308761942.6529 - val_loss: 1567648415.5616\n",
      "Epoch 78/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 1263099065.1821 - val_loss: 1659032046.4658\n",
      "Epoch 79/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1262191992.3024 - val_loss: 1533130916.8219\n",
      "Epoch 80/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1289900470.5430 - val_loss: 1532952405.9178\n",
      "Epoch 81/500\n",
      "1164/1164 [==============================] - 0s 276us/step - loss: 1255422812.5911 - val_loss: 1641299235.0685\n",
      "Epoch 82/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1299918181.2784 - val_loss: 1542670185.2055\n",
      "Epoch 83/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1236196579.8488 - val_loss: 1607096960.0000\n",
      "Epoch 84/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 1253531019.4364 - val_loss: 1694331653.2603\n",
      "Epoch 85/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 1241598596.8385 - val_loss: 1623533066.5205\n",
      "Epoch 86/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1292667863.7526 - val_loss: 1521875801.4247\n",
      "Epoch 87/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 1265775828.8935 - val_loss: 1683744836.3836\n",
      "Epoch 88/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1280636745.4570 - val_loss: 1587588309.9178\n",
      "Epoch 89/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1236064670.3505 - val_loss: 1544454897.9726\n",
      "Epoch 90/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 1242529230.7354 - val_loss: 1887706590.6849\n",
      "Epoch 91/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 1287184287.6701 - val_loss: 1646312144.6575\n",
      "Epoch 92/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 1251542849.8694 - val_loss: 1731797449.6438\n",
      "Epoch 93/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1244545409.0997 - val_loss: 1596557546.9589\n",
      "Epoch 94/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1249075295.0103 - val_loss: 1571030263.2329\n",
      "Epoch 95/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 1187634035.6838 - val_loss: 1551812583.4521\n",
      "Epoch 96/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1233091449.8419 - val_loss: 1616138208.4384\n",
      "Epoch 97/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1244999833.9519 - val_loss: 1585435537.5342\n",
      "Epoch 98/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1203238022.3780 - val_loss: 1538619456.8767\n",
      "Epoch 99/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1247453128.5773 - val_loss: 1687852233.6438\n",
      "Epoch 100/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1209470100.6735 - val_loss: 1583257854.2466\n",
      "Epoch 101/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1207313995.8763 - val_loss: 1632351975.4521\n",
      "Epoch 102/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1213119107.5189 - val_loss: 1554560247.2329\n",
      "Epoch 103/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1184543356.9210 - val_loss: 1539966688.4384\n",
      "Epoch 104/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1247271866.9416 - val_loss: 2087500430.0274\n",
      "Epoch 105/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1311200987.0515 - val_loss: 1561724731.6164\n",
      "Epoch 106/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1208991341.9656 - val_loss: 1543819449.8630\n",
      "Epoch 107/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1164993478.3780 - val_loss: 1581028362.5205\n",
      "Epoch 108/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1174611215.3952 - val_loss: 1677904657.5342\n",
      "Epoch 109/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 1166198128.4948 - val_loss: 1637169204.6027\n",
      "Epoch 110/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1309232827.7113 - val_loss: 1519380350.2466\n",
      "Epoch 111/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 1182457235.3540 - val_loss: 1530825820.9315\n",
      "Epoch 112/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1180848894.4605 - val_loss: 1548925650.4110\n",
      "Epoch 113/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1174477843.1340 - val_loss: 1535188174.9041\n",
      "Epoch 114/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 1139354439.2577 - val_loss: 1535376678.5753\n",
      "Epoch 115/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 1158225678.5155 - val_loss: 1544166457.8630\n",
      "Epoch 116/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1139281888.9897 - val_loss: 1660128410.3014\n",
      "Epoch 117/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1143576962.6392 - val_loss: 1636588608.8767\n",
      "Epoch 118/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1150857848.5223 - val_loss: 1572519836.0548\n",
      "Epoch 119/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1200853005.6357 - val_loss: 2175143685.2603\n",
      "Epoch 120/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 1275471939.2990 - val_loss: 1617330104.1096\n",
      "Epoch 121/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 1168337671.9175 - val_loss: 1666181233.9726\n",
      "Epoch 122/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 1143809398.7629 - val_loss: 1555228922.7397\n",
      "Epoch 123/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1196305441.3196 - val_loss: 1567489409.7534\n",
      "Epoch 124/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 1126705697.0997 - val_loss: 1554737642.9589\n",
      "Epoch 125/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1246809685.7732 - val_loss: 1746715365.6986\n",
      "Epoch 126/500\n",
      "1164/1164 [==============================] - 0s 252us/step - loss: 1134780203.9863 - val_loss: 1531335888.6575\n",
      "Epoch 127/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 1254388358.5979 - val_loss: 1547716164.3836\n",
      "Epoch 128/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1150982396.4811 - val_loss: 1574343557.2603\n",
      "Epoch 129/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1137651688.4674 - val_loss: 1724760085.0411\n",
      "Epoch 130/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1120411790.0756 - val_loss: 1536076007.4521\n",
      "Epoch 131/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1159785368.8522 - val_loss: 1540583041.7534\n",
      "Epoch 132/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 1099353499.3814 - val_loss: 1580884615.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1075141165.3058 - val_loss: 1564741523.2877\n",
      "Epoch 134/500\n",
      "1164/1164 [==============================] - 0s 253us/step - loss: 1166548232.7973 - val_loss: 1557592982.7945\n",
      "Epoch 135/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1090681414.8179 - val_loss: 1523052480.8767\n",
      "Epoch 136/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1108546396.3711 - val_loss: 1683972155.6164\n",
      "Epoch 137/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1079443724.0962 - val_loss: 1582384499.7260\n",
      "Epoch 138/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1070312943.2852 - val_loss: 1556826746.7397\n",
      "Epoch 139/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1063979898.9416 - val_loss: 1554343530.9589\n",
      "Epoch 140/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1074423626.7766 - val_loss: 1584908547.5068\n",
      "Epoch 141/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1183145505.3746 - val_loss: 1554092000.4384\n",
      "Epoch 142/500\n",
      "1164/1164 [==============================] - 0s 276us/step - loss: 1089897725.8007 - val_loss: 1537268320.4384\n",
      "Epoch 143/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1083970030.4055 - val_loss: 2174058273.3151\n",
      "Epoch 144/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1130452299.2165 - val_loss: 1539488669.8082\n",
      "Epoch 145/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 1106276130.3093 - val_loss: 1544843358.6849\n",
      "Epoch 146/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 1108594673.0447 - val_loss: 1641113556.1644\n",
      "Epoch 147/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1073071636.8935 - val_loss: 1575789770.5205\n",
      "Epoch 148/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1063880826.6117 - val_loss: 1679451037.8082\n",
      "Epoch 149/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1067426692.1787 - val_loss: 1571921415.0137\n",
      "Epoch 150/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 1076707792.9347 - val_loss: 1563311919.3425\n",
      "Epoch 151/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1076092736.0000 - val_loss: 1555528540.9315\n",
      "Epoch 152/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1042650151.8076 - val_loss: 1572944687.3425\n",
      "Epoch 153/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1057913577.7869 - val_loss: 1536903024.2192\n",
      "Epoch 154/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1075883918.0756 - val_loss: 1525287322.3014\n",
      "Epoch 155/500\n",
      "1164/1164 [==============================] - 0s 253us/step - loss: 1058798493.0309 - val_loss: 1542091905.7534\n",
      "Epoch 156/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 1037359793.7045 - val_loss: 1573495913.2055\n",
      "Epoch 157/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 1051056394.0069 - val_loss: 1555208416.4384\n",
      "Epoch 158/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 995718958.0756 - val_loss: 1549614662.1370\n",
      "Epoch 159/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1008079673.4021 - val_loss: 1575937949.8082\n",
      "Epoch 160/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 1039381812.7835 - val_loss: 1536385532.4932\n",
      "Epoch 161/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 1001968786.4742 - val_loss: 1570485449.6438\n",
      "Epoch 162/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1017698670.8454 - val_loss: 1767945110.7945\n",
      "Epoch 163/500\n",
      "1164/1164 [==============================] - 0s 275us/step - loss: 1003828657.4845 - val_loss: 1538954923.8356\n",
      "Epoch 164/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 990563934.9278 - val_loss: 1520563308.7123\n",
      "Epoch 165/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 1073660426.5567 - val_loss: 2043187571.7260\n",
      "Epoch 166/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 1109370052.6186 - val_loss: 1563255808.0000\n",
      "Epoch 167/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 981142545.3746 - val_loss: 1697285621.4795\n",
      "Epoch 168/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1027444388.5086 - val_loss: 1526109157.6986\n",
      "Epoch 169/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 1013338086.4880 - val_loss: 1545866159.3425\n",
      "Epoch 170/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 1002108161.0997 - val_loss: 1527117489.0959\n",
      "Epoch 171/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 980779707.6014 - val_loss: 1565401621.0411\n",
      "Epoch 172/500\n",
      "1164/1164 [==============================] - 0s 275us/step - loss: 970283267.5189 - val_loss: 1528122759.0137\n",
      "Epoch 173/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 973633411.5189 - val_loss: 1576037384.7671\n",
      "Epoch 174/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 980210406.9278 - val_loss: 1535340905.2055\n",
      "Epoch 175/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 975370631.0378 - val_loss: 1670540894.6849\n",
      "Epoch 176/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 985506968.1924 - val_loss: 1544526760.3288\n",
      "Epoch 177/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 963465750.2131 - val_loss: 1584139462.1370\n",
      "Epoch 178/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 996271065.2921 - val_loss: 1642495133.8082\n",
      "Epoch 179/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 984652574.7904 - val_loss: 1562750560.4384\n",
      "Epoch 180/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 942207466.0069 - val_loss: 1684314660.8219\n",
      "Epoch 181/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 982031430.3780 - val_loss: 1570853018.3014\n",
      "Epoch 182/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 991530836.6735 - val_loss: 1638918515.7260\n",
      "Epoch 183/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 971647950.7354 - val_loss: 1536447061.9178\n",
      "Epoch 184/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 923822735.5052 - val_loss: 1531328783.7808\n",
      "Epoch 185/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 923737734.5979 - val_loss: 1639861305.8630\n",
      "Epoch 186/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 974505361.0447 - val_loss: 1651978499.5068\n",
      "Epoch 187/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 952150893.8557 - val_loss: 1520553799.8904\n",
      "Epoch 188/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 928986193.3746 - val_loss: 1509009692.0548\n",
      "Epoch 189/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 924321885.2509 - val_loss: 1789645176.9863\n",
      "Epoch 190/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 984696876.5361 - val_loss: 1598256527.7808\n",
      "Epoch 191/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 922085728.2199 - val_loss: 1764731137.7534\n",
      "Epoch 192/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 950566262.7629 - val_loss: 1512435463.0137\n",
      "Epoch 193/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 899313727.2302 - val_loss: 1626084066.1918\n",
      "Epoch 194/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 913538738.4742 - val_loss: 1599819446.3562\n",
      "Epoch 195/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 929150637.8557 - val_loss: 1697854839.2329\n",
      "Epoch 196/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 978930392.4124 - val_loss: 1505748886.7945\n",
      "Epoch 197/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 882186785.4296 - val_loss: 1535688875.8356\n",
      "Epoch 198/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 906473211.3814 - val_loss: 1513729311.5616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 929028260.8385 - val_loss: 1560205455.7808\n",
      "Epoch 200/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 1036210131.9038 - val_loss: 1528596004.8219\n",
      "Epoch 201/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 892678212.6186 - val_loss: 1544710734.9041\n",
      "Epoch 202/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 846415444.4536 - val_loss: 1492062485.0411\n",
      "Epoch 203/500\n",
      "1164/1164 [==============================] - 0s 276us/step - loss: 912031186.9141 - val_loss: 1489123007.1233\n",
      "Epoch 204/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 912829896.6873 - val_loss: 1561449971.7260\n",
      "Epoch 205/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 931118314.2268 - val_loss: 1489474270.6849\n",
      "Epoch 206/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 857655888.8247 - val_loss: 1514217282.6301\n",
      "Epoch 207/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 865236072.0275 - val_loss: 1502151111.8904\n",
      "Epoch 208/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 977767867.1615 - val_loss: 1499746190.0274\n",
      "Epoch 209/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 866067642.0619 - val_loss: 1511135791.3425\n",
      "Epoch 210/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 821261767.6976 - val_loss: 1517314332.0548\n",
      "Epoch 211/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 852264821.8832 - val_loss: 1537993433.4247\n",
      "Epoch 212/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 838302650.3918 - val_loss: 1522665901.5890\n",
      "Epoch 213/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 902413543.3677 - val_loss: 1462532900.8219\n",
      "Epoch 214/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 824374312.6873 - val_loss: 1537920287.5616\n",
      "Epoch 215/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 908052597.4433 - val_loss: 1483713101.1507\n",
      "Epoch 216/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 807048978.9141 - val_loss: 1565344334.9041\n",
      "Epoch 217/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 790295467.5464 - val_loss: 1502051212.2740\n",
      "Epoch 218/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 810485973.1134 - val_loss: 1554194603.8356\n",
      "Epoch 219/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 810821183.3402 - val_loss: 1559959855.3425\n",
      "Epoch 220/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 831368670.6804 - val_loss: 1494573841.5342\n",
      "Epoch 221/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 814873639.5876 - val_loss: 1496824276.1644\n",
      "Epoch 222/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 781205076.8935 - val_loss: 1547006872.5479\n",
      "Epoch 223/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 839177408.6598 - val_loss: 1486130605.5890\n",
      "Epoch 224/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 801708866.8591 - val_loss: 1503703299.5068\n",
      "Epoch 225/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 844269404.8110 - val_loss: 1594642782.6849\n",
      "Epoch 226/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 887226595.8488 - val_loss: 1721141525.9178\n",
      "Epoch 227/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 825780377.5120 - val_loss: 1487678539.3973\n",
      "Epoch 228/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 784255457.6495 - val_loss: 1547447008.4384\n",
      "Epoch 229/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 766848784.7148 - val_loss: 1604111023.3425\n",
      "Epoch 230/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 755277795.8488 - val_loss: 1509562871.2329\n",
      "Epoch 231/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 830126148.3986 - val_loss: 1665973709.1507\n",
      "Epoch 232/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 806400695.9725 - val_loss: 1464767067.1781\n",
      "Epoch 233/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 815070101.9931 - val_loss: 1508812328.3288\n",
      "Epoch 234/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 749437176.5223 - val_loss: 1502065674.5205\n",
      "Epoch 235/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 774179326.4055 - val_loss: 1529351674.7397\n",
      "Epoch 236/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 727832290.4192 - val_loss: 1725036684.2740\n",
      "Epoch 237/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 714255803.0515 - val_loss: 1593121129.2055\n",
      "Epoch 238/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 753299584.3299 - val_loss: 1498994158.4658\n",
      "Epoch 239/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 724026119.1478 - val_loss: 1511513259.8356\n",
      "Epoch 240/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 683443604.8935 - val_loss: 1608492649.2055\n",
      "Epoch 241/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 698749704.1375 - val_loss: 1497159623.8904\n",
      "Epoch 242/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 694595897.6220 - val_loss: 1499557453.1507\n",
      "Epoch 243/500\n",
      "1164/1164 [==============================] - 0s 286us/step - loss: 682603153.3746 - val_loss: 1507410607.3425\n",
      "Epoch 244/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 762337995.1065 - val_loss: 1522413483.8356\n",
      "Epoch 245/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 699837269.3333 - val_loss: 1561062596.3836\n",
      "Epoch 246/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 682391581.2509 - val_loss: 1538629996.7123\n",
      "Epoch 247/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 650738857.1271 - val_loss: 1536223431.8904\n",
      "Epoch 248/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 661671794.1443 - val_loss: 1522633615.7808\n",
      "Epoch 249/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 686892095.2852 - val_loss: 1505863827.2877\n",
      "Epoch 250/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 761336475.7113 - val_loss: 1788155280.6575\n",
      "Epoch 251/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 913211615.4502 - val_loss: 1636461436.4932\n",
      "Epoch 252/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 726269840.7148 - val_loss: 1645428609.7534\n",
      "Epoch 253/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 680550541.7457 - val_loss: 1564121435.1781\n",
      "Epoch 254/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 673840426.5567 - val_loss: 1474795870.6849\n",
      "Epoch 255/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 731494621.1409 - val_loss: 1500672213.9178\n",
      "Epoch 256/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 723453075.1340 - val_loss: 1551577770.0822\n",
      "Epoch 257/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 689183943.4777 - val_loss: 1541569909.4795\n",
      "Epoch 258/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 752351189.9931 - val_loss: 1854369886.6849\n",
      "Epoch 259/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 719726879.1203 - val_loss: 1541083688.3288\n",
      "Epoch 260/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 670071619.8488 - val_loss: 1485549764.3836\n",
      "Epoch 261/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 650243366.2680 - val_loss: 1569783818.5205\n",
      "Epoch 262/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 623008317.8007 - val_loss: 1586802463.5616\n",
      "Epoch 263/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 643703468.5361 - val_loss: 1528387934.6849\n",
      "Epoch 264/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 622288287.0103 - val_loss: 1523269965.1507\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164/1164 [==============================] - 0s 256us/step - loss: 609493659.7113 - val_loss: 1522717546.9589\n",
      "Epoch 266/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 607309729.8694 - val_loss: 1560361363.2877\n",
      "Epoch 267/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 599078907.0515 - val_loss: 1572036118.7945\n",
      "Epoch 268/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 644698949.4983 - val_loss: 1557368853.0411\n",
      "Epoch 269/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 593163931.3814 - val_loss: 1608327900.9315\n",
      "Epoch 270/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 630602380.2612 - val_loss: 1507557888.0000\n",
      "Epoch 271/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 599942592.3299 - val_loss: 1548345066.9589\n",
      "Epoch 272/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 586882842.8316 - val_loss: 1529493311.1233\n",
      "Epoch 273/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 568133266.9141 - val_loss: 1524787652.3836\n",
      "Epoch 274/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 570940943.8351 - val_loss: 1545607459.0685\n",
      "Epoch 275/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 558405380.3986 - val_loss: 1636593514.9589\n",
      "Epoch 276/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 580540051.6838 - val_loss: 1688272173.5890\n",
      "Epoch 277/500\n",
      "1164/1164 [==============================] - 0s 276us/step - loss: 579426467.0790 - val_loss: 1525060999.0137\n",
      "Epoch 278/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 561261373.8007 - val_loss: 1578968228.8219\n",
      "Epoch 279/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 632922314.5567 - val_loss: 1667510303.5616\n",
      "Epoch 280/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 655640815.2852 - val_loss: 1535851211.3973\n",
      "Epoch 281/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 556051683.5189 - val_loss: 1719243353.4247\n",
      "Epoch 282/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 636921840.8247 - val_loss: 1556744062.2466\n",
      "Epoch 283/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 574622583.2027 - val_loss: 1507466913.3151\n",
      "Epoch 284/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 546080771.7388 - val_loss: 1511171591.0137\n",
      "Epoch 285/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 539843317.8832 - val_loss: 1515674964.1644\n",
      "Epoch 286/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 621315957.6632 - val_loss: 1553487731.7260\n",
      "Epoch 287/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 517812281.1821 - val_loss: 1496563354.3014\n",
      "Epoch 288/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 510506961.5945 - val_loss: 1635026891.3973\n",
      "Epoch 289/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 527527661.3058 - val_loss: 1546329684.1644\n",
      "Epoch 290/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 535423395.6289 - val_loss: 1588585976.9863\n",
      "Epoch 291/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 561419274.9966 - val_loss: 1580602452.1644\n",
      "Epoch 292/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 518998614.7629 - val_loss: 1579385452.7123\n",
      "Epoch 293/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 537124430.0206 - val_loss: 1575793450.0822\n",
      "Epoch 294/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 499016952.7423 - val_loss: 1577857514.9589\n",
      "Epoch 295/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 616405012.0137 - val_loss: 1583575709.8082\n",
      "Epoch 296/500\n",
      "1164/1164 [==============================] - 0s 275us/step - loss: 539299982.9553 - val_loss: 1522635702.3562\n",
      "Epoch 297/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 521664736.7698 - val_loss: 1583130936.1096\n",
      "Epoch 298/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 549157213.0309 - val_loss: 1764716466.8493\n",
      "Epoch 299/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 550636692.7835 - val_loss: 1542111368.7671\n",
      "Epoch 300/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 485975503.6151 - val_loss: 1512085272.5479\n",
      "Epoch 301/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 466515392.4399 - val_loss: 1553123219.2877\n",
      "Epoch 302/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 518175713.4845 - val_loss: 1883776908.2740\n",
      "Epoch 303/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 581178329.5120 - val_loss: 1655843229.8082\n",
      "Epoch 304/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 500310539.8763 - val_loss: 1592826346.9589\n",
      "Epoch 305/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 475562629.7182 - val_loss: 1509215936.8767\n",
      "Epoch 306/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 468516084.6735 - val_loss: 1693605242.7397\n",
      "Epoch 307/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 484950935.0928 - val_loss: 1504886394.7397\n",
      "Epoch 308/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 498630754.7491 - val_loss: 1526025994.5205\n",
      "Epoch 309/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 484630091.4364 - val_loss: 1586986951.8904\n",
      "Epoch 310/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 507971417.0722 - val_loss: 1513221796.8219\n",
      "Epoch 311/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 452104914.2543 - val_loss: 1513560060.4932\n",
      "Epoch 312/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 455708400.0550 - val_loss: 1503740668.4932\n",
      "Epoch 313/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 509521157.9381 - val_loss: 1712596851.7260\n",
      "Epoch 314/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 511224780.9759 - val_loss: 1484180876.2740\n",
      "Epoch 315/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 444140934.9278 - val_loss: 1575659190.3562\n",
      "Epoch 316/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 499956850.2543 - val_loss: 1662999359.1233\n",
      "Epoch 317/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 517367423.6151 - val_loss: 1498933767.0137\n",
      "Epoch 318/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 452397838.1856 - val_loss: 1520642079.5616\n",
      "Epoch 319/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 413756466.5842 - val_loss: 1515703197.8082\n",
      "Epoch 320/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 435881857.3196 - val_loss: 1589370560.8767\n",
      "Epoch 321/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 467401748.4536 - val_loss: 1560662391.2329\n",
      "Epoch 322/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 423917931.4364 - val_loss: 1545009183.5616\n",
      "Epoch 323/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 425615360.3299 - val_loss: 1617637684.6027\n",
      "Epoch 324/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 423066208.4399 - val_loss: 1575557698.6301\n",
      "Epoch 325/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 417348791.8076 - val_loss: 1853535130.3014\n",
      "Epoch 326/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 533573810.5842 - val_loss: 1624798593.7534\n",
      "Epoch 327/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 446648599.4227 - val_loss: 1582509462.7945\n",
      "Epoch 328/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 431350341.4983 - val_loss: 1651924339.7260\n",
      "Epoch 329/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 495965465.4021 - val_loss: 1555317419.8356\n",
      "Epoch 330/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 420968978.2543 - val_loss: 1541161654.3562\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164/1164 [==============================] - 0s 272us/step - loss: 417340609.0447 - val_loss: 1528336874.9589\n",
      "Epoch 332/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 432374267.1615 - val_loss: 1529520952.1096\n",
      "Epoch 333/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 412100685.5258 - val_loss: 1513155352.5479\n",
      "Epoch 334/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 389891291.1615 - val_loss: 1604687198.6849\n",
      "Epoch 335/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 469794059.2165 - val_loss: 1561242515.2877\n",
      "Epoch 336/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 465496368.8935 - val_loss: 1648975780.8219\n",
      "Epoch 337/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 411757656.9622 - val_loss: 1558874080.4384\n",
      "Epoch 338/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 382199099.9313 - val_loss: 1557239320.5479\n",
      "Epoch 339/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 408961919.3402 - val_loss: 1553559432.7671\n",
      "Epoch 340/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 415489994.0069 - val_loss: 1527136354.1918\n",
      "Epoch 341/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 434512025.7320 - val_loss: 1558308643.0685\n",
      "Epoch 342/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 401539516.9210 - val_loss: 1524524295.0137\n",
      "Epoch 343/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 422379831.6426 - val_loss: 1568311813.2603\n",
      "Epoch 344/500\n",
      "1164/1164 [==============================] - 0s 274us/step - loss: 391099555.6838 - val_loss: 1557414912.0000\n",
      "Epoch 345/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 364749492.9485 - val_loss: 1623660242.4110\n",
      "Epoch 346/500\n",
      "1164/1164 [==============================] - 0s 253us/step - loss: 388443352.1924 - val_loss: 1526432483.9452\n",
      "Epoch 347/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 368516442.8316 - val_loss: 1534922892.2740\n",
      "Epoch 348/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 420416918.9828 - val_loss: 1546445729.3151\n",
      "Epoch 349/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 418438099.0241 - val_loss: 1494110614.7945\n",
      "Epoch 350/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 378171951.6151 - val_loss: 1586792546.1918\n",
      "Epoch 351/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 380521608.9622 - val_loss: 1502462232.5479\n",
      "Epoch 352/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 380240227.4089 - val_loss: 1540854373.6986\n",
      "Epoch 353/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 408637804.6460 - val_loss: 1551633404.4932\n",
      "Epoch 354/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 388489070.7354 - val_loss: 1556892184.5479\n",
      "Epoch 355/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 443593962.6667 - val_loss: 1723913899.8356\n",
      "Epoch 356/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 528464785.4296 - val_loss: 1579791391.5616\n",
      "Epoch 357/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 367935236.5636 - val_loss: 1576588891.1781\n",
      "Epoch 358/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 396946500.7285 - val_loss: 1539119047.8904\n",
      "Epoch 359/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 371237925.3333 - val_loss: 1571280643.5068\n",
      "Epoch 360/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 345012457.4570 - val_loss: 1546191773.8082\n",
      "Epoch 361/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 347566002.4742 - val_loss: 1715123564.7123\n",
      "Epoch 362/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 370028419.2990 - val_loss: 1600307578.7397\n",
      "Epoch 363/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 351307219.6014 - val_loss: 1549441707.8356\n",
      "Epoch 364/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 365592554.4467 - val_loss: 1561196147.7260\n",
      "Epoch 365/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 408148780.9759 - val_loss: 1544512448.8767\n",
      "Epoch 366/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 384184815.7251 - val_loss: 1622130347.8356\n",
      "Epoch 367/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 367887366.0481 - val_loss: 1581753642.0822\n",
      "Epoch 368/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 375934540.8660 - val_loss: 1547960400.6575\n",
      "Epoch 369/500\n",
      "1164/1164 [==============================] - 0s 277us/step - loss: 352901961.7869 - val_loss: 1607195658.5205\n",
      "Epoch 370/500\n",
      "1164/1164 [==============================] - 0s 279us/step - loss: 396884851.6838 - val_loss: 1567237965.1507\n",
      "Epoch 371/500\n",
      "1164/1164 [==============================] - 0s 282us/step - loss: 331650303.4502 - val_loss: 1539608611.0685\n",
      "Epoch 372/500\n",
      "1164/1164 [==============================] - 0s 290us/step - loss: 344612103.9175 - val_loss: 1562837342.6849\n",
      "Epoch 373/500\n",
      "1164/1164 [==============================] - 0s 279us/step - loss: 467634595.5189 - val_loss: 1574001723.6164\n",
      "Epoch 374/500\n",
      "1164/1164 [==============================] - 0s 285us/step - loss: 434015052.5911 - val_loss: 1483760408.5479\n",
      "Epoch 375/500\n",
      "1164/1164 [==============================] - 0s 285us/step - loss: 310841775.6151 - val_loss: 1581513549.1507\n",
      "Epoch 376/500\n",
      "1164/1164 [==============================] - 0s 288us/step - loss: 348360531.6838 - val_loss: 1691084435.2877\n",
      "Epoch 377/500\n",
      "1164/1164 [==============================] - 0s 286us/step - loss: 345527134.3505 - val_loss: 1559453955.5068\n",
      "Epoch 378/500\n",
      "1164/1164 [==============================] - 0s 281us/step - loss: 357998901.9931 - val_loss: 1592620733.3699\n",
      "Epoch 379/500\n",
      "1164/1164 [==============================] - 0s 276us/step - loss: 333467805.3608 - val_loss: 1606281770.0822\n",
      "Epoch 380/500\n",
      "1164/1164 [==============================] - 0s 287us/step - loss: 334689565.0309 - val_loss: 1596381173.4795\n",
      "Epoch 381/500\n",
      "1164/1164 [==============================] - 0s 284us/step - loss: 569459761.7045 - val_loss: 1723326243.0685\n",
      "Epoch 382/500\n",
      "1164/1164 [==============================] - 0s 285us/step - loss: 354107163.9313 - val_loss: 1569698079.5616\n",
      "Epoch 383/500\n",
      "1164/1164 [==============================] - 0s 288us/step - loss: 297263055.0653 - val_loss: 1560679388.9315\n",
      "Epoch 384/500\n",
      "1164/1164 [==============================] - 0s 290us/step - loss: 298255229.4708 - val_loss: 1545823281.0959\n",
      "Epoch 385/500\n",
      "1164/1164 [==============================] - 0s 285us/step - loss: 320277891.3814 - val_loss: 1583048360.3288\n",
      "Epoch 386/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 310724313.7869 - val_loss: 1546220298.5205\n",
      "Epoch 387/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 337157466.3918 - val_loss: 1928764801.7534\n",
      "Epoch 388/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 353939236.0687 - val_loss: 1568320059.6164\n",
      "Epoch 389/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 304849205.7732 - val_loss: 1494109099.8356\n",
      "Epoch 390/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 280436344.0275 - val_loss: 1574149270.7945\n",
      "Epoch 391/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 283629258.4467 - val_loss: 1579541486.4658\n",
      "Epoch 392/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 348644117.5533 - val_loss: 1538107044.8219\n",
      "Epoch 393/500\n",
      "1164/1164 [==============================] - 0s 250us/step - loss: 338362585.6220 - val_loss: 1621327191.6712\n",
      "Epoch 394/500\n",
      "1164/1164 [==============================] - 0s 253us/step - loss: 379959925.2784 - val_loss: 1525161941.9178\n",
      "Epoch 395/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 300725664.8797 - val_loss: 1559148414.2466\n",
      "Epoch 396/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 290773337.8144 - val_loss: 1791273377.3151\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164/1164 [==============================] - 0s 258us/step - loss: 345029393.0447 - val_loss: 1676057687.6712\n",
      "Epoch 398/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 311785348.9485 - val_loss: 1587892641.3151\n",
      "Epoch 399/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 296103435.6564 - val_loss: 1597161763.0685\n",
      "Epoch 400/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 278314674.5292 - val_loss: 1536547587.5068\n",
      "Epoch 401/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 291983978.8866 - val_loss: 1531035349.9178\n",
      "Epoch 402/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 363868444.8110 - val_loss: 1590017308.0548\n",
      "Epoch 403/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 437677759.0928 - val_loss: 1542762106.7397\n",
      "Epoch 404/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 303638314.0069 - val_loss: 1615086907.6164\n",
      "Epoch 405/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 309880108.9759 - val_loss: 1582118126.4658\n",
      "Epoch 406/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 286736994.9691 - val_loss: 1513720779.3973\n",
      "Epoch 407/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 273174195.3540 - val_loss: 1562494835.7260\n",
      "Epoch 408/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 290168483.4089 - val_loss: 1563645510.1370\n",
      "Epoch 409/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 281177029.1134 - val_loss: 1559534528.8767\n",
      "Epoch 410/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 323671634.1443 - val_loss: 1701387046.5753\n",
      "Epoch 411/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 323765269.1684 - val_loss: 1955863520.4384\n",
      "Epoch 412/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 426364598.9828 - val_loss: 1534504900.3836\n",
      "Epoch 413/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 298004933.1684 - val_loss: 1529997662.6849\n",
      "Epoch 414/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 296866579.5739 - val_loss: 1602229163.8356\n",
      "Epoch 415/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 347973921.5395 - val_loss: 1541346125.1507\n",
      "Epoch 416/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 330326730.9966 - val_loss: 1604703284.6027\n",
      "Epoch 417/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 287069999.2852 - val_loss: 1531258659.0685\n",
      "Epoch 418/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 281441336.1375 - val_loss: 1581554789.6986\n",
      "Epoch 419/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 276936614.0481 - val_loss: 1598550184.3288\n",
      "Epoch 420/500\n",
      "1164/1164 [==============================] - 0s 258us/step - loss: 279092034.6392 - val_loss: 1540478674.4110\n",
      "Epoch 421/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 282982149.2784 - val_loss: 1607195697.0959\n",
      "Epoch 422/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 292513803.8763 - val_loss: 1653483081.6438\n",
      "Epoch 423/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 304425652.0687 - val_loss: 1552204452.8219\n",
      "Epoch 424/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 289488965.1684 - val_loss: 1606955642.7397\n",
      "Epoch 425/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 281787452.2612 - val_loss: 1561146241.7534\n",
      "Epoch 426/500\n",
      "1164/1164 [==============================] - 0s 270us/step - loss: 275629580.0962 - val_loss: 1654434198.7945\n",
      "Epoch 427/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 308990076.4811 - val_loss: 1588781276.9315\n",
      "Epoch 428/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 260319875.9588 - val_loss: 1595319047.0137\n",
      "Epoch 429/500\n",
      "1164/1164 [==============================] - 0s 260us/step - loss: 236525694.0206 - val_loss: 1536397852.0548\n",
      "Epoch 430/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 232499993.0722 - val_loss: 1608419050.9589\n",
      "Epoch 431/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 253259118.4055 - val_loss: 1659743638.7945\n",
      "Epoch 432/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 265432905.2371 - val_loss: 1573455493.2603\n",
      "Epoch 433/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 248747703.6976 - val_loss: 1593182474.5205\n",
      "Epoch 434/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 325353308.8660 - val_loss: 1568620189.8082\n",
      "Epoch 435/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 288829233.8144 - val_loss: 1687917182.2466\n",
      "Epoch 436/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 288474323.9588 - val_loss: 1583336840.7671\n",
      "Epoch 437/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 230005463.6976 - val_loss: 1573743272.3288\n",
      "Epoch 438/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 289462654.9003 - val_loss: 1637801966.4658\n",
      "Epoch 439/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 263977182.1306 - val_loss: 1549069108.6027\n",
      "Epoch 440/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 230287699.4089 - val_loss: 1628118485.9178\n",
      "Epoch 441/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 236197947.5464 - val_loss: 1660601600.0000\n",
      "Epoch 442/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 259623512.7423 - val_loss: 1604084932.3836\n",
      "Epoch 443/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 234607449.0447 - val_loss: 1605133974.7945\n",
      "Epoch 444/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 267323505.3746 - val_loss: 1795473797.2603\n",
      "Epoch 445/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 263841727.3952 - val_loss: 1619708906.9589\n",
      "Epoch 446/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 245315728.8797 - val_loss: 1574548353.7534\n",
      "Epoch 447/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 294066134.7629 - val_loss: 1691083183.3425\n",
      "Epoch 448/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 311844980.1787 - val_loss: 1830588458.0822\n",
      "Epoch 449/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 279594334.5155 - val_loss: 1600021851.1781\n",
      "Epoch 450/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 230137357.8007 - val_loss: 1607518832.2192\n",
      "Epoch 451/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 323406900.5636 - val_loss: 1723188581.6986\n",
      "Epoch 452/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 338586796.8660 - val_loss: 1638972019.7260\n",
      "Epoch 453/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 334499860.3436 - val_loss: 1729466368.0000\n",
      "Epoch 454/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 274556481.9794 - val_loss: 1622812517.6986\n",
      "Epoch 455/500\n",
      "1164/1164 [==============================] - 0s 252us/step - loss: 219268872.4674 - val_loss: 1589905520.2192\n",
      "Epoch 456/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 225249640.0275 - val_loss: 1569448090.3014\n",
      "Epoch 457/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 213773040.7973 - val_loss: 1549458863.3425\n",
      "Epoch 458/500\n",
      "1164/1164 [==============================] - 0s 272us/step - loss: 228722310.3780 - val_loss: 1649336235.8356\n",
      "Epoch 459/500\n",
      "1164/1164 [==============================] - 0s 273us/step - loss: 236261470.9828 - val_loss: 1713288044.7123\n",
      "Epoch 460/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 231643400.0275 - val_loss: 1611813912.5479\n",
      "Epoch 461/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 239924945.9244 - val_loss: 1691559357.3699\n",
      "Epoch 462/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 227143616.6598 - val_loss: 1654264902.1370\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164/1164 [==============================] - 0s 264us/step - loss: 222841908.3162 - val_loss: 1607267440.2192\n",
      "Epoch 464/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 235464275.7938 - val_loss: 1572807104.8767\n",
      "Epoch 465/500\n",
      "1164/1164 [==============================] - 0s 251us/step - loss: 209239260.1787 - val_loss: 1565065296.6575\n",
      "Epoch 466/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 217339309.2509 - val_loss: 1664997000.7671\n",
      "Epoch 467/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 252853122.0893 - val_loss: 1870507597.1507\n",
      "Epoch 468/500\n",
      "1164/1164 [==============================] - 0s 256us/step - loss: 312804188.0412 - val_loss: 1901761792.0000\n",
      "Epoch 469/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 298784010.1168 - val_loss: 1615751602.8493\n",
      "Epoch 470/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 212761685.3058 - val_loss: 1616097539.5068\n",
      "Epoch 471/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 200040596.4536 - val_loss: 1613686135.2329\n",
      "Epoch 472/500\n",
      "1164/1164 [==============================] - 0s 275us/step - loss: 222777643.3265 - val_loss: 1590258126.9041\n",
      "Epoch 473/500\n",
      "1164/1164 [==============================] - 0s 275us/step - loss: 245108289.8144 - val_loss: 1816088709.2603\n",
      "Epoch 474/500\n",
      "1164/1164 [==============================] - 0s 274us/step - loss: 252984664.6598 - val_loss: 1547593545.6438\n",
      "Epoch 475/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 216785093.9931 - val_loss: 1633973360.2192\n",
      "Epoch 476/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 205384658.9416 - val_loss: 1654810090.9589\n",
      "Epoch 477/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 264090708.8660 - val_loss: 1869815246.9041\n",
      "Epoch 478/500\n",
      "1164/1164 [==============================] - 0s 254us/step - loss: 241922484.3436 - val_loss: 1654982778.7397\n",
      "Epoch 479/500\n",
      "1164/1164 [==============================] - 0s 259us/step - loss: 194522588.1512 - val_loss: 1589039191.6712\n",
      "Epoch 480/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 225903118.1306 - val_loss: 1685144649.6438\n",
      "Epoch 481/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 294047759.8351 - val_loss: 1591506533.6986\n",
      "Epoch 482/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 224781729.7869 - val_loss: 1650062378.0822\n",
      "Epoch 483/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 221434609.8969 - val_loss: 1689267413.9178\n",
      "Epoch 484/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 246670230.2131 - val_loss: 1728918654.2466\n",
      "Epoch 485/500\n",
      "1164/1164 [==============================] - 0s 264us/step - loss: 208803636.0275 - val_loss: 1630156551.0137\n",
      "Epoch 486/500\n",
      "1164/1164 [==============================] - 0s 267us/step - loss: 190194569.5670 - val_loss: 1623172194.1918\n",
      "Epoch 487/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 210786012.5361 - val_loss: 1616731581.3699\n",
      "Epoch 488/500\n",
      "1164/1164 [==============================] - 0s 257us/step - loss: 250885603.9863 - val_loss: 1646432497.9726\n",
      "Epoch 489/500\n",
      "1164/1164 [==============================] - 0s 252us/step - loss: 210049293.7457 - val_loss: 1674092147.7260\n",
      "Epoch 490/500\n",
      "1164/1164 [==============================] - 0s 265us/step - loss: 218736742.7629 - val_loss: 1628599492.3836\n",
      "Epoch 491/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 180524022.2680 - val_loss: 1665560263.8904\n",
      "Epoch 492/500\n",
      "1164/1164 [==============================] - 0s 262us/step - loss: 199842664.6323 - val_loss: 1618208908.2740\n",
      "Epoch 493/500\n",
      "1164/1164 [==============================] - 0s 266us/step - loss: 197231557.5533 - val_loss: 1560805007.7808\n",
      "Epoch 494/500\n",
      "1164/1164 [==============================] - 0s 255us/step - loss: 177760252.1512 - val_loss: 1697742511.3425\n",
      "Epoch 495/500\n",
      "1164/1164 [==============================] - 0s 268us/step - loss: 187344349.9107 - val_loss: 1644116844.7123\n",
      "Epoch 496/500\n",
      "1164/1164 [==============================] - 0s 263us/step - loss: 200929497.4296 - val_loss: 1651718028.2740\n",
      "Epoch 497/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 183161505.2096 - val_loss: 1650393631.5616\n",
      "Epoch 498/500\n",
      "1164/1164 [==============================] - 0s 261us/step - loss: 191859024.7148 - val_loss: 1705010225.0959\n",
      "Epoch 499/500\n",
      "1164/1164 [==============================] - 0s 271us/step - loss: 180758596.1787 - val_loss: 1636022240.4384\n",
      "Epoch 500/500\n",
      "1164/1164 [==============================] - 0s 269us/step - loss: 175208627.1340 - val_loss: 1608077112.1096\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "newAdam = Adam(learning_rate=0.0005)\n",
    "NN_500E_NewAdam.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_500E_NewAdam.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_500E_NewAdam.save('NN_5000E_NewAdam_V2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 695,297\n",
      "Trainable params: 695,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_Sig = Sequential()\n",
    "NN_5000E_Adam_Sig.add(Dense(512,input_dim = 330,activation = 'sigmoid'))\n",
    "NN_5000E_Adam_Sig.add(Dense(512,activation = 'sigmoid'))\n",
    "NN_5000E_Adam_Sig.add(Dense(512,activation = 'sigmoid'))\n",
    "NN_5000E_Adam_Sig.add(Dense(1))\n",
    "NN_5000E_Adam_Sig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 364us/step - loss: 37765465534.6290 - val_loss: 38856311962.3014\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37760839083.3248 - val_loss: 38851632927.5616\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37756176252.3805 - val_loss: 38846826748.4931\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37751193261.2991 - val_loss: 38841367622.1370\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37745548971.5441 - val_loss: 38835620204.7123\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37739652777.7892 - val_loss: 38829458361.8630\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37733663901.0660 - val_loss: 38823570894.9041\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37727911614.8483 - val_loss: 38817877006.0274\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37722319242.8586 - val_loss: 38812273734.1370\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37716798786.0291 - val_loss: 38806748174.0274\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37711336034.7147 - val_loss: 38801228168.7671\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37705886606.8072 - val_loss: 38795753387.8356\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37700468985.1997 - val_loss: 38790304978.4110\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37695077452.3393 - val_loss: 38784852697.4247\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37689687407.6572 - val_loss: 38779443452.4931\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37684336289.0146 - val_loss: 38773981127.8904\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 37678964479.7806 - val_loss: 38768613291.8356\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37673629230.9443 - val_loss: 38763233897.2055\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37668293715.3590 - val_loss: 38757846759.4521\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37662964371.8526 - val_loss: 38752457489.5342\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37657637643.1877 - val_loss: 38747105195.8356\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37652331194.4610 - val_loss: 38741736013.1507\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37647024177.1380 - val_loss: 38736370926.4658\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37641713795.6195 - val_loss: 38731015658.9589\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37636415628.3942 - val_loss: 38725684518.5753\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 37631123020.7781 - val_loss: 38720334525.3699\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 37625830946.6598 - val_loss: 38714992836.3836\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37620546639.8492 - val_loss: 38709638915.5069\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37615245229.5184 - val_loss: 38704294140.4931\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37609942443.3248 - val_loss: 38698978486.3562\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37604684702.6015 - val_loss: 38693630008.1096\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37599393523.4961 - val_loss: 38688331186.8493\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37594135414.2382 - val_loss: 38682998924.2740\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37588857109.2785 - val_loss: 38677657515.8356\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 37583581963.1877 - val_loss: 38672350278.1370\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37578291987.9623 - val_loss: 38667061724.9315\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37573038374.8278 - val_loss: 38661679749.2603\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37567736295.8698 - val_loss: 38656375036.4931\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37562480097.7275 - val_loss: 38651053715.2877\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37557219478.9237 - val_loss: 38645727063.6712\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37551939696.3153 - val_loss: 38640386833.5342\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37546659359.1500 - val_loss: 38635104620.7123\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37541417953.2888 - val_loss: 38629788517.6986\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37536160465.2751 - val_loss: 38624502489.4247\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37530913073.3573 - val_loss: 38619158107.1781\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37525648042.6667 - val_loss: 38613881112.5479\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37520407607.2802 - val_loss: 38608596430.9041\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37515154127.5201 - val_loss: 38603312198.1370\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37509925992.4182 - val_loss: 38597969891.9452\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37504646111.5338 - val_loss: 38592705465.8630\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37499414807.0334 - val_loss: 38587396600.9863\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37494167399.3213 - val_loss: 38582122131.2877\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37488929294.4781 - val_loss: 38576804625.5342\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37483697800.4456 - val_loss: 38571488298.0822\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37478438696.1440 - val_loss: 38566246876.9315\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37473214530.6872 - val_loss: 38560950580.6027\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37467961073.7412 - val_loss: 38555669994.9589\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37462729218.1937 - val_loss: 38550376167.4521\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37457483360.0823 - val_loss: 38545103549.3699\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37452250307.6744 - val_loss: 38539755295.5616\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 37446980712.4182 - val_loss: 38534491767.2329\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37441751536.6444 - val_loss: 38529196368.6575\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37436511606.6769 - val_loss: 38523888682.0822\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37431263393.4533 - val_loss: 38518638339.5069\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37426032510.1354 - val_loss: 38513364374.7945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37420806614.3205 - val_loss: 38508010622.2466\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37415536322.3582 - val_loss: 38502743671.2329\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 37410309570.1388 - val_loss: 38497450797.5890\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37405076672.1645 - val_loss: 38492161066.0822\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37399840706.5776 - val_loss: 38486900736.0000\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37394613480.5278 - val_loss: 38481583735.2329\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37389368189.2579 - val_loss: 38476314427.6164\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37384131820.0377 - val_loss: 38471026547.7260\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37378893752.0480 - val_loss: 38465764871.0137\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 37373654076.5450 - val_loss: 38460444840.3288\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37368407909.5664 - val_loss: 38455184285.8082\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37363190939.3111 - val_loss: 38449917334.7945\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37357977947.4756 - val_loss: 38444616044.7123\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 232us/step - loss: 37352746407.8149 - val_loss: 38439353806.9041\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37347513144.8158 - val_loss: 38434082198.7945\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37342292452.3599 - val_loss: 38428770079.5616\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37337063094.0737 - val_loss: 38423503857.9726\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 37331837698.4130 - val_loss: 38418243303.4521\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37326635123.8252 - val_loss: 38412945828.8219\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37321405409.2888 - val_loss: 38407698403.9452\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37316182065.1380 - val_loss: 38402445368.1096\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37310959214.1217 - val_loss: 38397139982.0274\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37305726830.3410 - val_loss: 38391896877.5890\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37300516069.0180 - val_loss: 38386602601.2055\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37295286014.0257 - val_loss: 38381376441.8630\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37290090327.5270 - val_loss: 38376056916.1644\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37284859151.1362 - val_loss: 38370802926.4658\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37279636545.8098 - val_loss: 38365580582.5753\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37274431644.1885 - val_loss: 38360293376.0000\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 261us/step - loss: 37269211490.4953 - val_loss: 38355026424.9863\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37263998726.8003 - val_loss: 38349771313.0959\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37258781661.7789 - val_loss: 38344476419.5069\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37253551715.5921 - val_loss: 38339209412.3836\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37248341363.1671 - val_loss: 38333921981.3699\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37243107001.5835 - val_loss: 38328704182.3562\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37237913622.8141 - val_loss: 38323423877.2603\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37232689752.1851 - val_loss: 38318160012.2740\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37227471353.4190 - val_loss: 38312884925.3699\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37222256734.7661 - val_loss: 38307633685.0411\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37217034966.5398 - val_loss: 38302391983.3425\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 37211833859.0711 - val_loss: 38297087214.4658\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37206617750.4850 - val_loss: 38291842819.5069\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37201403226.5981 - val_loss: 38286597021.8082\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37196193325.1894 - val_loss: 38281309366.3562\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37190956275.0574 - val_loss: 38276083150.9041\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 37185759844.4696 - val_loss: 38270775239.8904\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37180552915.9075 - val_loss: 38265488706.6301\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 37175335580.6273 - val_loss: 38260260190.6849\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37170134476.6684 - val_loss: 38255014841.8630\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37164942464.9871 - val_loss: 38249735434.5205\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 37159723299.3179 - val_loss: 38244519655.4521\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37154513106.5913 - val_loss: 38239258652.0548\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37149297175.2528 - val_loss: 38233980310.7945\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37144087101.8612 - val_loss: 38228714481.9726\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 37138891680.3565 - val_loss: 38223466888.7671\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 266us/step - loss: 37133700274.1251 - val_loss: 38218225635.9452\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 279us/step - loss: 37128497918.9032 - val_loss: 38212981016.5479\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 37123279497.3231 - val_loss: 38207658012.0548\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 37118050898.9203 - val_loss: 38202443242.9589\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 37112870410.0908 - val_loss: 38197196996.3836\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37107671666.5090 - val_loss: 38191969883.1781\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 37102483220.8398 - val_loss: 38186710170.3014\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37097282608.2605 - val_loss: 38181456629.4795\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37092088992.5758 - val_loss: 38176209316.8219\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 37086897475.7841 - val_loss: 38170950782.2466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37081676500.7849 - val_loss: 38165743924.6027\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 37076492333.6281 - val_loss: 38160474673.0959\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37071288535.8560 - val_loss: 38155209068.7123\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 37066082467.2082 - val_loss: 38149985097.6438\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 37060892203.4344 - val_loss: 38144735708.9315\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 37055698521.0626 - val_loss: 38139490808.9863\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37050510521.1448 - val_loss: 38134242766.9041\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 37045310631.5955 - val_loss: 38129019974.1370\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 37040122110.4644 - val_loss: 38123787867.1781\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37034932345.0900 - val_loss: 38118537075.7260\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 37029733970.0428 - val_loss: 38113249364.1644\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 37024533102.9991 - val_loss: 38108021128.7671\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37019349769.4327 - val_loss: 38102786328.5479\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37014152413.9983 - val_loss: 38097569483.3973\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 37008977656.7609 - val_loss: 38092310219.3973\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 37003781055.9452 - val_loss: 38087067844.3836\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36998602095.6572 - val_loss: 38081815201.3151\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36993409782.1285 - val_loss: 38076591959.6712\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36988220771.3727 - val_loss: 38071369615.7808\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36983046335.2871 - val_loss: 38066106985.2055\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36977850176.7129 - val_loss: 38060896704.8767\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36972665072.4250 - val_loss: 38055629753.8630\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36967467817.0214 - val_loss: 38050398600.7671\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36962292052.4559 - val_loss: 38045169860.3836\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 36957100470.7318 - val_loss: 38039933601.3151\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36951917293.3539 - val_loss: 38034705983.1233\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36946739851.0780 - val_loss: 38029463608.1096\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36941544127.7258 - val_loss: 38024268196.8219\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36936383102.7935 - val_loss: 38019013982.6849\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36931187955.0574 - val_loss: 38013806171.1781\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36926004456.5278 - val_loss: 38008553584.2192\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36920812358.8552 - val_loss: 38003322318.9041\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36915638272.0000 - val_loss: 37998049700.8219\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36910428823.3625 - val_loss: 37992847388.0548\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36905246484.8398 - val_loss: 37987606415.7808\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36900053135.9040 - val_loss: 37982389290.0822\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36894877671.4310 - val_loss: 37977123012.3836\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36889692790.0189 - val_loss: 37971896291.9452\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36884513408.5484 - val_loss: 37966680120.1096\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36879343073.7275 - val_loss: 37961446666.5205\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36874157518.4233 - val_loss: 37956237059.5069\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36868993311.8081 - val_loss: 37950990307.9452\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36863806082.3033 - val_loss: 37945746810.7397\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36858624101.7858 - val_loss: 37940518294.7945\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36853450601.0763 - val_loss: 37935292808.7671\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36848265182.6564 - val_loss: 37930089766.5753\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36843104766.6838 - val_loss: 37924861755.6164\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36837918342.6907 - val_loss: 37919636494.0274\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36832744552.4182 - val_loss: 37914377005.5890\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36827554623.8355 - val_loss: 37909184455.8904\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36822380243.9075 - val_loss: 37903976700.4931\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36817219738.4336 - val_loss: 37898697405.3699\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36812023181.4910 - val_loss: 37893487125.0411\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36806838556.2982 - val_loss: 37888244020.6027\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36801664183.3899 - val_loss: 37883020610.6301\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36796487246.5330 - val_loss: 37877820317.8082\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36791324728.1577 - val_loss: 37872539002.7397\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36786132021.5253 - val_loss: 37867385224.7671\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36780971103.6435 - val_loss: 37862153959.4521\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36775797185.2614 - val_loss: 37856912257.7534\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36770605436.8192 - val_loss: 37851695580.9315\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36765436755.1397 - val_loss: 37846427283.2877\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36760254213.0454 - val_loss: 37841238380.7123\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36755090378.4747 - val_loss: 37836006947.0685\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36749910679.3625 - val_loss: 37830795544.5479\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36744732220.9837 - val_loss: 37825564503.6712\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36739562358.2382 - val_loss: 37820348331.8356\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36734393114.9820 - val_loss: 37815105507.9452\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36729206982.3068 - val_loss: 37809914360.9863\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36724067048.0891 - val_loss: 37804649654.3562\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36718885762.5227 - val_loss: 37799498289.0959\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36713746523.2562 - val_loss: 37794242952.7671\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36708551731.7703 - val_loss: 37789052030.2466\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36703393546.3102 - val_loss: 37783822392.1096\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36698241883.9143 - val_loss: 37778583383.6712\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36693065987.7292 - val_loss: 37773407947.3973\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36687915295.8081 - val_loss: 37768155809.3151\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36682738381.7652 - val_loss: 37762989687.2329\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36677585582.1765 - val_loss: 37757770036.6027\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36672410975.8629 - val_loss: 37752545392.2192\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36667245460.0720 - val_loss: 37747282312.7671\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36662063354.9546 - val_loss: 37742092231.8904\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 36656903969.1243 - val_loss: 37736917749.4795\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36651756141.2442 - val_loss: 37731698996.6027\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36646592547.0985 - val_loss: 37726504707.5069\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36641443396.0034 - val_loss: 37721255262.6849\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 36636271746.7421 - val_loss: 37716065013.4795\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36631113720.9803 - val_loss: 37710830830.4658\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36625949259.9006 - val_loss: 37705623411.7260\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 36620790837.5253 - val_loss: 37700415936.8767\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36615629305.4190 - val_loss: 37695241847.2329\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36610491094.5398 - val_loss: 37690007383.6712\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36605325087.3693 - val_loss: 37684822352.6575\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36600165927.9246 - val_loss: 37679626885.2603\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36595020141.0248 - val_loss: 37674372671.1233\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36589855451.8046 - val_loss: 37669180345.8630\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36584700900.7986 - val_loss: 37664016524.2740\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 36579564657.1928 - val_loss: 37658818026.9589\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36574417766.4439 - val_loss: 37653606400.0000\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36569262629.2922 - val_loss: 37648405882.7397\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36564100437.3333 - val_loss: 37643202952.7671\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36558933061.3196 - val_loss: 37638020166.1370\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36553779938.8243 - val_loss: 37632784355.9452\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36548625498.3787 - val_loss: 37627556569.4247\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36543486457.4190 - val_loss: 37622326650.7397\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36538324284.7644 - val_loss: 37617155759.3425\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36533164733.9709 - val_loss: 37611957767.0137\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36528019554.2759 - val_loss: 37606744961.7534\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36522864875.1602 - val_loss: 37601571096.5479\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36517725995.6538 - val_loss: 37596363790.0274\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36512575803.8869 - val_loss: 37591126857.6438\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36507421358.1765 - val_loss: 37585962026.0822\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36502278017.6452 - val_loss: 37580745237.0411\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36497121678.3685 - val_loss: 37575553865.6438\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36491978123.7361 - val_loss: 37570356939.3973\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 263us/step - loss: 36486824550.2245 - val_loss: 37565189021.8082\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36481680878.0120 - val_loss: 37559959327.5616\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36476527276.4216 - val_loss: 37554780973.5890\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36471390760.8021 - val_loss: 37549559695.7808\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36466234447.8492 - val_loss: 37544397894.1370\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36461102354.6461 - val_loss: 37539197208.5479\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36455948382.7661 - val_loss: 37533989397.0411\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36450784237.5733 - val_loss: 37528814577.9726\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36445656654.5330 - val_loss: 37523602277.6986\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 36440516439.5270 - val_loss: 37518405856.4384\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36435368501.0865 - val_loss: 37513224248.1096\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36430228265.0214 - val_loss: 37508043088.6575\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36425086474.0908 - val_loss: 37502852615.0137\n",
      "Epoch 259/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 247us/step - loss: 36419954521.2819 - val_loss: 37497654173.8082\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36414807691.9554 - val_loss: 37492467964.4931\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36409664979.6881 - val_loss: 37487280240.2192\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36404526596.8260 - val_loss: 37482079274.0822\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36399381996.2571 - val_loss: 37476889922.6301\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36394242837.7172 - val_loss: 37471721556.1644\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36389099426.9889 - val_loss: 37466531755.8356\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36383964840.0343 - val_loss: 37461280178.8493\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36378782161.0557 - val_loss: 37456092005.6986\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36373650673.3025 - val_loss: 37450890815.1233\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36368516725.1414 - val_loss: 37445692093.3699\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36363371208.5004 - val_loss: 37440529618.4110\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36358231825.3299 - val_loss: 37435357997.5890\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36353113188.9083 - val_loss: 37430156582.5753\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36347975021.9023 - val_loss: 37424993883.1781\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36342831395.3179 - val_loss: 37419799032.9863\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36337682840.8980 - val_loss: 37414648228.8219\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36332569081.4190 - val_loss: 37409404619.3973\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36327413933.7378 - val_loss: 37404236926.2466\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36322267120.2057 - val_loss: 37399056215.6712\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 36317144593.1105 - val_loss: 37393850255.7808\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 36312007049.1037 - val_loss: 37388702537.6438\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36306888967.2391 - val_loss: 37383502300.9315\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 36301742188.8055 - val_loss: 37378355256.1096\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36296630752.8500 - val_loss: 37373142001.9726\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36291493768.6650 - val_loss: 37367950350.0274\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36286346165.4156 - val_loss: 37362801958.5753\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36281229922.7147 - val_loss: 37357618105.8630\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36276085910.0463 - val_loss: 37352403505.0959\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36270953609.7618 - val_loss: 37347220718.4658\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 36265826140.7918 - val_loss: 37342053923.0685\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36260716063.1500 - val_loss: 37336876579.0685\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36255573484.2571 - val_loss: 37331739409.5342\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36250453226.2828 - val_loss: 37326506965.9178\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36245300365.2716 - val_loss: 37321396167.8904\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 36240192421.6213 - val_loss: 37316161760.4384\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36235063878.6358 - val_loss: 37310972128.4384\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36229932043.4070 - val_loss: 37305803930.3014\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36224804581.4567 - val_loss: 37300599317.0411\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36219663954.0428 - val_loss: 37295469890.6301\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36214559337.7344 - val_loss: 37290272739.9452\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36209424078.6427 - val_loss: 37285109535.5616\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36204313581.5733 - val_loss: 37279950932.1644\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 36199197549.4636 - val_loss: 37274787615.5616\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 36194080402.9752 - val_loss: 37269625308.9315\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36188970758.8003 - val_loss: 37264434105.8630\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36183820054.5947 - val_loss: 37259303052.2740\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36178706607.4927 - val_loss: 37254086824.3288\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36173576018.2622 - val_loss: 37248916325.6986\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36168465096.5004 - val_loss: 37243720633.8630\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36163333740.3668 - val_loss: 37238573140.1644\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36158227646.4096 - val_loss: 37233417454.4658\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36153112465.4396 - val_loss: 37228241513.2055\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36147989039.8218 - val_loss: 37223084032.0000\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36142873855.3419 - val_loss: 37217873976.1096\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36137743181.8749 - val_loss: 37212752966.1370\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36132629762.8518 - val_loss: 37207592679.4521\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36127516654.4507 - val_loss: 37202380323.0685\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 36122391075.5373 - val_loss: 37197232604.9315\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36117283753.1311 - val_loss: 37192073103.7808\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36112177306.4336 - val_loss: 37186916295.8904\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36107069568.1097 - val_loss: 37181765435.6164\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36101961087.4516 - val_loss: 37176594488.1096\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36096839739.6675 - val_loss: 37171463378.4110\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 36091744656.1234 - val_loss: 37166295685.2603\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 36086628704.7404 - val_loss: 37161114750.2466\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36081514371.4002 - val_loss: 37155955641.8630\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 36076391449.4464 - val_loss: 37150796589.5890\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36071294519.7189 - val_loss: 37145628391.4521\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36066187707.9966 - val_loss: 37140466758.1370\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36061061009.4396 - val_loss: 37135335480.1096\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36055966892.8603 - val_loss: 37130164083.7260\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36050849756.9015 - val_loss: 37125011147.3973\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 36045751152.9734 - val_loss: 37119852039.0137\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 36040645327.5201 - val_loss: 37114682045.3699\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 36035530141.2853 - val_loss: 37109530680.1096\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 36030408038.8826 - val_loss: 37104350923.3973\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 36025288042.3925 - val_loss: 37099204103.0137\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 36020182773.2511 - val_loss: 37094054140.4931\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 36015077832.2811 - val_loss: 37088886840.1096\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 36009970546.7284 - val_loss: 37083726609.5342\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 36004866179.6195 - val_loss: 37078559589.6986\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35999757114.5707 - val_loss: 37073407719.4521\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 35994657141.7995 - val_loss: 37068249340.4931\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35989544349.2853 - val_loss: 37063137420.2740\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35984452171.9006 - val_loss: 37057950481.5342\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 35979335090.3445 - val_loss: 37052804166.1370\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35974242051.2905 - val_loss: 37047664696.1096\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35969122398.7661 - val_loss: 37042488025.4247\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35964023993.1448 - val_loss: 37037292277.4795\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 35958906844.9015 - val_loss: 37032160494.4658\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35953812694.9786 - val_loss: 37027038362.3014\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35948723669.4430 - val_loss: 37021897208.9863\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35943625869.2716 - val_loss: 37016731311.3425\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35938517441.2614 - val_loss: 37011590943.5616\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35933419521.7549 - val_loss: 37006443225.4247\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35928322862.2862 - val_loss: 37001298424.9863\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35923230899.0026 - val_loss: 36996116592.2192\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 35918111632.5621 - val_loss: 36990960008.7671\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35912997932.7506 - val_loss: 36985822502.5753\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35907907494.4987 - val_loss: 36980661149.8082\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35902813186.6324 - val_loss: 36975506361.8630\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35897707810.4404 - val_loss: 36970397808.2192\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35892624390.1422 - val_loss: 36965209578.9589\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35887507780.6615 - val_loss: 36960097097.6438\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35882401549.8200 - val_loss: 36954953531.6164\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35877304241.0283 - val_loss: 36949805589.0411\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35872211302.0051 - val_loss: 36944665614.0274\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35867123887.4927 - val_loss: 36939525863.4521\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35862041369.2271 - val_loss: 36934352671.5616\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35856934506.6118 - val_loss: 36929213145.4247\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35851843320.7609 - val_loss: 36924054766.4658\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35846749421.7926 - val_loss: 36918922534.5753\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35841644092.9837 - val_loss: 36913796194.1918\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35836550499.3727 - val_loss: 36908629623.2329\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35831462735.6298 - val_loss: 36903483700.6027\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 237us/step - loss: 35826379034.5433 - val_loss: 36898340527.3425\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35821295631.7943 - val_loss: 36893202852.8219\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35816205391.8492 - val_loss: 36888106587.1781\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35811131095.4173 - val_loss: 36882930870.3562\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35806033077.6350 - val_loss: 36877802958.9041\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 35800944176.6992 - val_loss: 36872693283.0685\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35795864071.4584 - val_loss: 36867565203.2877\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35790777920.4936 - val_loss: 36862427977.6438\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35785704459.4070 - val_loss: 36857280652.2740\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35780618383.9040 - val_loss: 36852153245.8082\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35775528967.0197 - val_loss: 36847042784.4384\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35770445692.3805 - val_loss: 36841861176.1096\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 251us/step - loss: 35765347483.3111 - val_loss: 36836729617.5342\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35760273351.8423 - val_loss: 36831582572.7123\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35755194403.0985 - val_loss: 36826471101.3699\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35750124121.9400 - val_loss: 36821362547.7260\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35745035900.1611 - val_loss: 36816217578.9589\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35739942648.7609 - val_loss: 36811075527.8904\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35734834733.1894 - val_loss: 36805947392.0000\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35729741021.9983 - val_loss: 36800814711.2329\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35724663213.9572 - val_loss: 36795629904.6575\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35719579098.7078 - val_loss: 36790486058.0822\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35714489130.7764 - val_loss: 36785385023.1233\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35709415539.8252 - val_loss: 36780254811.1781\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35704327802.4062 - val_loss: 36775135260.0548\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35699258725.1277 - val_loss: 36769954100.6027\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 259us/step - loss: 35694158269.7515 - val_loss: 36764865185.3151\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35689083655.6778 - val_loss: 36759717467.1781\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35683996683.4070 - val_loss: 36754556226.6301\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35678904488.4730 - val_loss: 36749473258.9589\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35673836708.0857 - val_loss: 36744308595.7260\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 35668745008.0411 - val_loss: 36739190503.4521\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35663668275.7703 - val_loss: 36734087672.9863\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35658611556.6889 - val_loss: 36728949942.3562\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 35653520755.1671 - val_loss: 36723832691.7260\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35648457407.7258 - val_loss: 36718686881.3151\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 35643369354.4199 - val_loss: 36713566881.3151\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35638291914.9135 - val_loss: 36708435547.1781\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 243us/step - loss: 35633221717.9914 - val_loss: 36703280254.2466\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35628150201.3642 - val_loss: 36698189094.5753\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35623083852.9974 - val_loss: 36693123801.4247\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35618030750.8209 - val_loss: 36687977822.6849\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35612937648.5895 - val_loss: 36682865678.0274\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35607880897.9194 - val_loss: 36677730696.7671\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35602806747.1465 - val_loss: 36672601887.5616\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35597713997.6555 - val_loss: 36667485141.9178\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35592657273.3093 - val_loss: 36662336638.2466\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35587587899.4482 - val_loss: 36657225166.9041\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35582514327.8012 - val_loss: 36652158471.0137\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35577454069.0317 - val_loss: 36647006937.4247\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35572397202.5364 - val_loss: 36641883570.8493\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35567322527.0403 - val_loss: 36636799817.6438\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35562259679.7532 - val_loss: 36631674655.5616\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35557192122.2416 - val_loss: 36626551906.1918\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35552137461.6898 - val_loss: 36621415353.8630\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35547059857.2202 - val_loss: 36616313196.7123\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35542006239.0951 - val_loss: 36611180010.9589\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35536926546.2622 - val_loss: 36606071906.1918\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35531850363.2836 - val_loss: 36601003022.0274\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35526801437.8338 - val_loss: 36595833589.4795\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35521726370.9889 - val_loss: 36590710952.3288\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35516652451.8663 - val_loss: 36585583938.6301\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35511587179.2699 - val_loss: 36580473308.9315\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35506514967.6915 - val_loss: 36575421874.8493\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35501458917.2374 - val_loss: 36570268209.0959\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35496384141.7104 - val_loss: 36565162909.8082\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35491323591.6230 - val_loss: 36560048184.1096\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35486271693.3265 - val_loss: 36554930933.4795\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35481207020.9152 - val_loss: 36549830066.8493\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35476159750.3616 - val_loss: 36544724038.1370\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35471099326.6290 - val_loss: 36539629343.5616\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35466039962.8723 - val_loss: 36534491164.0548\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35460967370.4747 - val_loss: 36529409935.7808\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35455926868.6752 - val_loss: 36524283819.8356\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35450855652.1405 - val_loss: 36519173919.5616\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35445799019.0506 - val_loss: 36514044829.8082\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 236us/step - loss: 35440737542.3616 - val_loss: 36508967473.0959\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 249us/step - loss: 35435686112.6307 - val_loss: 36503862342.1370\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35430633749.2785 - val_loss: 36498744362.0822\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 239us/step - loss: 35425568773.2648 - val_loss: 36493643776.0000\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 35420499499.4344 - val_loss: 36488551606.3562\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 246us/step - loss: 35415457114.5981 - val_loss: 36483418196.1644\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35410388198.7729 - val_loss: 36478330403.0685\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35405338076.4627 - val_loss: 36473246369.3151\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35400300394.8312 - val_loss: 36468112622.4658\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 258us/step - loss: 35395242656.1371 - val_loss: 36463035882.9589\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35390190262.9512 - val_loss: 36457930471.4521\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35385126452.2091 - val_loss: 36452814848.0000\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35380059610.7078 - val_loss: 36447673021.3699\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35375006833.1928 - val_loss: 36442592690.8493\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 240us/step - loss: 35369961266.6735 - val_loss: 36437487784.3288\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 35364904931.9212 - val_loss: 36432412223.1233\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35359863742.1902 - val_loss: 36427293401.4247\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35354813912.9529 - val_loss: 36422182098.4110\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35349770341.7858 - val_loss: 36417079885.1507\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35344718038.1011 - val_loss: 36412013357.5890\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 35339678250.5570 - val_loss: 36406943126.7945\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35334641802.6392 - val_loss: 36401811736.5479\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35329583965.6692 - val_loss: 36396711150.4658\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35324544636.1611 - val_loss: 36391580265.2055\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35319490112.4936 - val_loss: 36386519516.9315\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35314464320.4936 - val_loss: 36381420501.9178\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 252us/step - loss: 35309412906.5570 - val_loss: 36376320084.1644\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 238us/step - loss: 35304359018.1731 - val_loss: 36371239304.7671\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 241us/step - loss: 35299298892.7781 - val_loss: 36366150108.9315\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35294251901.2579 - val_loss: 36361055414.3562\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 254us/step - loss: 35289203860.2913 - val_loss: 36355958419.2877\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35284155377.0831 - val_loss: 36350857384.3288\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35279121379.0437 - val_loss: 36345714603.8356\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 256us/step - loss: 35274053514.4199 - val_loss: 36340652733.3699\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35268997516.6135 - val_loss: 36335577396.6027\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 250us/step - loss: 35263954041.9674 - val_loss: 36330432371.7260\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35258905032.2811 - val_loss: 36325316074.9589\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35253852137.1859 - val_loss: 36320239111.0137\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 35248827009.4259 - val_loss: 36315141218.1918\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35243785880.2399 - val_loss: 36310123057.0959\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 255us/step - loss: 35238769633.2888 - val_loss: 36305036835.0685\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35233713653.0317 - val_loss: 36299925027.0685\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35228673009.0831 - val_loss: 36294811872.4384\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 257us/step - loss: 35223626945.9194 - val_loss: 36289734010.7397\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35218598988.3393 - val_loss: 36284617657.8630\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 245us/step - loss: 35213552433.7961 - val_loss: 36279574752.4384\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 244us/step - loss: 35208533231.5476 - val_loss: 36274484378.3014\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 253us/step - loss: 35203491476.7301 - val_loss: 36269369877.0411\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 35198437047.8286 - val_loss: 36264309970.4110\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 251us/step - loss: 35193409967.7121 - val_loss: 36259218025.2055\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0005)\n",
    "NN_5000E_Adam_Sig.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_Sig.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,220,609\n",
      "Trainable params: 1,220,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_4H = Sequential()\n",
    "NN_5000E_Adam_4H.add(Dense(512,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(512,activation = 'relu'))\n",
    "NN_5000E_Adam_4H.add(Dense(1))\n",
    "NN_5000E_Adam_4H.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 1s 564us/step - loss: 36522277088.6307 - val_loss: 31151011924.1644\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 20591323523.4002 - val_loss: 10548069663.5616\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 14787735020.2571 - val_loss: 9263632727.6712\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 12293208674.7147 - val_loss: 7920128925.8082\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 9516187921.4396 - val_loss: 5965733312.8767\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 6733085789.2853 - val_loss: 4627476713.2055\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 4693404259.3728 - val_loss: 4056714520.5479\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 3240308142.8346 - val_loss: 3607858887.8904\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 2409489225.2956 - val_loss: 3407602991.3425\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 2126030431.5338 - val_loss: 3345038679.6712\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 1923661741.2991 - val_loss: 3390656392.7671\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1856447810.9066 - val_loss: 3235776711.8904\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1840494072.1028 - val_loss: 3213287765.9178\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1782692888.1302 - val_loss: 3306326983.8904\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1750170984.5004 - val_loss: 3425477902.0274\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 417us/step - loss: 1759172968.4730 - val_loss: 3297372075.8356\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1739661912.5141 - val_loss: 3182036495.7808\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1700264707.7292 - val_loss: 3237325718.7945\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1689910471.8423 - val_loss: 3233075962.7397\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1677819253.6898 - val_loss: 3279000328.7671\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1672347774.7935 - val_loss: 3259854074.7397\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1654582417.7686 - val_loss: 3256749399.6712\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1636965410.5501 - val_loss: 3173431262.6849\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1677840963.1260 - val_loss: 3256274823.0137\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1653054868.7301 - val_loss: 3350165290.0822\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 1s 455us/step - loss: 1613606679.4722 - val_loss: 3368744814.4658\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1626568677.2922 - val_loss: 3261663114.5205\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1598763332.2228 - val_loss: 3400512554.0822\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1600926150.6358 - val_loss: 3133992418.1918\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1589578693.8680 - val_loss: 3169283257.8630\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 1558678889.7344 - val_loss: 3343467656.7671\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 1577731098.2416 - val_loss: 3109704747.8356\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1572402602.5570 - val_loss: 3108685816.9863\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1556857881.7755 - val_loss: 3194043000.9863\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1531136180.0171 - val_loss: 3077415045.2603\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1559198172.5724 - val_loss: 3153962674.8493\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1611650858.1731 - val_loss: 3321784872.3288\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1597638399.6710 - val_loss: 3112523512.9863\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1533095930.1868 - val_loss: 3112745910.3562\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1507373505.8098 - val_loss: 3048931233.3151\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 1505514252.2296 - val_loss: 3165863196.0548\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1541081999.5750 - val_loss: 3124507476.1644\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1483151867.5030 - val_loss: 3368232248.1096\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1506677220.6341 - val_loss: 3230176112.2192\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1464773561.9949 - val_loss: 3109345416.7671\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1473269284.3599 - val_loss: 3029772579.0685\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1474278194.2896 - val_loss: 3350865646.4658\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1468301756.8740 - val_loss: 3040980655.3425\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1444248563.2219 - val_loss: 3273193668.3836\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 1441196837.0180 - val_loss: 3289186696.7671\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1465705852.3805 - val_loss: 3054998640.2192\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1445793033.4327 - val_loss: 3009686117.6986\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1448398886.1697 - val_loss: 3376718620.0548\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1442741500.4901 - val_loss: 3039573184.8767\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 1419594656.2468 - val_loss: 3103301109.4795\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1412442016.7952 - val_loss: 3072513343.1233\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1392019265.3710 - val_loss: 2961614932.1644\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1446132969.9263 - val_loss: 2986880175.3425\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1397039893.0591 - val_loss: 2973036999.8904\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 1436366527.5613 - val_loss: 3078874971.1781\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1374469245.4773 - val_loss: 2989103146.0822\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1401208453.1551 - val_loss: 3078489358.0274\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1404507123.8252 - val_loss: 2962517556.6027\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1373522788.4696 - val_loss: 3419958615.6712\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 1s 492us/step - loss: 1412739832.3222 - val_loss: 3066478935.6712\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1385106021.9777 - val_loss: 3052150110.6849\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1385407327.5338 - val_loss: 3518912722.4110\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1387324834.6598 - val_loss: 3015115821.5890\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1360344916.7575 - val_loss: 3181765951.1233\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 414us/step - loss: 1356330097.4670 - val_loss: 2938336606.6849\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1418422828.9152 - val_loss: 3055152359.4521\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 408us/step - loss: 1389436894.1354 - val_loss: 3155283982.0274\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 1375963933.8338 - val_loss: 3211531123.7260\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1515055199.0951 - val_loss: 2916702348.2740\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1378849899.9554 - val_loss: 2923911280.2192\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 413us/step - loss: 1347275776.6581 - val_loss: 2924796110.9041\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 1422471533.0797 - val_loss: 2990133830.1370\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1365481410.7969 - val_loss: 2926225425.5342\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1343566834.6187 - val_loss: 3069888519.0137\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1397603578.7901 - val_loss: 2906680456.7671\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1361736407.0883 - val_loss: 3027433657.8630\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1297740856.8706 - val_loss: 2982782909.3699\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1337794199.0883 - val_loss: 2964935013.6986\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1344212505.8852 - val_loss: 2905368421.6986\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1337217342.8483 - val_loss: 3134342459.6164\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1304985361.0009 - val_loss: 3129265088.8767\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1320477071.2459 - val_loss: 2910153934.9041\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 1357981463.9657 - val_loss: 3150098537.2055\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1373008714.5844 - val_loss: 3004727278.4658\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1327203684.3599 - val_loss: 2886679432.7671\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1354050444.8329 - val_loss: 2916040125.3699\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1443282470.4987 - val_loss: 2858416924.0548\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1274284851.5510 - val_loss: 3335619359.5616\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1332225653.0865 - val_loss: 2850390545.5342\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1297488776.7198 - val_loss: 3218708767.5616\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1288654257.4670 - val_loss: 2883222969.8630\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1315380586.3925 - val_loss: 2911319446.7945\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1277727962.2691 - val_loss: 3091833638.5753\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1351574174.6015 - val_loss: 2860897763.9452\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1283803369.4053 - val_loss: 2917407512.5479\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1269597817.5287 - val_loss: 2836882137.4247\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1277439467.7635 - val_loss: 3185674250.5205\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 1328414660.8260 - val_loss: 2819263295.1233\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1267059175.5955 - val_loss: 3268857722.7397\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1286872024.7335 - val_loss: 2884893134.9041\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1269414652.7644 - val_loss: 2836079342.4658\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1277289148.8740 - val_loss: 3226905796.3836\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1337045110.6769 - val_loss: 2912508700.0548\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1257782190.2314 - val_loss: 2805235824.2192\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 411us/step - loss: 1253752236.4216 - val_loss: 3031019754.9589\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1265631103.5613 - val_loss: 2966189385.6438\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1254794863.3282 - val_loss: 3039772307.2877\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 1273395907.7841 - val_loss: 3015003164.0548\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1253965045.6350 - val_loss: 2833160090.3014\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1248249266.6598 - val_loss: 2793115721.6438\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1235316038.3068 - val_loss: 2814190970.7397\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1242431011.5921 - val_loss: 2917721915.6164\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1215784993.4533 - val_loss: 2791357678.4658\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1227567860.0583 - val_loss: 2799876092.4932\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1204748677.7035 - val_loss: 2772784054.3562\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1241430347.6812 - val_loss: 2829291463.8904\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1203923034.9820 - val_loss: 2980978354.8493\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 1227110923.5167 - val_loss: 2726641320.3288\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1224827167.3693 - val_loss: 2758921773.5890\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1216114306.7695 - val_loss: 2849170474.0822\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1208462259.2219 - val_loss: 2765550206.2466\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1178334835.6058 - val_loss: 3064930535.4521\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1242277517.9846 - val_loss: 2776714061.1507\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1168476084.4284 - val_loss: 2790439487.1233\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1180584411.1465 - val_loss: 2937083875.9452\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1196678562.0566 - val_loss: 2905820500.1644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1228621927.9246 - val_loss: 2713756279.2329\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 410us/step - loss: 1170014581.2511 - val_loss: 2879766373.6986\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1151639312.4524 - val_loss: 2739778556.4932\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1161729214.9032 - val_loss: 2823046936.5479\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1136940189.0660 - val_loss: 2735173772.2740\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1374524349.3402 - val_loss: 2740995797.9178\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1256290006.7592 - val_loss: 2676047721.2055\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1219013163.5441 - val_loss: 3056892068.8219\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1175807710.8209 - val_loss: 2801659167.5616\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1141791732.3188 - val_loss: 2757831231.1233\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 1127327780.1680 - val_loss: 2737458295.2329\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1209805676.1474 - val_loss: 3516409617.5342\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1162274225.1380 - val_loss: 2675946969.4247\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1152418114.4130 - val_loss: 2801360590.9041\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1134924492.1200 - val_loss: 2961354320.6575\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1133271640.2674 - val_loss: 2716638965.4795\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1167033444.5793 - val_loss: 2647884600.1096\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1125002850.0566 - val_loss: 2801871847.4521\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1130881244.7918 - val_loss: 2723554237.3699\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1104355664.7266 - val_loss: 2765979483.1781\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 1s 455us/step - loss: 1124271407.1637 - val_loss: 2821367613.3699\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 1114570797.5733 - val_loss: 3038661454.9041\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1147617141.0317 - val_loss: 2604635970.6301\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1111880157.6692 - val_loss: 3401820396.7123\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1170500358.4713 - val_loss: 2696339080.7671\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 1086342238.9032 - val_loss: 2697793108.1644\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 1108077620.6478 - val_loss: 2832108351.1233\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1104968992.8775 - val_loss: 2569963520.0000\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1103239603.8800 - val_loss: 2687750305.3151\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1120879070.4370 - val_loss: 2821650165.4795\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1129409480.7198 - val_loss: 2820961201.0959\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1197193376.5210 - val_loss: 2704260963.9452\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1163431229.3128 - val_loss: 2805474561.7534\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 418us/step - loss: 1068764773.4019 - val_loss: 2606075844.3836\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1049542469.6761 - val_loss: 2823917047.2329\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 1102754081.4259 - val_loss: 2579630518.3562\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1079847800.1851 - val_loss: 2649085930.9589\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1125941684.7849 - val_loss: 2754391592.3288\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 1065836692.9494 - val_loss: 2620755960.9863\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1030397758.6290 - val_loss: 2701324843.8356\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1029007056.8912 - val_loss: 2569067470.9041\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1057597332.0720 - val_loss: 2654585500.0548\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 1112998012.1611 - val_loss: 2549296867.9452\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1046072091.4207 - val_loss: 2772417765.6986\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1060361687.9109 - val_loss: 2562131704.9863\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1083178665.1585 - val_loss: 2557425727.1233\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1038767162.1868 - val_loss: 2552461753.8630\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 1058269719.6915 - val_loss: 2641547583.1233\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1017577372.6547 - val_loss: 2596697991.0137\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 1033077963.7087 - val_loss: 2538548981.4795\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 1006965434.2965 - val_loss: 2590699842.6301\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 1018358084.7164 - val_loss: 2573801826.1918\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 1003363456.4936 - val_loss: 2688863068.9315\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 412us/step - loss: 1014420952.3496 - val_loss: 2551687518.6849\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 1018725788.8466 - val_loss: 2528942500.8219\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1052294238.1080 - val_loss: 2584050958.0274\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 1031049205.5253 - val_loss: 2567224334.0274\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 1025497806.8620 - val_loss: 2614238016.8767\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 1003398974.9580 - val_loss: 2518541908.1644\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1057644201.5150 - val_loss: 2615751445.0411\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 981876905.2408 - val_loss: 2585163630.4658\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 1s 451us/step - loss: 1028487203.5373 - val_loss: 2502089194.9589\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 1019378153.5698 - val_loss: 2575126538.5205\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 1s 446us/step - loss: 1022293632.3839 - val_loss: 2593028273.0959\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 976082292.1817 - val_loss: 2573779561.2055\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 1023460718.6701 - val_loss: 2541961191.4521\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 980955752.5278 - val_loss: 2521318952.3288\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 965736293.1277 - val_loss: 2500116050.4110\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 970083816.7472 - val_loss: 2444630431.5616\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 1067123853.9023 - val_loss: 2674072440.9863\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 983837678.5878 - val_loss: 2897060513.3151\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1115245671.2665 - val_loss: 2622692625.5342\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 975434417.5767 - val_loss: 2688465379.9452\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 983308236.1200 - val_loss: 2503049694.6849\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 951119468.0925 - val_loss: 2766748196.8219\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 997028387.5373 - val_loss: 2981307234.1918\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 1028715966.8209 - val_loss: 2464263634.4110\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 958872795.0368 - val_loss: 2495568682.0822\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 985832051.2768 - val_loss: 2447847767.6712\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 957202617.5287 - val_loss: 2474049039.7808\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 977453249.3710 - val_loss: 2503193084.4932\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 924376434.8380 - val_loss: 2492283058.8493\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 945514387.5784 - val_loss: 2546149814.3562\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 955767238.1422 - val_loss: 2794607095.2329\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 1s 457us/step - loss: 931387452.5450 - val_loss: 2565829263.7808\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 922580138.2965 - val_loss: 2511601230.9041\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 1012442514.9203 - val_loss: 2570016177.0959\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 920826590.2177 - val_loss: 2515948172.2740\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 910687443.0848 - val_loss: 2527533694.2466\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 946499936.6307 - val_loss: 2582226616.1096\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 944178932.6478 - val_loss: 2501055575.6712\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 948697753.0077 - val_loss: 2560802458.3014\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 900709444.2228 - val_loss: 2679332709.6986\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 911544116.8535 - val_loss: 2415079790.4658\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 908810597.2922 - val_loss: 2644379144.7671\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 906620429.2716 - val_loss: 2421240640.8767\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 894227365.2374 - val_loss: 2449338320.6575\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 865456966.4165 - val_loss: 2567168552.3288\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 918058290.1251 - val_loss: 2475005134.9041\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 893168682.9957 - val_loss: 2458523854.9041\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 959278870.4850 - val_loss: 2403692305.5342\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 890078937.2819 - val_loss: 2483831921.9726\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 898361193.2134 - val_loss: 2510960057.8630\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 1s 452us/step - loss: 970780942.3685 - val_loss: 2408832478.6849\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 943779464.6650 - val_loss: 2549861414.5753\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 984472130.1114 - val_loss: 2493290639.7808\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 994768016.8912 - val_loss: 2533802001.5342\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 878162922.3925 - val_loss: 2454324343.2329\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 877589596.6821 - val_loss: 2380361147.6164\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 911282183.6778 - val_loss: 2781867688.3288\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 961077939.0848 - val_loss: 2482427535.7808\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 901307280.8363 - val_loss: 2374933109.4795\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 839346405.7858 - val_loss: 2508189897.6438\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 846065842.2348 - val_loss: 2416079793.0959\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 876929966.2588 - val_loss: 2405825460.6027\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 881971499.5990 - val_loss: 2461471552.8767\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 1026497828.0308 - val_loss: 2580763316.6027\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 940188732.6547 - val_loss: 2563567966.6849\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 1033726922.0360 - val_loss: 2387850588.9315\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 871534964.1817 - val_loss: 2429442842.3014\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 909385648.9186 - val_loss: 2562697219.5068\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 866050949.8132 - val_loss: 2507730016.4384\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 840345883.2014 - val_loss: 2462088819.7260\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 887160160.9049 - val_loss: 2387740046.0274\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 885163780.9632 - val_loss: 2568999688.7671\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 881363563.9829 - val_loss: 2421478305.3151\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 831474608.9460 - val_loss: 2423309382.1370\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 832505091.6744 - val_loss: 2431839032.1096\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 846284255.7806 - val_loss: 2414436655.3425\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 821298057.5424 - val_loss: 2397715456.0000\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 876104139.5716 - val_loss: 2587999116.2740\n",
      "Epoch 263/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 426us/step - loss: 809903481.3093 - val_loss: 2481664671.5616\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 817842361.8578 - val_loss: 2401059868.0548\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 827466964.1542 - val_loss: 2538248945.9726\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 820705424.0686 - val_loss: 2347676878.9041\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 825997942.4850 - val_loss: 2434173759.1233\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 895748078.3959 - val_loss: 2428477632.8767\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 822585974.5124 - val_loss: 2452980557.1507\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 801043098.4884 - val_loss: 2391332821.9178\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 886114413.7652 - val_loss: 2459997108.6027\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 839023465.8440 - val_loss: 2453516280.9863\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 808831226.3513 - val_loss: 2446906611.7260\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 806534559.4516 - val_loss: 2489390183.4521\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 806042001.1654 - val_loss: 2429343568.6575\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 814260592.5347 - val_loss: 2389523440.2192\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 787634547.3865 - val_loss: 2407609998.0274\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 784523957.5527 - val_loss: 2423837594.3014\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 795087403.8732 - val_loss: 2404417618.4110\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 789063277.5733 - val_loss: 2452517842.4110\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 839851849.6247 - val_loss: 2455173042.8493\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 841785062.7181 - val_loss: 2529570693.2603\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 914266457.2819 - val_loss: 2575414896.2192\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 831771568.6992 - val_loss: 2453789255.8904\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 790015239.2391 - val_loss: 2360814688.4384\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 788207536.3702 - val_loss: 2400364689.5342\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 842039451.2014 - val_loss: 2380899142.1370\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 417us/step - loss: 803941542.1148 - val_loss: 2440020427.3973\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 769553763.8663 - val_loss: 2453919742.2466\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 800665857.0831 - val_loss: 2360788118.7945\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 866723271.1842 - val_loss: 2336134550.7945\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 786412193.4533 - val_loss: 2469033186.1918\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 774387014.5810 - val_loss: 2501145656.1096\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 759279214.9443 - val_loss: 2388313345.7534\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 768833315.2356 - val_loss: 2368530628.3836\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 417us/step - loss: 745396218.1868 - val_loss: 2483869504.8767\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 740539419.3659 - val_loss: 2339098997.4795\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 414us/step - loss: 770241684.8398 - val_loss: 2390654704.2192\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 747615910.5261 - val_loss: 2397503480.9863\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 793495796.1817 - val_loss: 2334234552.1096\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 801730959.5201 - val_loss: 2345727675.6164\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 747542744.1851 - val_loss: 2498170655.5616\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 1s 480us/step - loss: 790751367.3488 - val_loss: 2389159960.5479\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 743665199.4379 - val_loss: 2553739458.6301\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 762377482.5844 - val_loss: 2390248981.0411\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 750283890.0428 - val_loss: 2323665294.0274\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 787193796.1131 - val_loss: 2705346779.1781\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 815940878.4233 - val_loss: 2566856213.0411\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 415us/step - loss: 784603573.2237 - val_loss: 2365077779.2877\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 724795739.8320 - val_loss: 2409498073.4247\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 765429001.7069 - val_loss: 2467798670.0274\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 772722542.5056 - val_loss: 2446749320.7671\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 851150413.6555 - val_loss: 2352762944.8767\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 764232299.9143 - val_loss: 2384771352.5479\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 742819693.8201 - val_loss: 2428034414.4658\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 715300996.8260 - val_loss: 2491498972.9315\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 733766702.9991 - val_loss: 2359009779.7260\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 694370764.8329 - val_loss: 2477721403.6164\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 742151629.6281 - val_loss: 2688429918.6849\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 749009446.8826 - val_loss: 2313789971.2877\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 706460612.0034 - val_loss: 2383975294.2466\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 1s 445us/step - loss: 727507675.3111 - val_loss: 2582766311.4521\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 821800171.7087 - val_loss: 2506657118.6849\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 819613654.5947 - val_loss: 2310187758.4658\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 745200026.4336 - val_loss: 2436599951.7808\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 752391363.0163 - val_loss: 2345429190.1370\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 738840697.9400 - val_loss: 2316779960.1096\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 1s 437us/step - loss: 732201030.4713 - val_loss: 2504809985.7534\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 709335316.8398 - val_loss: 2438000248.9863\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 751711049.6247 - val_loss: 2343722653.8082\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 701395589.7035 - val_loss: 2370005360.2192\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 677976394.5844 - val_loss: 2420657094.1370\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 700541107.2219 - val_loss: 2480075974.1370\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 665851731.3316 - val_loss: 2451428702.6849\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 678998788.0308 - val_loss: 2371011647.1233\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 698614768.1508 - val_loss: 2317950434.1918\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 675414115.5647 - val_loss: 2542269987.0685\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 729897242.7626 - val_loss: 2656059246.4658\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 711171766.2382 - val_loss: 2323855822.9041\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 687465815.4447 - val_loss: 2380172303.7808\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 667565321.4602 - val_loss: 2360235961.8630\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 672494633.0763 - val_loss: 2280649303.6712\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 653599729.9606 - val_loss: 2542033481.6438\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 652296081.4944 - val_loss: 2357716036.3836\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 698488538.9820 - val_loss: 2469881154.6301\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 699070963.6058 - val_loss: 2367242375.0137\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 666605859.0985 - val_loss: 2313763520.8767\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 641228013.9023 - val_loss: 2376246275.5068\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 648157152.9871 - val_loss: 2290733813.4795\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 648029400.2399 - val_loss: 2482713542.1370\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 676783162.9546 - val_loss: 2253589304.1096\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 687731260.4353 - val_loss: 2551187357.8082\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 693525812.6478 - val_loss: 2263384802.1918\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 1s 457us/step - loss: 649249442.8243 - val_loss: 2436736422.5753\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 630722665.3505 - val_loss: 2339113026.6301\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 631198143.6984 - val_loss: 2449198979.5068\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 660726545.2202 - val_loss: 2276557955.5068\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 635180405.9914 - val_loss: 2411087189.9178\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 415us/step - loss: 646835009.1791 - val_loss: 2376843516.4932\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 635925468.1063 - val_loss: 2278746971.1781\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 730552981.5801 - val_loss: 2407490644.1644\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 660039041.1791 - val_loss: 2309187825.9726\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 624311635.0300 - val_loss: 2276247792.2192\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 651175797.7584 - val_loss: 2285672430.4658\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 625971637.5253 - val_loss: 2301243157.0411\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 651141655.4173 - val_loss: 2284701497.8630\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 610031888.0137 - val_loss: 2266322361.8630\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 614614797.6007 - val_loss: 2308266020.8219\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 634982278.9649 - val_loss: 2225863843.0685\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 607783560.9940 - val_loss: 2366102224.6575\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 608315344.6307 - val_loss: 2311168033.3151\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 637371135.3967 - val_loss: 2220983750.1370\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 704354636.6684 - val_loss: 2210336911.7808\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 662216000.7129 - val_loss: 2249227704.1096\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 671174157.4910 - val_loss: 2508978645.9178\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 681831503.8492 - val_loss: 2270667134.2466\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 801104037.2374 - val_loss: 2259342562.1918\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 600770757.0180 - val_loss: 2209300872.7671\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 606772524.9152 - val_loss: 2260240164.8219\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 598738966.7044 - val_loss: 2365470788.3836\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 581708820.7849 - val_loss: 2277087009.3151\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 589641918.3548 - val_loss: 2193358307.9452\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 594558691.2631 - val_loss: 2206415970.1918\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 656423462.5536 - val_loss: 2602849858.6301\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 639719073.6727 - val_loss: 2368870259.7260\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 646062660.7164 - val_loss: 2277231956.1644\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 612187533.1620 - val_loss: 2401172110.0274\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 590911884.9974 - val_loss: 2243274266.3014\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 584990705.1928 - val_loss: 2282490723.9452\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 599397960.3907 - val_loss: 2252540701.8082\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 615689960.3633 - val_loss: 2325972318.6849\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 577663039.8081 - val_loss: 2354439639.6712\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 593966307.3728 - val_loss: 2181883719.8904\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 552265748.2913 - val_loss: 2190654048.4384\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 419us/step - loss: 637857781.4156 - val_loss: 2214793082.7397\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 583126219.6264 - val_loss: 2182806457.8630\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 628089033.9263 - val_loss: 2403850236.4932\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 599288422.6358 - val_loss: 2366905063.4521\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 626103832.1302 - val_loss: 2407291341.1507\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 570548071.0746 - val_loss: 2214153749.0411\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 600729730.2211 - val_loss: 2782370617.8630\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 616668776.5553 - val_loss: 2386182559.5616\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 627390685.6144 - val_loss: 2224731155.2877\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 557893881.9400 - val_loss: 2292105396.6027\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 545144828.6547 - val_loss: 2192441014.3562\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 558283691.4344 - val_loss: 2155195441.0959\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 544811436.0377 - val_loss: 2201508706.1918\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 550698000.5621 - val_loss: 2233732707.9452\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 591090273.2065 - val_loss: 2172412410.7397\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 1s 441us/step - loss: 562197502.7935 - val_loss: 2129002520.5479\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 1s 443us/step - loss: 624774251.9280 - val_loss: 2283998595.5068\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 1s 458us/step - loss: 597099676.4353 - val_loss: 2149478075.6164\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 1s 467us/step - loss: 546849668.2228 - val_loss: 2303420338.8493\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 1s 472us/step - loss: 527472307.1945 - val_loss: 2259343105.7534\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 1s 469us/step - loss: 522604062.8483 - val_loss: 2153799485.3699\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 1s 465us/step - loss: 533793090.4267 - val_loss: 2258412345.8630\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 1s 475us/step - loss: 519035235.7841 - val_loss: 2166524107.3973\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 1s 461us/step - loss: 542402578.3171 - val_loss: 2244855183.7808\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 1s 469us/step - loss: 569013728.3016 - val_loss: 2332655921.0959\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 1s 459us/step - loss: 538103436.0925 - val_loss: 2310023907.9452\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 1s 462us/step - loss: 576505642.6941 - val_loss: 2210883284.1644\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 1s 459us/step - loss: 542632405.9366 - val_loss: 2129097684.1644\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 1s 438us/step - loss: 554214285.9023 - val_loss: 2197056727.6712\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 515045332.5656 - val_loss: 2158640757.4795\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 584308170.8997 - val_loss: 2138831093.4795\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 508733226.8860 - val_loss: 2285831792.2192\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 589167336.1440 - val_loss: 2079473627.1781\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 522222990.7524 - val_loss: 2168033316.8219\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 571651492.4696 - val_loss: 2291274958.9041\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 603015320.4593 - val_loss: 2229901936.2192\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 524343174.9786 - val_loss: 2101377988.3836\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 539728373.8543 - val_loss: 2122909390.9041\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 511874972.2228 - val_loss: 2186072272.6575\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 562759148.3119 - val_loss: 2117983684.3836\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 519693291.8183 - val_loss: 2158459200.8767\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 493881214.0805 - val_loss: 2166377168.6575\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 502078934.1834 - val_loss: 2098739897.8630\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 424us/step - loss: 529026566.9923 - val_loss: 2395801175.6712\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 530601616.3016 - val_loss: 2187134965.4795\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 422us/step - loss: 487350926.5330 - val_loss: 2291397042.8493\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 486936561.5767 - val_loss: 2138136269.1507\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 413us/step - loss: 493159076.7986 - val_loss: 2202595319.2329\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 531578425.1997 - val_loss: 2168301138.4110\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 415us/step - loss: 487667499.3796 - val_loss: 2122696525.1507\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 518301955.1260 - val_loss: 2126776128.8767\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 498038780.9837 - val_loss: 2188954511.7808\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 500780114.0017 - val_loss: 2085714360.1096\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 425us/step - loss: 517685615.8355 - val_loss: 2329906233.8630\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 1s 447us/step - loss: 551063976.7061 - val_loss: 2312218701.1507\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 490981971.3590 - val_loss: 2148451112.3288\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 528969558.9237 - val_loss: 2170177642.9589\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 423us/step - loss: 523604603.7361 - val_loss: 2373947397.2603\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 1s 428us/step - loss: 499428918.2382 - val_loss: 2314304887.2329\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 419us/step - loss: 493898900.0171 - val_loss: 2212574897.0959\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 492465896.5827 - val_loss: 2152268365.1507\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 497642579.1397 - val_loss: 2111886814.6849\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 454758872.5141 - val_loss: 2128725640.7671\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 472131492.2502 - val_loss: 2209085664.4384\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 466152114.4267 - val_loss: 2141905867.3973\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 469449370.2416 - val_loss: 2094584314.7397\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 471798480.6718 - val_loss: 2066637643.3973\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 1s 448us/step - loss: 474862000.7266 - val_loss: 2130776227.0685\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 488551699.7429 - val_loss: 2306299700.6027\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 475858674.9751 - val_loss: 2053234994.8493\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 504993967.1088 - val_loss: 2120908228.3836\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 486189729.8509 - val_loss: 2164837248.0000\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 466126397.9434 - val_loss: 2137085981.8082\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 443284154.0771 - val_loss: 2146301299.7260\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 420us/step - loss: 455077509.4567 - val_loss: 2115810872.1096\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 466901363.0643 - val_loss: 2240322144.4384\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 428us/step - loss: 493800170.4473 - val_loss: 2065612896.4384\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 455589020.4353 - val_loss: 2319207637.9178\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 427us/step - loss: 445601691.5030 - val_loss: 2126078651.6164\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 441519543.4996 - val_loss: 2352376386.6301\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 431745276.0788 - val_loss: 2092260366.0274\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 416us/step - loss: 430217983.4516 - val_loss: 2081458086.5753\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 468114833.5561 - val_loss: 2017135800.1096\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 453311539.0574 - val_loss: 2151033261.5890\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 523021385.1585 - val_loss: 2098038508.7123\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 1s 436us/step - loss: 465422913.1928 - val_loss: 2426776540.9315\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 1s 439us/step - loss: 550481967.5201 - val_loss: 2151403662.0274\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 1s 432us/step - loss: 470275424.1371 - val_loss: 2125608796.9315\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 434303994.8175 - val_loss: 2263325247.1233\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 488932887.2734 - val_loss: 2025614132.6027\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 453335345.7686 - val_loss: 2259035151.7808\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 446069468.8055 - val_loss: 2068731272.7671\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 1s 431us/step - loss: 436329514.4747 - val_loss: 2057267622.5753\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 421us/step - loss: 431849700.5244 - val_loss: 2130841768.3288\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 457425081.9949 - val_loss: 2139316381.8082\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 1s 450us/step - loss: 448494086.4987 - val_loss: 2002187051.8356\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 448693023.7532 - val_loss: 2117843424.4384\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 1s 434us/step - loss: 455686421.2374 - val_loss: 2070145285.2603\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 1s 433us/step - loss: 416661227.8183 - val_loss: 2164533696.8767\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 1s 442us/step - loss: 495962642.2622 - val_loss: 2005678027.3973\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 1s 430us/step - loss: 426483906.4953 - val_loss: 2140407115.3973\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 426us/step - loss: 429844164.6067 - val_loss: 2062513083.6164\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 414us/step - loss: 433833588.0994 - val_loss: 2207829184.8767\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 1s 435us/step - loss: 607598219.4070 - val_loss: 1982930601.2055\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 1s 429us/step - loss: 430218705.5081 - val_loss: 1972770870.3562\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 1s 440us/step - loss: 399483474.8518 - val_loss: 2035059394.6301\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_5000E_Adam_4H.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_4H.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 32)                10592     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,737\n",
      "Trainable params: 12,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_32 = Sequential()\n",
    "NN_5000E_Adam_32.add(Dense(32,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_Adam_32.add(Dense(32,activation = 'relu'))\n",
    "NN_5000E_Adam_32.add(Dense(32,activation = 'relu'))\n",
    "NN_5000E_Adam_32.add(Dense(1))\n",
    "NN_5000E_Adam_32.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 38706398633.5698 - val_loss: 39777723770.7397\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 38636421785.1174 - val_loss: 39698240722.4110\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 38542318570.0634 - val_loss: 39589462240.4384\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 38415337147.3385 - val_loss: 39443433948.9315\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 38248806998.4302 - val_loss: 39249987275.3973\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 38010765052.2708 - val_loss: 38963096646.1370\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 37672731139.9486 - val_loss: 38570601149.3699\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 37220937980.7095 - val_loss: 38052890708.1644\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 36598502590.4096 - val_loss: 37321046773.4795\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 35805219818.0634 - val_loss: 36460606842.7397\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 34872381573.3745 - val_loss: 35419379571.7260\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 33742581523.0848 - val_loss: 34171426282.9589\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 32438129647.3282 - val_loss: 32714959409.0959\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 30893797028.5244 - val_loss: 30992828584.3288\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 29121939647.2871 - val_loss: 29113267073.7534\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 27253701934.7249 - val_loss: 27067186218.0822\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 25301668003.2082 - val_loss: 24952807003.1781\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 23338820777.3505 - val_loss: 22845223921.9726\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 21412865454.8346 - val_loss: 20753600960.8767\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 19594083869.3950 - val_loss: 18759517422.4658\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 17935180062.9306 - val_loss: 16933127967.5616\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 16475649507.4824 - val_loss: 15357747775.1233\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 15268909963.2973 - val_loss: 13884133572.3836\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 14237559091.1123 - val_loss: 12753926494.6849\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 13452300094.9580 - val_loss: 11853913466.7397\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 12808024805.4567 - val_loss: 11034024693.4795\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 12319047574.2656 - val_loss: 10391662409.6438\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 11900296191.1225 - val_loss: 9917871608.9863\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 11603727163.0094 - val_loss: 9430912631.2329\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 11313423176.6101 - val_loss: 9087031239.8904\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 11068894077.2579 - val_loss: 8854256345.4247\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 10853735214.2862 - val_loss: 8725884857.8630\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 10660931209.3231 - val_loss: 8466526853.2603\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 10486329650.2348 - val_loss: 8288456963.5068\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 10292422791.5681 - val_loss: 8086953212.4932\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 10128356060.6821 - val_loss: 7959175459.0685\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 9976599358.5193 - val_loss: 7823500351.1233\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 9809923101.8338 - val_loss: 7669834352.2192\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 9703149746.1251 - val_loss: 7552567930.7397\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 9534539733.4430 - val_loss: 7462937049.4247\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 9383754433.9195 - val_loss: 7324561692.0548\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 9245272851.7429 - val_loss: 7246285809.9726\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 9122447823.5201 - val_loss: 7161663526.5753\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 8975761924.6067 - val_loss: 7036752208.6575\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 8848736644.7164 - val_loss: 6965342043.1781\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 8735802418.6735 - val_loss: 6901014952.3288\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 8607325949.3676 - val_loss: 6790326380.7123\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 8477249712.1508 - val_loss: 6724546279.4521\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 8336319042.6872 - val_loss: 6644477012.1644\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 8235009435.5304 - val_loss: 6559246392.1096\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 8093321635.6470 - val_loss: 6502898835.2877\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 7982328565.4704 - val_loss: 6442004297.6438\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 7857201790.7935 - val_loss: 6377018550.3562\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 7735639634.9203 - val_loss: 6300772453.6986\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 7639975582.8209 - val_loss: 6226937982.2466\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 7512915052.8055 - val_loss: 6183156981.4795\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 7406318823.7601 - val_loss: 6127344668.0548\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 7282975436.4490 - val_loss: 6049111706.3014\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 7178417607.1842 - val_loss: 6007947253.4795\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 7063475700.1542 - val_loss: 5945050960.6575\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 6953709088.4662 - val_loss: 5879241931.3973\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 6847420000.0823 - val_loss: 5820818323.2877\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 6753905585.6864 - val_loss: 5772550256.2192\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 6623230864.3428 - val_loss: 5707564978.8493\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 6525066252.7232 - val_loss: 5657811810.1918\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 6425273773.0797 - val_loss: 5607142968.1096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 6317624499.0026 - val_loss: 5556530887.8904\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 6214892520.7472 - val_loss: 5502116827.1781\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 6116913004.8055 - val_loss: 5452863030.3562\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 6025396548.6615 - val_loss: 5398700131.9452\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 5953267253.3059 - val_loss: 5374689651.7260\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 5810141920.4113 - val_loss: 5317422718.2466\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 5734094331.1740 - val_loss: 5277504990.6849\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5636116918.2931 - val_loss: 5215588639.5616\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 5530374620.9015 - val_loss: 5179111062.7945\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 5449547373.6829 - val_loss: 5137831530.9589\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5341673511.0471 - val_loss: 5091163600.6575\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5265072582.7455 - val_loss: 5050199011.9452\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 5163992398.3136 - val_loss: 5004535776.4384\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 5080508594.6187 - val_loss: 4963202773.9178\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4997120554.1183 - val_loss: 4926502570.0822\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4913954565.2648 - val_loss: 4888727716.8219\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4815495078.9374 - val_loss: 4849002865.9726\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4736895983.3282 - val_loss: 4811981357.5890\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 4650270387.4413 - val_loss: 4771804938.5205\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 4571201740.9974 - val_loss: 4734898526.6849\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 4488653437.4773 - val_loss: 4699172348.4932\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 4418284794.2965 - val_loss: 4663280436.6027\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 4328052583.3213 - val_loss: 4628027493.6986\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 4247456842.1731 - val_loss: 4593235662.9041\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 4164169424.1782 - val_loss: 4560153840.2192\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 4087768613.5116 - val_loss: 4527197715.2877\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 4018893261.1071 - val_loss: 4496667085.1507\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 3943134419.2494 - val_loss: 4462239614.2466\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 3875217084.6547 - val_loss: 4430877392.6575\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 3805339698.2348 - val_loss: 4400140181.0411\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 3734887477.0865 - val_loss: 4373305508.8219\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 3670403773.6418 - val_loss: 4341492283.6164\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 3607399924.5930 - val_loss: 4312472546.1918\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3540711237.5390 - val_loss: 4283318605.1507\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3472353100.2296 - val_loss: 4259193168.6575\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 3411745480.3907 - val_loss: 4232893983.5616\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3361530084.5793 - val_loss: 4200075370.9589\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3285369875.8526 - val_loss: 4180581216.4384\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 3222169827.7018 - val_loss: 4155386408.3288\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 3173382167.3076 - val_loss: 4120383561.6438\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 3103955209.4327 - val_loss: 4099355448.1096\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 3050930032.0960 - val_loss: 4077304104.3288\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2990750478.3685 - val_loss: 4043948764.9315\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2940906004.4010 - val_loss: 4018824591.7808\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 2882607095.2254 - val_loss: 4009177217.7534\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2830177688.1851 - val_loss: 3965381930.0822\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2774880382.2451 - val_loss: 3952398397.3699\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 2730119532.8055 - val_loss: 3926675943.4521\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2679935106.1388 - val_loss: 3909341378.6301\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2640372572.1337 - val_loss: 3888944827.6164\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2588194538.3925 - val_loss: 3874660306.4110\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 2547997006.2039 - val_loss: 3858030118.5753\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2508642872.2674 - val_loss: 3837574517.4795\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2469528089.4464 - val_loss: 3817418906.3014\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 2427632317.7515 - val_loss: 3798146256.6575\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 2396896891.3933 - val_loss: 3799322247.0137\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 2362590387.0026 - val_loss: 3763367294.2466\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 2318120108.4216 - val_loss: 3753669028.8219\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2286852517.0728 - val_loss: 3738668835.0685\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2254323046.0051 - val_loss: 3722019175.4521\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2222012521.0763 - val_loss: 3713085522.4110\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2191895375.5201 - val_loss: 3695300153.8630\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2167147673.6658 - val_loss: 3681623038.2466\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 2139802497.3162 - val_loss: 3664703047.8904\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 2113456239.4379 - val_loss: 3662482817.7534\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 2085059142.3068 - val_loss: 3639073692.0548\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 52us/step - loss: 2062470155.5167 - val_loss: 3629449210.7397\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 2039034682.6804 - val_loss: 3611442688.0000\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 2017470409.5973 - val_loss: 3597317581.1507\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1994395819.6538 - val_loss: 3595217275.6164\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1974552403.7978 - val_loss: 3586392843.3973\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 1971996256.00 - 0s 55us/step - loss: 1957795174.6632 - val_loss: 3578731761.9726\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1939415341.8475 - val_loss: 3568260553.6438\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1922744864.3290 - val_loss: 3552882700.2740\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1905478207.0677 - val_loss: 3553967503.7808\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1890238106.9820 - val_loss: 3538871984.2192\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1877667966.3822 - val_loss: 3536281866.5205\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1864408960.0000 - val_loss: 3516147306.9589\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1850358573.8475 - val_loss: 3512954774.7945\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1837450442.4747 - val_loss: 3505507644.4932\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1829624468.3462 - val_loss: 3491177894.5753\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1815536968.9392 - val_loss: 3500005283.0685\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1807436928.2194 - val_loss: 3495819360.4384\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1795641924.9906 - val_loss: 3479796967.4521\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1787179761.4122 - val_loss: 3471683278.0274\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1780303638.4302 - val_loss: 3469492081.9726\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1771548038.4713 - val_loss: 3463687374.9041\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1764629664.7952 - val_loss: 3461038145.7534\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1757342492.6272 - val_loss: 3456917567.1233\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 1751547446.5124 - val_loss: 3453712243.7260\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1746295093.9640 - val_loss: 3448716894.6849\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1739427787.5716 - val_loss: 3440058282.9589\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1734687408.1508 - val_loss: 3435727543.2329\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1730488431.8766 - val_loss: 3425369769.2055\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1727635935.7532 - val_loss: 3436082506.5205\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1722694381.6829 - val_loss: 3414917388.2740\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1718910985.8166 - val_loss: 3423651845.2603\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1716679538.6735 - val_loss: 3415767932.4932\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1711951244.3942 - val_loss: 3426715008.8767\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1707524151.4996 - val_loss: 3415765361.0959\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1705556316.1337 - val_loss: 3410250505.6438\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1702480068.5518 - val_loss: 3415080218.3014\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1702778834.8106 - val_loss: 3395565839.7808\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1697179953.7961 - val_loss: 3407484970.9589\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1694956684.9426 - val_loss: 3413392680.3288\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1692443871.9177 - val_loss: 3410999443.2877\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1692344402.0428 - val_loss: 3384032043.8356\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1687718659.7292 - val_loss: 3402425109.9178\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1684760729.3368 - val_loss: 3401716743.0137\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 1681913474.6324 - val_loss: 3391241259.8356\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 53us/step - loss: 1681247660.8603 - val_loss: 3390127026.8493\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1679080424.4182 - val_loss: 3398176941.5890\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 53us/step - loss: 1680472277.2648 - val_loss: 3392955113.2055\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1673838683.5853 - val_loss: 3386586562.6301\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1672412963.8663 - val_loss: 3384779902.2466\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1674562137.9949 - val_loss: 3386585903.3425\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 1670759076.8535 - val_loss: 3361329436.0548\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1666544476.0788 - val_loss: 3383822623.5616\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 63us/step - loss: 1666571945.1311 - val_loss: 3396075585.7534\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1664615394.1662 - val_loss: 3384505978.7397\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1666060725.7995 - val_loss: 3386037789.8082\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1661833314.7695 - val_loss: 3399095325.8082\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1659161578.7215 - val_loss: 3369155649.7534\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1659652241.6590 - val_loss: 3366439484.4932\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1655639092.5381 - val_loss: 3383871337.2055\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1655291298.1114 - val_loss: 3378685585.5342\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1653014404.9906 - val_loss: 3394723612.0548\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1651405891.8389 - val_loss: 3376431242.5205\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1650283011.6195 - val_loss: 3382085351.4521\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1647595548.0788 - val_loss: 3367060853.4795\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1645953143.8835 - val_loss: 3363220888.5479\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1646748258.7147 - val_loss: 3364070696.3288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1642946155.7635 - val_loss: 3378011390.2466\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1643436666.3239 - val_loss: 3388817851.6164\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1641126022.1422 - val_loss: 3370086361.4247\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1640486235.0368 - val_loss: 3368569985.7534\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1640567324.9015 - val_loss: 3365025458.8493\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1636792076.9152 - val_loss: 3356467892.6027\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1633960917.0043 - val_loss: 3374617394.8493\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1637340350.7798 - val_loss: 3348085214.6849\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1630970737.5219 - val_loss: 3367064267.3973\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1631393451.5441 - val_loss: 3367508408.1096\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1632107544.2399 - val_loss: 3358085837.1507\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1629815965.2853 - val_loss: 3360494528.8767\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1630682019.4276 - val_loss: 3344180395.8356\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1624866225.4670 - val_loss: 3376202373.2603\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1624640587.6812 - val_loss: 3369888859.1781\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1623777854.1902 - val_loss: 3369012103.0137\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1621197153.0420 - val_loss: 3353191995.6164\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1620273572.5244 - val_loss: 3350942855.0137\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1620673721.1448 - val_loss: 3344478467.5068\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1618500240.5073 - val_loss: 3357727873.7534\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1619188639.9177 - val_loss: 3358749336.5479\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1617198681.3093 - val_loss: 3338672303.3425\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1614507859.2768 - val_loss: 3354863195.1781\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1613196823.1431 - val_loss: 3362721052.0548\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1612524431.9040 - val_loss: 3349652231.0137\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1610517926.9374 - val_loss: 3338402808.9863\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1611139156.2365 - val_loss: 3354705194.0822\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1609206515.0574 - val_loss: 3348781113.8630\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1606634112.7129 - val_loss: 3352287654.5753\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1608319920.2605 - val_loss: 3366012263.4521\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1610905307.0368 - val_loss: 3346298688.8767\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1603822376.4182 - val_loss: 3356487969.3151\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1603342626.7695 - val_loss: 3338179043.9452\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1601124574.5193 - val_loss: 3338147429.6986\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1599499721.4876 - val_loss: 3341876406.3562\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1600386606.7249 - val_loss: 3361123033.4247\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1598714451.1397 - val_loss: 3335292542.2466\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1599877571.1260 - val_loss: 3325158875.1781\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1600471715.9760 - val_loss: 3368318337.7534\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1594547448.1028 - val_loss: 3327266288.2192\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1594258169.6932 - val_loss: 3330957715.2877\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1592677826.7969 - val_loss: 3351511466.0822\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1591808407.5818 - val_loss: 3329061919.5616\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1593877713.9332 - val_loss: 3352627929.4247\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1590893470.5467 - val_loss: 3312453696.8767\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1591728951.3899 - val_loss: 3349289852.4932\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1589881132.4764 - val_loss: 3330775594.0822\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1588658104.3770 - val_loss: 3320039490.6301\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1586497934.1491 - val_loss: 3331378533.6986\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1585370064.3428 - val_loss: 3342122816.8767\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1584601782.9512 - val_loss: 3329291313.0959\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1582765797.2374 - val_loss: 3339787418.3014\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1583465219.6195 - val_loss: 3319001585.9726\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1584579680.6855 - val_loss: 3333327921.0959\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1582124058.7626 - val_loss: 3325263484.4932\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1582069529.6658 - val_loss: 3357233393.9726\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1583155360.7952 - val_loss: 3328286083.5068\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1577047561.6521 - val_loss: 3339482282.0822\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1576756690.4816 - val_loss: 3342498053.2603\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1576185572.5244 - val_loss: 3324439883.3973\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1575592102.7181 - val_loss: 3334397031.4521\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1574631051.4070 - val_loss: 3341170154.9589\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1576035657.3779 - val_loss: 3306831628.2740\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1572128399.4105 - val_loss: 3337726525.3699\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1570996126.9306 - val_loss: 3317617194.0822\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1571672843.1877 - val_loss: 3326764831.5616\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 60us/step - loss: 1570279104.1097 - val_loss: 3324334576.2192\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1568328393.8166 - val_loss: 3333199596.7123\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1569793750.1560 - val_loss: 3337802536.3288\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1566240392.4456 - val_loss: 3336586560.8767\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1568994391.8423 - val_loss: 3313692328.3288\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1567468620.2296 - val_loss: 3312366188.7123\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1564970378.9683 - val_loss: 3312891207.8904\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1566892999.8423 - val_loss: 3317635817.2055\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1561978648.1851 - val_loss: 3338508084.6027\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1564405482.8312 - val_loss: 3323758125.5890\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1565620191.0951 - val_loss: 3338893227.8356\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1561465066.2828 - val_loss: 3313342681.4247\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1568981902.2039 - val_loss: 3330112536.5479\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1560113636.5244 - val_loss: 3294286199.2329\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1558503755.4619 - val_loss: 3318952651.3973\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1556752483.4824 - val_loss: 3303615663.3425\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1559867775.0129 - val_loss: 3317163043.0685\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1555163925.9640 - val_loss: 3310872523.3973\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1554209150.0257 - val_loss: 3302283106.1918\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1554028558.4781 - val_loss: 3298381620.6027\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1554974751.5887 - val_loss: 3307001003.8356\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1557085587.0848 - val_loss: 3302131852.2740\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1552921951.6435 - val_loss: 3312779860.1644\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1553246008.8706 - val_loss: 3301375992.9863\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1549916051.1945 - val_loss: 3301833533.3699\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1550725861.1277 - val_loss: 3305065864.7671\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1548908395.4893 - val_loss: 3305409518.4658\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1547857614.6427 - val_loss: 3300498784.4384\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1548983276.5861 - val_loss: 3314609166.0274\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1547381346.6050 - val_loss: 3294355559.4521\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1546236545.2614 - val_loss: 3310683700.6027\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1545287706.8723 - val_loss: 3297308366.9041\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1544330124.4490 - val_loss: 3294957266.4110\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1545272419.3728 - val_loss: 3303228505.4247\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1546049333.8543 - val_loss: 3294140303.7808\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1542332286.6838 - val_loss: 3306862090.5205\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1543987471.2734 - val_loss: 3297484133.6986\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1542748617.1585 - val_loss: 3326367018.0822\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1542180393.5698 - val_loss: 3288134673.5342\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1539066629.2648 - val_loss: 3276072177.9726\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1542246092.4490 - val_loss: 3305773776.6575\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1539218996.3188 - val_loss: 3279851672.5479\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1537352052.4833 - val_loss: 3308955306.0822\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1537320515.6744 - val_loss: 3291054977.7534\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1539481241.2271 - val_loss: 3305520399.7808\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1536118347.0231 - val_loss: 3288447644.0548\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1534592269.2168 - val_loss: 3284422559.5616\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1537395395.0985 - val_loss: 3270059772.4932\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1531610300.2159 - val_loss: 3312667781.2603\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1533855421.4225 - val_loss: 3305355228.9315\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1535321952.3016 - val_loss: 3298388953.4247\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1538843926.9237 - val_loss: 3288880587.3973\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1532028982.4027 - val_loss: 3284776916.1644\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1531159296.2742 - val_loss: 3282761985.7534\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1531414114.0291 - val_loss: 3274923909.2603\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1529698755.1808 - val_loss: 3292283521.7534\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1529307895.2254 - val_loss: 3278986851.9452\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1529553500.1885 - val_loss: 3279407056.6575\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1529385230.9169 - val_loss: 3287744361.2055\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1529842700.9426 - val_loss: 3311285730.1918\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1525120427.3248 - val_loss: 3271882197.9178\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1526953513.1859 - val_loss: 3286710014.2466\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1524520400.3702 - val_loss: 3291868356.3836\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1524830274.1388 - val_loss: 3299909972.1644\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1525849500.7369 - val_loss: 3275655671.2329\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1522915575.0060 - val_loss: 3283981357.5890\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1521478965.2511 - val_loss: 3273719729.0959\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1525159656.9666 - val_loss: 3279379178.9589\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1523251915.5716 - val_loss: 3289551121.5342\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1520413531.9143 - val_loss: 3284330848.4384\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1521950434.2759 - val_loss: 3275888320.8767\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1519656317.6967 - val_loss: 3271421639.8904\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 54us/step - loss: 1517919038.8483 - val_loss: 3275567707.1781\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1520154150.8278 - val_loss: 3277380253.8082\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1520201249.6727 - val_loss: 3269832893.3699\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1521117311.0129 - val_loss: 3273244414.2466\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1519509877.4704 - val_loss: 3266068923.6164\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1516237902.8895 - val_loss: 3281168811.8356\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1516469935.1637 - val_loss: 3282818002.4110\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1516114923.9280 - val_loss: 3283774890.0822\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1512970700.0651 - val_loss: 3274600013.1507\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1517373470.7112 - val_loss: 3294449583.3425\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1525440964.6615 - val_loss: 3250548818.4110\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1513587383.3899 - val_loss: 3260082093.5890\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1510653332.6204 - val_loss: 3282825591.2329\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1512875770.1868 - val_loss: 3263326285.1507\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 53us/step - loss: 1514542504.8021 - val_loss: 3268497383.4521\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1511196022.0189 - val_loss: 3301923797.9178\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1512069283.8663 - val_loss: 3261537280.0000\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1510187746.2759 - val_loss: 3270397724.0548\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1510388869.7309 - val_loss: 3270987470.9041\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1508622600.9392 - val_loss: 3250580078.4658\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1512035835.7224 - val_loss: 3248653578.5205\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1509030281.7618 - val_loss: 3275158685.8082\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1506152789.1962 - val_loss: 3267227232.4384\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1506064821.1962 - val_loss: 3271577901.5890\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1504672111.4379 - val_loss: 3249588017.0959\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1505568442.0771 - val_loss: 3269657901.5890\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1504521214.1354 - val_loss: 3257113496.5479\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1507002240.2194 - val_loss: 3253819136.0000\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1504684521.4053 - val_loss: 3248412649.2055\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1502914994.3719 - val_loss: 3253278495.5616\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1501579723.3522 - val_loss: 3267931127.2329\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1502474516.6204 - val_loss: 3271842645.9178\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1503408805.9503 - val_loss: 3287094917.2603\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1500035197.1482 - val_loss: 3248584376.1096\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1501230360.4045 - val_loss: 3270496112.2192\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1500860263.1020 - val_loss: 3249280582.1370\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1497934593.0968 - val_loss: 3270298659.0685\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1499776000.3290 - val_loss: 3256270998.7945\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1497232771.8389 - val_loss: 3263570677.4795\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1498850310.2519 - val_loss: 3262840221.8082\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1496281235.4139 - val_loss: 3241033584.2192\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1497488735.3145 - val_loss: 3245896626.8493\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1497479608.9254 - val_loss: 3262576419.0685\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1499584348.5176 - val_loss: 3262936691.7260\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1503448550.2245 - val_loss: 3256721062.5753\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1498932223.4516 - val_loss: 3257401715.7260\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1497135519.4790 - val_loss: 3265295628.2740\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1494110699.8183 - val_loss: 3256117975.6712\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1497377424.5621 - val_loss: 3256655160.1096\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1495445215.1500 - val_loss: 3263472839.8904\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1494065969.7961 - val_loss: 3259768546.1918\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1492116730.6804 - val_loss: 3246462972.4932\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1492950162.5364 - val_loss: 3254962712.5479\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1490286117.2922 - val_loss: 3264291832.9863\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1494607285.1414 - val_loss: 3229488913.5342\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1490344395.7361 - val_loss: 3267381917.8082\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1490028983.4996 - val_loss: 3251606594.6301\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1488713414.8003 - val_loss: 3241056436.6027\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1488494062.5056 - val_loss: 3250394033.0959\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1488652402.5090 - val_loss: 3253074198.7945\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 58us/step - loss: 1486969053.2305 - val_loss: 3231215961.4247\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1485900301.8201 - val_loss: 3240620473.8630\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1490707363.6470 - val_loss: 3247976372.6027\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1488909484.6410 - val_loss: 3274217538.6301\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1495862845.0934 - val_loss: 3234048885.4795\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1485780904.8569 - val_loss: 3238229065.6438\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1487108986.9546 - val_loss: 3245870991.7808\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1490039268.5793 - val_loss: 3216480452.3836\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1480992769.5356 - val_loss: 3258522483.7260\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1484978125.7104 - val_loss: 3243279184.6575\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1486306557.5321 - val_loss: 3250113153.7534\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1482138049.2614 - val_loss: 3218907947.8356\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1482320573.5870 - val_loss: 3224521633.3151\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1479427623.9246 - val_loss: 3247877453.1507\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1485569207.0608 - val_loss: 3228562154.9589\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1485710774.4027 - val_loss: 3276820548.3836\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1481066139.6401 - val_loss: 3236017283.5068\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1479683953.0831 - val_loss: 3231855323.1781\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1478071504.3976 - val_loss: 3243903042.6301\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1482730487.5544 - val_loss: 3248476898.1918\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1478934622.2177 - val_loss: 3222848634.7397\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1479707065.6384 - val_loss: 3217185758.6849\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1479066300.7644 - val_loss: 3234499347.2877\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1479548089.2545 - val_loss: 3219090284.7123\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1475982091.5167 - val_loss: 3255215668.6027\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1475937192.6924 - val_loss: 3239381507.5068\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1474830663.6778 - val_loss: 3232866833.5342\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1475361120.4662 - val_loss: 3245886232.5479\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1481581588.8398 - val_loss: 3225789113.8630\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1475648315.6675 - val_loss: 3253279921.0959\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1474589375.3967 - val_loss: 3225022891.8356\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1473099330.3582 - val_loss: 3230469945.8630\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1475045690.4610 - val_loss: 3217910180.8219\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1473758648.5416 - val_loss: 3231167386.3014\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1471057962.3376 - val_loss: 3233282987.8356\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1473022559.8629 - val_loss: 3220702179.9452\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1471570520.0754 - val_loss: 3220594302.2466\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1469428385.5081 - val_loss: 3233011775.1233\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1472438270.4644 - val_loss: 3222713854.2466\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1470033951.4790 - val_loss: 3241057792.0000\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1470120003.8389 - val_loss: 3212787189.4795\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1474844036.6067 - val_loss: 3229537560.5479\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1472377732.7164 - val_loss: 3205435207.8904\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 1468226268.7918 - val_loss: 3222889137.0959\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1467326716.3805 - val_loss: 3222296444.4932\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1466337237.7172 - val_loss: 3225696613.6986\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1467379493.6213 - val_loss: 3219830079.1233\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1466157290.6118 - val_loss: 3229535917.5890\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1466948386.5501 - val_loss: 3210768203.3973\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1464894467.7292 - val_loss: 3216125906.4110\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1465758578.5090 - val_loss: 3234856998.5753\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1465763920.6170 - val_loss: 3208414521.8630\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1464103865.1448 - val_loss: 3228899152.6575\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1465476036.1131 - val_loss: 3222152968.7671\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1463218183.1294 - val_loss: 3212645158.5753\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1463579299.9760 - val_loss: 3207096763.6164\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1463970871.1705 - val_loss: 3214238935.6712\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1463704969.7618 - val_loss: 3194173436.4932\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1460909807.2185 - val_loss: 3242586289.0959\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1462218206.6564 - val_loss: 3195322410.0822\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1460174671.4105 - val_loss: 3231075243.8356\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1460402533.1277 - val_loss: 3217991138.1918\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1462218801.4670 - val_loss: 3196542492.0548\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1461586358.9512 - val_loss: 3225326230.7945\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 52us/step - loss: 1457585468.8740 - val_loss: 3198147790.9041\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1457424939.3248 - val_loss: 3217194671.3425\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1458521830.3342 - val_loss: 3205390181.6986\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1456691644.4901 - val_loss: 3213111255.6712\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1460065529.7481 - val_loss: 3195573916.0548\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1456073851.9966 - val_loss: 3228109978.3014\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 55us/step - loss: 1456722377.5150 - val_loss: 3195960516.3836\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1456343124.6752 - val_loss: 3195000917.9178\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1455973650.8655 - val_loss: 3208429326.0274\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1455483148.7232 - val_loss: 3213158640.2192\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1457038310.1148 - val_loss: 3220148371.2877\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1454206584.1028 - val_loss: 3198300805.2603\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1454387145.5424 - val_loss: 3200413061.2603\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1452827117.5184 - val_loss: 3202696868.8219\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1454262713.9674 - val_loss: 3208549428.6027\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1454195866.1045 - val_loss: 3188978384.6575\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1454608477.0111 - val_loss: 3186756976.2192\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1451465321.1311 - val_loss: 3222083682.1918\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1453027177.6247 - val_loss: 3206809184.4384\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1450490898.7009 - val_loss: 3207057283.5068\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 56us/step - loss: 1450616565.7446 - val_loss: 3212872234.0822\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1450770115.0163 - val_loss: 3200044149.4795\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1453509328.5621 - val_loss: 3210151893.9178\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 61us/step - loss: 1452355236.9632 - val_loss: 3179999398.5753\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1449791432.3907 - val_loss: 3220240220.9315\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1447590060.8603 - val_loss: 3194245600.4384\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1447647414.8415 - val_loss: 3199469266.4110\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1449048873.8989 - val_loss: 3193018480.2192\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1446570931.8800 - val_loss: 3194738570.5205\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1448366469.0454 - val_loss: 3198471087.3425\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1449191750.9649 - val_loss: 3209340421.2603\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1450744712.4456 - val_loss: 3208845601.3151\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1446352680.2536 - val_loss: 3176652184.5479\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1446298082.1388 - val_loss: 3200123697.0959\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 57us/step - loss: 1444904612.8535 - val_loss: 3206175114.5205\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 58us/step - loss: 1446772943.5201 - val_loss: 3188714450.4110\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1446655241.8715 - val_loss: 3194649866.5205\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 60us/step - loss: 1443726001.1380 - val_loss: 3210666197.9178\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 62us/step - loss: 1443403879.5407 - val_loss: 3194751077.6986\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 59us/step - loss: 1448296398.5330 - val_loss: 3211983658.0822\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_5000E_Adam_32.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_32.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 128)               42368     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 75,521\n",
      "Trainable params: 75,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_5000E_Adam_128 = Sequential()\n",
    "NN_5000E_Adam_128.add(Dense(128,input_dim = 330,activation = 'relu'))\n",
    "NN_5000E_Adam_128.add(Dense(128,activation = 'relu'))\n",
    "NN_5000E_Adam_128.add(Dense(128,activation = 'relu'))\n",
    "NN_5000E_Adam_128.add(Dense(1))\n",
    "NN_5000E_Adam_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 187us/step - loss: 38690821717.5527 - val_loss: 39492075295.5616\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 38067167105.6452 - val_loss: 38787898438.1370\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 37190807258.9272 - val_loss: 37712415982.4658\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 35843968595.7978 - val_loss: 36016919930.7397\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 33685374161.7138 - val_loss: 33240283023.7808\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 30315134535.5133 - val_loss: 29067547633.9726\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 25726978767.5201 - val_loss: 23658073130.0822\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 20687751560.2262 - val_loss: 17790178893.1507\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 16332400330.2554 - val_loss: 13507428772.8219\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 13912655913.2408 - val_loss: 10726015200.4384\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 12373337261.7378 - val_loss: 9575326229.0411\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 11631635721.4327 - val_loss: 8843370446.9041\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 10945010183.0197 - val_loss: 7988676488.7671\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 10465418717.9983 - val_loss: 7637861512.7671\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 9926815894.7044 - val_loss: 7271128025.4247\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 9455436974.6153 - val_loss: 6929785249.3151\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 9050618438.8552 - val_loss: 6756696190.2466\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 8458948733.6967 - val_loss: 6462015224.9863\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 8060035825.3025 - val_loss: 6213013760.0000\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 7721604976.3153 - val_loss: 6058501624.9863\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 7373885489.5767 - val_loss: 5837274918.5753\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 7046762151.7052 - val_loss: 5713586190.0274\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 6714713529.8029 - val_loss: 5560544222.6849\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 6362998518.3479 - val_loss: 5411602556.4932\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 6114681818.9272 - val_loss: 5261357199.7808\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 5900298889.7618 - val_loss: 5140693509.2603\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 5516017395.4961 - val_loss: 5024565849.4247\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 5262466807.8835 - val_loss: 4911693916.9315\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 5033685816.8158 - val_loss: 4801774953.2055\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 4785897392.1508 - val_loss: 4711544777.6438\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 4565737980.9289 - val_loss: 4624816354.1918\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 4373846530.4130 - val_loss: 4538253781.9178\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 4170533894.2519 - val_loss: 4471793390.4658\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 4027080239.1637 - val_loss: 4381940913.0959\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 3817368406.1011 - val_loss: 4327780955.1781\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 3671174179.9760 - val_loss: 4255320768.8767\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 3509813862.4439 - val_loss: 4198651961.8630\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 3364312493.4087 - val_loss: 4145323935.5616\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 3233605219.0437 - val_loss: 4083228373.9178\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 3113194758.7455 - val_loss: 4038278405.2603\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 3000024144.7266 - val_loss: 3987423161.8630\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2897044877.8201 - val_loss: 3940047659.8356\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 2794538529.1243 - val_loss: 3898660660.6027\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 2693925538.3308 - val_loss: 3870363409.5342\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 2615841646.3410 - val_loss: 3825830321.0959\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 2525107162.5981 - val_loss: 3806016874.9589\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2449423670.2931 - val_loss: 3767683345.5342\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 2376894208.9323 - val_loss: 3727610050.6301\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 2313798758.7729 - val_loss: 3701340980.6027\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2247536923.4207 - val_loss: 3680367987.7260\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2197614061.7926 - val_loss: 3645921213.3699\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2149296620.4764 - val_loss: 3624097872.6575\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 2101034082.4953 - val_loss: 3586967536.2192\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 2060009782.6221 - val_loss: 3564261879.2329\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 2017589945.1448 - val_loss: 3563128867.0685\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1986802820.9906 - val_loss: 3533260000.4384\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1953185707.7635 - val_loss: 3501930897.5342\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1921736022.6495 - val_loss: 3493290848.4384\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1891507887.7395 - val_loss: 3492703905.3151\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1872829801.2408 - val_loss: 3479570442.5205\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1850119845.6213 - val_loss: 3461361009.9726\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1833115860.6752 - val_loss: 3449006435.9452\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1815890317.2716 - val_loss: 3434561678.0274\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1798590653.0934 - val_loss: 3440421863.4521\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1790863390.4919 - val_loss: 3453983845.6986\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1780702719.2871 - val_loss: 3410398958.4658\n",
      "Epoch 67/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 77us/step - loss: 1765073418.6941 - val_loss: 3411879232.8767\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1758582463.3967 - val_loss: 3396047347.7260\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1744228315.3111 - val_loss: 3391115974.1370\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1740766425.8303 - val_loss: 3383109579.3973\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1731204590.8895 - val_loss: 3370837176.1096\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1725354745.0900 - val_loss: 3366179091.2877\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1718979936.6307 - val_loss: 3377862207.1233\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1712693046.8415 - val_loss: 3371860983.2329\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1708490303.5613 - val_loss: 3378068564.1644\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1704787961.7481 - val_loss: 3339882573.1507\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1703973682.1251 - val_loss: 3357356445.8082\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1695298964.4010 - val_loss: 3339705628.0548\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1689236585.5150 - val_loss: 3365038067.7260\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1690931133.9709 - val_loss: 3380680388.3836\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1688811651.5099 - val_loss: 3322751175.8904\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1685057484.7781 - val_loss: 3350533686.3562\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1679914373.8680 - val_loss: 3327800735.5616\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1679541471.7532 - val_loss: 3319176711.0137\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1669090301.0386 - val_loss: 3360757882.7397\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1668658837.2785 - val_loss: 3353300683.3973\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1664280498.7832 - val_loss: 3345946013.8082\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1661486543.7395 - val_loss: 3336027839.1233\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1659604884.7301 - val_loss: 3359719420.4932\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1656503828.5107 - val_loss: 3338508133.6986\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1660222528.0000 - val_loss: 3330688746.9589\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1655388307.1945 - val_loss: 3313850185.6438\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1648768505.3093 - val_loss: 3330929718.3562\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1644764600.8158 - val_loss: 3338596937.6438\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 88us/step - loss: 1646409940.0720 - val_loss: 3339107941.6986\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1643141319.1294 - val_loss: 3353732111.7808\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1636680942.8895 - val_loss: 3323005729.3151\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1635330841.0077 - val_loss: 3323178573.1507\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1634361155.8389 - val_loss: 3359353712.2192\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1631797359.3282 - val_loss: 3318075213.1507\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1629113475.6744 - val_loss: 3319366305.3151\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1627805146.2691 - val_loss: 3334105887.5616\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1629693944.9803 - val_loss: 3318363120.2192\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1626486403.6195 - val_loss: 3317063436.2740\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1618069643.4893 - val_loss: 3336611662.9041\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1619008606.3273 - val_loss: 3334277624.9863\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1617880009.8166 - val_loss: 3302084320.4384\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1610036048.9460 - val_loss: 3332106103.2329\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1617190670.5878 - val_loss: 3321647861.4795\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1608856921.8303 - val_loss: 3330656031.5616\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1607572440.8432 - val_loss: 3327140579.9452\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1607331026.5638 - val_loss: 3349558008.9863\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1610473889.6727 - val_loss: 3352170232.9863\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1606755967.5064 - val_loss: 3293851223.6712\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1602693199.9589 - val_loss: 3327297080.1096\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1597508780.4764 - val_loss: 3291412015.3425\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1595430501.3470 - val_loss: 3300611426.1918\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1596271285.1962 - val_loss: 3320798600.7671\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1604448752.0411 - val_loss: 3320680824.9863\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1590719620.1680 - val_loss: 3327045374.2466\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1587118316.5861 - val_loss: 3304098256.6575\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1587905175.7464 - val_loss: 3322614454.3562\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1590611202.5775 - val_loss: 3312616069.2603\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1599297664.5484 - val_loss: 3298919811.5068\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1585494978.3582 - val_loss: 3293800064.0000\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1579680696.3222 - val_loss: 3337476565.9178\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1579820378.9820 - val_loss: 3313943704.5479\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1575912695.0608 - val_loss: 3332444913.9726\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1571208151.8560 - val_loss: 3292374017.7534\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1570281117.3950 - val_loss: 3293225699.9452\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1567917123.9486 - val_loss: 3292520125.3699\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1566880886.2382 - val_loss: 3258921528.1096\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1570674846.0531 - val_loss: 3255703068.0548\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1563468971.9829 - val_loss: 3270459430.5753\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1562383891.7978 - val_loss: 3266234839.6712\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1558576079.4653 - val_loss: 3267359046.1370\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1557170502.5261 - val_loss: 3324256352.4384\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1558175326.0531 - val_loss: 3227761960.3288\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1556239595.2151 - val_loss: 3343159089.0959\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1555928486.4987 - val_loss: 3265898780.0548\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1549365186.9066 - val_loss: 3272611441.9726\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1550740153.1448 - val_loss: 3262053619.7260\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1545835599.7395 - val_loss: 3290108261.6986\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1555280816.2605 - val_loss: 3227780208.2192\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1546191682.9066 - val_loss: 3286265459.7260\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1543843507.4413 - val_loss: 3246309409.3151\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1546611775.6161 - val_loss: 3236711758.9041\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1543095150.5604 - val_loss: 3265072373.4795\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1544141717.0591 - val_loss: 3252649612.2740\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1549295673.8578 - val_loss: 3208628355.5068\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1537496262.7455 - val_loss: 3269559927.2329\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1538829363.6058 - val_loss: 3275735843.0685\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1534752111.5476 - val_loss: 3240437475.9452\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1528171347.5784 - val_loss: 3299476245.0411\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1527832808.3085 - val_loss: 3271722033.0959\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1526442370.9614 - val_loss: 3302241050.3014\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1521467822.2862 - val_loss: 3237932151.2329\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1525087722.7763 - val_loss: 3292718020.3836\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1521724569.7207 - val_loss: 3232061354.0822\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1524208277.4430 - val_loss: 3227814670.0274\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1521896209.0831 - val_loss: 3244831744.0000\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1515204024.4867 - val_loss: 3241420286.2466\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1514870550.0463 - val_loss: 3225552178.8493\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1518505196.0377 - val_loss: 3297948612.3836\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1519946437.4841 - val_loss: 3275245373.3699\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1511770031.0540 - val_loss: 3264484257.3151\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1508949058.9066 - val_loss: 3265124969.2055\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1508174864.7815 - val_loss: 3237168403.2877\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1506134690.1114 - val_loss: 3192860545.7534\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1509281838.2862 - val_loss: 3215589863.4521\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1502696444.3256 - val_loss: 3241339698.8493\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1518082064.6718 - val_loss: 3235630469.2603\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1505001920.1645 - val_loss: 3217396911.3425\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1502174259.7704 - val_loss: 3263088120.9863\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1498949032.4730 - val_loss: 3163575196.0548\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1500360093.6144 - val_loss: 3210644658.8493\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1499736509.9709 - val_loss: 3279094901.4795\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1489219477.8269 - val_loss: 3204941343.5616\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1492210820.3873 - val_loss: 3206655747.5068\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1494217260.6958 - val_loss: 3257974954.0822\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1487787094.4302 - val_loss: 3234007706.3014\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1485465137.1380 - val_loss: 3218581318.1370\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1483763452.8192 - val_loss: 3198049711.3425\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1481178088.3085 - val_loss: 3204465613.1507\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1482555226.7078 - val_loss: 3261255616.8767\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1482571524.7712 - val_loss: 3194029340.0548\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1478707517.3676 - val_loss: 3224623731.7260\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1480306651.1465 - val_loss: 3186029978.3014\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1478709230.3410 - val_loss: 3159731394.6301\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1479275049.2408 - val_loss: 3250761664.8767\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1482342482.8106 - val_loss: 3267631095.2329\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1471410374.4439 - val_loss: 3162824761.8630\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1471130591.6710 - val_loss: 3203604450.1918\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1470992428.7506 - val_loss: 3156579708.4932\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1465524189.7789 - val_loss: 3270903902.6849\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1479179382.5673 - val_loss: 3171777918.2466\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1465199777.5630 - val_loss: 3167468505.4247\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1468787796.8946 - val_loss: 3259688109.5890\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 76us/step - loss: 1459983632.4524 - val_loss: 3164350236.0548\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1459066925.9023 - val_loss: 3197279603.7260\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1459778316.4490 - val_loss: 3218539085.1507\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1455076517.3470 - val_loss: 3173961978.7397\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1469992295.7601 - val_loss: 3283399466.0822\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1460079372.9426 - val_loss: 3190675250.8493\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1453765550.6427 - val_loss: 3171887473.9726\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1452141877.0865 - val_loss: 3207173442.6301\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 73us/step - loss: 1450308726.2382 - val_loss: 3140537363.2877\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1455467347.7429 - val_loss: 3158695727.3425\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1457097786.8997 - val_loss: 3236488868.8219\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1445272320.2194 - val_loss: 3151867181.5890\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1448726323.8800 - val_loss: 3129861691.6164\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1444694799.0814 - val_loss: 3184161118.6849\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1441820524.3668 - val_loss: 3201284160.8767\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1444807998.5741 - val_loss: 3143746782.6849\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1441310125.6829 - val_loss: 3185047536.2192\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1436894381.1894 - val_loss: 3125299704.9863\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1440056680.4730 - val_loss: 3172982231.6712\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1438581463.6367 - val_loss: 3212501116.4932\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1431788792.8158 - val_loss: 3129181317.2603\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1438056743.3762 - val_loss: 3123997243.6164\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1428388586.1731 - val_loss: 3216173487.3425\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1429461352.5278 - val_loss: 3115027247.3425\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1438753438.6015 - val_loss: 3166862371.0685\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1427598430.6564 - val_loss: 3152806924.2740\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1429185400.9803 - val_loss: 3148019068.4932\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1431519465.1859 - val_loss: 3119732390.5753\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1441836262.3342 - val_loss: 3086973923.9452\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1420599451.0643 - val_loss: 3214283218.4110\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1422123318.1834 - val_loss: 3119011876.8219\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1421013158.7181 - val_loss: 3123354688.8767\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1425210077.2305 - val_loss: 3094355014.1370\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1430701472.5758 - val_loss: 3144101454.9041\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1420990268.7644 - val_loss: 3125365507.5068\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1415673226.4747 - val_loss: 3117257035.3973\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1413499840.6033 - val_loss: 3131148209.0959\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1414287335.1568 - val_loss: 3151103903.5616\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1410445226.8312 - val_loss: 3162833341.3699\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1411216462.7524 - val_loss: 3115704568.9863\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1408967594.5570 - val_loss: 3227565624.1096\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1417664557.2991 - val_loss: 3155346859.8356\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1412325827.9486 - val_loss: 3121459501.5890\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1414032368.9734 - val_loss: 3254407434.5205\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1408156286.3548 - val_loss: 3089405517.1507\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1407466827.2425 - val_loss: 3110096759.2329\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1423163069.5321 - val_loss: 3061301426.8493\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1398782519.2802 - val_loss: 3228339350.7945\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1407763370.0086 - val_loss: 3123664224.4384\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1404778553.9126 - val_loss: 3122049402.7397\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1402358232.0754 - val_loss: 3097738089.2055\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1395852786.7284 - val_loss: 3121076334.4658\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1392871868.3256 - val_loss: 3106225716.6027\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1396617313.1791 - val_loss: 3104958130.8493\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1402070312.3633 - val_loss: 3217251138.6301\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1396243119.6024 - val_loss: 3119514148.8219\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1392088711.2391 - val_loss: 3108879517.8082\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1393486394.5707 - val_loss: 3202783826.4110\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1407678321.7961 - val_loss: 3086451079.0137\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1394161979.2288 - val_loss: 3044552004.3836\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1383245954.0840 - val_loss: 3163632622.4658\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1394473553.8783 - val_loss: 3175485191.0137\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1392112947.6607 - val_loss: 3116972316.0548\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1381544879.6572 - val_loss: 3075198071.2329\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1387125735.4310 - val_loss: 3122764186.3014\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1388404438.6495 - val_loss: 3135612026.7397\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1380272853.8817 - val_loss: 3126829838.0274\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1385263274.1183 - val_loss: 3088221492.6027\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1379664126.6290 - val_loss: 3028957592.5479\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1385406710.7318 - val_loss: 3115687194.3014\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1374478207.6161 - val_loss: 3038248479.5616\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1381103564.4490 - val_loss: 3060688012.2740\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1376695011.8663 - val_loss: 3045779603.2877\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1371959017.6247 - val_loss: 3077756873.6438\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1382485112.2125 - val_loss: 3040809156.3836\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1375180540.3805 - val_loss: 3061841941.0411\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1381865727.2322 - val_loss: 3099671299.5068\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1375198702.1765 - val_loss: 3029189533.8082\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1371808962.6872 - val_loss: 3086926825.2055\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1365922099.9075 - val_loss: 3010399744.0000\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1371698134.3205 - val_loss: 3078232810.9589\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1361941808.5895 - val_loss: 3045185141.4795\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1363065444.6341 - val_loss: 3083774732.2740\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1363375714.9340 - val_loss: 3082717962.5205\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1362878025.3779 - val_loss: 3060259324.4932\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1361047722.5021 - val_loss: 3080823986.8493\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1365214802.8106 - val_loss: 3106728784.6575\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 74us/step - loss: 1362335999.2871 - val_loss: 3081102300.9315\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1357606438.4987 - val_loss: 3061972636.0548\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1359639439.8492 - val_loss: 3090892526.4658\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1353645182.7935 - val_loss: 3084135718.5753\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1354111368.7746 - val_loss: 3073343224.9863\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1354369310.4919 - val_loss: 3113130583.6712\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1354708760.7883 - val_loss: 3015799327.5616\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1362132809.2682 - val_loss: 3126767104.0000\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1357877152.2468 - val_loss: 3057918451.7260\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1352642612.2091 - val_loss: 3166298865.9726\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1360120600.2399 - val_loss: 3050691349.0411\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1346302341.7035 - val_loss: 3017302001.9726\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1341032707.5167 - val_loss: 3101190776.9863\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1343770026.8312 - val_loss: 3016246910.2466\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1345521843.2219 - val_loss: 3070906932.6027\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1345454852.4422 - val_loss: 3087084437.0411\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1347558890.1731 - val_loss: 3026717827.5068\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1336329178.9272 - val_loss: 3026385308.0548\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1333413089.1243 - val_loss: 3061588067.9452\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1334000292.6889 - val_loss: 3001451218.4110\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1343190219.7361 - val_loss: 3088089372.0548\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1337866588.3530 - val_loss: 3053700671.1233\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1338517866.2828 - val_loss: 3043050360.9863\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1340747394.4953 - val_loss: 2988757214.6849\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1330004558.4233 - val_loss: 3081226380.2740\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1332904437.0865 - val_loss: 3025844413.3699\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1328083447.8835 - val_loss: 3135792119.2329\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1337228534.7318 - val_loss: 3028174865.5342\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1330163055.6572 - val_loss: 2984515168.4384\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1349279007.9177 - val_loss: 3102535371.3973\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1341520307.9897 - val_loss: 3098223803.6164\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1325636692.8946 - val_loss: 3060485095.4521\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1325307057.6864 - val_loss: 3037452056.5479\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1324753657.4739 - val_loss: 2951958235.1781\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1316794146.3582 - val_loss: 3109231149.5890\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1324125157.4567 - val_loss: 2990095093.4795\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1332797153.5630 - val_loss: 2964578309.2603\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1320622854.6358 - val_loss: 3006426827.3973\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1328548622.5330 - val_loss: 3057665690.3014\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1322097556.8946 - val_loss: 2994948404.6027\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1316253060.9357 - val_loss: 3069805233.0959\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1321836734.7386 - val_loss: 3024580665.8630\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1310083821.0249 - val_loss: 2984159621.2603\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1312768183.1979 - val_loss: 2956205994.0822\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1316037687.3350 - val_loss: 3075665685.0411\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 75us/step - loss: 1318095657.1585 - val_loss: 3072681147.6164\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1310741673.5698 - val_loss: 2991538752.8767\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1304317506.9066 - val_loss: 3077951677.3699\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1308258751.0677 - val_loss: 3022073233.5342\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1305852619.5716 - val_loss: 2977221335.6712\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1301489061.0180 - val_loss: 3007367178.5205\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1307269222.9923 - val_loss: 2974396563.2877\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 83us/step - loss: 1311471675.5578 - val_loss: 2942342524.4932\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1313529684.9494 - val_loss: 2958171923.2877\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1316290481.0283 - val_loss: 3017989852.9315\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1302944480.9597 - val_loss: 2998342955.8356\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1306564665.9949 - val_loss: 2908773049.8630\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1290980283.5578 - val_loss: 3123779135.1233\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1308742390.5124 - val_loss: 2935492285.3699\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1297373274.5433 - val_loss: 3005975734.3562\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1292808827.4482 - val_loss: 2978460682.5205\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1293763687.2117 - val_loss: 2950951525.6986\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1295543918.9991 - val_loss: 2993230232.5479\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1291041840.2605 - val_loss: 2999319848.3288\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1296490945.7001 - val_loss: 3029567340.7123\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1291783669.4704 - val_loss: 3000805719.6712\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1297742858.6392 - val_loss: 2913414792.7671\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1291499661.4910 - val_loss: 2970454889.2055\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1284413575.5681 - val_loss: 3019385172.1644\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1282621840.0137 - val_loss: 2978971733.9178\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1286484404.8946 - val_loss: 2917488555.8356\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1288201781.7446 - val_loss: 3014019899.6164\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1280858378.0908 - val_loss: 2941398133.4795\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1283020353.5904 - val_loss: 2960164555.3973\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1281955410.4267 - val_loss: 2927155918.9041\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1285965594.1594 - val_loss: 2958851633.0959\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1278120962.8518 - val_loss: 2974425696.4384\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1278688157.1757 - val_loss: 3002447468.7123\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1282968973.2716 - val_loss: 2908233389.5890\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1270675301.3470 - val_loss: 3042337748.1644\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1275843168.0823 - val_loss: 2916194828.2740\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1275324840.4319 - val_loss: 2984403573.4795\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1277021424.4250 - val_loss: 2966258325.0411\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1272731812.1954 - val_loss: 2982504847.7808\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1278813451.0780 - val_loss: 3013950954.9589\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1274804810.5844 - val_loss: 2907470065.9726\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1291251532.9974 - val_loss: 2910986667.8356\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1267836301.7104 - val_loss: 2943999021.5890\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1265071365.7584 - val_loss: 2990992748.7123\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1265105959.4310 - val_loss: 2928455160.9863\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1266203766.3479 - val_loss: 3033253621.4795\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1265334329.6110 - val_loss: 2946811788.2740\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1264504616.7472 - val_loss: 2947762929.9726\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1263734859.0231 - val_loss: 3080744739.0685\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1276775422.0531 - val_loss: 2946494548.1644\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1258152897.3710 - val_loss: 2991523173.6986\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1259881912.5690 - val_loss: 2951391042.6301\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1259461874.3445 - val_loss: 2968980723.7260\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1256595616.4662 - val_loss: 2917681232.6575\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1258324576.4662 - val_loss: 2987782436.8219\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1260789038.5604 - val_loss: 3012164927.1233\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1258888362.7763 - val_loss: 2899332646.5753\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1247820202.4473 - val_loss: 2984323282.4110\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1254597403.7498 - val_loss: 2971140271.3425\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1266001405.7515 - val_loss: 2992339782.1370\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1253539477.9914 - val_loss: 3001430494.6849\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1253713981.4225 - val_loss: 2976922604.7123\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1247123562.8312 - val_loss: 2948899569.9726\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1252074047.9452 - val_loss: 2891783206.5753\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1256808549.8406 - val_loss: 2901894648.9863\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1251228532.2639 - val_loss: 2918974471.0137\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1265526109.1757 - val_loss: 2994700487.8904\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1249477696.9323 - val_loss: 2923473774.4658\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1263228350.1902 - val_loss: 2841196572.0548\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1253857367.0060 - val_loss: 3006037844.1644\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1257952915.9623 - val_loss: 2984407609.8630\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1238504395.4619 - val_loss: 2906402198.7945\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1241806175.0951 - val_loss: 2927156844.7123\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1243983053.4087 - val_loss: 2927357115.6164\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1237128931.4824 - val_loss: 2926511282.8493\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1233665872.1234 - val_loss: 2997228852.6027\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1238511880.0891 - val_loss: 2904200455.0137\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1235477104.9734 - val_loss: 2920015459.9452\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1234618984.7746 - val_loss: 2934325523.2877\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1240989484.4216 - val_loss: 3020602385.5342\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1236627842.3033 - val_loss: 2869569036.2740\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1226983362.6324 - val_loss: 3001148559.7808\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1224360613.1551 - val_loss: 2843035321.8630\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1249337101.1620 - val_loss: 2879421618.8493\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1232299887.9314 - val_loss: 2968840810.9589\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1232177238.3205 - val_loss: 3011360599.6712\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1232062966.0189 - val_loss: 2900132120.5479\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1226646518.8963 - val_loss: 2925581280.4384\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1227932505.0626 - val_loss: 2856132620.2740\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1231789232.5895 - val_loss: 2927484873.6438\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1219139068.9563 - val_loss: 2877281948.0548\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1224683678.2725 - val_loss: 2996278755.9452\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1229758011.5578 - val_loss: 2897336609.3151\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1214978020.7986 - val_loss: 2977064635.6164\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1223068926.4507 - val_loss: 2916446541.1507\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1221659319.0608 - val_loss: 2912431905.3151\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1217538875.2562 - val_loss: 2869864540.9315\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1217142348.9152 - val_loss: 2930624545.3151\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1222312499.9897 - val_loss: 2867450592.4384\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1209137791.8903 - val_loss: 2937896367.3425\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1215404177.8235 - val_loss: 2858437553.0959\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1218568101.6761 - val_loss: 2907695489.7534\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1216943899.8595 - val_loss: 2931543352.1096\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1219653819.9966 - val_loss: 2864201936.6575\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1224183054.5330 - val_loss: 2963660305.5342\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1209737774.9169 - val_loss: 2867739323.6164\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1219377380.8809 - val_loss: 2924813738.0822\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1221337511.5407 - val_loss: 2903357704.7671\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1204105478.4713 - val_loss: 2853729185.3151\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1218430043.1465 - val_loss: 2856052581.6986\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1211704926.3273 - val_loss: 2870568556.7123\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 82us/step - loss: 1209801040.0411 - val_loss: 2869554891.3973\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1203635385.9126 - val_loss: 2876667469.1507\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1199343002.5433 - val_loss: 2954341232.2192\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1216482433.9743 - val_loss: 2825529194.9589\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1199646071.3350 - val_loss: 2913399094.3562\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1210088481.2888 - val_loss: 2925798184.3288\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1199240831.1774 - val_loss: 2845141917.8082\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1199894547.7155 - val_loss: 2878760011.3973\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1195495279.7121 - val_loss: 2953202502.1370\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1200559536.6992 - val_loss: 2889595114.9589\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1197830189.2442 - val_loss: 2844562000.6575\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1189756686.9169 - val_loss: 2963656702.2466\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1199854526.4096 - val_loss: 2889451176.3288\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1191452364.0103 - val_loss: 2902736387.5068\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1190887908.1954 - val_loss: 2897406898.8493\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1196029999.8766 - val_loss: 2829632066.6301\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1197924567.9657 - val_loss: 2974215927.2329\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1198655793.3573 - val_loss: 2865318622.6849\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1185361183.9314 - val_loss: 2905817503.5616\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1193657399.2528 - val_loss: 2888334469.2603\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1184990142.3548 - val_loss: 2863090505.6438\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 78us/step - loss: 1188486239.4790 - val_loss: 2842957252.3836\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1188595814.2245 - val_loss: 2892383512.5479\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1190590372.5244 - val_loss: 2827251631.3425\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1198473161.7069 - val_loss: 2877694178.1918\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1182912518.0326 - val_loss: 2909647379.2877\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1181008338.1525 - val_loss: 2894570378.5205\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1180401603.0163 - val_loss: 2903558436.8219\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1187769878.9237 - val_loss: 2938208680.3288\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1170512352.6855 - val_loss: 2805979788.2740\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1187661252.0583 - val_loss: 2866597125.2603\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1173947475.3042 - val_loss: 2886037191.8904\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1167690929.0283 - val_loss: 2787052300.2740\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1190646753.1243 - val_loss: 2852057607.0137\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1175442687.8081 - val_loss: 2914026687.1233\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1173763821.4636 - val_loss: 2841390635.8356\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1172965924.4970 - val_loss: 2829201697.3151\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1171807578.5159 - val_loss: 2849873688.5479\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1168474988.3668 - val_loss: 2839483623.4521\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1177092422.4987 - val_loss: 2769246840.9863\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1206495235.0163 - val_loss: 2831547923.2877\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1170958137.0900 - val_loss: 2852846818.1918\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1170009483.6264 - val_loss: 2905960951.2329\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1168014905.3368 - val_loss: 2824092203.8356\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1160493215.6984 - val_loss: 2959308070.5753\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1175736961.6452 - val_loss: 2825483765.4795\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1178672316.4901 - val_loss: 2936679169.7534\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1169963932.7095 - val_loss: 2838038087.8904\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 76us/step - loss: 1166746205.2853 - val_loss: 2896109929.2055\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1162822181.2922 - val_loss: 2814668561.5342\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 79us/step - loss: 1156284524.8877 - val_loss: 2876832206.9041\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 80us/step - loss: 1179239352.5416 - val_loss: 2936843397.2603\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 75us/step - loss: 1160361078.4850 - val_loss: 2809424945.0959\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 81us/step - loss: 1153918058.1183 - val_loss: 2836176119.2329\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1157276527.2734 - val_loss: 2823545093.2603\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1159490228.2091 - val_loss: 2866422954.0822\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 78us/step - loss: 1159725948.1611 - val_loss: 2816017116.9315\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1158251411.9623 - val_loss: 2893251059.7260\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 77us/step - loss: 1163715978.4199 - val_loss: 2830939967.1233\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_5000E_Adam_128.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_5000E_Adam_128.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 512)               169472    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 432,641\n",
      "Trainable params: 432,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_500E_1H = Sequential()\n",
    "NN_500E_1H.add(Dense(512,input_dim = 330,activation = 'relu'))\n",
    "NN_500E_1H.add(Dense(512,activation = 'relu'))\n",
    "NN_500E_1H.add(Dense(1))\n",
    "NN_500E_1H.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1167 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 0s 274us/step - loss: 37315028674.3582 - val_loss: 37191868359.8904\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 34670875241.7344 - val_loss: 34077835656.7671\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 30991707826.5638 - val_loss: 29510343750.1370\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 181us/step - loss: 26036271552.3839 - val_loss: 23620228306.4110\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 20506454550.3753 - val_loss: 17563180817.5342\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 16197170727.9246 - val_loss: 13097517168.2192\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 13490555313.4670 - val_loss: 10542575125.0411\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 11950503666.6187 - val_loss: 9014504882.8493\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 10914384783.6847 - val_loss: 7763919468.7123\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 10067454718.4644 - val_loss: 7220150450.8493\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 9136653946.1320 - val_loss: 6749834225.9726\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 8366443936.5758 - val_loss: 6327585886.6849\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 180us/step - loss: 7717556697.8303 - val_loss: 6000714986.9589\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 7186532844.9152 - val_loss: 5706583201.3151\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 6515859842.7421 - val_loss: 5414860233.6438\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 5978292068.9083 - val_loss: 5178900264.3288\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 5542993590.0737 - val_loss: 4983877091.9452\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 5032659067.4207 - val_loss: 4799289342.2466\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 4665423896.8980 - val_loss: 4645329190.5753\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 4353698071.9109 - val_loss: 4495737047.6712\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 4054433321.0214 - val_loss: 4392187577.8630\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 3749640709.5938 - val_loss: 4272741889.7534\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 3536665930.6941 - val_loss: 4174349447.0137\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 3297821516.3393 - val_loss: 4096969671.8904\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 3110048505.9674 - val_loss: 4052673525.4795\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 2935378196.4010 - val_loss: 3961064462.0274\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 2779042569.0488 - val_loss: 3905559702.7945\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 180us/step - loss: 2652014658.9066 - val_loss: 3842299432.3288\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 2531300596.7027 - val_loss: 3798827141.2603\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 2430988893.7241 - val_loss: 3745671564.2740\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 2338622697.1859 - val_loss: 3720047421.3699\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 2260526976.9871 - val_loss: 3665621954.6301\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 2187125384.8843 - val_loss: 3631143564.2740\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 2132022882.8243 - val_loss: 3617098813.3699\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 2076032572.4353 - val_loss: 3576360938.9589\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 2024760738.1114 - val_loss: 3555087389.8082\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1986936308.3736 - val_loss: 3552991342.4658\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1949047595.7635 - val_loss: 3503962915.0685\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 1917269984.5210 - val_loss: 3509827701.4795\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1887271394.7147 - val_loss: 3503179740.9315\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1862797180.8192 - val_loss: 3470618148.8219\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1838407799.1157 - val_loss: 3456655587.9452\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1821753861.9229 - val_loss: 3451772394.9589\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1806544170.7763 - val_loss: 3431800449.7534\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1787762029.2442 - val_loss: 3431017857.7534\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1772413779.3042 - val_loss: 3415600562.8493\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1758605655.5270 - val_loss: 3421956329.2055\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1754524641.2888 - val_loss: 3403857846.3562\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1743829941.3059 - val_loss: 3417888590.9041\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1733097519.4927 - val_loss: 3393846142.2466\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1722630336.8226 - val_loss: 3380560606.6849\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1714408404.2365 - val_loss: 3376155770.7397\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1709978285.9023 - val_loss: 3375490689.7534\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1704343698.6461 - val_loss: 3366487829.0411\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1702087523.7018 - val_loss: 3356079570.4110\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1691812845.7378 - val_loss: 3360359315.2877\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1685336782.4781 - val_loss: 3375123894.3562\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1686588384.9049 - val_loss: 3359355602.4110\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1681345133.0249 - val_loss: 3333076779.8356\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1675188586.1731 - val_loss: 3370475821.5890\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1667915564.4764 - val_loss: 3356171025.5342\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1667027711.8903 - val_loss: 3388621645.1507\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1657937805.7104 - val_loss: 3342111945.6438\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1663353738.2005 - val_loss: 3348182754.1918\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1653331115.1054 - val_loss: 3366345747.2877\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1655902098.5364 - val_loss: 3379900068.8219\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1648449816.3496 - val_loss: 3355527729.0959\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1643874144.0823 - val_loss: 3337687820.2740\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1640827852.7781 - val_loss: 3353097636.8219\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1639270160.3976 - val_loss: 3337490688.0000\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1634624033.5630 - val_loss: 3343139952.2192\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1631566120.5827 - val_loss: 3341120948.6027\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1635436093.4225 - val_loss: 3305758039.6712\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1622641392.2057 - val_loss: 3348590930.4110\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1625013358.5604 - val_loss: 3349232969.6438\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1622145831.3762 - val_loss: 3320904789.9178\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1617142902.3479 - val_loss: 3345644933.2603\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1614403354.1045 - val_loss: 3372705511.4521\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1612069741.7378 - val_loss: 3293882510.0274\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1608827022.4781 - val_loss: 3325956581.6986\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1607301779.5236 - val_loss: 3352520817.9726\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1604683141.8132 - val_loss: 3338757952.8767\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1604178378.1183 - val_loss: 3336159556.3836\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1599913849.7481 - val_loss: 3297213664.4384\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1594738597.1825 - val_loss: 3366801141.4795\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1591738433.1517 - val_loss: 3329352926.6849\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1591458210.8792 - val_loss: 3318909029.6986\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1590982046.3822 - val_loss: 3308497811.2877\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1588919537.9057 - val_loss: 3323234640.6575\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1589014372.7301 - val_loss: 3307856873.2055\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1581768065.7549 - val_loss: 3309634752.8767\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1584813957.7035 - val_loss: 3298508785.9726\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1579001397.8543 - val_loss: 3272298894.0274\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1572653457.8783 - val_loss: 3333281609.6438\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1574142408.7198 - val_loss: 3285592177.9726\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1576762191.9589 - val_loss: 3314581454.9041\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1572271445.0591 - val_loss: 3342638886.5753\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1564947625.2956 - val_loss: 3285431837.8082\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1565575662.2314 - val_loss: 3279120340.1644\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1560303332.5793 - val_loss: 3278397857.3151\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1567668225.2065 - val_loss: 3365976786.4110\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1557275402.5296 - val_loss: 3265063264.4384\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1558877992.6924 - val_loss: 3354253952.0000\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1552700832.3565 - val_loss: 3266758706.8493\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1553089813.0591 - val_loss: 3320114624.8767\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1546484455.9794 - val_loss: 3285040417.3151\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1546580004.8535 - val_loss: 3326570366.2466\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1544759771.4207 - val_loss: 3273808839.8904\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1549289305.0626 - val_loss: 3277493314.6301\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1539036359.8423 - val_loss: 3260876477.3699\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1542860901.2374 - val_loss: 3282846078.2466\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1534709017.4464 - val_loss: 3269854865.5342\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1534751264.8500 - val_loss: 3296201457.9726\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1528887551.3419 - val_loss: 3261128533.9178\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1528385593.4739 - val_loss: 3274377991.0137\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1533527148.8055 - val_loss: 3271168042.0822\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1522830240.1919 - val_loss: 3245230220.2740\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1523892837.2374 - val_loss: 3237864956.4932\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1522261966.0394 - val_loss: 3284612741.2603\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1522785384.0891 - val_loss: 3262917102.4658\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1519165144.1165 - val_loss: 3298911586.1918\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1529299856.2879 - val_loss: 3278141496.1096\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1522754574.2588 - val_loss: 3263848749.5890\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1513285360.0960 - val_loss: 3278229623.2329\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1514650125.2716 - val_loss: 3201067363.9452\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1511519014.7181 - val_loss: 3299334919.0137\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1509639659.4619 - val_loss: 3265399362.6301\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1504056791.2528 - val_loss: 3230316549.2603\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1500614732.2296 - val_loss: 3269410938.7397\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1498183694.9169 - val_loss: 3235858393.4247\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1500985989.1003 - val_loss: 3227157684.6027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1499194769.6590 - val_loss: 3228848405.0411\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1494834233.9126 - val_loss: 3203703075.0685\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1493585565.2853 - val_loss: 3217558794.5205\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1496104212.6204 - val_loss: 3188617789.3699\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1494191274.8312 - val_loss: 3298419843.5068\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1487912581.0454 - val_loss: 3203506900.1644\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1495450916.8535 - val_loss: 3238017388.7123\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1487215100.0514 - val_loss: 3229990629.6986\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1484912450.1937 - val_loss: 3185915483.1781\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1481396838.9374 - val_loss: 3199070316.7123\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1480322579.9349 - val_loss: 3209328999.4521\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1477870024.2811 - val_loss: 3218827420.0548\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1476194067.0848 - val_loss: 3214861838.0274\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1476328917.3333 - val_loss: 3222851275.3973\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1473758148.3325 - val_loss: 3204257483.3973\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1473763765.9092 - val_loss: 3167591762.4110\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1468890786.3719 - val_loss: 3249749333.9178\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1466296010.4747 - val_loss: 3184588740.3836\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1479339953.0831 - val_loss: 3257148735.1233\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1459738126.9717 - val_loss: 3155807203.9452\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1468020457.8989 - val_loss: 3230487455.5616\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1467576966.5810 - val_loss: 3208534713.8630\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1459418274.2211 - val_loss: 3203149312.0000\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1467769116.6272 - val_loss: 3221557642.5205\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1458138971.2836 - val_loss: 3126444642.1918\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1457023278.3136 - val_loss: 3189015031.2329\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1452216593.3299 - val_loss: 3221237842.4110\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1463663629.9297 - val_loss: 3234237727.5616\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1456292125.1757 - val_loss: 3201688453.2603\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1448378137.9126 - val_loss: 3173139971.5068\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1450147078.8003 - val_loss: 3207035353.4247\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1449656834.3582 - val_loss: 3195080924.9315\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1446053675.9829 - val_loss: 3176446840.9863\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1448684265.8440 - val_loss: 3207829398.7945\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1441257053.0111 - val_loss: 3134001546.5205\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1442477649.6041 - val_loss: 3180028721.0959\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1438727716.0857 - val_loss: 3181341624.1096\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1437855169.5904 - val_loss: 3183206371.9452\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1436665262.8346 - val_loss: 3190770396.9315\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1438779932.7918 - val_loss: 3175425834.0822\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1437544903.6230 - val_loss: 3147711533.5890\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1431401924.8535 - val_loss: 3160866731.8356\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1430647362.7421 - val_loss: 3162103627.3973\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1438471647.8629 - val_loss: 3080320263.0137\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1427229249.3162 - val_loss: 3151083239.4521\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1429403859.0848 - val_loss: 3099396525.5890\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1434836707.4824 - val_loss: 3152029385.6438\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1427304010.8038 - val_loss: 3138980679.8904\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1430047138.6598 - val_loss: 3183665506.1918\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1424476048.1234 - val_loss: 3104112087.6712\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1418332255.8629 - val_loss: 3247054963.7260\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1420282364.0514 - val_loss: 3087104087.6712\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1421974227.2494 - val_loss: 3136672613.6986\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1415499252.9220 - val_loss: 3144995750.5753\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1416346929.0831 - val_loss: 3119313169.5342\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1413025078.6221 - val_loss: 3118817448.3288\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1409323811.7566 - val_loss: 3143995865.4247\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1408828644.5793 - val_loss: 3125622117.6986\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1416309831.0746 - val_loss: 3177310183.4521\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1409511477.0865 - val_loss: 3128015984.2192\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1405851288.4045 - val_loss: 3170470042.3014\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1404473893.7309 - val_loss: 3084152369.0959\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1406922148.5518 - val_loss: 3083450050.6301\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1403853702.1971 - val_loss: 3111937008.2192\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1400905794.6324 - val_loss: 3103091245.5890\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1396826188.5587 - val_loss: 3098127440.6575\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1397424325.6487 - val_loss: 3104948420.3836\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1394368216.9529 - val_loss: 3130412942.0274\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1399225521.6864 - val_loss: 3037778556.4932\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1401163106.7969 - val_loss: 3152657278.2466\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1395044963.8115 - val_loss: 3071270368.4384\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1391320107.8732 - val_loss: 3112499575.2329\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1388457493.6898 - val_loss: 3100581118.2466\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1389107352.6787 - val_loss: 3101615866.7397\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1387113397.1962 - val_loss: 3123269554.8493\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1388549245.8063 - val_loss: 3093736062.2466\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1389706529.5630 - val_loss: 3162695736.1096\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1386238145.4259 - val_loss: 3087381155.0685\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1382074242.3033 - val_loss: 3093986693.2603\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1381908823.4173 - val_loss: 3075597987.0685\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1387165900.0925 - val_loss: 3031338225.9726\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1395195432.2536 - val_loss: 3107067234.1918\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1380676580.8535 - val_loss: 3108179841.7534\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1391910216.2262 - val_loss: 3155716341.4795\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1375506934.5398 - val_loss: 3053554724.8219\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1386063965.3402 - val_loss: 3121331087.7808\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1374614086.5261 - val_loss: 3055813235.7260\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1378252734.2999 - val_loss: 3108765056.0000\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1375893148.4627 - val_loss: 3070547697.9726\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1380307815.1020 - val_loss: 3127550990.0274\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1367932035.1808 - val_loss: 3066910870.7945\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1365885398.6495 - val_loss: 3068394497.7534\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1378019126.0463 - val_loss: 3034665966.4658\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1373355156.4010 - val_loss: 3073423796.6027\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1364225923.1808 - val_loss: 3095787670.7945\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1367264075.2973 - val_loss: 3144637317.2603\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1364112170.0086 - val_loss: 3010497653.4795\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1369643733.2237 - val_loss: 3005151482.7397\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1359913242.5433 - val_loss: 3032340928.8767\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1364319435.5716 - val_loss: 3063132154.7397\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1361290383.4653 - val_loss: 3044027251.7260\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1355220255.2048 - val_loss: 3037863781.6986\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1351072918.0463 - val_loss: 3065345930.5205\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1363206585.8303 - val_loss: 3063245441.7534\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1351144082.3171 - val_loss: 3052489652.6027\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1368458748.2708 - val_loss: 3102289928.7671\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1362870192.8089 - val_loss: 3016290407.4521\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1347241756.6821 - val_loss: 3036717748.6027\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1345427874.3856 - val_loss: 2997531214.9041\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1342691961.4739 - val_loss: 3122720469.9178\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1359942157.8201 - val_loss: 3077138090.0822\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1344189502.6290 - val_loss: 3064088216.5479\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1339096164.8260 - val_loss: 2997879210.0822\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1346550806.9512 - val_loss: 2995009921.7534\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1345517716.8946 - val_loss: 3138842161.0959\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1347399486.0257 - val_loss: 3054075013.2603\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1339446634.5021 - val_loss: 2960078034.4110\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1344987320.2125 - val_loss: 3038697237.0411\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1339969448.3085 - val_loss: 3088044126.6849\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1336182689.5630 - val_loss: 2975944120.1096\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1341513526.5124 - val_loss: 3030476545.7534\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1341409879.4722 - val_loss: 3064799081.2055\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1333578372.9357 - val_loss: 3016648251.6164\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1335303471.1088 - val_loss: 3038118813.8082\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1325362177.8646 - val_loss: 2981165999.3425\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1330154972.5724 - val_loss: 3070005761.7534\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1332356265.3505 - val_loss: 3014303875.5068\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1323182665.6795 - val_loss: 2995376853.9178\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1325399349.3608 - val_loss: 3039482706.4110\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1323853158.4439 - val_loss: 2972400126.2466\n",
      "Epoch 262/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 175us/step - loss: 1331742575.9040 - val_loss: 2983347953.9726\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1322969068.1474 - val_loss: 2999233437.8082\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1325709812.3736 - val_loss: 2948871111.8904\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1319454295.1705 - val_loss: 3027924883.2877\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1319151775.4790 - val_loss: 2978417109.9178\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1316628719.1637 - val_loss: 2983793849.8630\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1324831273.9537 - val_loss: 3020292837.6986\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1319023766.7592 - val_loss: 2923802243.5068\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1314177399.4996 - val_loss: 3019780404.6027\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1317192751.3830 - val_loss: 2940756032.8767\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1317408587.3522 - val_loss: 2965475229.8082\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1311329999.6572 - val_loss: 3033924343.2329\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1313409653.5801 - val_loss: 3009352467.2877\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1312649425.7138 - val_loss: 3073956322.1918\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1320635826.8380 - val_loss: 2988136314.7397\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1304978835.4687 - val_loss: 2914882991.3425\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1310697930.4747 - val_loss: 3021648403.2877\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1306578379.7909 - val_loss: 2992599409.9726\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1304749285.2374 - val_loss: 2997729367.6712\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1305360851.1397 - val_loss: 3054258596.8219\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1302241478.8826 - val_loss: 2973233916.4932\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1301173095.1568 - val_loss: 3034198931.2877\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1296778896.0686 - val_loss: 2893460650.0822\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 1304081349.7584 - val_loss: 3044056584.7671\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 190us/step - loss: 1307546485.8543 - val_loss: 2904137501.8082\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 191us/step - loss: 1301135578.3787 - val_loss: 2934102077.3699\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 186us/step - loss: 1302715198.9854 - val_loss: 2940728409.4247\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1292220500.2365 - val_loss: 2975911737.8630\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1294294835.8800 - val_loss: 3026599834.3014\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1295697770.1183 - val_loss: 2921296426.0822\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1288709267.6332 - val_loss: 2981139771.6164\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1292714257.2202 - val_loss: 2983060436.1644\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1292512649.4327 - val_loss: 2971155313.9726\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1298626690.9614 - val_loss: 2937800774.1370\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1289446185.3505 - val_loss: 2925798617.4247\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1283740500.5656 - val_loss: 2992090240.0000\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1286734162.8106 - val_loss: 2966588396.7123\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1287027812.9083 - val_loss: 2953481577.2055\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1292886082.2485 - val_loss: 2926363100.9315\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1280676051.1397 - val_loss: 2985889136.2192\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1305777941.4979 - val_loss: 3059140937.6438\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1293633796.1680 - val_loss: 2981515888.2192\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1279606451.7704 - val_loss: 2876981006.0274\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1273897293.4636 - val_loss: 3064936339.2877\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1282833342.1354 - val_loss: 2915763689.2055\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1275759232.9871 - val_loss: 2917104559.3425\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1271161642.8312 - val_loss: 2913697653.4795\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1280673440.5758 - val_loss: 2882323215.7808\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1267589126.1971 - val_loss: 2960895763.2877\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1271020445.3950 - val_loss: 2900114602.0822\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1270690873.6932 - val_loss: 2924173790.6849\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1269123571.9349 - val_loss: 2898760111.3425\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1274095231.1225 - val_loss: 2882125105.0959\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1272002406.4439 - val_loss: 2878777275.6164\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1268666860.3668 - val_loss: 2903444699.1781\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1267449707.3796 - val_loss: 2874975317.9178\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1266572173.9846 - val_loss: 2880182734.9041\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1265637773.1620 - val_loss: 2948092503.6712\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1263553088.0548 - val_loss: 2879617700.8219\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1261248178.7832 - val_loss: 2963113410.6301\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1255773775.4105 - val_loss: 2865518763.8356\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1267417911.9109 - val_loss: 2931513121.3151\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1258263824.0686 - val_loss: 2938248986.3014\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1254945253.8406 - val_loss: 2879494678.7945\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1260733119.3419 - val_loss: 2949298361.8630\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1253375998.2451 - val_loss: 2905074081.3151\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1263154684.3805 - val_loss: 2955825062.5753\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1254281836.3668 - val_loss: 2912716538.7397\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1250946054.2519 - val_loss: 2922847789.5890\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1254447664.4799 - val_loss: 2961930769.5342\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1253670352.5073 - val_loss: 2863370872.9863\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1248950893.0249 - val_loss: 2853797747.7260\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1254028187.8046 - val_loss: 3003580763.1781\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1256037022.2725 - val_loss: 2908640815.3425\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1259318683.4756 - val_loss: 2842734609.5342\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1264734909.4773 - val_loss: 2839478536.7671\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1242764779.2699 - val_loss: 2888942840.9863\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1242306391.0883 - val_loss: 2834431638.7945\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1242636591.6024 - val_loss: 2915873255.4521\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1243641610.7489 - val_loss: 2855332581.6986\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1240285475.7566 - val_loss: 2848123176.3288\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1242308943.1911 - val_loss: 2898200674.1918\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1238495101.0386 - val_loss: 2900130461.8082\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1241199578.6530 - val_loss: 2832159284.6027\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1235823598.3136 - val_loss: 2844795453.3699\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1245936585.2682 - val_loss: 2846639542.3562\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1238163026.3719 - val_loss: 2824456528.6575\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1239989174.0737 - val_loss: 2857422416.6575\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1235677960.9940 - val_loss: 2928574348.2740\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1232735735.9931 - val_loss: 2869492679.8904\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1240868395.9829 - val_loss: 2827326483.2877\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1228010216.3085 - val_loss: 2863481084.4932\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1227188903.5955 - val_loss: 2865763142.1370\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1225744499.7155 - val_loss: 2821229688.9863\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1231328016.5347 - val_loss: 2918150119.4521\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1244080364.2571 - val_loss: 2813549192.7671\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1235131676.9563 - val_loss: 2853226131.2877\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1222747815.5955 - val_loss: 2837830068.6027\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1218564204.7506 - val_loss: 2907235177.2055\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1230142663.8423 - val_loss: 2840624029.8082\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1216783149.7378 - val_loss: 2835447369.6438\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1220425965.0249 - val_loss: 2807666619.6164\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1220695535.3282 - val_loss: 2838438296.5479\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1220780544.6033 - val_loss: 2878642477.5890\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1217090689.3710 - val_loss: 2855982250.0822\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1213924091.1740 - val_loss: 2843535907.0685\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1219327932.9837 - val_loss: 2774986350.4658\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1218864004.4970 - val_loss: 2793300429.1507\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1212229949.6967 - val_loss: 2831930737.9726\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1211667747.0985 - val_loss: 2852982601.6438\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1213747994.9272 - val_loss: 2805749505.7534\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1207991295.5613 - val_loss: 2794501393.5342\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1205371672.1302 - val_loss: 2821225438.6849\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1204352147.0300 - val_loss: 2906593716.6027\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1208957601.1243 - val_loss: 2819471949.1507\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1203188959.4790 - val_loss: 2779140890.3014\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1219976639.7258 - val_loss: 2748292750.0274\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1216865482.5844 - val_loss: 2767301097.2055\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1203462797.0523 - val_loss: 2845217637.6986\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1198210961.2202 - val_loss: 2815441457.0959\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1198454603.4619 - val_loss: 2870674684.4932\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1198387118.6153 - val_loss: 2794913521.9726\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1199062104.4319 - val_loss: 2783874996.6027\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1199923650.4679 - val_loss: 2854769905.9726\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1192066503.7875 - val_loss: 2778701944.9863\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1194436834.6050 - val_loss: 2785146143.5616\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1210357915.2014 - val_loss: 2770981518.0274\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1196198321.7412 - val_loss: 2809237987.9452\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1190510725.4841 - val_loss: 2769142254.4658\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1195550978.4679 - val_loss: 2754038622.6849\n",
      "Epoch 392/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 167us/step - loss: 1194996301.6555 - val_loss: 2860333389.1507\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1187779177.9537 - val_loss: 2812116793.8630\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1186398046.2725 - val_loss: 2826688878.4658\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1189064424.7198 - val_loss: 2785884032.0000\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1188443536.5621 - val_loss: 2836600046.4658\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1185510655.2322 - val_loss: 2776230901.4795\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1187375549.3128 - val_loss: 2809821203.2877\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1180257150.9580 - val_loss: 2774626161.9726\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1181016472.2399 - val_loss: 2853340526.4658\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1180045217.2888 - val_loss: 2741655937.7534\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1181592951.2802 - val_loss: 2819270608.6575\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1175301321.3231 - val_loss: 2775820109.1507\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1180646243.5921 - val_loss: 2746420702.6849\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1177251809.6178 - val_loss: 2782180085.4795\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1171888328.3907 - val_loss: 2781179200.8767\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1174505434.5433 - val_loss: 2800674368.8767\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1177882332.7918 - val_loss: 2814586997.4795\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1173492407.3762 - val_loss: 2766070936.5479\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1179875054.5604 - val_loss: 2744561909.4795\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1174554510.1491 - val_loss: 2736749667.9452\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1171589981.0111 - val_loss: 2745053953.7534\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1166020395.8458 - val_loss: 2809257733.2603\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1166949792.9049 - val_loss: 2779700383.5616\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1174294388.8123 - val_loss: 2768061720.5479\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1167368243.9349 - val_loss: 2892913295.7808\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 1172740965.9503 - val_loss: 2753840739.9452\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1165217020.1611 - val_loss: 2703913491.2877\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1173349306.7901 - val_loss: 2793832118.3562\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1162344795.3659 - val_loss: 2772192119.2329\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1163219127.9383 - val_loss: 2833508399.3425\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1167402177.4533 - val_loss: 2785251086.0274\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1157276278.1285 - val_loss: 2774923884.7123\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 1160454854.9649 - val_loss: 2750381678.4658\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1153314921.6247 - val_loss: 2761940039.8904\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1162512417.1791 - val_loss: 2757364306.4110\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1154348778.0360 - val_loss: 2735159820.2740\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1156092964.2502 - val_loss: 2756811258.7397\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1160378365.3676 - val_loss: 2696211238.5753\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1164571595.9829 - val_loss: 2830658128.6575\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1158279900.3805 - val_loss: 2781469382.1370\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1148499736.2399 - val_loss: 2717235117.5890\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1150633840.3702 - val_loss: 2773992328.7671\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1146513381.3745 - val_loss: 2717910899.7260\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1146350182.5536 - val_loss: 2709895185.5342\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1152961658.0223 - val_loss: 2772352322.6301\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1145670806.8963 - val_loss: 2758604992.8767\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1142615517.6692 - val_loss: 2734153098.5205\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1157493938.3376 - val_loss: 2800605462.7945\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1138191524.1954 - val_loss: 2688267379.7260\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1146616604.4079 - val_loss: 2715024245.4795\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1150861615.5201 - val_loss: 2837676724.6027\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 1145849471.0129 - val_loss: 2718175209.2055\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1145488372.3736 - val_loss: 2652436608.0000\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1164997228.4216 - val_loss: 2775186291.7260\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1135284835.9760 - val_loss: 2751465933.1507\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1137593442.4953 - val_loss: 2735837638.1370\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1132006251.7361 - val_loss: 2708203386.7397\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1138115343.6847 - val_loss: 2683439391.5616\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1139765243.2836 - val_loss: 2728276522.0822\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 1132071740.3256 - val_loss: 2718741155.0685\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1130127707.8046 - val_loss: 2712132436.1644\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1145174902.0463 - val_loss: 2658424153.4247\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1134574207.0129 - val_loss: 2705778723.0685\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1130904981.0043 - val_loss: 2710782251.8356\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 1139274133.6624 - val_loss: 2794782509.5890\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1151135686.8003 - val_loss: 2754844763.1781\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1131579318.6221 - val_loss: 2659550974.2466\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1116771861.9914 - val_loss: 2782558399.1233\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 1130127745.1517 - val_loss: 2713946674.8493\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1120211946.1731 - val_loss: 2700679653.6986\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 1128732453.6761 - val_loss: 2766594328.5479\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1123788964.7986 - val_loss: 2709428238.0274\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 1119661451.6812 - val_loss: 2770372464.2192\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1126740613.4841 - val_loss: 2699937313.3151\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1122872063.1225 - val_loss: 2657749944.1096\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1124363109.5664 - val_loss: 2656557343.5616\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1122707196.8740 - val_loss: 2668460640.4384\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1118526203.0643 - val_loss: 2660293842.4110\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1115871453.8338 - val_loss: 2689540097.7534\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1115483877.8955 - val_loss: 2736692207.3425\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1111898191.9589 - val_loss: 2651729849.8630\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1101995607.3076 - val_loss: 2825248943.3425\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1116079575.1979 - val_loss: 2649945166.9041\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1120136125.4773 - val_loss: 2676112843.3973\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1104416788.1817 - val_loss: 2765490617.8630\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1119598747.3111 - val_loss: 2676602434.6301\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1115953851.3933 - val_loss: 2684436091.6164\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1111801332.9220 - val_loss: 2747725692.4932\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1108185286.5261 - val_loss: 2711726090.5205\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1104744101.6213 - val_loss: 2700173410.1918\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1103761732.6615 - val_loss: 2675744471.6712\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1100812274.1799 - val_loss: 2721587943.4521\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1101844595.9349 - val_loss: 2725707306.0822\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1104896594.8655 - val_loss: 2631405182.2466\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1102339366.6084 - val_loss: 2681277388.2740\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 1102172249.3642 - val_loss: 2615350475.3973\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1092507479.1842 - val_loss: 2779674129.5342\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1111013321.9263 - val_loss: 2667322356.6027\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1097216608.3016 - val_loss: 2713862548.1644\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 1102458905.1174 - val_loss: 2683880463.7808\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1099997836.5587 - val_loss: 2662023864.1096\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1097724972.0925 - val_loss: 2626973273.4247\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 1087307654.2519 - val_loss: 2726045308.4932\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 1097397482.9409 - val_loss: 2700623652.8219\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 1094706161.6315 - val_loss: 2691211351.6712\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 1094648169.7344 - val_loss: 2704708844.7123\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1089752727.3625 - val_loss: 2664464984.5479\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 1093873680.2879 - val_loss: 2682409014.3562\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 1085849150.7386 - val_loss: 2679263491.5068\n"
     ]
    }
   ],
   "source": [
    "newAdam = Adam(learning_rate=0.0001)\n",
    "NN_500E_1H.compile(loss='mean_squared_error', optimizer=newAdam)\n",
    "history = NN_500E_1H.fit(x=X,y=y,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plotHistory(history)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>122062.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>277848.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>205789.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>163611.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>161607.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>76489.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>97922.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>143914.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>103312.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>227599.406250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  122062.539062\n",
       "1     1462  277848.437500\n",
       "2     1463  205789.843750\n",
       "3     1464  163611.500000\n",
       "4     1465  161607.421875\n",
       "...    ...            ...\n",
       "1454  2915   76489.148438\n",
       "1455  2916   97922.929688\n",
       "1456  2917  143914.687500\n",
       "1457  2918  103312.507812\n",
       "1458  2919  227599.406250\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(pred(NN_500E_NewAdam))\n",
    "y_df = y_df.rename(columns={0:'SalePrice'})\n",
    "out = Id.copy()\n",
    "out = out.join(y_df)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(r'~/Datas/KaggleHouse/NN_500E_NewAdam_V2_Nolog.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
